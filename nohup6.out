nohup: ignoring input
2023-02-13 11:31:02.449 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 10
    │        └ 'FreeSolv'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f062960b050>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b359790>
                                              └ <finetune.FineTune object at 0x7f062960b050>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'regression'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b359790>
                   │                        │  │    │    │    │    │                                            │    └ 'expt'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b359790>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b359790>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'regression'
    │                 │             │           │          └ 'expt'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-13 11:31:02.488 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 50
    │        └ 'FreeSolv'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061f226d90>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3be750>
                                              └ <finetune.FineTune object at 0x7f061f226d90>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'regression'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3be750>
                   │                        │  │    │    │    │    │                                            │    └ 'expt'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3be750>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3be750>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'regression'
    │                 │             │           │          └ 'expt'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-13 11:31:02.528 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 100
    │        └ 'FreeSolv'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f0626a78210>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3be750>
                                              └ <finetune.FineTune object at 0x7f0626a78210>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'regression'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3be750>
                   │                        │  │    │    │    │    │                                            │    └ 'expt'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3be750>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3be750>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'regression'
    │                 │             │           │          └ 'expt'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-13 11:31:02.567 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 200
    │        └ 'FreeSolv'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f062b44f210>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3be750>
                                              └ <finetune.FineTune object at 0x7f062b44f210>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'regression'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3be750>
                   │                        │  │    │    │    │    │                                            │    └ 'expt'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3be750>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3be750>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'regression'
    │                 │             │           │          └ 'expt'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-13 11:31:02.607 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 500
    │        └ 'FreeSolv'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed69f90>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed69fd0>
                                              └ <finetune.FineTune object at 0x7f061ed69f90>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'regression'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed69fd0>
                   │                        │  │    │    │    │    │                                            │    └ 'expt'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed69fd0>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed69fd0>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'regression'
    │                 │             │           │          └ 'expt'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-13 11:31:02.646 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 10
    │        └ 'FreeSolv_2'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed8a050>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f07807b5210>
                                              └ <finetune.FineTune object at 0x7f061ed8a050>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f07807b5210>
                   │                        │  │    │    │    │    │                                            │    └ 'target_2'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f07807b5210>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f07807b5210>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_2'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-13 11:31:02.685 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 50
    │        └ 'FreeSolv_2'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed76950>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed76d50>
                                              └ <finetune.FineTune object at 0x7f061ed76950>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed76d50>
                   │                        │  │    │    │    │    │                                            │    └ 'target_2'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed76d50>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed76d50>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_2'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-13 11:31:02.724 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 100
    │        └ 'FreeSolv_2'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed86fd0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b356410>
                                              └ <finetune.FineTune object at 0x7f061ed86fd0>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b356410>
                   │                        │  │    │    │    │    │                                            │    └ 'target_2'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b356410>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b356410>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_2'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-13 11:31:02.764 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 200
    │        └ 'FreeSolv_2'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed78fd0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b356410>
                                              └ <finetune.FineTune object at 0x7f061ed78fd0>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b356410>
                   │                        │  │    │    │    │    │                                            │    └ 'target_2'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b356410>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b356410>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_2'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-13 11:31:02.803 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 500
    │        └ 'FreeSolv_2'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f062b9f4090>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061f5a0510>
                                              └ <finetune.FineTune object at 0x7f062b9f4090>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061f5a0510>
                   │                        │  │    │    │    │    │                                            │    └ 'target_2'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061f5a0510>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061f5a0510>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_2'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-13 11:31:02.842 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 10
    │        └ 'FreeSolv_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061f226f10>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061f226d90>
                                              └ <finetune.FineTune object at 0x7f061f226f10>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061f226d90>
                   │                        │  │    │    │    │    │                                            │    └ 'target_5'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061f226d90>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061f226d90>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_5'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-13 11:31:02.882 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 50
    │        └ 'FreeSolv_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed6d9d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6d8d0>
                                              └ <finetune.FineTune object at 0x7f061ed6d9d0>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6d8d0>
                   │                        │  │    │    │    │    │                                            │    └ 'target_5'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6d8d0>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6d8d0>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_5'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-13 11:31:02.921 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 100
    │        └ 'FreeSolv_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061f207350>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3f66d0>
                                              └ <finetune.FineTune object at 0x7f061f207350>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3f66d0>
                   │                        │  │    │    │    │    │                                            │    └ 'target_5'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3f66d0>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3f66d0>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_5'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}2023-02-13 11:31:02.960 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 200
    │        └ 'FreeSolv_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed6d150>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6dd10>
                                              └ <finetune.FineTune object at 0x7f061ed6d150>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6dd10>
                   │                        │  │    │    │    │    │                                            │    └ 'target_5'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6dd10>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6dd10>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_5'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-13 11:31:02.999 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 500
    │        └ 'FreeSolv_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed6d6d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6d4d0>
                                              └ <finetune.FineTune object at 0x7f061ed6d6d0>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6d4d0>
                   │                        │  │    │    │    │    │                                            │    └ 'target_5'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6d4d0>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6d4d0>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_5'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'

Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 5.251064777374268
Validation loss: 3.6320555210113525 MAE: 1.7009298
Validation loss: 2.4294042587280273 MAE: 1.3380234
Validation loss: 1.6634782552719116 MAE: 1.1004198
Validation loss: 1.3214055299758911 MAE: 1.0439951
Validation loss: 1.4268107414245605 MAE: 0.9961616
Validation loss: 1.7995142936706543 MAE: 0.9799246
Validation loss: 2.160893440246582 MAE: 1.0263944
Validation loss: 2.338019371032715 MAE: 1.0759968
Validation loss: 2.3574326038360596 MAE: 1.0786752
Validation loss: 2.095693588256836 MAE: 0.99936825
Validation loss: 1.7989463806152344 MAE: 0.9693015
Validation loss: 1.565213918685913 MAE: 0.98734283
Validation loss: 1.380892276763916 MAE: 1.0158329
Validation loss: 1.3241338729858398 MAE: 1.0401897
Validation loss: 1.3665392398834229 MAE: 1.0604724
Validation loss: 1.4819296598434448 MAE: 1.0754238
Validation loss: 1.630401849746704 MAE: 1.0833056
Validation loss: 1.7331702709197998 MAE: 1.0899209
Validation loss: 1.7614941596984863 MAE: 1.082199
Validation loss: 1.8056206703186035 MAE: 1.0949854
Validation loss: 1.7031939029693604 MAE: 1.0598716
Validation loss: 1.5743013620376587 MAE: 1.0068022
Validation loss: 1.3965250253677368 MAE: 0.9444621
Validation loss: 1.2586686611175537 MAE: 0.89204854
Validation loss: 1.127504825592041 MAE: 0.83280575
Validation loss: 1.02432119846344 MAE: 0.80482036
Validation loss: 0.9666619896888733 MAE: 0.79108274
Validation loss: 0.9673328399658203 MAE: 0.7936079
Validation loss: 0.976220965385437 MAE: 0.7975469
Validation loss: 1.0013025999069214 MAE: 0.79141176
Validation loss: 1.0080265998840332 MAE: 0.78984463
Validation loss: 1.0140472650527954 MAE: 0.79626817
Validation loss: 1.021433711051941 MAE: 0.80551654
Validation loss: 1.0279966592788696 MAE: 0.8097593
Validation loss: 1.0369226932525635 MAE: 0.8151147
Validation loss: 1.0445688962936401 MAE: 0.83227515
Validation loss: 1.046895980834961 MAE: 0.8366781
Validation loss: 1.0355734825134277 MAE: 0.82514805
Validation loss: 1.0217796564102173 MAE: 0.8032453
Validation loss: 1.0093038082122803 MAE: 0.7867625
Validation loss: 0.9927244186401367 MAE: 0.7677251
Validation loss: 0.9948958158493042 MAE: 0.75639963
Validation loss: 0.993236243724823 MAE: 0.74779105
Validation loss: 0.9830278754234314 MAE: 0.73818266
Validation loss: 0.9717379808425903 MAE: 0.7333784
Validation loss: 0.9607214331626892 MAE: 0.7245617
Validation loss: 0.9401626586914062 MAE: 0.7143267
Validation loss: 0.9311692118644714 MAE: 0.7104203
Validation loss: 0.9422457218170166 MAE: 0.7143555
Validation loss: 0.9581477046012878 MAE: 0.717192
50 0 0.9534028172492981
Validation loss: 1.0059905052185059 MAE: 0.75104564
Validation loss: 1.0506014823913574 MAE: 0.7766143
Validation loss: 1.042209506034851 MAE: 0.77581286
Validation loss: 0.977310061454773 MAE: 0.73778844
Validation loss: 0.9703270792961121 MAE: 0.73917913
Validation loss: 0.9496415257453918 MAE: 0.7266807
Validation loss: 0.9257790446281433 MAE: 0.7138868
Validation loss: 0.853564977645874 MAE: 0.66548276
Validation loss: 0.7865952253341675 MAE: 0.623248
Validation loss: 0.7353142499923706 MAE: 0.5877874
Validation loss: 0.6965580582618713 MAE: 0.56235033
Validation loss: 0.6648733615875244 MAE: 0.5467124
Validation loss: 0.6417986154556274 MAE: 0.5326774
Validation loss: 0.6213338375091553 MAE: 0.5185999
Validation loss: 0.5762299299240112 MAE: 0.49808258
Validation loss: 0.5536745190620422 MAE: 0.49257216
Validation loss: 0.5345249772071838 MAE: 0.4834974
Validation loss: 0.5200226902961731 MAE: 0.48786524
Validation loss: 0.5264792442321777 MAE: 0.5112302
Validation loss: 0.5227486491203308 MAE: 0.5144498
Validation loss: 0.5357418060302734 MAE: 0.55122185
Validation loss: 0.5253483057022095 MAE: 0.56249
Validation loss: 0.4987432062625885 MAE: 0.54196644
Validation loss: 0.46912071108818054 MAE: 0.5228924
Validation loss: 0.43524473905563354 MAE: 0.4984098
Validation loss: 0.39143338799476624 MAE: 0.4633077
Validation loss: 0.3540201485157013 MAE: 0.43678048
Validation loss: 0.3340896964073181 MAE: 0.4197599
Validation loss: 0.30718231201171875 MAE: 0.40459266
Validation loss: 0.29704785346984863 MAE: 0.41299355
Validation loss: 0.29909399151802063 MAE: 0.41516858
Validation loss: 0.3059527575969696 MAE: 0.42389742
Validation loss: 0.3051750659942627 MAE: 0.42188814
Validation loss: 0.30554088950157166 MAE: 0.41286212
Validation loss: 0.3030570447444916 MAE: 0.39238727
Validation loss: 0.31462979316711426 MAE: 0.40328786
Validation loss: 0.33079794049263 MAE: 0.43029067
Validation loss: 0.34536850452423096 MAE: 0.44806397
Validation loss: 0.34126612544059753 MAE: 0.44934666
Validation loss: 0.32005512714385986 MAE: 0.4293512
Validation loss: 0.30663397908210754 MAE: 0.40947238
Validation loss: 0.30835092067718506 MAE: 0.4192041
Validation loss: 0.3006387948989868 MAE: 0.41498283
Validation loss: 0.27625736594200134 MAE: 0.3899
Validation loss: 0.2554256319999695 MAE: 0.3777203
Validation loss: 0.23345650732517242 MAE: 0.3655253
Validation loss: 0.22624200582504272 MAE: 0.37566912
Validation loss: 0.2384314239025116 MAE: 0.40138328
Validation loss: 0.24958164989948273 MAE: 0.4203238
Validation loss: 0.2619110941886902 MAE: 0.43937713
Loaded trained model with success.
Test loss: 1.8336807643853437 Test MAE: 1.0560527
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 4.648876190185547
Validation loss: 2.195804245617925 MAE: 1.2462486
Validation loss: 1.669543906134002 MAE: 1.0433712
Validation loss: 2.3463797155691655 MAE: 1.1905116
Validation loss: 2.2118726117270335 MAE: 1.1593566
Validation loss: 1.7646066899202308 MAE: 1.0645524
Validation loss: 1.629003685347888 MAE: 1.0742983
Validation loss: 1.759754093325868 MAE: 1.110178
Validation loss: 1.9017663926494366 MAE: 1.1490266
Validation loss: 1.869463536204124 MAE: 1.1328121
Validation loss: 1.7430521322756398 MAE: 1.0951625
Validation loss: 1.5916430463596267 MAE: 1.0646056
Validation loss: 1.4912400245666504 MAE: 1.0372736
Validation loss: 1.4856058505116676 MAE: 1.0122275
Validation loss: 1.5518330432930771 MAE: 1.0271269
Validation loss: 1.640807025286616 MAE: 1.0446364
Validation loss: 1.7168806231751734 MAE: 1.0669698
Validation loss: 1.7798775020910769 MAE: 1.0908747
Validation loss: 1.826275110244751 MAE: 1.1104275
Validation loss: 1.893387616897116 MAE: 1.1348532
Validation loss: 1.9081031667942903 MAE: 1.1350229
Validation loss: 1.8573444035588478 MAE: 1.1219006
Validation loss: 1.7966221984551878 MAE: 1.1055424
Validation loss: 1.7826154329338852 MAE: 1.1003038
Validation loss: 1.8536215752971417 MAE: 1.1202341
Validation loss: 1.8912169033167314 MAE: 1.1297398
25 0 1.3421239852905273
Validation loss: 1.899967033035901 MAE: 1.1311659
Validation loss: 1.8654065132141113 MAE: 1.1201738
Validation loss: 1.8258164123613008 MAE: 1.1068579
Validation loss: 1.7611962167584165 MAE: 1.0860331
Validation loss: 1.6962902351301543 MAE: 1.0641785
Validation loss: 1.6735519146432682 MAE: 1.0563874
Validation loss: 1.6846808657354237 MAE: 1.0597942
Validation loss: 1.6339276128885698 MAE: 1.0434579
Validation loss: 1.624985660825457 MAE: 1.0392832
Validation loss: 1.6173592781534 MAE: 1.036004
Validation loss: 1.5778502542145398 MAE: 1.0185086
Validation loss: 1.5396050239095882 MAE: 1.0001756
Validation loss: 1.5334706963325033 MAE: 0.99788916
Validation loss: 1.5435837920831175 MAE: 1.000022
Validation loss: 1.5134655504810566 MAE: 0.9905552
Validation loss: 1.4593540198948918 MAE: 0.97412544
Validation loss: 1.4404533809545088 MAE: 0.96623456
Validation loss: 1.3826806168166959 MAE: 0.94336987
Validation loss: 1.3470346343760589 MAE: 0.93463874
Validation loss: 1.3480971516395102 MAE: 0.9345292
Validation loss: 1.3292792646252378 MAE: 0.9288701
Validation loss: 1.3495236854163968 MAE: 0.93607754
Validation loss: 1.3592451153969278 MAE: 0.94603807
Validation loss: 1.3132980113126793 MAE: 0.932341
Validation loss: 1.275452664920262 MAE: 0.91759574
50 0 1.4791568517684937
Validation loss: 1.2670714465939268 MAE: 0.9168848
Validation loss: 1.270040628861408 MAE: 0.9201879
Validation loss: 1.3026684668599342 MAE: 0.9270546
Validation loss: 1.336252937511522 MAE: 0.9319127
Validation loss: 1.3038383211408342 MAE: 0.92376524
Validation loss: 1.2435169195642277 MAE: 0.90730846
Validation loss: 1.1789565499947996 MAE: 0.8878372
Validation loss: 1.136119317035286 MAE: 0.87900877
Validation loss: 1.1371145613339482 MAE: 0.8891632
Validation loss: 1.1925076440889009 MAE: 0.90180534
Validation loss: 1.215604040087486 MAE: 0.9148897
Validation loss: 1.1643397856731803 MAE: 0.89514285
Validation loss: 1.0942892614676027 MAE: 0.8599743
Validation loss: 1.0734700718704535 MAE: 0.84465224
Validation loss: 1.1053711419202843 MAE: 0.85268384
Validation loss: 1.1700569975132844 MAE: 0.87342143
Validation loss: 1.1586914451754824 MAE: 0.8770424
Validation loss: 1.1127515131113481 MAE: 0.8749174
Validation loss: 1.079026849902406 MAE: 0.87187266
Validation loss: 1.0343122628270363 MAE: 0.85293394
Validation loss: 1.0151350035959361 MAE: 0.83872664
Validation loss: 1.0238402643982245 MAE: 0.84380263
Validation loss: 1.1397821368003378 MAE: 0.9012968
Validation loss: 1.1762767470612818 MAE: 0.917263
Validation loss: 1.1083521088775323 MAE: 0.896945
75 0 0.8279606103897095
Validation loss: 0.9393719605037144 MAE: 0.8222865
Validation loss: 0.7959799182658293 MAE: 0.7477907
Validation loss: 0.7363737651279995 MAE: 0.7214562
Validation loss: 0.7494560650416783 MAE: 0.6985272
Validation loss: 0.8466233951704842 MAE: 0.746885
Validation loss: 0.9534828127646933 MAE: 0.7964027
Validation loss: 0.9541189220486855 MAE: 0.8071024
Validation loss: 0.8764048668803001 MAE: 0.7855962
Validation loss: 0.833382891148937 MAE: 0.7845455
Validation loss: 0.9457172070230756 MAE: 0.84083915
Validation loss: 1.044397620522246 MAE: 0.87716216
Validation loss: 1.0394639336332983 MAE: 0.8644521
Validation loss: 0.9700805824630114 MAE: 0.8267627
Validation loss: 0.9511347911795791 MAE: 0.80155534
Validation loss: 0.9057567739973262 MAE: 0.7655287
Validation loss: 0.7922380031371603 MAE: 0.69976777
Validation loss: 0.6831323090864687 MAE: 0.6428519
Validation loss: 0.6209197640419006 MAE: 0.6212611
Validation loss: 0.560355151186184 MAE: 0.59544075
Validation loss: 0.556974032703711 MAE: 0.6037715
Validation loss: 0.5031228904821434 MAE: 0.5722096
Validation loss: 0.47615809951509747 MAE: 0.5653848
Validation loss: 0.4930183279271029 MAE: 0.5864959
Validation loss: 0.5792272498413008 MAE: 0.6317223
Validation loss: 0.62719811225424 MAE: 0.645195
Loaded trained model with success.
Test loss: 1.515516863506249 Test MAE: 0.97378874
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 6.291897296905518
Validation loss: 1.6964892474087803 MAE: 1.0462431
Validation loss: 2.271391242441505 MAE: 1.1676638
Validation loss: 2.1260645600280377 MAE: 1.1331866
Validation loss: 1.7005370539246183 MAE: 1.0315176
Validation loss: 1.8616678209015818 MAE: 1.1172318
Validation loss: 1.920233388139744 MAE: 1.1431031
Validation loss: 1.7315924846369661 MAE: 1.0658988
Validation loss: 1.7456695546556 MAE: 1.0467381
Validation loss: 1.8203860938248009 MAE: 1.0526438
Validation loss: 1.6302481468277747 MAE: 1.0235826
Validation loss: 1.5966406169563834 MAE: 1.0199896
Validation loss: 1.7727068024452286 MAE: 1.0488402
12 2 2.092973470687866
Validation loss: 1.9254901529562594 MAE: 1.0815065
Validation loss: 1.659116925615253 MAE: 1.0193415
Validation loss: 1.6136781058528207 MAE: 1.0047338
Validation loss: 1.7109096965404471 MAE: 1.0222614
Validation loss: 1.7009541651215216 MAE: 1.0201604
Validation loss: 1.5967451388185674 MAE: 1.0001804
Validation loss: 1.5510627332359854 MAE: 0.9970488
Validation loss: 1.546783872325011 MAE: 0.99883306
Validation loss: 1.6504375344575053 MAE: 1.0238502
Validation loss: 1.8450097820975564 MAE: 1.0761336
Validation loss: 1.7091923928019976 MAE: 1.0497764
Validation loss: 1.4528648299400253 MAE: 0.9776251
Validation loss: 1.431123875608348 MAE: 0.9746838
25 0 1.9616518020629883
Validation loss: 1.46611351196212 MAE: 0.9847344
Validation loss: 1.5680902419668254 MAE: 1.0084075
Validation loss: 1.5182652425284338 MAE: 0.9912089
Validation loss: 1.382370063752839 MAE: 0.95375603
Validation loss: 1.3643383835301255 MAE: 0.94790906
Validation loss: 1.3552687411958522 MAE: 0.9450152
Validation loss: 1.3883262126132696 MAE: 0.9585966
Validation loss: 1.3766175954028814 MAE: 0.9614015
Validation loss: 1.3062549889689745 MAE: 0.9413547
Validation loss: 1.254774180927662 MAE: 0.91643447
Validation loss: 1.2521840020863697 MAE: 0.928445
Validation loss: 1.5268707142935858 MAE: 1.018146
37 2 1.667585849761963
Validation loss: 1.8351449454673614 MAE: 1.1148717
Validation loss: 1.3725676970048384 MAE: 0.9620516
Validation loss: 1.222951144883127 MAE: 0.8848571
Validation loss: 1.2073176123879172 MAE: 0.87601364
Validation loss: 1.2070189876989885 MAE: 0.87705225
Validation loss: 1.2358063941050057 MAE: 0.90299875
Validation loss: 1.1798353526327345 MAE: 0.8711654
Validation loss: 1.1206236987402944 MAE: 0.83625823
Validation loss: 1.131835512440614 MAE: 0.8148136
Validation loss: 0.9988861270625182 MAE: 0.77627134
Validation loss: 1.0012741001567456 MAE: 0.80683845
Validation loss: 1.3195078493368746 MAE: 0.94695854
Validation loss: 1.215718519205999 MAE: 0.90616024
50 0 1.2846126556396484
Validation loss: 1.1331831313142873 MAE: 0.85933214
Validation loss: 1.2172345320383708 MAE: 0.8791655
Validation loss: 1.0958637035254277 MAE: 0.83676654
Validation loss: 0.992179864283764 MAE: 0.808704
Validation loss: 1.0166707225520202 MAE: 0.8367144
Validation loss: 0.9700972498065293 MAE: 0.8097376
Validation loss: 0.8137671679559381 MAE: 0.73739827
Validation loss: 0.7578844765220025 MAE: 0.6881414
Validation loss: 0.7854637831750543 MAE: 0.6790482
Validation loss: 0.7791353391878533 MAE: 0.72193044
Validation loss: 0.8617304363335022 MAE: 0.77090764
Validation loss: 0.8178049313901651 MAE: 0.7509689
62 2 1.1269043684005737
Validation loss: 0.8947049421493454 MAE: 0.7840384
Validation loss: 0.9899093984353422 MAE: 0.8166319
Validation loss: 0.8297102848688761 MAE: 0.75217575
Validation loss: 0.8512447741296556 MAE: 0.7484768
Validation loss: 0.726433829225675 MAE: 0.70010716
Validation loss: 0.7071779147543088 MAE: 0.6929409
Validation loss: 0.6760432918866476 MAE: 0.6835782
Validation loss: 0.7701941069328424 MAE: 0.71750754
Validation loss: 0.7161589776626741 MAE: 0.69429964
Validation loss: 0.653627092790122 MAE: 0.6577441
Validation loss: 0.6924803606187454 MAE: 0.67605406
Validation loss: 0.725295836275274 MAE: 0.68940055
Validation loss: 0.6501280809893752 MAE: 0.66188717
75 0 1.1950587034225464
Validation loss: 0.5775391697281539 MAE: 0.6305157
Validation loss: 0.5477311448617415 MAE: 0.61470824
Validation loss: 0.69591013861425 MAE: 0.68296385
Validation loss: 0.6547904008566731 MAE: 0.6657559
Validation loss: 0.6782390710079309 MAE: 0.6731536
Validation loss: 0.6221651139885488 MAE: 0.6282358
Validation loss: 0.5728280884448929 MAE: 0.61260325
Validation loss: 0.5240846384655345 MAE: 0.5989457
Validation loss: 0.5837064054277208 MAE: 0.6243258
Validation loss: 0.6282201367195206 MAE: 0.64651287
Validation loss: 0.6421316344328601 MAE: 0.6408599
Validation loss: 0.7346752358205391 MAE: 0.6776997
87 2 0.8858687877655029
Validation loss: 0.6493754715028436 MAE: 0.6430259
Validation loss: 0.6616871623378812 MAE: 0.63926697
Validation loss: 0.663907826548875 MAE: 0.64033085
Validation loss: 0.5007664808119187 MAE: 0.5714434
Validation loss: 0.4528435757665923 MAE: 0.55187213
Validation loss: 0.431242476509075 MAE: 0.52871615
Validation loss: 0.4563473733988675 MAE: 0.53040016
Validation loss: 0.48275826322008863 MAE: 0.5592485
Validation loss: 0.5429450159121041 MAE: 0.5728674
Validation loss: 0.5706665095957842 MAE: 0.57927537
Validation loss: 0.44773928806035207 MAE: 0.5381332
Validation loss: 0.5044568195713289 MAE: 0.5764041
Validation loss: 0.49095193605230314 MAE: 0.5673988
Loaded trained model with success.
Test loss: 1.195197223490513 Test MAE: 0.83857906
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 7.59597110748291
Validation loss: 2.8101692499227857 MAE: 1.3112171
Validation loss: 2.689429202870508 MAE: 1.27411
Validation loss: 1.5858512290159064 MAE: 1.0087959
Validation loss: 1.6224170911252198 MAE: 1.0300556
Validation loss: 1.643999058397571 MAE: 1.02457
Validation loss: 2.2154380837876593 MAE: 1.1736122
Validation loss: 1.5878006537355969 MAE: 0.99909645
7 1 1.5159499645233154
Validation loss: 1.5455978767356682 MAE: 1.0019138
Validation loss: 1.5410787034873388 MAE: 0.99509853
Validation loss: 1.5593076842514115 MAE: 0.9897257
Validation loss: 1.5283539654621527 MAE: 0.98509145
Validation loss: 1.5688224845196135 MAE: 0.98889554
Validation loss: 1.619062316777119 MAE: 0.9998638
Validation loss: 1.6286148707471302 MAE: 1.0000716
14 2 1.768676996231079
Validation loss: 1.6292281462319533 MAE: 0.9987006
Validation loss: 1.551297173428176 MAE: 0.972538
Validation loss: 1.5391693528573118 MAE: 0.96755356
Validation loss: 1.6126867320070315 MAE: 0.99605995
Validation loss: 1.5333705122147374 MAE: 0.99669766
Validation loss: 1.498709027791143 MAE: 0.9770156
Validation loss: 1.5322223817882825 MAE: 0.9834918
21 3 0.9997708797454834
Validation loss: 1.465819584664388 MAE: 0.9603112
Validation loss: 1.489496184952894 MAE: 0.9641504
Validation loss: 1.525294937680115 MAE: 0.979391
Validation loss: 1.3459957346844313 MAE: 0.92470026
Validation loss: 1.3948706773357775 MAE: 0.9380544
Validation loss: 1.2897710925969645 MAE: 0.91914177
Validation loss: 1.2964838084264017 MAE: 0.92206913
28 4 1.1121819019317627
Validation loss: 1.2311639779776185 MAE: 0.89462847
Validation loss: 1.1585690022712976 MAE: 0.86906064
Validation loss: 1.0893857871467745 MAE: 0.84763587
Validation loss: 1.1914189543256808 MAE: 0.8777338
Validation loss: 1.049893314215406 MAE: 0.82178795
Validation loss: 0.981503214668389 MAE: 0.79724735
Validation loss: 0.9402713871481431 MAE: 0.7808243
35 5 1.688607931137085
Validation loss: 0.961190841305795 MAE: 0.7956939
Validation loss: 0.8800844460276503 MAE: 0.76014256
Validation loss: 0.874958242303762 MAE: 0.735881
Validation loss: 0.7902660176682113 MAE: 0.7046582
Validation loss: 0.8116053624368792 MAE: 0.7111784
Validation loss: 0.8276805362509723 MAE: 0.7245758
Validation loss: 0.8151832070557317 MAE: 0.72811806
42 6 0.3700910210609436
Validation loss: 0.767206196509414 MAE: 0.7009556
Validation loss: 0.6822603310472403 MAE: 0.64298403
Validation loss: 0.6642391448044896 MAE: 0.635198
Validation loss: 0.6743513148034638 MAE: 0.64611226
Validation loss: 0.6945295938894377 MAE: 0.6520493
Validation loss: 0.6589444087977385 MAE: 0.64303714
Validation loss: 0.6193660343412178 MAE: 0.61905915
Validation loss: 0.5933788806649308 MAE: 0.62087345
50 0 0.5954544544219971
Validation loss: 0.6356463246609099 MAE: 0.6327062
Validation loss: 0.5560198262633391 MAE: 0.59072363
Validation loss: 0.5216238368396184 MAE: 0.57038087
Validation loss: 0.5216985270006573 MAE: 0.5787732
Validation loss: 0.5289504274950555 MAE: 0.57857096
Validation loss: 0.5796023712086318 MAE: 0.6028054
Validation loss: 0.5478962995299143 MAE: 0.5883938
57 1 0.6996980905532837
Validation loss: 0.5252370596231528 MAE: 0.5830953
Validation loss: 0.5159805030678984 MAE: 0.5823105
Validation loss: 0.5371281103273133 MAE: 0.5932949
Validation loss: 0.5658048813666531 MAE: 0.6133912
Validation loss: 0.5251255093806952 MAE: 0.5688971
Validation loss: 0.4726261047262642 MAE: 0.53647906
Validation loss: 0.5112854161454206 MAE: 0.57985336
64 2 0.7598250508308411
Validation loss: 0.4933499211642011 MAE: 0.5578372
Validation loss: 0.47957184506421113 MAE: 0.5357873
Validation loss: 0.45948830801038887 MAE: 0.5354808
Validation loss: 0.41933434445354806 MAE: 0.5167022
Validation loss: 0.43995199985240574 MAE: 0.5255346
Validation loss: 0.4416964581264323 MAE: 0.52884096
Validation loss: 0.4667223420873958 MAE: 0.5453532
71 3 0.6018050909042358
Validation loss: 0.39843842843968663 MAE: 0.49479225
Validation loss: 0.39179759124415603 MAE: 0.48254493
Validation loss: 0.37995562047215564 MAE: 0.48440644
Validation loss: 0.40164227132222163 MAE: 0.50052035
Validation loss: 0.41489006256937383 MAE: 0.52338403
Validation loss: 0.3912525527441322 MAE: 0.50362855
Validation loss: 0.4264979118378318 MAE: 0.524939
78 4 0.6511885523796082
Validation loss: 0.3861523543170948 MAE: 0.49632502
Validation loss: 0.4006278438484249 MAE: 0.50452244
Validation loss: 0.4100017905534811 MAE: 0.5106855
Validation loss: 0.3559961473971755 MAE: 0.46835944
Validation loss: 0.3923882719260364 MAE: 0.49916402
Validation loss: 0.3963603293476392 MAE: 0.50059855
Validation loss: 0.4778377094760013 MAE: 0.54775816
85 5 0.4261416792869568
Validation loss: 0.3644013225133695 MAE: 0.48031804
Validation loss: 0.3730914583757295 MAE: 0.4764975
Validation loss: 0.417912147152963 MAE: 0.50784576
Validation loss: 0.34202932802277 MAE: 0.46514693
Validation loss: 0.38493285316917764 MAE: 0.48216438
Validation loss: 0.3399817657530607 MAE: 0.45891532
Validation loss: 0.3472547866591257 MAE: 0.47379962
92 6 0.6131786108016968
Validation loss: 0.3566510458687442 MAE: 0.47534987
Validation loss: 0.3525189469807112 MAE: 0.47823155
Validation loss: 0.34719081290403203 MAE: 0.47955582
Validation loss: 0.36554670341350326 MAE: 0.4897572
Validation loss: 0.3410055724220659 MAE: 0.4790513
Validation loss: 0.32564716707521946 MAE: 0.45612285
Validation loss: 0.3759476039277848 MAE: 0.48344558
Validation loss: 0.32550382224758667 MAE: 0.46015155
Loaded trained model with success.
Test loss: 0.9127930750595674 Test MAE: 0.7419273
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 2.144277572631836
Validation loss: 1.580732216577014 MAE: 1.0333173
Validation loss: 1.5668656200110793 MAE: 1.0207552
Validation loss: 1.809001905406883 MAE: 1.1093024
3 2 1.5937918424606323
Validation loss: 1.5425489566369144 MAE: 1.0048902
Validation loss: 1.572229657478944 MAE: 0.9972509
Validation loss: 1.4455256939889911 MAE: 0.9799064
6 4 0.9731517434120178
Validation loss: 1.564788270331098 MAE: 0.9851243
Validation loss: 1.3368869812072877 MAE: 0.9246646
Validation loss: 1.3402136920210355 MAE: 0.92322856
9 6 1.1782863140106201
Validation loss: 1.1971113072607464 MAE: 0.87934905
Validation loss: 1.1538677710091663 MAE: 0.87242806
Validation loss: 1.161343520772242 MAE: 0.85421157
12 8 1.1176347732543945
Validation loss: 0.9331021580046308 MAE: 0.77934045
Validation loss: 0.8960795815817578 MAE: 0.7521098
Validation loss: 0.9725212343709024 MAE: 0.8007709
15 10 0.9903651475906372
Validation loss: 0.8809894582551563 MAE: 0.7474992
Validation loss: 0.8501674345356668 MAE: 0.72729784
Validation loss: 0.8349367592759983 MAE: 0.7362837
18 12 0.8880330920219421
Validation loss: 0.7709831632449775 MAE: 0.7045961
Validation loss: 0.7000072732239304 MAE: 0.6585369
Validation loss: 0.7907898209854691 MAE: 0.70747167
21 14 1.2243125438690186
Validation loss: 0.6373484064796884 MAE: 0.63525474
Validation loss: 0.6106394139941566 MAE: 0.62249357
Validation loss: 0.6218465113926507 MAE: 0.6274202
Validation loss: 0.6320040154313754 MAE: 0.64025307
25 0 0.9187227487564087
Validation loss: 0.6100523963958802 MAE: 0.6239195
Validation loss: 0.6216816098274354 MAE: 0.62631977
Validation loss: 0.5477938680706139 MAE: 0.58302814
28 2 0.9787970781326294
Validation loss: 0.5805494737529564 MAE: 0.6120122
Validation loss: 0.680203071696486 MAE: 0.6664209
Validation loss: 0.564255735678281 MAE: 0.60311705
31 4 0.5098598003387451
Validation loss: 0.51378729198882 MAE: 0.57006454
Validation loss: 0.5954676278249056 MAE: 0.6254007
Validation loss: 0.5191795133158773 MAE: 0.5727972
34 6 0.7123051285743713
Validation loss: 0.5225055448277919 MAE: 0.581468
Validation loss: 0.47527568702229517 MAE: 0.54858804
Validation loss: 0.5231694986442764 MAE: 0.58716506
37 8 0.5148430466651917
Validation loss: 0.4801520727320998 MAE: 0.55122155
Validation loss: 0.5356551138217559 MAE: 0.5777791
Validation loss: 0.503560532309966 MAE: 0.56114066
40 10 0.7658377885818481
Validation loss: 0.4985360056460501 MAE: 0.55563444
Validation loss: 0.4739065865476528 MAE: 0.55253255
Validation loss: 0.46857291280864954 MAE: 0.5398725
43 12 0.5502594113349915
Validation loss: 0.4635849504289264 MAE: 0.5357362
Validation loss: 0.5119154911958622 MAE: 0.5640507
Validation loss: 0.4714401589486307 MAE: 0.5464989
46 14 0.6368045210838318
Validation loss: 0.4406164763924593 MAE: 0.5321976
Validation loss: 0.4327127194117926 MAE: 0.5250389
Validation loss: 0.437996946140855 MAE: 0.5296493
Validation loss: 0.44812453235079625 MAE: 0.53715974
50 0 0.5024653077125549
Validation loss: 0.4185452608163944 MAE: 0.51341575
Validation loss: 0.4020448669880808 MAE: 0.50633764
Validation loss: 0.40935855070670285 MAE: 0.5107009
53 2 0.6341639161109924
Validation loss: 0.4269084939975777 MAE: 0.5249415
Validation loss: 0.4163416442507971 MAE: 0.5147676
Validation loss: 0.4319796175779943 MAE: 0.5246748
56 4 0.48721805214881897
Validation loss: 0.4000020117344025 MAE: 0.5083046
Validation loss: 0.4449992113576862 MAE: 0.5318536
Validation loss: 0.41960657419327024 MAE: 0.5141227
59 6 0.8520067930221558
Validation loss: 0.4883724438523004 MAE: 0.5602366
Validation loss: 0.39966541080771084 MAE: 0.51059186
Validation loss: 0.38304281957402736 MAE: 0.49598432
62 8 0.6909056305885315
Validation loss: 0.372098768402436 MAE: 0.48999372
Validation loss: 0.37366328103269986 MAE: 0.49273133
Validation loss: 0.4104164522850442 MAE: 0.51808983
65 10 0.35313791036605835
Validation loss: 0.3761929078904804 MAE: 0.48979005
Validation loss: 0.3615270709704779 MAE: 0.4879905
Validation loss: 0.38559846158973676 MAE: 0.49543747
68 12 0.917851448059082
Validation loss: 0.39343710927542797 MAE: 0.5087953
Validation loss: 0.3891887025747127 MAE: 0.5056908
Validation loss: 0.47643695613425335 MAE: 0.54124475
71 14 0.7035099267959595
Validation loss: 0.4064974498772669 MAE: 0.5138959
Validation loss: 0.38070306767203765 MAE: 0.4898977
Validation loss: 0.44025141550209335 MAE: 0.52153116
Validation loss: 0.4012422610619264 MAE: 0.5165634
75 0 0.40667468309402466
Validation loss: 0.3800991610558573 MAE: 0.49908346
Validation loss: 0.45074420053519326 MAE: 0.5287587
Validation loss: 0.3349108141744304 MAE: 0.4707983
78 2 0.4669162631034851
Validation loss: 0.3304041528510665 MAE: 0.46287555
Validation loss: 0.3708997911704566 MAE: 0.49654782
Validation loss: 0.33484910407620583 MAE: 0.46539795
81 4 0.3952949345111847
Validation loss: 0.3263141477633574 MAE: 0.46512392
Validation loss: 0.32582325328566986 MAE: 0.4593281
Validation loss: 0.3726204754952677 MAE: 0.49972996
84 6 0.4922561049461365
Validation loss: 0.30356225658036423 MAE: 0.4382158
Validation loss: 0.29812268578337286 MAE: 0.43941033
Validation loss: 0.31228594711882796 MAE: 0.44983798
87 8 0.8313666582107544
Validation loss: 0.35037769195073115 MAE: 0.46546748
Validation loss: 0.3103334827867443 MAE: 0.44205594
Validation loss: 0.3274228161047838 MAE: 0.46398285
90 10 0.5954213738441467
Validation loss: 0.2982649677143785 MAE: 0.44042334
Validation loss: 0.2947831203440626 MAE: 0.43853167
Validation loss: 0.2848071839981423 MAE: 0.4282769
93 12 0.5666038393974304
Validation loss: 0.2873529997880091 MAE: 0.43387765
Validation loss: 0.3450374513088104 MAE: 0.47627985
Validation loss: 0.31222808071391617 MAE: 0.45235193
96 14 0.3428477346897125
Validation loss: 0.2911043086486732 MAE: 0.42910662
Validation loss: 0.27289546240785556 MAE: 0.41425425
Validation loss: 0.28840297657645536 MAE: 0.43314233
Validation loss: 0.31767879256265674 MAE: 0.45304054
Loaded trained model with success.
Test loss: 0.7044914431704888 Test MAE: 0.6473302
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 2}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.6514731645584106
Validation loss: 0.746344268321991 ROC AUC: 0.9
Validation loss: 0.8534281849861145 ROC AUC: 0.85
Validation loss: 0.8354105949401855 ROC AUC: 0.85
Validation loss: 0.8873124122619629 ROC AUC: 1.0
Validation loss: 0.9815051555633545 ROC AUC: 0.9500000000000001
Validation loss: 1.016523838043213 ROC AUC: 0.9500000000000001
Validation loss: 0.9544211626052856 ROC AUC: 0.85
Validation loss: 0.8617274761199951 ROC AUC: 0.85
Validation loss: 0.7649765610694885 ROC AUC: 0.75
Validation loss: 0.7187196016311646 ROC AUC: 0.7
Validation loss: 0.6751239895820618 ROC AUC: 0.7
Validation loss: 0.6460282802581787 ROC AUC: 0.7
Validation loss: 0.6225880980491638 ROC AUC: 0.7
Validation loss: 0.6202108263969421 ROC AUC: 0.7
Validation loss: 0.5989704132080078 ROC AUC: 0.7
Validation loss: 0.5746520757675171 ROC AUC: 0.7
Validation loss: 0.530125617980957 ROC AUC: 0.8
Validation loss: 0.4815515875816345 ROC AUC: 0.9
Validation loss: 0.4420541226863861 ROC AUC: 0.9500000000000001
Validation loss: 0.4175487160682678 ROC AUC: 0.9500000000000001
Validation loss: 0.39201927185058594 ROC AUC: 0.9500000000000001
Validation loss: 0.37198173999786377 ROC AUC: 1.0
Validation loss: 0.3477371037006378 ROC AUC: 1.0
Validation loss: 0.3278363049030304 ROC AUC: 1.0
Validation loss: 0.3080733120441437 ROC AUC: 1.0
Validation loss: 0.2857002019882202 ROC AUC: 1.0
Validation loss: 0.2729743421077728 ROC AUC: 1.0
Validation loss: 0.249747171998024 ROC AUC: 1.0
Validation loss: 0.2378283143043518 ROC AUC: 1.0
Validation loss: 0.22783544659614563 ROC AUC: 1.0
Validation loss: 0.21890197694301605 ROC AUC: 1.0
Validation loss: 0.21461635828018188 ROC AUC: 1.0
Validation loss: 0.20434661209583282 ROC AUC: 1.0
Validation loss: 0.1972959190607071 ROC AUC: 1.0
Validation loss: 0.18524587154388428 ROC AUC: 1.0
Validation loss: 0.17286416888237 ROC AUC: 1.0
Validation loss: 0.16295649111270905 ROC AUC: 1.0
Validation loss: 0.15341028571128845 ROC AUC: 1.0
Validation loss: 0.1454441398382187 ROC AUC: 1.0
Validation loss: 0.1329338699579239 ROC AUC: 1.0
Validation loss: 0.1263565868139267 ROC AUC: 1.0
Validation loss: 0.12553852796554565 ROC AUC: 1.0
Validation loss: 0.12173688411712646 ROC AUC: 1.0
Validation loss: 0.12151005864143372 ROC AUC: 1.0
Validation loss: 0.10993384569883347 ROC AUC: 1.0
Validation loss: 0.10090114921331406 ROC AUC: 1.0
Validation loss: 0.09420713782310486 ROC AUC: 1.0
Validation loss: 0.08254840970039368 ROC AUC: 1.0
Validation loss: 0.06540824472904205 ROC AUC: 1.0
Validation loss: 0.0529477559030056 ROC AUC: 1.0
50 0 0.041292861104011536
Validation loss: 0.04398947209119797 ROC AUC: 1.0
Validation loss: 0.03423435613512993 ROC AUC: 1.0
Validation loss: 0.026872122660279274 ROC AUC: 1.0
Validation loss: 0.02010171115398407 ROC AUC: 1.0
Validation loss: 0.014657467603683472 ROC AUC: 1.0
Validation loss: 0.011662718839943409 ROC AUC: 1.0
Validation loss: 0.008957134559750557 ROC AUC: 1.0
Validation loss: 0.010568560101091862 ROC AUC: 1.0
Validation loss: 0.01130816899240017 ROC AUC: 1.0
Validation loss: 0.011869828216731548 ROC AUC: 1.0
Validation loss: 0.010712326504290104 ROC AUC: 1.0
Validation loss: 0.011712449602782726 ROC AUC: 1.0
Validation loss: 0.009996064938604832 ROC AUC: 1.0
Validation loss: 0.011980361305177212 ROC AUC: 1.0
Validation loss: 0.010847575031220913 ROC AUC: 1.0
Validation loss: 0.010421535931527615 ROC AUC: 1.0
Validation loss: 0.009150464087724686 ROC AUC: 1.0
Validation loss: 0.011120433919131756 ROC AUC: 1.0
Validation loss: 0.011502090841531754 ROC AUC: 1.0
Validation loss: 0.011844775639474392 ROC AUC: 1.0
Validation loss: 0.012630145996809006 ROC AUC: 1.0
Validation loss: 0.011112993583083153 ROC AUC: 1.0
Validation loss: 0.011261099018156528 ROC AUC: 1.0
Validation loss: 0.00890505313873291 ROC AUC: 1.0
Validation loss: 0.007230848073959351 ROC AUC: 1.0
Validation loss: 0.006398945581167936 ROC AUC: 1.0
Validation loss: 0.005461331456899643 ROC AUC: 1.0
Validation loss: 0.0046452721580863 ROC AUC: 1.0
Validation loss: 0.003939003683626652 ROC AUC: 1.0
Validation loss: 0.002649926580488682 ROC AUC: 1.0
Validation loss: 0.0019724881276488304 ROC AUC: 1.0
Validation loss: 0.0016232442576438189 ROC AUC: 1.0
Validation loss: 0.0012801015982404351 ROC AUC: 1.0
Validation loss: 0.0010691973147913814 ROC AUC: 1.0
Validation loss: 0.000882001593708992 ROC AUC: 1.0
Validation loss: 0.0006652018055319786 ROC AUC: 1.0
Validation loss: 0.000593879260122776 ROC AUC: 1.0
Validation loss: 0.00046815298264846206 ROC AUC: 1.0
Validation loss: 0.00036913715302944183 ROC AUC: 1.0
Validation loss: 0.00031955851591192186 ROC AUC: 1.0
Validation loss: 0.0002959944831673056 ROC AUC: 1.0
Validation loss: 0.00041267782216891646 ROC AUC: 1.0
Validation loss: 0.0005821696249768138 ROC AUC: 1.0
Validation loss: 0.0007578578661195934 ROC AUC: 1.0
Validation loss: 0.0010717854602262378 ROC AUC: 1.0
Validation loss: 0.0014003756223246455 ROC AUC: 1.0
Validation loss: 0.0014076330699026585 ROC AUC: 1.0
Validation loss: 0.0011849742149934173 ROC AUC: 1.0
Validation loss: 0.0011366059770807624 ROC AUC: 1.0
Validation loss: 0.0013036631280556321 ROC AUC: 1.0
Loaded trained model with success.
Test loss: 0.8313115611790727 Test ROC AUC: 0.5239826917471919
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 2}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.6992977857589722
Validation loss: 0.6932292094036024 ROC AUC: 0.36666666666666664
Validation loss: 0.7279365464132659 ROC AUC: 0.47333333333333333
Validation loss: 0.774754210394256 ROC AUC: 0.5333333333333333
Validation loss: 0.7863242273428002 ROC AUC: 0.615
Validation loss: 0.7265425531231627 ROC AUC: 0.64
Validation loss: 0.6910932562789138 ROC AUC: 0.7466666666666668
Validation loss: 0.6903548325811114 ROC AUC: 0.4933333333333333
Validation loss: 0.6865902117320469 ROC AUC: 0.695
Validation loss: 0.6578480309369613 ROC AUC: 0.665
Validation loss: 0.6328358540729601 ROC AUC: 0.68
Validation loss: 0.6220273630959647 ROC AUC: 0.705
Validation loss: 0.620011107045777 ROC AUC: 0.72
Validation loss: 0.6212481613061867 ROC AUC: 0.7150000000000001
Validation loss: 0.6200524921319923 ROC AUC: 0.72
Validation loss: 0.6249973190074064 ROC AUC: 0.7266666666666667
Validation loss: 0.6355759002724473 ROC AUC: 0.7316666666666667
Validation loss: 0.6409116302217756 ROC AUC: 0.7433333333333333
Validation loss: 0.629205195271239 ROC AUC: 0.7516666666666667
Validation loss: 0.6211533899209938 ROC AUC: 0.7483333333333334
Validation loss: 0.6179000942074523 ROC AUC: 0.7450000000000001
Validation loss: 0.6138426953432511 ROC AUC: 0.7533333333333334
Validation loss: 0.6288867179228335 ROC AUC: 0.7383333333333333
Validation loss: 0.6921929826541823 ROC AUC: 0.7333333333333332
Validation loss: 0.7691520549813096 ROC AUC: 0.7316666666666667
Validation loss: 0.810654028337829 ROC AUC: 0.7366666666666667
25 0 0.8520776629447937
Validation loss: 0.7779252675114846 ROC AUC: 0.7466666666666666
Validation loss: 0.7502432064134248 ROC AUC: 0.745
Validation loss: 0.7050561795429308 ROC AUC: 0.745
Validation loss: 0.6651857483143709 ROC AUC: 0.75
Validation loss: 0.6764597941418083 ROC AUC: 0.7483333333333333
Validation loss: 0.6828370836316323 ROC AUC: 0.7516666666666666
Validation loss: 0.6923292327900322 ROC AUC: 0.7616666666666667
Validation loss: 0.7119882970440145 ROC AUC: 0.7766666666666667
Validation loss: 0.7218095441253818 ROC AUC: 0.7899999999999999
Validation loss: 0.6805001071521214 ROC AUC: 0.805
Validation loss: 0.6318051571748695 ROC AUC: 0.8166666666666667
Validation loss: 0.6041475887201271 ROC AUC: 0.8216666666666667
Validation loss: 0.5996872819199854 ROC AUC: 0.8283333333333333
Validation loss: 0.622309250491006 ROC AUC: 0.8350000000000001
Validation loss: 0.6628270343858369 ROC AUC: 0.8333333333333334
Validation loss: 0.6962352632259836 ROC AUC: 0.8366666666666667
Validation loss: 0.7076816437195759 ROC AUC: 0.83
Validation loss: 0.710086423523572 ROC AUC: 0.825
Validation loss: 0.7007938562607279 ROC AUC: 0.8283333333333333
Validation loss: 0.6830279085100913 ROC AUC: 0.84
Validation loss: 0.6563748194246876 ROC AUC: 0.8616666666666667
Validation loss: 0.6421026429351495 ROC AUC: 0.8700000000000001
Validation loss: 0.6392284437101714 ROC AUC: 0.8783333333333333
Validation loss: 0.638252563622533 ROC AUC: 0.8916666666666667
Validation loss: 0.6267378512693911 ROC AUC: 0.915
50 0 0.4917471408843994
Validation loss: 0.6154340797541092 ROC AUC: 0.92
Validation loss: 0.6005315269742694 ROC AUC: 0.9216666666666666
Validation loss: 0.6127096475387106 ROC AUC: 0.925
Validation loss: 0.6335773498428111 ROC AUC: 0.9266666666666666
Validation loss: 0.6818098644821011 ROC AUC: 0.9266666666666667
Validation loss: 0.6347444762988966 ROC AUC: 0.9249999999999999
Validation loss: 0.5794130198809565 ROC AUC: 0.9166666666666667
Validation loss: 0.5154801978140461 ROC AUC: 0.9233333333333333
Validation loss: 0.46824394440164374 ROC AUC: 0.9216666666666667
Validation loss: 0.45470683611169155 ROC AUC: 0.9183333333333333
Validation loss: 0.49632778581307857 ROC AUC: 0.9183333333333333
Validation loss: 0.5132031319092731 ROC AUC: 0.9249999999999999
Validation loss: 0.5614117560338001 ROC AUC: 0.9283333333333333
Validation loss: 0.6042024742583839 ROC AUC: 0.935
Validation loss: 0.6564522568060427 ROC AUC: 0.9383333333333334
Validation loss: 0.6987853269187771 ROC AUC: 0.9466666666666667
Validation loss: 0.7428638789118552 ROC AUC: 0.9466666666666667
Validation loss: 0.7119594252839381 ROC AUC: 0.9516666666666667
Validation loss: 0.6822651746321697 ROC AUC: 0.9516666666666667
Validation loss: 0.6100361152571074 ROC AUC: 0.955
Validation loss: 0.5170470980965362 ROC AUC: 0.9583333333333333
Validation loss: 0.45356882834921075 ROC AUC: 0.9550000000000001
Validation loss: 0.4132191319854892 ROC AUC: 0.9550000000000001
Validation loss: 0.4033961825224818 ROC AUC: 0.9550000000000001
Validation loss: 0.4156442990108412 ROC AUC: 0.9583333333333334
75 0 0.38827458024024963
Validation loss: 0.4087468160658467 ROC AUC: 0.9583333333333334
Validation loss: 0.36983824566918977 ROC AUC: 0.9633333333333334
Validation loss: 0.3758385449039693 ROC AUC: 0.9716666666666667
Validation loss: 0.40030901468529995 ROC AUC: 0.975
Validation loss: 0.3967104067607802 ROC AUC: 0.9816666666666667
Validation loss: 0.38632255518923 ROC AUC: 0.9816666666666667
Validation loss: 0.4067924387600957 ROC AUC: 0.985
Validation loss: 0.43708302293504986 ROC AUC: 0.985
Validation loss: 0.45813272193986543 ROC AUC: 0.9866666666666666
Validation loss: 0.4607112133989529 ROC AUC: 0.9883333333333333
Validation loss: 0.46986028612876424 ROC AUC: 0.995
Validation loss: 0.4370323103301379 ROC AUC: 0.9966666666666666
Validation loss: 0.3717332229930527 ROC AUC: 0.9966666666666666
Validation loss: 0.3236835556370871 ROC AUC: 0.9966666666666666
Validation loss: 0.31856165187699453 ROC AUC: 0.9966666666666666
Validation loss: 0.31412771830753405 ROC AUC: 0.9966666666666666
Validation loss: 0.2978684801836403 ROC AUC: 0.9966666666666666
Validation loss: 0.29270299843379427 ROC AUC: 0.9983333333333333
Validation loss: 0.27156636696688985 ROC AUC: 1.0
Validation loss: 0.26392791709121394 ROC AUC: 1.0
Validation loss: 0.27385290301575954 ROC AUC: 1.0
Validation loss: 0.24043232962793235 ROC AUC: 1.0
Validation loss: 0.20757916448067645 ROC AUC: 1.0
Validation loss: 0.20156929201009322 ROC AUC: 1.0
Validation loss: 0.24177896946060415 ROC AUC: 1.0
Loaded trained model with success.
Test loss: 1.4048597331689203 Test ROC AUC: 0.592757523283568
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 2}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.6950676441192627
Validation loss: 0.7059658518945328 ROC AUC: 0.5610204081632654
Validation loss: 0.6929223459176342 ROC AUC: 0.5824489795918367
Validation loss: 0.7027460908648944 ROC AUC: 0.573469387755102
Validation loss: 0.699346150412704 ROC AUC: 0.5897959183673469
Validation loss: 0.7172767736695029 ROC AUC: 0.5922448979591837
Validation loss: 0.6897586632256556 ROC AUC: 0.5522448979591837
Validation loss: 0.6868609436834702 ROC AUC: 0.5412244897959184
Validation loss: 0.7102661524156128 ROC AUC: 0.5477551020408162
Validation loss: 0.6932131425298825 ROC AUC: 0.5514285714285714
Validation loss: 0.6847694142900332 ROC AUC: 0.5514285714285715
Validation loss: 0.7213176886240641 ROC AUC: 0.5710204081632653
Validation loss: 0.702494684493903 ROC AUC: 0.476734693877551
12 2 0.7224245071411133
Validation loss: 0.7157018636212205 ROC AUC: 0.4448979591836735
Validation loss: 0.7053284554770498 ROC AUC: 0.4616326530612245
Validation loss: 0.703738028954978 ROC AUC: 0.4726530612244898
Validation loss: 0.7007687627667128 ROC AUC: 0.5681632653061225
Validation loss: 0.6870422170619772 ROC AUC: 0.5885714285714285
Validation loss: 0.7115394978812246 ROC AUC: 0.5657142857142857
Validation loss: 0.6990799319864524 ROC AUC: 0.573469387755102
Validation loss: 0.6897610558403863 ROC AUC: 0.5914285714285714
Validation loss: 0.7235180308120419 ROC AUC: 0.5971428571428571
Validation loss: 0.7066298783427537 ROC AUC: 0.6093877551020408
Validation loss: 0.6896469273952522 ROC AUC: 0.5502040816326531
Validation loss: 0.7255382375283674 ROC AUC: 0.5444897959183673
Validation loss: 0.6835565874070832 ROC AUC: 0.589795918367347
25 0 0.6114137172698975
Validation loss: 0.6914122508029745 ROC AUC: 0.676734693877551
Validation loss: 0.7321833715294347 ROC AUC: 0.666530612244898
Validation loss: 0.6985154645611541 ROC AUC: 0.6710204081632652
Validation loss: 0.6711071838032115 ROC AUC: 0.6844897959183673
Validation loss: 0.6491741748771283 ROC AUC: 0.7024489795918367
Validation loss: 0.6383848172245603 ROC AUC: 0.7240816326530612
Validation loss: 0.6513638670998391 ROC AUC: 0.7342857142857143
Validation loss: 0.6843930338368271 ROC AUC: 0.7477551020408163
Validation loss: 0.6952522932881057 ROC AUC: 0.7775510204081633
Validation loss: 0.7040366328725911 ROC AUC: 0.7848979591836734
Validation loss: 0.7130301275638619 ROC AUC: 0.7889795918367347
Validation loss: 0.7073042847291388 ROC AUC: 0.7918367346938776
37 2 0.6737726926803589
Validation loss: 0.6687807844142721 ROC AUC: 0.7493877551020408
Validation loss: 0.6286318783808236 ROC AUC: 0.7669387755102041
Validation loss: 0.642621431386832 ROC AUC: 0.8387755102040817
Validation loss: 0.685933854844835 ROC AUC: 0.8485714285714285
Validation loss: 0.6546338068114387 ROC AUC: 0.8555102040816327
Validation loss: 0.6132580252608868 ROC AUC: 0.8587755102040816
Validation loss: 0.6241261670083711 ROC AUC: 0.8771428571428571
Validation loss: 0.7248094093920004 ROC AUC: 0.8579591836734695
Validation loss: 0.7159252124603348 ROC AUC: 0.876734693877551
Validation loss: 0.6437923348311222 ROC AUC: 0.8657142857142857
Validation loss: 0.603647130306321 ROC AUC: 0.86
Validation loss: 0.5975640669013514 ROC AUC: 0.8763265306122449
Validation loss: 0.595030968839472 ROC AUC: 0.896734693877551
50 0 0.6097366809844971
Validation loss: 0.6170357459723347 ROC AUC: 0.9224489795918367
Validation loss: 0.6582043274785533 ROC AUC: 0.9359183673469388
Validation loss: 0.6478060225043634 ROC AUC: 0.9359183673469388
Validation loss: 0.5757940124080638 ROC AUC: 0.9424489795918367
Validation loss: 0.5497927424883602 ROC AUC: 0.933469387755102
Validation loss: 0.5567865326549067 ROC AUC: 0.9293877551020409
Validation loss: 0.5714805336913678 ROC AUC: 0.9110204081632652
Validation loss: 0.6201376433324333 ROC AUC: 0.8995918367346938
Validation loss: 0.6488345575453055 ROC AUC: 0.9228571428571428
Validation loss: 0.6051475435043826 ROC AUC: 0.9248979591836736
Validation loss: 0.4579111122422748 ROC AUC: 0.9293877551020407
Validation loss: 0.4476674825254113 ROC AUC: 0.9175510204081633
62 2 0.4591875672340393
Validation loss: 0.44522680658282654 ROC AUC: 0.9195918367346939
Validation loss: 0.5145597457885742 ROC AUC: 0.936734693877551
Validation loss: 0.5101401352822178 ROC AUC: 0.9551020408163265
Validation loss: 0.4674853769817738 ROC AUC: 0.973469387755102
Validation loss: 0.417289806134773 ROC AUC: 0.9787755102040816
Validation loss: 0.33121111767009054 ROC AUC: 0.98
Validation loss: 0.3928860652853142 ROC AUC: 0.9767346938775511
Validation loss: 0.42284365434839266 ROC AUC: 0.9608163265306122
Validation loss: 0.3694922547185361 ROC AUC: 0.9681632653061224
Validation loss: 0.36852049827575684 ROC AUC: 0.9779591836734693
Validation loss: 0.30880149265732426 ROC AUC: 0.9857142857142858
Validation loss: 0.2747622423551299 ROC AUC: 0.9861224489795919
Validation loss: 0.2582096147416818 ROC AUC: 0.9775510204081632
75 0 0.41205281019210815
Validation loss: 0.3046656283691074 ROC AUC: 0.9693877551020408
Validation loss: 0.3632180668187864 ROC AUC: 0.966530612244898
Validation loss: 0.49325910963193337 ROC AUC: 0.9555102040816326
Validation loss: 0.6721052605696399 ROC AUC: 0.9506122448979591
Validation loss: 0.5295002574872489 ROC AUC: 0.9395918367346939
Validation loss: 0.40958689920830005 ROC AUC: 0.9616326530612245
Validation loss: 0.4005317239448278 ROC AUC: 0.9759183673469387
Validation loss: 0.368766917724802 ROC AUC: 0.9816326530612245
Validation loss: 0.3011087681910004 ROC AUC: 0.9881632653061224
Validation loss: 0.23595749865276644 ROC AUC: 0.9902040816326532
Validation loss: 0.19886239174038473 ROC AUC: 0.9938775510204081
Validation loss: 0.16773405249672707 ROC AUC: 0.9959183673469387
87 2 0.3454832434654236
Validation loss: 0.18738407498658305 ROC AUC: 0.9955102040816327
Validation loss: 0.24768771108879586 ROC AUC: 0.9959183673469387
Validation loss: 0.22043233936784243 ROC AUC: 0.9955102040816327
Validation loss: 0.2178352971307256 ROC AUC: 0.993061224489796
Validation loss: 0.19540886445478958 ROC AUC: 0.9877551020408163
Validation loss: 0.2172262543680692 ROC AUC: 0.9836734693877551
Validation loss: 0.21515824856481167 ROC AUC: 0.9828571428571429
Validation loss: 0.18848959936036003 ROC AUC: 0.9869387755102041
Validation loss: 0.20140077790828667 ROC AUC: 0.9861224489795919
Validation loss: 0.29868547362510606 ROC AUC: 0.9930612244897958
Validation loss: 0.4029788661129641 ROC AUC: 0.9951020408163265
Validation loss: 0.3695868304883591 ROC AUC: 0.9951020408163265
Validation loss: 0.28833446117362593 ROC AUC: 0.996326530612245
Loaded trained model with success.
Test loss: 1.6846139706658814 Test ROC AUC: 0.6878825332476394
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 2}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.8139287829399109
Validation loss: 1.038112252800908 ROC AUC: 0.5975757575757575
Validation loss: 0.7068184626162352 ROC AUC: 0.48343434343434344
Validation loss: 0.6991509953934942 ROC AUC: 0.43767676767676766
Validation loss: 0.7043578082592643 ROC AUC: 0.6190909090909091
Validation loss: 0.7398459303319155 ROC AUC: 0.6197979797979798
Validation loss: 0.6623807561457457 ROC AUC: 0.6331313131313132
Validation loss: 0.6669743884747951 ROC AUC: 0.6337373737373738
7 1 0.6681015491485596
Validation loss: 0.751483539540564 ROC AUC: 0.6412121212121211
Validation loss: 0.6518440324457446 ROC AUC: 0.6501010101010101
Validation loss: 0.6704265867645417 ROC AUC: 0.6670707070707071
Validation loss: 0.6589266304394708 ROC AUC: 0.6851515151515153
Validation loss: 0.631060058148063 ROC AUC: 0.6976767676767677
Validation loss: 0.629735682777424 ROC AUC: 0.7053535353535354
Validation loss: 0.6667776748762658 ROC AUC: 0.7122222222222222
14 2 0.6475935578346252
Validation loss: 0.6168151566730672 ROC AUC: 0.7141414141414142
Validation loss: 0.6455332256441739 ROC AUC: 0.7231313131313132
Validation loss: 0.6687889102116302 ROC AUC: 0.738989898989899
Validation loss: 0.6029254256480903 ROC AUC: 0.7553535353535354
Validation loss: 0.7527989080203837 ROC AUC: 0.7736363636363636
Validation loss: 0.6849539621391488 ROC AUC: 0.7857575757575757
Validation loss: 0.5672884316899669 ROC AUC: 0.8071717171717171
21 3 0.6707719564437866
Validation loss: 0.5421745881962416 ROC AUC: 0.8175757575757576
Validation loss: 0.5819224391750355 ROC AUC: 0.8331313131313132
Validation loss: 0.5666144771791582 ROC AUC: 0.8397979797979798
Validation loss: 0.6327652143473601 ROC AUC: 0.8470707070707071
Validation loss: 0.7354680746044945 ROC AUC: 0.8446464646464648
Validation loss: 0.5443832547820393 ROC AUC: 0.8581818181818182
Validation loss: 0.5670798498781482 ROC AUC: 0.8835353535353536
28 4 0.6320474147796631
Validation loss: 0.5479338738187474 ROC AUC: 0.8950505050505051
Validation loss: 0.5471726083875301 ROC AUC: 0.9031313131313131
Validation loss: 0.46089572253538735 ROC AUC: 0.9073737373737374
Validation loss: 0.5991239772370113 ROC AUC: 0.9153535353535354
Validation loss: 0.5833093386199606 ROC AUC: 0.9168686868686868
Validation loss: 0.5000744279305539 ROC AUC: 0.9213131313131313
Validation loss: 0.5758920219076339 ROC AUC: 0.9280808080808081
35 5 0.4759933352470398
Validation loss: 0.5291757895119825 ROC AUC: 0.9394949494949494
Validation loss: 0.5215684037711752 ROC AUC: 0.9411111111111111
Validation loss: 0.457129707138742 ROC AUC: 0.9376767676767677
Validation loss: 0.4381899980444405 ROC AUC: 0.9415151515151515
Validation loss: 0.4507159075545306 ROC AUC: 0.9382828282828283
Validation loss: 0.3616375180345085 ROC AUC: 0.9352525252525252
Validation loss: 0.3535107491004407 ROC AUC: 0.943939393939394
42 6 0.3366844356060028
Validation loss: 0.5297771168114552 ROC AUC: 0.9425252525252525
Validation loss: 0.4632141783309342 ROC AUC: 0.9393939393939394
Validation loss: 0.37137525487485246 ROC AUC: 0.9364646464646464
Validation loss: 0.36689868906335016 ROC AUC: 0.9387878787878787
Validation loss: 0.37220644816082327 ROC AUC: 0.944949494949495
Validation loss: 0.32815511801734043 ROC AUC: 0.9512121212121212
Validation loss: 0.32620100257684237 ROC AUC: 0.9515151515151515
Validation loss: 0.3169706854688462 ROC AUC: 0.9555555555555556
50 0 0.5305518507957458
Validation loss: 0.33809056668425325 ROC AUC: 0.9514141414141415
Validation loss: 0.3588095469091406 ROC AUC: 0.9484848484848485
Validation loss: 0.35808943578945335 ROC AUC: 0.9456565656565656
Validation loss: 0.3096548522537078 ROC AUC: 0.956060606060606
Validation loss: 0.3793610662371669 ROC AUC: 0.9592929292929293
Validation loss: 0.49361538557551016 ROC AUC: 0.955959595959596
Validation loss: 0.35881758904337285 ROC AUC: 0.9578787878787878
57 1 0.41414791345596313
Validation loss: 0.3142107290838232 ROC AUC: 0.9615151515151514
Validation loss: 0.4045476492625385 ROC AUC: 0.964949494949495
Validation loss: 0.401470672348561 ROC AUC: 0.9675757575757575
Validation loss: 0.4460144640512802 ROC AUC: 0.9661616161616162
Validation loss: 0.3040831107739827 ROC AUC: 0.954848484848485
Validation loss: 0.3211328174600649 ROC AUC: 0.9631313131313132
Validation loss: 0.28392840135636643 ROC AUC: 0.9698989898989899
64 2 0.32959893345832825
Validation loss: 0.32848174712765754 ROC AUC: 0.9678787878787879
Validation loss: 0.2918797325548814 ROC AUC: 0.967979797979798
Validation loss: 0.301402508164171 ROC AUC: 0.974040404040404
Validation loss: 0.2724048796685497 ROC AUC: 0.9792929292929293
Validation loss: 0.23715566974788455 ROC AUC: 0.9781818181818183
Validation loss: 0.2685756218343524 ROC AUC: 0.972929292929293
Validation loss: 0.3242879966320704 ROC AUC: 0.9642424242424242
71 3 0.5779635310173035
Validation loss: 0.36463150237897535 ROC AUC: 0.9643434343434344
Validation loss: 0.3252459309208932 ROC AUC: 0.9764646464646465
Validation loss: 0.265105623845479 ROC AUC: 0.981010101010101
Validation loss: 0.27383575914193636 ROC AUC: 0.9816161616161616
Validation loss: 0.2973556687409554 ROC AUC: 0.9846464646464647
Validation loss: 0.27006408261444104 ROC AUC: 0.9824242424242424
Validation loss: 0.23986686646339284 ROC AUC: 0.9816161616161616
78 4 0.10631749778985977
Validation loss: 0.23373484757527635 ROC AUC: 0.9751515151515152
Validation loss: 0.2432377202127447 ROC AUC: 0.983030303030303
Validation loss: 0.22675471535729402 ROC AUC: 0.9863636363636363
Validation loss: 0.22889529430686528 ROC AUC: 0.9861616161616162
Validation loss: 0.2797605077825 ROC AUC: 0.9790909090909091
Validation loss: 0.22086707120714474 ROC AUC: 0.9831313131313133
Validation loss: 0.23746633402366735 ROC AUC: 0.9862626262626263
85 5 0.27993807196617126
Validation loss: 0.18875576866481772 ROC AUC: 0.9872727272727273
Validation loss: 0.15669662853581223 ROC AUC: 0.9877777777777779
Validation loss: 0.15147116750328984 ROC AUC: 0.987979797979798
Validation loss: 0.1612892575824081 ROC AUC: 0.985050505050505
Validation loss: 0.16085487637837328 ROC AUC: 0.9912121212121212
Validation loss: 0.142773266039302 ROC AUC: 0.9950505050505051
Validation loss: 0.16482029551986474 ROC AUC: 0.9908080808080809
92 6 0.6317729949951172
Validation loss: 0.1535874379415009 ROC AUC: 0.9929292929292929
Validation loss: 0.17451215374409854 ROC AUC: 0.9873737373737375
Validation loss: 0.2285802726020765 ROC AUC: 0.9885858585858586
Validation loss: 0.3051759918131421 ROC AUC: 0.9864646464646465
Validation loss: 0.19743690733334526 ROC AUC: 0.9871717171717171
Validation loss: 0.20732981299784914 ROC AUC: 0.9792929292929293
Validation loss: 0.22758189395032635 ROC AUC: 0.9758585858585858
Validation loss: 0.1849619866765324 ROC AUC: 0.9848484848484849
Loaded trained model with success.
Test loss: 0.9366422611748632 Test ROC AUC: 0.7188295941133267
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 2}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.6825207471847534
Validation loss: 0.706535355600422 ROC AUC: 0.515711348155764
Validation loss: 0.692113038294301 ROC AUC: 0.5172856959259735
Validation loss: 0.693174351790625 ROC AUC: 0.5418969284153707
3 2 0.6891776919364929
Validation loss: 0.6940274914663158 ROC AUC: 0.5650944608662126
Validation loss: 0.6949079788041735 ROC AUC: 0.594894615088035
Validation loss: 0.6882293149082359 ROC AUC: 0.5994088163475132
6 4 0.7018558979034424
Validation loss: 0.6827449520269712 ROC AUC: 0.6059311142526668
Validation loss: 0.6799295064442621 ROC AUC: 0.6289358694255237
Validation loss: 0.7099398866684021 ROC AUC: 0.645257678961573
9 6 0.6543920636177063
Validation loss: 0.6993120456028558 ROC AUC: 0.665033414728184
Validation loss: 0.7110846260028755 ROC AUC: 0.692745148438504
Validation loss: 0.7190616818850408 ROC AUC: 0.7277342243927516
12 8 0.6009543538093567
Validation loss: 0.7852168402117574 ROC AUC: 0.7712215653514972
Validation loss: 0.600891725572651 ROC AUC: 0.7995116308957717
Validation loss: 0.592097277273396 ROC AUC: 0.8010538491196505
15 10 0.648902177810669
Validation loss: 0.6129366839099265 ROC AUC: 0.8091023004755173
Validation loss: 0.5609640918059913 ROC AUC: 0.8177290836653387
Validation loss: 0.5553111693185413 ROC AUC: 0.8255044338773937
18 12 0.6059803366661072
Validation loss: 0.6022118967855143 ROC AUC: 0.831657241999743
Validation loss: 0.5620949950390206 ROC AUC: 0.8310467806194577
Validation loss: 0.49796333037062973 ROC AUC: 0.8554331062845393
21 14 0.5181642770767212
Validation loss: 0.4955873065338823 ROC AUC: 0.8498425652229791
Validation loss: 0.5188930176780793 ROC AUC: 0.8574251381570492
Validation loss: 0.48835610889480685 ROC AUC: 0.8623248939724971
Validation loss: 0.48287452760344757 ROC AUC: 0.8707910294306644
25 0 0.5443824529647827
Validation loss: 0.4887044502045205 ROC AUC: 0.8599794370903482
Validation loss: 0.5113721578297968 ROC AUC: 0.8648309985863
Validation loss: 0.4667002915858267 ROC AUC: 0.879626654671636
28 2 0.6315826773643494
Validation loss: 0.5157222142200432 ROC AUC: 0.884687058218738
Validation loss: 0.4711463372549695 ROC AUC: 0.8849762241357152
Validation loss: 0.46691769146489237 ROC AUC: 0.881891787687958
31 4 0.373970091342926
Validation loss: 0.4562744076600772 ROC AUC: 0.8930728698110783
Validation loss: 0.4605321837570481 ROC AUC: 0.8895868140341858
Validation loss: 0.41252025717007135 ROC AUC: 0.8973139699267446
34 6 0.48676812648773193
Validation loss: 0.4504121951684206 ROC AUC: 0.8876269117080067
Validation loss: 0.42262056595337893 ROC AUC: 0.9049286724071456
Validation loss: 0.42418346268858365 ROC AUC: 0.9055873281069272
37 8 0.6482283473014832
Validation loss: 0.470193949634422 ROC AUC: 0.9053142269631153
Validation loss: 0.41589859510232546 ROC AUC: 0.9182142398149338
Validation loss: 0.4077575627811447 ROC AUC: 0.9065672792700168
40 10 0.4357152581214905
Validation loss: 0.4370338424652038 ROC AUC: 0.906856445186994
Validation loss: 0.4331640647742935 ROC AUC: 0.9130092533093433
Validation loss: 0.4121163522074361 ROC AUC: 0.9156760056548002
43 12 0.5894258618354797
Validation loss: 0.4071798425518678 ROC AUC: 0.9142783703894101
Validation loss: 0.3788397177785097 ROC AUC: 0.9216681660454955
Validation loss: 0.3754185078019847 ROC AUC: 0.9249293149980723
46 14 0.3730715811252594
Validation loss: 0.39661105487771886 ROC AUC: 0.9128486055776892
Validation loss: 0.40485036104380007 ROC AUC: 0.9152261920061688
Validation loss: 0.37355093374280984 ROC AUC: 0.9322869811078268
Validation loss: 0.35438065168136107 ROC AUC: 0.9355802596067344
50 0 0.35886263847351074
Validation loss: 0.38069767936437066 ROC AUC: 0.9345199845778177
Validation loss: 0.36600082515475746 ROC AUC: 0.9428897313969926
Validation loss: 0.35486600501742777 ROC AUC: 0.9370100244184552
53 2 0.42826491594314575
Validation loss: 0.36671887150030574 ROC AUC: 0.931499807222722
Validation loss: 0.3988939033959337 ROC AUC: 0.9257325536563423
Validation loss: 0.355192975195233 ROC AUC: 0.9351786402775992
56 4 0.22900475561618805
Validation loss: 0.3545519050830352 ROC AUC: 0.9490425395193419
Validation loss: 0.34982811950729464 ROC AUC: 0.940190849505205
Validation loss: 0.33202491530435596 ROC AUC: 0.9472432849248169
59 6 0.45148494839668274
Validation loss: 0.33551342865985956 ROC AUC: 0.9400944608662126
Validation loss: 0.34140123471707284 ROC AUC: 0.9379739108083794
Validation loss: 0.2939586330929357 ROC AUC: 0.9517414214111297
62 8 0.39203140139579773
Validation loss: 0.327088380803565 ROC AUC: 0.9500867497750931
Validation loss: 0.32281786328804996 ROC AUC: 0.9548901169515487
Validation loss: 0.3004620173471963 ROC AUC: 0.9555327078781648
65 10 0.4690232574939728
Validation loss: 0.31344521562298217 ROC AUC: 0.957572934070171
Validation loss: 0.3105116739182291 ROC AUC: 0.9585207556869297
Validation loss: 0.29064816654564624 ROC AUC: 0.9546973396735638
68 12 0.5021891593933105
Validation loss: 0.31437222656601654 ROC AUC: 0.9590187636550572
Validation loss: 0.29851671808468316 ROC AUC: 0.9558379385683073
Validation loss: 0.27687584517714015 ROC AUC: 0.9612196375787174
71 14 0.3620345890522003
Validation loss: 0.3284525577434318 ROC AUC: 0.9536370646446473
Validation loss: 0.3065738487458659 ROC AUC: 0.9544403033029173
Validation loss: 0.2766072504625531 ROC AUC: 0.9621353296491453
Validation loss: 0.2952275182417256 ROC AUC: 0.9607698239300861
75 0 0.37198543548583984
Validation loss: 0.2770544140336509 ROC AUC: 0.9680150366276828
Validation loss: 0.2909787333680537 ROC AUC: 0.9617176455468449
Validation loss: 0.2778952678363166 ROC AUC: 0.9690271173371032
78 2 0.4095991849899292
Validation loss: 0.27799653845702954 ROC AUC: 0.9660872638478345
Validation loss: 0.26973548812235526 ROC AUC: 0.9670190206914279
Validation loss: 0.26451478979152765 ROC AUC: 0.9671957331962473
81 4 0.40428370237350464
Validation loss: 0.24776383673021932 ROC AUC: 0.9684809150494795
Validation loss: 0.2590315502010032 ROC AUC: 0.9722882662896799
Validation loss: 0.2578990512596581 ROC AUC: 0.9707942423852975
84 6 0.2208653837442398
Validation loss: 0.23274140648230282 ROC AUC: 0.9743606220280169
Validation loss: 0.2522785878611471 ROC AUC: 0.9703604935098317
Validation loss: 0.25275777414709866 ROC AUC: 0.9708263719316282
87 8 0.4211239516735077
Validation loss: 0.23249390918410612 ROC AUC: 0.9753727027374374
Validation loss: 0.2375470777312835 ROC AUC: 0.975163860686287
Validation loss: 0.22663810756617414 ROC AUC: 0.9779109368975709
90 10 0.2125556617975235
Validation loss: 0.24406265104581454 ROC AUC: 0.9739911322452127
Validation loss: 0.2163445180905367 ROC AUC: 0.9746337231718288
Validation loss: 0.242728912191305 ROC AUC: 0.9727541447114767
93 12 0.2523486018180847
Validation loss: 0.2396309937766654 ROC AUC: 0.9730272458552885
Validation loss: 0.23980343007372473 ROC AUC: 0.9760313584372189
Validation loss: 0.23877462523733686 ROC AUC: 0.9772040868782933
96 14 0.21793796122074127
Validation loss: 0.22475509814365593 ROC AUC: 0.9762402004883691
Validation loss: 0.23619959349622707 ROC AUC: 0.9722561367433492
Validation loss: 0.2349790831904612 ROC AUC: 0.976754273229662
Validation loss: 0.2551604808272723 ROC AUC: 0.9740393265647089
Loaded trained model with success.
Test loss: 0.5356968420160251 Test ROC AUC: 0.8377336047481238
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.7909753322601318
Validation loss: 1.6742138862609863 ROC AUC: 0.3
Validation loss: 1.6167575120925903 ROC AUC: 0.4375
Validation loss: 1.6186057329177856 ROC AUC: 0.6375
Validation loss: 1.664382815361023 ROC AUC: 0.6875
Validation loss: 1.7375471591949463 ROC AUC: 0.725
Validation loss: 1.8135266304016113 ROC AUC: 0.6875
Validation loss: 1.8974645137786865 ROC AUC: 0.7375
Validation loss: 1.9559361934661865 ROC AUC: 0.5625
Validation loss: 2.005363941192627 ROC AUC: 0.4875
Validation loss: 1.9840295314788818 ROC AUC: 0.4375
Validation loss: 1.9376291036605835 ROC AUC: 0.425
Validation loss: 1.825675368309021 ROC AUC: 0.425
Validation loss: 1.6960703134536743 ROC AUC: 0.475
Validation loss: 1.621395230293274 ROC AUC: 0.525
Validation loss: 1.523436427116394 ROC AUC: 0.575
Validation loss: 1.4718786478042603 ROC AUC: 0.5875
Validation loss: 1.415558099746704 ROC AUC: 0.6375
Validation loss: 1.3569718599319458 ROC AUC: 0.6625
Validation loss: 1.2751396894454956 ROC AUC: 0.7125
Validation loss: 1.1832022666931152 ROC AUC: 0.75
Validation loss: 1.1352152824401855 ROC AUC: 0.7875
Validation loss: 1.1207085847854614 ROC AUC: 0.75
Validation loss: 1.1102960109710693 ROC AUC: 0.75
Validation loss: 1.0901286602020264 ROC AUC: 0.75
Validation loss: 1.071765422821045 ROC AUC: 0.775
Validation loss: 1.0545477867126465 ROC AUC: 0.775
Validation loss: 1.0712405443191528 ROC AUC: 0.8
Validation loss: 1.056712031364441 ROC AUC: 0.85
Validation loss: 1.0533711910247803 ROC AUC: 0.875
Validation loss: 1.0531327724456787 ROC AUC: 0.875
Validation loss: 1.0855703353881836 ROC AUC: 0.85
Validation loss: 1.131547212600708 ROC AUC: 0.7875
Validation loss: 1.205053448677063 ROC AUC: 0.725
Validation loss: 1.2592780590057373 ROC AUC: 0.7
Validation loss: 1.2829134464263916 ROC AUC: 0.7
Validation loss: 1.3151065111160278 ROC AUC: 0.7
Validation loss: 1.285188913345337 ROC AUC: 0.7125
Validation loss: 1.2666431665420532 ROC AUC: 0.7125
Validation loss: 1.2405438423156738 ROC AUC: 0.725
Validation loss: 1.2299766540527344 ROC AUC: 0.75
Validation loss: 1.1958308219909668 ROC AUC: 0.7625
Validation loss: 1.160285472869873 ROC AUC: 0.775
Validation loss: 1.106947422027588 ROC AUC: 0.7875
Validation loss: 1.0962508916854858 ROC AUC: 0.7875
Validation loss: 1.0750889778137207 ROC AUC: 0.7875
Validation loss: 1.0831396579742432 ROC AUC: 0.7875
Validation loss: 1.086862325668335 ROC AUC: 0.775
Validation loss: 1.1024997234344482 ROC AUC: 0.775
Validation loss: 1.0808335542678833 ROC AUC: 0.8
Validation loss: 1.0735138654708862 ROC AUC: 0.8
50 0 0.7510287761688232
Validation loss: 1.0766901969909668 ROC AUC: 0.8
Validation loss: 1.0616525411605835 ROC AUC: 0.8
Validation loss: 1.0420563220977783 ROC AUC: 0.8
Validation loss: 1.0541834831237793 ROC AUC: 0.8
Validation loss: 1.079245924949646 ROC AUC: 0.8
Validation loss: 1.1187516450881958 ROC AUC: 0.775
Validation loss: 1.1272714138031006 ROC AUC: 0.775
Validation loss: 1.1262058019638062 ROC AUC: 0.775
Validation loss: 1.1103675365447998 ROC AUC: 0.775
Validation loss: 1.0754969120025635 ROC AUC: 0.7875
Validation loss: 1.0203356742858887 ROC AUC: 0.7875
Validation loss: 0.9761126041412354 ROC AUC: 0.8125
Validation loss: 0.9690673351287842 ROC AUC: 0.8125
Validation loss: 0.9615662097930908 ROC AUC: 0.8125
Validation loss: 0.9482809901237488 ROC AUC: 0.8125
Validation loss: 0.9391619563102722 ROC AUC: 0.8375
Validation loss: 0.9072663187980652 ROC AUC: 0.85
Validation loss: 0.857396125793457 ROC AUC: 0.875
Validation loss: 0.790671706199646 ROC AUC: 0.875
Validation loss: 0.7500835061073303 ROC AUC: 0.8875
Validation loss: 0.7376239895820618 ROC AUC: 0.8875
Validation loss: 0.7131607532501221 ROC AUC: 0.9125
Validation loss: 0.7128414511680603 ROC AUC: 0.9125
Validation loss: 0.7206131219863892 ROC AUC: 0.9375
Validation loss: 0.7486042380332947 ROC AUC: 0.9375
Validation loss: 0.7962006330490112 ROC AUC: 0.9375
Validation loss: 0.7887478470802307 ROC AUC: 0.925
Validation loss: 0.7767588496208191 ROC AUC: 0.9375
Validation loss: 0.7251850962638855 ROC AUC: 0.95
Validation loss: 0.6476033329963684 ROC AUC: 0.95
Validation loss: 0.6246858835220337 ROC AUC: 0.95
Validation loss: 0.593835711479187 ROC AUC: 0.95
Validation loss: 0.5627709627151489 ROC AUC: 0.95
Validation loss: 0.5409827828407288 ROC AUC: 0.95
Validation loss: 0.5195410251617432 ROC AUC: 0.975
Validation loss: 0.5141497254371643 ROC AUC: 0.975
Validation loss: 0.5121337175369263 ROC AUC: 0.975
Validation loss: 0.5440428256988525 ROC AUC: 0.95
Validation loss: 0.594005823135376 ROC AUC: 0.95
Validation loss: 0.626361608505249 ROC AUC: 0.95
Validation loss: 0.6317911148071289 ROC AUC: 0.95
Validation loss: 0.6414327621459961 ROC AUC: 0.95
Validation loss: 0.6604390740394592 ROC AUC: 0.95
Validation loss: 0.667003870010376 ROC AUC: 0.95
Validation loss: 0.6666908860206604 ROC AUC: 0.95
Validation loss: 0.6574237942695618 ROC AUC: 0.95
Validation loss: 0.6577814817428589 ROC AUC: 0.925
Validation loss: 0.619448184967041 ROC AUC: 0.925
Validation loss: 0.6042840480804443 ROC AUC: 0.9375
Validation loss: 0.5617128610610962 ROC AUC: 0.95
Loaded trained model with success.
Test loss: 5.469375155349457 Test ROC AUC: 0.4970471924534764
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.7163325548171997
Validation loss: 1.6166122665210647 ROC AUC: 0.5286111111111111
Validation loss: 1.677319548567947 ROC AUC: 0.5322222222222223
Validation loss: 1.7649905341012138 ROC AUC: 0.558
Validation loss: 1.8025952553262516 ROC AUC: 0.6078888888888889
Validation loss: 1.821016973378707 ROC AUC: 0.5535555555555556
Validation loss: 1.737700815103492 ROC AUC: 0.5689444444444444
Validation loss: 1.6548914836377513 ROC AUC: 0.5776666666666667
Validation loss: 1.595408860518008 ROC AUC: 0.5682777777777778
Validation loss: 1.5711683983705482 ROC AUC: 0.5972777777777778
Validation loss: 1.5614981432350314 ROC AUC: 0.6132777777777777
Validation loss: 1.5506137366197548 ROC AUC: 0.6168333333333333
Validation loss: 1.536632851678498 ROC AUC: 0.6167777777777778
Validation loss: 1.5251812423978532 ROC AUC: 0.6262222222222221
Validation loss: 1.5203763660119505 ROC AUC: 0.6272777777777778
Validation loss: 1.5111437233126894 ROC AUC: 0.6443333333333333
Validation loss: 1.51569956176135 ROC AUC: 0.6463888888888889
Validation loss: 1.5316419820396268 ROC AUC: 0.6408333333333334
Validation loss: 1.5501230249599534 ROC AUC: 0.6332777777777778
Validation loss: 1.5727039478263076 ROC AUC: 0.6288333333333334
Validation loss: 1.5721853533569647 ROC AUC: 0.6205555555555555
Validation loss: 1.5732577284988092 ROC AUC: 0.6263888888888889
Validation loss: 1.5845686416236722 ROC AUC: 0.6177777777777778
Validation loss: 1.5939477146888266 ROC AUC: 0.6136666666666667
Validation loss: 1.5660284976569974 ROC AUC: 0.6330555555555557
Validation loss: 1.5426865670145775 ROC AUC: 0.647
25 0 1.4814791679382324
Validation loss: 1.5170855522155762 ROC AUC: 0.6711111111111112
Validation loss: 1.5177202224731445 ROC AUC: 0.6656666666666667
Validation loss: 1.5191520501156242 ROC AUC: 0.6772777777777778
Validation loss: 1.5328502071147063 ROC AUC: 0.6878333333333334
Validation loss: 1.5451956087229204 ROC AUC: 0.6831666666666667
Validation loss: 1.5486866770958414 ROC AUC: 0.6743333333333333
Validation loss: 1.5672051493002443 ROC AUC: 0.6687222222222223
Validation loss: 1.5378008326705621 ROC AUC: 0.682888888888889
Validation loss: 1.5043044284898408 ROC AUC: 0.7037777777777778
Validation loss: 1.4798185509078357 ROC AUC: 0.7009444444444444
Validation loss: 1.4631837533444774 ROC AUC: 0.7118888888888889
Validation loss: 1.4599912117938607 ROC AUC: 0.7145
Validation loss: 1.4604174068995885 ROC AUC: 0.6752222222222223
Validation loss: 1.4658049782928155 ROC AUC: 0.6635
Validation loss: 1.480955111737154 ROC AUC: 0.6568333333333334
Validation loss: 1.4938514962488292 ROC AUC: 0.6516111111111111
Validation loss: 1.5035657079852358 ROC AUC: 0.6503888888888889
Validation loss: 1.4930855619664094 ROC AUC: 0.6677777777777779
Validation loss: 1.4859481466059783 ROC AUC: 0.6785
Validation loss: 1.4694415087602577 ROC AUC: 0.6861111111111111
Validation loss: 1.4562089126937243 ROC AUC: 0.6972777777777778
Validation loss: 1.4331363512545217 ROC AUC: 0.7056111111111111
Validation loss: 1.3975055923267288 ROC AUC: 0.7178888888888889
Validation loss: 1.3511891413708121 ROC AUC: 0.7352777777777778
Validation loss: 1.317935627333972 ROC AUC: 0.7297777777777777
50 0 1.421130657196045
Validation loss: 1.3020107064928328 ROC AUC: 0.7349444444444445
Validation loss: 1.2745910007126477 ROC AUC: 0.7434999999999999
Validation loss: 1.2493437747566067 ROC AUC: 0.7671111111111111
Validation loss: 1.2375832966395788 ROC AUC: 0.7891111111111111
Validation loss: 1.229833488561669 ROC AUC: 0.8029999999999999
Validation loss: 1.216981668861545 ROC AUC: 0.8077222222222222
Validation loss: 1.206742143144413 ROC AUC: 0.8008888888888889
Validation loss: 1.2047721147537231 ROC AUC: 0.7923888888888888
Validation loss: 1.199972719562297 ROC AUC: 0.7924444444444445
Validation loss: 1.1952202271442025 ROC AUC: 0.7987777777777778
Validation loss: 1.1845574232996727 ROC AUC: 0.8037222222222222
Validation loss: 1.1777406687639198 ROC AUC: 0.8053333333333332
Validation loss: 1.2291416100093298 ROC AUC: 0.8049999999999999
Validation loss: 1.2991562862785495 ROC AUC: 0.8004444444444443
Validation loss: 1.3345395861839762 ROC AUC: 0.7811666666666668
Validation loss: 1.309264521209561 ROC AUC: 0.7902222222222223
Validation loss: 1.2631321585908228 ROC AUC: 0.8089999999999999
Validation loss: 1.3440782975177377 ROC AUC: 0.8091666666666667
Validation loss: 1.4392292110287412 ROC AUC: 0.7939999999999999
Validation loss: 1.3586769176989186 ROC AUC: 0.7993888888888889
Validation loss: 1.2850058297721707 ROC AUC: 0.8137222222222222
Validation loss: 1.268981653816846 ROC AUC: 0.8031111111111111
Validation loss: 1.3037925885648143 ROC AUC: 0.7813888888888888
Validation loss: 1.2520674223802528 ROC AUC: 0.7892222222222223
Validation loss: 1.1788408561628692 ROC AUC: 0.8000555555555555
75 0 1.0981926918029785
Validation loss: 1.098690711722082 ROC AUC: 0.8246111111111111
Validation loss: 1.0906351950703834 ROC AUC: 0.8410555555555554
Validation loss: 1.077626347541809 ROC AUC: 0.8657777777777778
Validation loss: 0.9928799673002593 ROC AUC: 0.8728333333333333
Validation loss: 0.9452825018337795 ROC AUC: 0.8820000000000002
Validation loss: 0.9517246326621698 ROC AUC: 0.8875
Validation loss: 0.9555955833318283 ROC AUC: 0.8872222222222221
Validation loss: 0.9699817482306032 ROC AUC: 0.8862222222222222
Validation loss: 0.9713954803894977 ROC AUC: 0.8848888888888891
Validation loss: 1.01655582992398 ROC AUC: 0.8712222222222223
Validation loss: 1.0849081715758966 ROC AUC: 0.8675
Validation loss: 1.0863343063665896 ROC AUC: 0.8737222222222222
Validation loss: 1.0713426665383943 ROC AUC: 0.8644444444444443
Validation loss: 1.0433583697494195 ROC AUC: 0.8562222222222221
Validation loss: 0.978733634462162 ROC AUC: 0.8648333333333333
Validation loss: 0.9656271727717652 ROC AUC: 0.8662777777777778
Validation loss: 0.9511814421536972 ROC AUC: 0.863111111111111
Validation loss: 0.9434376456299607 ROC AUC: 0.8622777777777777
Validation loss: 0.916532251299644 ROC AUC: 0.8722222222222223
Validation loss: 0.8402603998476145 ROC AUC: 0.8927222222222222
Validation loss: 0.7902713186886846 ROC AUC: 0.9027777777777779
Validation loss: 0.7666387533654972 ROC AUC: 0.9093333333333332
Validation loss: 0.766654372215271 ROC AUC: 0.9126111111111109
Validation loss: 0.7487134094140968 ROC AUC: 0.9157777777777778
Validation loss: 0.7450127066398153 ROC AUC: 0.9199999999999999
Loaded trained model with success.
Test loss: 3.4354456211180864 Test ROC AUC: 0.5293292770581557
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.7081345319747925
Validation loss: 1.6665441484162302 ROC AUC: 0.4891381578947368
Validation loss: 1.6982496820314965 ROC AUC: 0.5315986842105264
Validation loss: 1.73774596416589 ROC AUC: 0.5679934210526316
Validation loss: 1.737188002075812 ROC AUC: 0.5544736842105263
Validation loss: 1.62232973960915 ROC AUC: 0.5718026315789473
Validation loss: 1.6005787596558079 ROC AUC: 0.5297828947368421
Validation loss: 1.6250289040382462 ROC AUC: 0.5417368421052631
Validation loss: 1.6187812571573739 ROC AUC: 0.5572565789473684
Validation loss: 1.6217140621609158 ROC AUC: 0.573296052631579
Validation loss: 1.5970423305877532 ROC AUC: 0.5717039473684211
Validation loss: 1.5777412363977144 ROC AUC: 0.5661513157894736
Validation loss: 1.5786165384331134 ROC AUC: 0.5707302631578947
12 2 1.5773391723632812
Validation loss: 1.6198369228478633 ROC AUC: 0.5674802631578947
Validation loss: 1.6314818835017657 ROC AUC: 0.5642631578947368
Validation loss: 1.6259564101093946 ROC AUC: 0.5648618421052631
Validation loss: 1.6068982487977153 ROC AUC: 0.5679342105263159
Validation loss: 1.6338351736165055 ROC AUC: 0.5693223684210527
Validation loss: 1.6602088333380343 ROC AUC: 0.6028947368421054
Validation loss: 1.6173160015934644 ROC AUC: 0.5696907894736841
Validation loss: 1.5922208037039247 ROC AUC: 0.5764144736842105
Validation loss: 1.5822153247968116 ROC AUC: 0.6131052631578947
Validation loss: 1.587577506749317 ROC AUC: 0.6226710526315788
Validation loss: 1.6097290792850534 ROC AUC: 0.5996118421052632
Validation loss: 1.5769477938160752 ROC AUC: 0.636203947368421
Validation loss: 1.5348694745940392 ROC AUC: 0.6315921052631579
25 0 1.5841186046600342
Validation loss: 1.5445487053707392 ROC AUC: 0.6396776315789474
Validation loss: 1.5785036363987008 ROC AUC: 0.6217236842105264
Validation loss: 1.5909522470801767 ROC AUC: 0.6258552631578947
Validation loss: 1.589936536971969 ROC AUC: 0.6293486842105263
Validation loss: 1.5306530853714606 ROC AUC: 0.6456513157894737
Validation loss: 1.5196872010375515 ROC AUC: 0.6551513157894738
Validation loss: 1.5106039817887122 ROC AUC: 0.6606447368421053
Validation loss: 1.5170824347120342 ROC AUC: 0.6536973684210526
Validation loss: 1.5206567590886897 ROC AUC: 0.6831315789473684
Validation loss: 1.5223918671559806 ROC AUC: 0.6757039473684211
Validation loss: 1.5205332064869428 ROC AUC: 0.6805592105263158
Validation loss: 1.504837008437725 ROC AUC: 0.6845263157894738
37 2 1.526017427444458
Validation loss: 1.4847551704657198 ROC AUC: 0.6817434210526315
Validation loss: 1.4739857273872452 ROC AUC: 0.6737763157894736
Validation loss: 1.4810646531557796 ROC AUC: 0.6807302631578948
Validation loss: 1.4873942642500906 ROC AUC: 0.6971315789473683
Validation loss: 1.4652816984388564 ROC AUC: 0.7027763157894736
Validation loss: 1.472967919677195 ROC AUC: 0.7025986842105263
Validation loss: 1.483545133561799 ROC AUC: 0.7099013157894736
Validation loss: 1.4359470750346328 ROC AUC: 0.7096973684210527
Validation loss: 1.407667804245997 ROC AUC: 0.7179473684210527
Validation loss: 1.4067044390572443 ROC AUC: 0.7282171052631579
Validation loss: 1.4590899017122057 ROC AUC: 0.6968026315789474
Validation loss: 1.539423000932944 ROC AUC: 0.6823289473684211
Validation loss: 1.5828073084956469 ROC AUC: 0.6800986842105263
50 0 1.3633354902267456
Validation loss: 1.5958619840217358 ROC AUC: 0.6815921052631578
Validation loss: 1.5413855747743086 ROC AUC: 0.695
Validation loss: 1.520326372348901 ROC AUC: 0.7045921052631579
Validation loss: 1.5022786277713198 ROC AUC: 0.7055263157894737
Validation loss: 1.4093814143026717 ROC AUC: 0.7307763157894738
Validation loss: 1.342588525829893 ROC AUC: 0.7619736842105264
Validation loss: 1.3063952706076882 ROC AUC: 0.7741315789473685
Validation loss: 1.3154218991597493 ROC AUC: 0.7636776315789473
Validation loss: 1.3022391687739978 ROC AUC: 0.7776842105263159
Validation loss: 1.3097038738655322 ROC AUC: 0.7712434210526317
Validation loss: 1.3048504061169095 ROC AUC: 0.7629802631578947
Validation loss: 1.268368630698233 ROC AUC: 0.7814342105263158
62 2 1.2961615324020386
Validation loss: 1.2159765284470838 ROC AUC: 0.8067565789473683
Validation loss: 1.2088909805423083 ROC AUC: 0.8327763157894736
Validation loss: 1.2230229365705239 ROC AUC: 0.8166184210526316
Validation loss: 1.2429493978770092 ROC AUC: 0.802375
Validation loss: 1.2523747845129534 ROC AUC: 0.7892434210526315
Validation loss: 1.2756966653496329 ROC AUC: 0.7816776315789473
Validation loss: 1.2202681724471276 ROC AUC: 0.8050394736842105
Validation loss: 1.239200831663729 ROC AUC: 0.794875
Validation loss: 1.2166156588178691 ROC AUC: 0.7878881578947369
Validation loss: 1.2021109732714566 ROC AUC: 0.7957697368421053
Validation loss: 1.2056129869788583 ROC AUC: 0.8067302631578948
Validation loss: 1.2842945938158516 ROC AUC: 0.7741644736842105
Validation loss: 1.2560809164336233 ROC AUC: 0.7931710526315789
75 0 1.279919981956482
Validation loss: 1.2278267891720087 ROC AUC: 0.811046052631579
Validation loss: 1.2037159565723303 ROC AUC: 0.8229934210526316
Validation loss: 1.207167023360127 ROC AUC: 0.8253421052631579
Validation loss: 1.211563041715911 ROC AUC: 0.8284276315789475
Validation loss: 1.1656252916413123 ROC AUC: 0.8355592105263158
Validation loss: 1.1345379557272401 ROC AUC: 0.8446118421052633
Validation loss: 1.1370632323351773 ROC AUC: 0.8425460526315789
Validation loss: 1.1056840010363647 ROC AUC: 0.8509736842105264
Validation loss: 1.0734432562433107 ROC AUC: 0.8622565789473684
Validation loss: 1.0431089696258005 ROC AUC: 0.8724144736842107
Validation loss: 1.0282241906782594 ROC AUC: 0.8653157894736843
Validation loss: 1.0136991444260184 ROC AUC: 0.8642828947368422
87 2 1.2345199584960938
Validation loss: 1.0322238200842733 ROC AUC: 0.8576381578947367
Validation loss: 1.051997250980801 ROC AUC: 0.8582697368421053
Validation loss: 1.0628234015570746 ROC AUC: 0.8641644736842105
Validation loss: 1.0965270815473613 ROC AUC: 0.8533026315789474
Validation loss: 1.0625381391457838 ROC AUC: 0.8607828947368421
Validation loss: 1.0844586184530547 ROC AUC: 0.8559473684210527
Validation loss: 1.063268118434482 ROC AUC: 0.8591315789473685
Validation loss: 0.9938695870264612 ROC AUC: 0.8746776315789473
Validation loss: 0.9656269327558652 ROC AUC: 0.889059210526316
Validation loss: 0.9602438554619298 ROC AUC: 0.8942697368421053
Validation loss: 0.9300511184364858 ROC AUC: 0.8952434210526317
Validation loss: 0.912746791887765 ROC AUC: 0.8906907894736842
Validation loss: 0.9382115566369259 ROC AUC: 0.8857302631578948
Loaded trained model with success.
Test loss: 1.7430322031102756 Test ROC AUC: 0.6262003641026126
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.7590916156768799
Validation loss: 1.6540867299889799 ROC AUC: 0.5097616185897437
Validation loss: 1.82715576617562 ROC AUC: 0.5192924679487179
Validation loss: 1.6820387750414747 ROC AUC: 0.5314142628205129
Validation loss: 1.6158890400699635 ROC AUC: 0.5647395833333334
Validation loss: 1.594666803901519 ROC AUC: 0.5627307692307693
Validation loss: 1.579123532352735 ROC AUC: 0.5751137820512822
Validation loss: 1.5836249625862544 ROC AUC: 0.5877323717948718
7 1 1.62395441532135
Validation loss: 1.6054950377449917 ROC AUC: 0.5733822115384616
Validation loss: 1.5711842080456528 ROC AUC: 0.583994391025641
Validation loss: 1.5803785120422518 ROC AUC: 0.5843701923076923
Validation loss: 1.577974409913298 ROC AUC: 0.5870056089743588
Validation loss: 1.5663004448665447 ROC AUC: 0.595403044871795
Validation loss: 1.555352284680659 ROC AUC: 0.6144070512820513
Validation loss: 1.5766879529809232 ROC AUC: 0.6171442307692308
14 2 1.5059014558792114
Validation loss: 1.5723291216184145 ROC AUC: 0.611670673076923
Validation loss: 1.5621136648571072 ROC AUC: 0.6205320512820514
Validation loss: 1.5489585465522269 ROC AUC: 0.6385977564102564
Validation loss: 1.5311655584891237 ROC AUC: 0.652954326923077
Validation loss: 1.5063859793409031 ROC AUC: 0.6616338141025642
Validation loss: 1.5020596765393588 ROC AUC: 0.6656065705128205
Validation loss: 1.5355127336990892 ROC AUC: 0.6621891025641026
21 3 1.4317545890808105
Validation loss: 1.4980950421424368 ROC AUC: 0.6667972756410256
Validation loss: 1.5022633135618277 ROC AUC: 0.6726586538461538
Validation loss: 1.5071861096962014 ROC AUC: 0.6624198717948717
Validation loss: 1.504494436422185 ROC AUC: 0.6866113782051283
Validation loss: 1.4989785584972133 ROC AUC: 0.6895913461538462
Validation loss: 1.4410144563895375 ROC AUC: 0.7267916666666666
Validation loss: 1.405230725230883 ROC AUC: 0.7474951923076923
28 4 1.4640346765518188
Validation loss: 1.4081410499074352 ROC AUC: 0.7542540064102564
Validation loss: 1.3928202594344938 ROC AUC: 0.7569623397435896
Validation loss: 1.388250612733352 ROC AUC: 0.7638293269230769
Validation loss: 1.3190500646380323 ROC AUC: 0.7777403846153846
Validation loss: 1.3276269981010476 ROC AUC: 0.7653782051282051
Validation loss: 1.3084540492925212 ROC AUC: 0.782
Validation loss: 1.312080298236866 ROC AUC: 0.789241185897436
35 5 1.324137568473816
Validation loss: 1.274681681364625 ROC AUC: 0.7957820512820513
Validation loss: 1.193624778608581 ROC AUC: 0.8158645833333334
Validation loss: 1.1481699638031235 ROC AUC: 0.8393926282051283
Validation loss: 1.1742768170845568 ROC AUC: 0.850838141025641
Validation loss: 1.1976936534421527 ROC AUC: 0.8440841346153846
Validation loss: 1.2443055429650312 ROC AUC: 0.8272459935897436
Validation loss: 1.199212779950856 ROC AUC: 0.8144567307692308
42 6 1.2337913513183594
Validation loss: 1.1568567974483548 ROC AUC: 0.8402315705128205
Validation loss: 1.1693612187352014 ROC AUC: 0.8356097756410257
Validation loss: 1.147751219308556 ROC AUC: 0.8283028846153847
Validation loss: 1.1207106553729456 ROC AUC: 0.8495881410256411
Validation loss: 1.1438847283023086 ROC AUC: 0.8572115384615385
Validation loss: 1.0938569427135603 ROC AUC: 0.8670368589743589
Validation loss: 1.083537772971781 ROC AUC: 0.8697451923076922
Validation loss: 1.0644545860625991 ROC AUC: 0.871573717948718
50 0 1.3878395557403564
Validation loss: 1.1014308252526288 ROC AUC: 0.870110576923077
Validation loss: 1.092900079698419 ROC AUC: 0.866869391025641
Validation loss: 1.0147362869588574 ROC AUC: 0.8898036858974357
Validation loss: 0.9486129760143146 ROC AUC: 0.8991057692307691
Validation loss: 0.9473197609934975 ROC AUC: 0.8992836538461537
Validation loss: 1.0036472576347428 ROC AUC: 0.8776666666666667
Validation loss: 1.0685040741110567 ROC AUC: 0.8627612179487179
57 1 1.015588641166687
Validation loss: 1.0249984581865856 ROC AUC: 0.8752299679487179
Validation loss: 1.0291796377555809 ROC AUC: 0.8709479166666666
Validation loss: 0.9588732988990132 ROC AUC: 0.8879527243589743
Validation loss: 1.0307012892248641 ROC AUC: 0.8873052884615384
Validation loss: 0.9816293917109619 ROC AUC: 0.8872163461538461
Validation loss: 0.9826713533856761 ROC AUC: 0.8803092948717948
Validation loss: 1.04135320474155 ROC AUC: 0.8773125
64 2 1.1983582973480225
Validation loss: 0.8951524409217451 ROC AUC: 0.9061145833333333
Validation loss: 0.9501258925576905 ROC AUC: 0.8817620192307694
Validation loss: 1.0065080265902995 ROC AUC: 0.8740360576923077
Validation loss: 0.8901408353642603 ROC AUC: 0.9165248397435896
Validation loss: 0.9222847043569363 ROC AUC: 0.9050897435897436
Validation loss: 0.9521643762013421 ROC AUC: 0.9037403846153846
Validation loss: 0.918827805087794 ROC AUC: 0.9109887820512821
71 3 0.9511048793792725
Validation loss: 0.8527826801616343 ROC AUC: 0.9152788461538461
Validation loss: 0.92102454475422 ROC AUC: 0.9030072115384616
Validation loss: 1.013032186570479 ROC AUC: 0.8951738782051283
Validation loss: 0.937790078134393 ROC AUC: 0.9080064102564102
Validation loss: 0.849961069960091 ROC AUC: 0.9186258012820513
Validation loss: 0.8331340401615929 ROC AUC: 0.9179911858974359
Validation loss: 0.8516753618441635 ROC AUC: 0.9199439102564103
78 4 0.8305971026420593
Validation loss: 0.7794607455406956 ROC AUC: 0.9309439102564104
Validation loss: 0.7873318828829569 ROC AUC: 0.9245112179487179
Validation loss: 0.9142441240387347 ROC AUC: 0.911372596153846
Validation loss: 0.7915893065270467 ROC AUC: 0.9243725961538463
Validation loss: 0.7777906197998392 ROC AUC: 0.9271899038461537
Validation loss: 0.8086229646625231 ROC AUC: 0.9220376602564102
Validation loss: 0.8901099388922878 ROC AUC: 0.9112588141025639
85 5 0.9535122513771057
Validation loss: 0.8431973061968933 ROC AUC: 0.9122107371794872
Validation loss: 0.7916758806262184 ROC AUC: 0.9218741987179488
Validation loss: 0.764458992672925 ROC AUC: 0.932625
Validation loss: 0.8755091081312554 ROC AUC: 0.9226923076923077
Validation loss: 0.7629578547861109 ROC AUC: 0.9404967948717949
Validation loss: 0.8139885520216209 ROC AUC: 0.930523237179487
Validation loss: 0.8540906492789188 ROC AUC: 0.926895032051282
92 6 1.2929073572158813
Validation loss: 0.806391824879239 ROC AUC: 0.931485576923077
Validation loss: 0.8015650888184207 ROC AUC: 0.931613782051282
Validation loss: 0.7595917064340869 ROC AUC: 0.9341201923076923
Validation loss: 0.7482559950507466 ROC AUC: 0.934488782051282
Validation loss: 0.859961107148597 ROC AUC: 0.9226530448717949
Validation loss: 0.7994591863311116 ROC AUC: 0.9312564102564103
Validation loss: 0.703191028168453 ROC AUC: 0.9324310897435897
Validation loss: 0.7454567713354101 ROC AUC: 0.9325737179487179
Loaded trained model with success.
Test loss: 1.8289697295150174 Test ROC AUC: 0.6738607861944381
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.706025242805481
Validation loss: 1.6372009250587356 ROC AUC: 0.5223542008486564
Validation loss: 1.6142125822499185 ROC AUC: 0.5437005799151343
Validation loss: 1.7066002517998338 ROC AUC: 0.5243202212568195
3 2 1.6494832038879395
Validation loss: 1.6158534345741502 ROC AUC: 0.5467684501919579
Validation loss: 1.7494017504499049 ROC AUC: 0.5350229566579108
Validation loss: 1.812840746256536 ROC AUC: 0.5368833996767024
6 4 1.7377263307571411
Validation loss: 1.7131042026565644 ROC AUC: 0.5329517690442515
Validation loss: 1.6655032020771432 ROC AUC: 0.5521219741361891
Validation loss: 1.611075769923254 ROC AUC: 0.5936160759749444
9 6 1.6270447969436646
Validation loss: 1.6908967100785586 ROC AUC: 0.579410864821176
Validation loss: 1.621327201445738 ROC AUC: 0.5760242493433018
Validation loss: 1.6459903619093503 ROC AUC: 0.6084459870680946
12 8 1.5152422189712524
Validation loss: 1.6190358142336767 ROC AUC: 0.6443273287532836
Validation loss: 1.5909029431715758 ROC AUC: 0.6302865932511618
Validation loss: 1.5753884611722224 ROC AUC: 0.6481900070721358
15 10 1.531770944595337
Validation loss: 1.5192268102584716 ROC AUC: 0.67465414427157
Validation loss: 1.4922722417988137 ROC AUC: 0.7005415104061428
Validation loss: 1.5307745811695566 ROC AUC: 0.6692645696100221
18 12 1.5622363090515137
Validation loss: 1.4165044886793545 ROC AUC: 0.7138737643968479
Validation loss: 1.3997218016393198 ROC AUC: 0.723988702768236
Validation loss: 1.3601110767505928 ROC AUC: 0.7570772388361285
21 14 1.6435123682022095
Validation loss: 1.3501441877686189 ROC AUC: 0.762207639927258
Validation loss: 1.378035164309408 ROC AUC: 0.7373586552838958
Validation loss: 1.2722202314881381 ROC AUC: 0.7819292746009295
Validation loss: 1.3194729973653514 ROC AUC: 0.7647566084057386
25 0 1.423662781715393
Validation loss: 1.2912217278279856 ROC AUC: 0.78028743281471
Validation loss: 1.2614245613017876 ROC AUC: 0.7813308890684987
Validation loss: 1.2839380144356247 ROC AUC: 0.7757036168923015
28 2 1.374772071838379
Validation loss: 1.3170287014248376 ROC AUC: 0.788551279046272
Validation loss: 1.2794931044798337 ROC AUC: 0.7790632026672055
Validation loss: 1.3488829998310679 ROC AUC: 0.7842739664578703
31 4 1.432361125946045
Validation loss: 1.2929437334886296 ROC AUC: 0.7978315104061426
Validation loss: 1.2452090426771818 ROC AUC: 0.7931663911901393
Validation loss: 1.2626261297829882 ROC AUC: 0.7920423570418267
34 6 1.4398974180221558
Validation loss: 1.263743053935095 ROC AUC: 0.7891702838957365
Validation loss: 1.20180765660349 ROC AUC: 0.7975576409375631
Validation loss: 1.1771787283176889 ROC AUC: 0.8138298090523339
37 8 1.3357950448989868
Validation loss: 1.239560268684953 ROC AUC: 0.7982845877955143
Validation loss: 1.2258646571803427 ROC AUC: 0.8122944534249343
Validation loss: 1.2730947861929456 ROC AUC: 0.7954745908264297
40 10 1.2864006757736206
Validation loss: 1.2130174519781598 ROC AUC: 0.8075403596686199
Validation loss: 1.183905832992049 ROC AUC: 0.8119625399070518
Validation loss: 1.1986882161042973 ROC AUC: 0.815392152960194
43 12 1.2915704250335693
Validation loss: 1.1915891034330777 ROC AUC: 0.8235443968478482
Validation loss: 1.1172834718394613 ROC AUC: 0.8320444018993737
Validation loss: 1.125502292044416 ROC AUC: 0.8331018326934736
46 14 1.2250456809997559
Validation loss: 1.148376432114947 ROC AUC: 0.82600959486765
Validation loss: 1.1251478750624495 ROC AUC: 0.835381315417256
Validation loss: 1.1242793201205725 ROC AUC: 0.8316302283289554
Validation loss: 1.0755917541010824 ROC AUC: 0.8445462396443727
50 0 1.0341596603393555
Validation loss: 1.0572723147864331 ROC AUC: 0.8456510143463326
Validation loss: 1.0269267244902784 ROC AUC: 0.8587095797130733
Validation loss: 1.0840854981619275 ROC AUC: 0.8451066882198424
53 2 1.255470871925354
Validation loss: 1.0526128432793704 ROC AUC: 0.8521901212366135
Validation loss: 1.0718294979336267 ROC AUC: 0.8462078682562135
Validation loss: 1.0516051350232356 ROC AUC: 0.8512799787835925
56 4 1.1874481439590454
Validation loss: 1.029130525483875 ROC AUC: 0.8589304344311982
Validation loss: 1.0413942709714472 ROC AUC: 0.8548155283895736
Validation loss: 1.0309642151983562 ROC AUC: 0.863638945241463
59 6 1.1523869037628174
Validation loss: 0.9903287209107546 ROC AUC: 0.8658604859567589
Validation loss: 0.9805115279788245 ROC AUC: 0.8672948848252172
Validation loss: 1.0186609058437461 ROC AUC: 0.8590428510810264
62 8 1.1239380836486816
Validation loss: 1.0131385844790626 ROC AUC: 0.8616113022832895
Validation loss: 0.990103513898257 ROC AUC: 0.8676895110123256
Validation loss: 1.013773667907906 ROC AUC: 0.8624843099616084
65 10 1.1076767444610596
Validation loss: 0.9537882100126308 ROC AUC: 0.8778975005051526
Validation loss: 1.026064307871228 ROC AUC: 0.8551395403111739
Validation loss: 0.9615092901046386 ROC AUC: 0.8770288967468176
68 12 0.9562821984291077
Validation loss: 0.9911304494899834 ROC AUC: 0.8670456829662558
Validation loss: 0.9685410128566688 ROC AUC: 0.873988046069913
Validation loss: 0.9403432653041067 ROC AUC: 0.8812380571832692
71 14 1.2800517082214355
Validation loss: 0.9958062154018807 ROC AUC: 0.8724974934330169
Validation loss: 0.9461053947886389 ROC AUC: 0.8779852808648212
Validation loss: 0.9365844684755635 ROC AUC: 0.8817023277429785
Validation loss: 0.922405713904119 ROC AUC: 0.8833254354415032
75 0 1.1367154121398926
Validation loss: 0.9111022686432741 ROC AUC: 0.8895469094766618
Validation loss: 0.9147953907091297 ROC AUC: 0.88542702768236
Validation loss: 0.974250616673716 ROC AUC: 0.8741598848252172
78 2 0.8828161954879761
Validation loss: 0.893657699854436 ROC AUC: 0.8910868054152357
Validation loss: 0.9234854436828521 ROC AUC: 0.8861157516670033
Validation loss: 0.8732418916029538 ROC AUC: 0.8969254819155387
81 4 1.0261510610580444
Validation loss: 0.887745346119982 ROC AUC: 0.8927788432006466
Validation loss: 0.8896907565588942 ROC AUC: 0.894221281066882
Validation loss: 0.8479486609508614 ROC AUC: 0.903851208324914
84 6 1.0254935026168823
Validation loss: 0.8634339089622957 ROC AUC: 0.9064781006263892
Validation loss: 0.929415322974593 ROC AUC: 0.8896496170943623
Validation loss: 0.8504457261137112 ROC AUC: 0.9059861780157605
87 8 1.1957168579101562
Validation loss: 0.8350079601895594 ROC AUC: 0.9059331491210345
Validation loss: 0.8530105986671601 ROC AUC: 0.9068231036573046
Validation loss: 0.8028229240902918 ROC AUC: 0.917889964639321
90 10 1.1550780534744263
Validation loss: 0.8508377924471915 ROC AUC: 0.9068818943220851
Validation loss: 0.8118881012251478 ROC AUC: 0.9135287724792887
Validation loss: 0.8302997319636221 ROC AUC: 0.911802081228531
93 12 0.8572326302528381
Validation loss: 0.8470009512796192 ROC AUC: 0.9138714932309557
Validation loss: 0.858736825968794 ROC AUC: 0.9029793897757121
Validation loss: 0.7893336283300587 ROC AUC: 0.9195713063245099
96 14 0.921671450138092
Validation loss: 0.8093784357120614 ROC AUC: 0.9198190523338049
Validation loss: 0.8215756502323495 ROC AUC: 0.9134084128106688
Validation loss: 0.7859646399656613 ROC AUC: 0.9221598828046069
Validation loss: 0.7658077184566277 ROC AUC: 0.9295736047686403
Loaded trained model with success.
Test loss: 1.4660664678386828 Test ROC AUC: 0.7563315383908605
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 16.304973602294922
Validation loss: 12.94649600982666 MAE: 3.111402
Validation loss: 9.501909255981445 MAE: 2.4973438
Validation loss: 6.687620162963867 MAE: 1.9477762
Validation loss: 4.641534805297852 MAE: 1.6161976
Validation loss: 3.4971835613250732 MAE: 1.5582322
Validation loss: 3.3154244422912598 MAE: 1.637311
Validation loss: 4.19589900970459 MAE: 1.7591891
Validation loss: 5.629247188568115 MAE: 1.9776862
Validation loss: 7.647769451141357 MAE: 2.4098263
Validation loss: 10.492136001586914 MAE: 2.8722754
Validation loss: 12.917736053466797 MAE: 3.19769
Validation loss: 15.312262535095215 MAE: 3.4807029
Validation loss: 16.440719604492188 MAE: 3.6311717
Validation loss: 16.537302017211914 MAE: 3.6446428
Validation loss: 16.94529914855957 MAE: 3.7003818
Validation loss: 16.23675537109375 MAE: 3.603536
Validation loss: 15.006757736206055 MAE: 3.4459856
Validation loss: 13.541088104248047 MAE: 3.274177
Validation loss: 11.77370548248291 MAE: 3.0498283
Validation loss: 9.842693328857422 MAE: 2.7761354
Validation loss: 8.529582977294922 MAE: 2.5663328
Validation loss: 7.44954252243042 MAE: 2.374078
Validation loss: 6.693179607391357 MAE: 2.2240424
Validation loss: 6.104905128479004 MAE: 2.095544
Validation loss: 5.7621965408325195 MAE: 2.0143087
Validation loss: 5.515761375427246 MAE: 1.9557629
Validation loss: 5.32084846496582 MAE: 1.9231474
Validation loss: 4.967533588409424 MAE: 1.863205
Validation loss: 4.324579238891602 MAE: 1.7821844
Validation loss: 3.717066764831543 MAE: 1.6903626
Validation loss: 3.2828378677368164 MAE: 1.6093278
Validation loss: 2.8792049884796143 MAE: 1.5083351
Validation loss: 2.588365077972412 MAE: 1.4129868
Validation loss: 2.270470380783081 MAE: 1.270332
Validation loss: 2.0807600021362305 MAE: 1.1463761
Validation loss: 1.9577367305755615 MAE: 1.0616403
Validation loss: 1.903382420539856 MAE: 1.0584881
Validation loss: 1.9164214134216309 MAE: 1.0787338
Validation loss: 2.002192497253418 MAE: 1.1285139
Validation loss: 2.1007134914398193 MAE: 1.1636977
Validation loss: 2.2675046920776367 MAE: 1.2036405
Validation loss: 2.462214946746826 MAE: 1.235633
Validation loss: 2.5112500190734863 MAE: 1.2379112
Validation loss: 2.5860116481781006 MAE: 1.2426924
Validation loss: 2.5390827655792236 MAE: 1.2268758
Validation loss: 2.603292226791382 MAE: 1.2295427
Validation loss: 2.5449018478393555 MAE: 1.213434
Validation loss: 2.5513858795166016 MAE: 1.2055029
Validation loss: 2.501173257827759 MAE: 1.1878713
Validation loss: 2.4785854816436768 MAE: 1.1745358
50 0 1.000726342201233
Validation loss: 2.5449512004852295 MAE: 1.1754893
Validation loss: 2.70961594581604 MAE: 1.2136064
Validation loss: 2.702465772628784 MAE: 1.2115318
Validation loss: 2.744518756866455 MAE: 1.2202973
Validation loss: 2.726388692855835 MAE: 1.2143435
Validation loss: 2.6113901138305664 MAE: 1.1830684
Validation loss: 2.580252170562744 MAE: 1.1717442
Validation loss: 2.4663732051849365 MAE: 1.1382957
Validation loss: 2.437730312347412 MAE: 1.1283319
Validation loss: 2.3707141876220703 MAE: 1.1090808
Validation loss: 2.2457940578460693 MAE: 1.0737108
Validation loss: 2.168126106262207 MAE: 1.0514233
Validation loss: 2.0021026134490967 MAE: 1.0002849
Validation loss: 1.8944928646087646 MAE: 0.9664703
Validation loss: 1.8788501024246216 MAE: 0.9575961
Validation loss: 1.8223824501037598 MAE: 0.9366349
Validation loss: 1.8083869218826294 MAE: 0.9291246
Validation loss: 1.7788437604904175 MAE: 0.9172441
Validation loss: 1.7406679391860962 MAE: 0.9031909
Validation loss: 1.7500756978988647 MAE: 0.90562177
Validation loss: 1.7460485696792603 MAE: 0.9039826
Validation loss: 1.744215488433838 MAE: 0.90380394
Validation loss: 1.7278175354003906 MAE: 0.8994715
Validation loss: 1.7354791164398193 MAE: 0.9033631
Validation loss: 1.7233061790466309 MAE: 0.9003898
Validation loss: 1.689677357673645 MAE: 0.889582
Validation loss: 1.68927800655365 MAE: 0.88967365
Validation loss: 1.7405524253845215 MAE: 0.9071248
Validation loss: 1.7194334268569946 MAE: 0.8990488
Validation loss: 1.6998218297958374 MAE: 0.8906484
Validation loss: 1.7181252241134644 MAE: 0.903491
Validation loss: 1.7808823585510254 MAE: 0.934553
Validation loss: 1.8590929508209229 MAE: 0.97147346
Validation loss: 1.9374632835388184 MAE: 1.0064794
Validation loss: 2.0276412963867188 MAE: 1.0442564
Validation loss: 2.064044952392578 MAE: 1.059338
Validation loss: 2.09149169921875 MAE: 1.0696113
Validation loss: 2.2179856300354004 MAE: 1.1259296
Validation loss: 2.2526612281799316 MAE: 1.1423364
Validation loss: 2.2716586589813232 MAE: 1.1513668
Validation loss: 2.20363712310791 MAE: 1.124144
Validation loss: 2.2451171875 MAE: 1.1410842
Validation loss: 2.266604423522949 MAE: 1.148824
Validation loss: 2.3372912406921387 MAE: 1.1783599
Validation loss: 2.3725950717926025 MAE: 1.1885139
Validation loss: 2.323789119720459 MAE: 1.1700913
Validation loss: 2.2471249103546143 MAE: 1.1457937
Validation loss: 2.229673147201538 MAE: 1.1419835
Validation loss: 2.151681661605835 MAE: 1.1165395
Validation loss: 2.120224714279175 MAE: 1.107272
Loaded trained model with success.
Test loss: 8.818165807163014 Test MAE: 2.404879
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 24.391429901123047
Validation loss: 19.427952863732163 MAE: 3.8189166
Validation loss: 11.287169631646604 MAE: 2.7705088
Validation loss: 6.226474635455073 MAE: 2.0554135
Validation loss: 4.928695279724744 MAE: 1.8893543
Validation loss: 8.01862333258804 MAE: 2.3170552
Validation loss: 14.32328632899693 MAE: 3.1862283
Validation loss: 19.64152258269641 MAE: 3.8775797
Validation loss: 21.16585875530632 MAE: 4.0552025
Validation loss: 19.49730717405981 MAE: 3.860389
Validation loss: 15.376827045362823 MAE: 3.3259106
Validation loss: 11.511769586679886 MAE: 2.8195922
Validation loss: 8.467824935913086 MAE: 2.3805885
Validation loss: 6.425926695064622 MAE: 2.0891435
Validation loss: 5.386789545720937 MAE: 1.9459484
Validation loss: 4.989227625788475 MAE: 1.8953049
Validation loss: 4.8546611143618215 MAE: 1.875588
Validation loss: 4.822126729147775 MAE: 1.8649482
Validation loss: 4.854750467806446 MAE: 1.8674529
Validation loss: 4.927814989673848 MAE: 1.8845717
Validation loss: 4.979800185378717 MAE: 1.8956816
Validation loss: 4.981759947173449 MAE: 1.8983833
Validation loss: 4.9798097415846225 MAE: 1.9003067
Validation loss: 5.0257139400560025 MAE: 1.9057809
Validation loss: 5.154088497161865 MAE: 1.9248433
Validation loss: 5.227802432313258 MAE: 1.9310979
25 0 5.158473968505859
Validation loss: 5.25370234859233 MAE: 1.931921
Validation loss: 5.292520484145807 MAE: 1.9336437
Validation loss: 5.230718437506228 MAE: 1.927324
Validation loss: 5.146906444004604 MAE: 1.9184465
Validation loss: 5.060053270690295 MAE: 1.9062464
Validation loss: 4.993406694762561 MAE: 1.890382
Validation loss: 5.003956687693694 MAE: 1.8938121
Validation loss: 4.9982985671685665 MAE: 1.8939779
Validation loss: 4.9807261544830945 MAE: 1.8917786
Validation loss: 4.947619136498899 MAE: 1.8869969
Validation loss: 4.920186519622803 MAE: 1.8845606
Validation loss: 4.911408181093177 MAE: 1.8863953
Validation loss: 4.941102553387077 MAE: 1.8910743
Validation loss: 4.980962373772446 MAE: 1.8967077
Validation loss: 5.024144445146833 MAE: 1.9028387
Validation loss: 5.057708681846152 MAE: 1.9073669
Validation loss: 5.048412751178352 MAE: 1.905517
Validation loss: 5.020508114172488 MAE: 1.9011647
Validation loss: 4.978580971153415 MAE: 1.8951432
Validation loss: 4.95156141203277 MAE: 1.8901134
Validation loss: 4.933624072950714 MAE: 1.8873259
Validation loss: 4.923474837322624 MAE: 1.8852729
Validation loss: 4.920874829194983 MAE: 1.883423
Validation loss: 4.922738046062236 MAE: 1.882314
Validation loss: 4.921052660260882 MAE: 1.8817219
50 0 5.487539768218994
Validation loss: 4.918888880282032 MAE: 1.8814296
Validation loss: 4.9119061353255296 MAE: 1.8810496
Validation loss: 4.89519823813925 MAE: 1.8794082
Validation loss: 4.886639994017932 MAE: 1.8785992
Validation loss: 4.878562791006906 MAE: 1.8783914
Validation loss: 4.871852787173524 MAE: 1.8769221
Validation loss: 4.86017184354821 MAE: 1.8737223
Validation loss: 4.849286653557602 MAE: 1.8714076
Validation loss: 4.8393546513148715 MAE: 1.8684204
Validation loss: 4.832500321524484 MAE: 1.8661946
Validation loss: 4.829819328930913 MAE: 1.8648068
Validation loss: 4.821120242683255 MAE: 1.8619679
Validation loss: 4.8253036226545065 MAE: 1.8606474
Validation loss: 4.855174706906689 MAE: 1.8630953
Validation loss: 4.9101898037657445 MAE: 1.8642721
Validation loss: 4.95735873981398 MAE: 1.8678408
Validation loss: 4.944995714693653 MAE: 1.8586221
Validation loss: 4.935114062562281 MAE: 1.8550293
Validation loss: 4.933638309945866 MAE: 1.8517513
Validation loss: 4.870214170339156 MAE: 1.84481
Validation loss: 4.837908102541554 MAE: 1.8420475
Validation loss: 5.414493609447868 MAE: 1.8968328
Validation loss: 5.710440898428158 MAE: 1.9455074
Validation loss: 4.522941326608463 MAE: 1.7719245
Validation loss: 3.728283775096037 MAE: 1.6428651
75 0 5.126250743865967
Validation loss: 3.7451373314370913 MAE: 1.6489129
Validation loss: 3.739824256118463 MAE: 1.6447601
Validation loss: 3.4374203973886917 MAE: 1.5783229
Validation loss: 3.3957845240223166 MAE: 1.562004
Validation loss: 3.324845620564052 MAE: 1.5324967
Validation loss: 3.2529543954498914 MAE: 1.5007197
Validation loss: 3.3103722796148185 MAE: 1.528901
Validation loss: 3.441576928508525 MAE: 1.5641661
Validation loss: 3.613235595274945 MAE: 1.5885875
Validation loss: 4.392831184426132 MAE: 1.7512217
Validation loss: 4.637268611363003 MAE: 1.7941904
Validation loss: 4.430311446287194 MAE: 1.7338994
Validation loss: 3.568125627478775 MAE: 1.5285847
Validation loss: 2.914663027743904 MAE: 1.3445635
Validation loss: 2.2637085233415877 MAE: 1.2326661
Validation loss: 2.220582086212781 MAE: 1.2543987
Validation loss: 2.7894231883846983 MAE: 1.4063363
Validation loss: 2.8622772547663473 MAE: 1.4042003
Validation loss: 3.326880163075973 MAE: 1.49418
Validation loss: 3.5569329456407197 MAE: 1.5468364
Validation loss: 3.613497627024748 MAE: 1.5478164
Validation loss: 2.9380477350585315 MAE: 1.3605434
Validation loss: 2.7126079238190943 MAE: 1.3215164
Validation loss: 2.8632723117361265 MAE: 1.3575418
Validation loss: 3.495572109611667 MAE: 1.4929972
Loaded trained model with success.
Test loss: 5.773478358756495 Test MAE: 1.9335058
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 22.81336212158203
Validation loss: 10.179149001535743 MAE: 2.5438693
Validation loss: 5.75971275869042 MAE: 1.9695557
Validation loss: 7.760364754031403 MAE: 2.2940326
Validation loss: 9.245030157493822 MAE: 2.5008786
Validation loss: 8.807617437959921 MAE: 2.4425035
Validation loss: 7.644384706863249 MAE: 2.2799366
Validation loss: 6.456913042550135 MAE: 2.1187475
Validation loss: 5.915993777188388 MAE: 2.0404177
Validation loss: 6.279192385047373 MAE: 2.0626605
Validation loss: 6.159639413910683 MAE: 2.0406373
Validation loss: 6.083280216563832 MAE: 2.0423987
Validation loss: 6.51174188141871 MAE: 2.1137943
12 2 6.791153907775879
Validation loss: 6.766631680305558 MAE: 2.1511726
Validation loss: 6.262760942632502 MAE: 2.0752218
Validation loss: 5.920780239683209 MAE: 2.0172892
Validation loss: 5.878529948417587 MAE: 2.0231876
Validation loss: 5.968336755579168 MAE: 2.0332756
Validation loss: 6.051379887744634 MAE: 2.035515
Validation loss: 6.100310566449406 MAE: 2.0491166
Validation loss: 6.227324977065578 MAE: 2.061328
Validation loss: 6.171692626644867 MAE: 2.0611022
Validation loss: 6.447736518551605 MAE: 2.1072311
Validation loss: 4.7622467026566015 MAE: 1.8370383
Validation loss: 4.6907329053589795 MAE: 1.8145835
Validation loss: 4.67111279506876 MAE: 1.8048601
25 0 3.9425201416015625
Validation loss: 5.417240549819638 MAE: 1.9573586
Validation loss: 7.3618485780075344 MAE: 2.2137723
Validation loss: 7.086854900976624 MAE: 2.1801972
Validation loss: 6.190908489805279 MAE: 2.0753653
Validation loss: 6.592074427941833 MAE: 2.1176002
Validation loss: 7.321106650612571 MAE: 2.2080827
Validation loss: 6.894240393783107 MAE: 2.1534648
Validation loss: 6.0351479270241475 MAE: 2.0540175
Validation loss: 5.440604161734533 MAE: 1.9770808
Validation loss: 5.415625668535329 MAE: 1.9741259
Validation loss: 5.6303525392455285 MAE: 1.9911046
Validation loss: 5.816292165505765 MAE: 2.011935
37 2 5.987171173095703
Validation loss: 5.369705705931692 MAE: 1.9522831
Validation loss: 4.801999869972769 MAE: 1.8542016
Validation loss: 5.054538502837673 MAE: 1.8984996
Validation loss: 5.154623884143251 MAE: 1.9144659
Validation loss: 5.2072017939403805 MAE: 1.9246849
Validation loss: 6.720621214972602 MAE: 2.1547856
Validation loss: 8.99185862685695 MAE: 2.4631214
Validation loss: 8.511084633644181 MAE: 2.4024782
Validation loss: 8.0701952654906 MAE: 2.3405495
Validation loss: 9.261292274552162 MAE: 2.508614
Validation loss: 10.260445179963353 MAE: 2.6379502
Validation loss: 10.220347385213833 MAE: 2.6243234
Validation loss: 8.964303190057928 MAE: 2.4524534
50 0 5.073554039001465
Validation loss: 7.799864793064619 MAE: 2.29606
Validation loss: 7.428180925773852 MAE: 2.2463877
Validation loss: 6.89619564769244 MAE: 2.1647904
Validation loss: 6.128656984579684 MAE: 2.0609107
Validation loss: 5.7941154223499876 MAE: 2.0170457
Validation loss: 5.083595793656628 MAE: 1.9086475
Validation loss: 4.488263180761626 MAE: 1.8060714
Validation loss: 3.933698211053405 MAE: 1.6938754
Validation loss: 4.428753279676341 MAE: 1.7630606
Validation loss: 5.211620422324749 MAE: 1.8633088
Validation loss: 8.284552872783006 MAE: 2.3427832
Validation loss: 11.71363608042399 MAE: 2.8248057
62 2 5.102417945861816
Validation loss: 13.13177657849861 MAE: 3.0146751
Validation loss: 13.07298357318146 MAE: 3.0046237
Validation loss: 12.024812826002487 MAE: 2.855801
Validation loss: 10.19689912988682 MAE: 2.604597
Validation loss: 9.028797737275712 MAE: 2.458231
Validation loss: 8.847712680546925 MAE: 2.4280975
Validation loss: 7.331467349119861 MAE: 2.2149878
Validation loss: 5.82139417860243 MAE: 1.9521759
Validation loss: 6.124604427453243 MAE: 2.0081642
Validation loss: 5.448204421033763 MAE: 1.8846867
Validation loss: 4.3107504700169414 MAE: 1.6777663
Validation loss: 5.222911203750456 MAE: 1.8679285
Validation loss: 5.040327946345012 MAE: 1.8556385
75 0 4.409326076507568
Validation loss: 4.746853816388834 MAE: 1.8202424
Validation loss: 4.764406478766239 MAE: 1.833025
Validation loss: 4.8802813809327406 MAE: 1.8528831
Validation loss: 5.607288615872162 MAE: 1.967964
Validation loss: 5.031488360780658 MAE: 1.8856797
Validation loss: 4.804629443871854 MAE: 1.8646561
Validation loss: 4.035292844579677 MAE: 1.7383009
Validation loss: 4.476682395646066 MAE: 1.8126913
Validation loss: 5.268207858307193 MAE: 1.9285829
Validation loss: 6.287563273400972 MAE: 2.066905
Validation loss: 7.79436630191225 MAE: 2.2842062
Validation loss: 7.965038684883503 MAE: 2.3140454
87 2 5.168100833892822
Validation loss: 8.347903369653105 MAE: 2.365851
Validation loss: 8.505202813581986 MAE: 2.3832958
Validation loss: 8.168439171530984 MAE: 2.3344615
Validation loss: 7.663101316702487 MAE: 2.2638159
Validation loss: 5.97507934377651 MAE: 2.0094626
Validation loss: 5.64422901230629 MAE: 1.9582037
Validation loss: 4.992508522187821 MAE: 1.8503541
Validation loss: 4.570419157394255 MAE: 1.7731198
Validation loss: 4.772697605267919 MAE: 1.8064271
Validation loss: 4.815138417060929 MAE: 1.8018713
Validation loss: 4.336195603765622 MAE: 1.7148404
Validation loss: 4.130754615321304 MAE: 1.6608931
Validation loss: 3.9660219760856243 MAE: 1.6138414
Loaded trained model with success.
Test loss: 6.120022378130284 Test MAE: 1.9823465
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 25.187061309814453
Validation loss: 5.490997769724784 MAE: 1.9698167
Validation loss: 19.196204904335826 MAE: 3.836675
Validation loss: 9.896785685764485 MAE: 2.6096709
Validation loss: 5.9466813161744545 MAE: 2.055401
Validation loss: 5.4315248637942215 MAE: 1.959827
Validation loss: 5.534780475961503 MAE: 1.978116
Validation loss: 5.090991453908796 MAE: 1.8951256
7 1 6.027097702026367
Validation loss: 5.180761389995939 MAE: 1.9078429
Validation loss: 5.139906439948921 MAE: 1.8902068
Validation loss: 5.311169840582651 MAE: 1.902818
Validation loss: 5.004830822872756 MAE: 1.8659251
Validation loss: 5.032467269418228 MAE: 1.887757
Validation loss: 4.958644043860124 MAE: 1.8729712
Validation loss: 4.960168620449814 MAE: 1.865273
14 2 6.764198303222656
Validation loss: 4.744748024485219 MAE: 1.8272607
Validation loss: 4.888229923631678 MAE: 1.8488969
Validation loss: 5.819525719587527 MAE: 2.0146697
Validation loss: 5.5158374680945625 MAE: 1.9611869
Validation loss: 5.522544247421188 MAE: 1.9357764
Validation loss: 5.383058567142966 MAE: 1.8976891
Validation loss: 4.700079697460385 MAE: 1.774299
21 3 3.0308585166931152
Validation loss: 4.783685892670598 MAE: 1.7615117
Validation loss: 4.926271116314222 MAE: 1.7839432
Validation loss: 4.349499553891283 MAE: 1.7236313
Validation loss: 4.6764498260153 MAE: 1.7358004
Validation loss: 4.868423436754313 MAE: 1.7708142
Validation loss: 4.622228473874193 MAE: 1.7345726
Validation loss: 3.510653102817248 MAE: 1.5781957
28 4 5.058108329772949
Validation loss: 3.828730567615835 MAE: 1.6452765
Validation loss: 3.6128479823395234 MAE: 1.5936923
Validation loss: 3.946050914687727 MAE: 1.6909789
Validation loss: 4.378095370441226 MAE: 1.7651349
Validation loss: 4.164556899861474 MAE: 1.7152833
Validation loss: 4.343419120539373 MAE: 1.742614
Validation loss: 5.128953382597497 MAE: 1.8652117
35 5 3.360015869140625
Validation loss: 3.6758101873062365 MAE: 1.6063523
Validation loss: 3.537841070836513 MAE: 1.5854379
Validation loss: 3.5479170449415043 MAE: 1.5817552
Validation loss: 3.6662391010840336 MAE: 1.605305
Validation loss: 3.875524020075199 MAE: 1.6422571
Validation loss: 4.132105844104709 MAE: 1.6789705
Validation loss: 5.228673311933201 MAE: 1.8622497
42 6 5.258805751800537
Validation loss: 5.748401421398373 MAE: 1.9795445
Validation loss: 5.6429493295487445 MAE: 1.9599766
Validation loss: 4.810942323962648 MAE: 1.8034005
Validation loss: 4.0579942602608075 MAE: 1.6735758
Validation loss: 3.229361958240145 MAE: 1.4957821
Validation loss: 3.8318855618711694 MAE: 1.6256692
Validation loss: 4.179856008021676 MAE: 1.6779408
Validation loss: 4.068717585137142 MAE: 1.6558783
50 0 3.704033613204956
Validation loss: 3.5430635040129848 MAE: 1.5389799
Validation loss: 3.46428016681767 MAE: 1.5434488
Validation loss: 3.584865671905441 MAE: 1.571006
Validation loss: 3.5517971048403028 MAE: 1.5438565
Validation loss: 3.754383374698198 MAE: 1.5712345
Validation loss: 4.048262361306042 MAE: 1.6445028
Validation loss: 3.695351162747522 MAE: 1.562023
57 1 3.7476930618286133
Validation loss: 3.6662334581116336 MAE: 1.5684134
Validation loss: 3.9661232646386226 MAE: 1.6333349
Validation loss: 3.2483672281006473 MAE: 1.4815855
Validation loss: 3.3296728589426934 MAE: 1.498368
Validation loss: 3.2750307543193875 MAE: 1.4789109
Validation loss: 3.0198354002219348 MAE: 1.4149688
Validation loss: 2.984533680144267 MAE: 1.4017967
64 2 2.7656524181365967
Validation loss: 3.595055898829321 MAE: 1.5321484
Validation loss: 3.058194875717163 MAE: 1.4132657
Validation loss: 3.1284825310635207 MAE: 1.4339889
Validation loss: 3.2144042121705096 MAE: 1.4573002
Validation loss: 3.6895262236571194 MAE: 1.5530486
Validation loss: 4.684747113654362 MAE: 1.7536311
Validation loss: 4.435783460511634 MAE: 1.7063724
71 3 2.8052024841308594
Validation loss: 4.162774471781361 MAE: 1.6682388
Validation loss: 3.1807754878422725 MAE: 1.4780248
Validation loss: 2.995760797855243 MAE: 1.433864
Validation loss: 3.532157249786147 MAE: 1.5433439
Validation loss: 3.722419295478706 MAE: 1.5864482
Validation loss: 3.8619606686596892 MAE: 1.6228231
Validation loss: 3.561002475532455 MAE: 1.5520958
78 4 3.866274118423462
Validation loss: 3.168862090038894 MAE: 1.4552102
Validation loss: 4.025499485844943 MAE: 1.6237401
Validation loss: 3.7465491151090844 MAE: 1.562454
Validation loss: 3.381560929456548 MAE: 1.4966044
Validation loss: 3.7159868400899607 MAE: 1.5903509
Validation loss: 3.103951897453423 MAE: 1.446747
Validation loss: 3.446518584112426 MAE: 1.5030859
85 5 4.865251541137695
Validation loss: 3.259860990035474 MAE: 1.4540559
Validation loss: 3.335675045473492 MAE: 1.4653106
Validation loss: 3.1818367200880195 MAE: 1.4262806
Validation loss: 2.777293974430717 MAE: 1.3668501
Validation loss: 3.0675532566243082 MAE: 1.4008427
Validation loss: 2.848310950413421 MAE: 1.3593401
Validation loss: 3.145113265694086 MAE: 1.4115942
92 6 4.483733177185059
Validation loss: 3.0991480751852296 MAE: 1.4090015
Validation loss: 2.732098515309281 MAE: 1.3325315
Validation loss: 2.7927683693679732 MAE: 1.340835
Validation loss: 2.91952908039093 MAE: 1.3764231
Validation loss: 2.8334446294822886 MAE: 1.3375672
Validation loss: 2.914186559130798 MAE: 1.3583299
Validation loss: 2.9562776388235426 MAE: 1.3751348
Validation loss: 3.8461012408961004 MAE: 1.5646335
Loaded trained model with success.
Test loss: 4.741779669355974 Test MAE: 1.7221822
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 20.641613006591797
Validation loss: 15.590074865994808 MAE: 3.381391
Validation loss: 5.6288937299189445 MAE: 2.0007374
Validation loss: 5.96591849221973 MAE: 2.0409482
3 2 5.811363220214844
Validation loss: 5.539169150985075 MAE: 1.9909345
Validation loss: 5.303225222952619 MAE: 1.938421
Validation loss: 5.832042704125445 MAE: 1.9849983
6 4 7.327879428863525
Validation loss: 5.273229029470073 MAE: 1.8977606
Validation loss: 4.755669697014268 MAE: 1.8286128
Validation loss: 4.652206647372198 MAE: 1.8148265
9 6 4.670626640319824
Validation loss: 4.556532915226204 MAE: 1.7410879
Validation loss: 4.256679128788277 MAE: 1.7083285
Validation loss: 4.2485012860001925 MAE: 1.7121034
12 8 5.574502468109131
Validation loss: 4.050968413840315 MAE: 1.649049
Validation loss: 4.385159291819724 MAE: 1.713817
Validation loss: 3.899694105905139 MAE: 1.6318585
15 10 4.5875115394592285
Validation loss: 4.327122848831819 MAE: 1.6989902
Validation loss: 3.805050277518844 MAE: 1.6252803
Validation loss: 6.251338156048425 MAE: 2.0242314
18 12 4.638484954833984
Validation loss: 5.666935514113707 MAE: 1.9342183
Validation loss: 4.763269623200258 MAE: 1.771992
Validation loss: 4.158131219103246 MAE: 1.6638978
21 14 5.971047401428223
Validation loss: 4.147108075613966 MAE: 1.6536252
Validation loss: 3.805028632551969 MAE: 1.5934021
Validation loss: 6.3893703563896596 MAE: 2.0600064
Validation loss: 4.464620673345898 MAE: 1.7226053
25 0 3.849327325820923
Validation loss: 3.462818686613339 MAE: 1.5349326
Validation loss: 3.5648419465235097 MAE: 1.5413146
Validation loss: 4.9710211362055166 MAE: 1.8160052
28 2 4.330740928649902
Validation loss: 3.879485737106843 MAE: 1.6020412
Validation loss: 3.3937408173968175 MAE: 1.5051674
Validation loss: 3.7970484339880324 MAE: 1.5693132
31 4 4.782266139984131
Validation loss: 3.7217504428718278 MAE: 1.576666
Validation loss: 5.519077009571817 MAE: 1.9110386
Validation loss: 3.13527957136502 MAE: 1.4459585
34 6 3.1603832244873047
Validation loss: 3.196668734770261 MAE: 1.4465089
Validation loss: 3.093504893755865 MAE: 1.4389445
Validation loss: 3.289178349450977 MAE: 1.4772649
37 8 4.184358596801758
Validation loss: 3.0969492371431095 MAE: 1.4218239
Validation loss: 3.9123646324287673 MAE: 1.5967954
Validation loss: 3.2261994143048365 MAE: 1.459261
40 10 2.732083797454834
Validation loss: 3.1389615530958155 MAE: 1.4272703
Validation loss: 3.3226685320924902 MAE: 1.4889262
Validation loss: 3.5010065869960134 MAE: 1.5017103
43 12 5.4760050773620605
Validation loss: 3.0468047960009987 MAE: 1.4060086
Validation loss: 3.016272127269982 MAE: 1.4049375
Validation loss: 3.0892753629741785 MAE: 1.4118017
46 14 4.409521579742432
Validation loss: 3.5892198420239834 MAE: 1.5114406
Validation loss: 3.1784559266122883 MAE: 1.4338915
Validation loss: 2.9650456984200795 MAE: 1.3876616
Validation loss: 3.0209623720937357 MAE: 1.4195441
50 0 4.161304473876953
Validation loss: 3.298450912406784 MAE: 1.446321
Validation loss: 3.0778584518509065 MAE: 1.4138632
Validation loss: 3.278563205608146 MAE: 1.4602463
53 2 2.6873230934143066
Validation loss: 3.0023864438395225 MAE: 1.3805338
Validation loss: 2.8633890046863137 MAE: 1.3613895
Validation loss: 4.4980936231976285 MAE: 1.702489
56 4 4.238650321960449
Validation loss: 2.837039025847563 MAE: 1.3687071
Validation loss: 2.977599719244397 MAE: 1.4010171
Validation loss: 3.503965943036433 MAE: 1.5124758
59 6 2.777033567428589
Validation loss: 3.848175977179426 MAE: 1.5887156
Validation loss: 2.861581256251058 MAE: 1.3641297
Validation loss: 3.0608273054172614 MAE: 1.4023882
62 8 2.9001145362854004
Validation loss: 2.7429954360625546 MAE: 1.3410428
Validation loss: 3.065901039119713 MAE: 1.4262054
Validation loss: 2.853744143713452 MAE: 1.3603855
65 10 3.8161463737487793
Validation loss: 3.007223930053099 MAE: 1.3951849
Validation loss: 3.3224996053623053 MAE: 1.4680628
Validation loss: 2.7434499187316588 MAE: 1.3264484
68 12 2.720930337905884
Validation loss: 3.311949579892512 MAE: 1.457208
Validation loss: 2.8029925956993638 MAE: 1.3419629
Validation loss: 3.155667541022291 MAE: 1.423299
71 14 4.0307769775390625
Validation loss: 2.55437957977723 MAE: 1.2836508
Validation loss: 2.8140773247621342 MAE: 1.3495487
Validation loss: 2.5869568923193373 MAE: 1.2843947
Validation loss: 2.7648075171606337 MAE: 1.3328007
75 0 4.3188652992248535
Validation loss: 2.981059577995407 MAE: 1.3684314
Validation loss: 3.7170063985851343 MAE: 1.5391183
Validation loss: 2.5770690751696876 MAE: 1.2865504
78 2 3.1496598720550537
Validation loss: 2.749454802644993 MAE: 1.325471
Validation loss: 2.5664744874040686 MAE: 1.2925507
Validation loss: 2.8076708555699352 MAE: 1.3462336
81 4 2.2641162872314453
Validation loss: 2.8162178405540024 MAE: 1.3409718
Validation loss: 2.6047250039591816 MAE: 1.298903
Validation loss: 2.777965442928857 MAE: 1.3433319
84 6 2.569439649581909
Validation loss: 2.418525649215989 MAE: 1.2421572
Validation loss: 2.9602154930512268 MAE: 1.3681982
Validation loss: 3.1299019203874057 MAE: 1.4128007
87 8 3.020679473876953
Validation loss: 2.4472930751487105 MAE: 1.2432235
Validation loss: 2.4814583533751464 MAE: 1.266954
Validation loss: 2.526647616961676 MAE: 1.2690597
90 10 2.1566174030303955
Validation loss: 2.5346796684609147 MAE: 1.2837942
Validation loss: 2.621630194191942 MAE: 1.2987026
Validation loss: 2.4365410881195375 MAE: 1.2468245
93 12 4.133108139038086
Validation loss: 2.817984053988256 MAE: 1.3408546
Validation loss: 2.5607254314040375 MAE: 1.3004053
Validation loss: 3.1438403007740487 MAE: 1.4127158
96 14 2.678941011428833
Validation loss: 2.7564864674646534 MAE: 1.3235574
Validation loss: 2.9123381306986533 MAE: 1.376131
Validation loss: 2.6330595957731195 MAE: 1.2982819
Validation loss: 2.48633121249671 MAE: 1.2621347
Loaded trained model with success.
Test loss: 4.642771295081811 Test MAE: 1.6894623
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 2}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.6366441249847412
Validation loss: 0.6929954266500378 ROC AUC: 0.5584819277108434
Validation loss: 0.7156928081311779 ROC AUC: 0.5602650602409638
Validation loss: 0.6901398843419336 ROC AUC: 0.581574297188755
3 2 0.6962698698043823
Validation loss: 0.7360679651787859 ROC AUC: 0.5807228915662651
Validation loss: 0.7573185702841841 ROC AUC: 0.5965622489959839
Validation loss: 0.695574470894609 ROC AUC: 0.6042168674698796
6 4 0.6756537556648254
Validation loss: 0.6726847938401904 ROC AUC: 0.6421686746987952
Validation loss: 0.7030731151720326 ROC AUC: 0.6482008032128513
Validation loss: 1.1780457169355036 ROC AUC: 0.6349799196787147
9 6 0.6595389246940613
Validation loss: 0.8295645656471023 ROC AUC: 0.665429718875502
Validation loss: 0.6416564109569083 ROC AUC: 0.6875502008032128
Validation loss: 0.8520539719499424 ROC AUC: 0.6636465863453815
12 8 0.641089141368866
Validation loss: 0.9165120172596168 ROC AUC: 0.7097429718875502
Validation loss: 1.2416199739567024 ROC AUC: 0.6859116465863453
Validation loss: 0.6182193681448399 ROC AUC: 0.7549156626506024
15 10 0.5897687077522278
Validation loss: 0.6120131168671266 ROC AUC: 0.7525220883534136
Validation loss: 0.5754250046724309 ROC AUC: 0.7671887550200803
Validation loss: 0.5888197656146033 ROC AUC: 0.7646666666666667
18 12 0.6344643831253052
Validation loss: 0.5889106604880943 ROC AUC: 0.7633895582329319
Validation loss: 0.5639024906024666 ROC AUC: 0.7785381526104418
Validation loss: 0.5970956171920638 ROC AUC: 0.7733092369477912
21 14 0.4967922866344452
Validation loss: 0.5644346689413449 ROC AUC: 0.7833895582329317
Validation loss: 0.5665273758356939 ROC AUC: 0.7880722891566265
Validation loss: 0.5656692434050038 ROC AUC: 0.7876867469879518
Validation loss: 0.5720671894316205 ROC AUC: 0.7828755020080321
25 0 0.569783091545105
Validation loss: 0.5932725464891575 ROC AUC: 0.7806666666666666
Validation loss: 0.5514059217874416 ROC AUC: 0.7892610441767068
Validation loss: 0.5490813651878036 ROC AUC: 0.7958875502008032
28 2 0.4490779638290405
Validation loss: 0.5701702344632579 ROC AUC: 0.7793172690763052
Validation loss: 0.5423343815282734 ROC AUC: 0.7983052208835342
Validation loss: 0.549890357232046 ROC AUC: 0.802425702811245
31 4 0.6172495484352112
Validation loss: 0.6139117949950194 ROC AUC: 0.8005140562248996
Validation loss: 0.5836355781746293 ROC AUC: 0.7988433734939758
Validation loss: 0.5433846473216055 ROC AUC: 0.8002811244979919
34 6 0.6984238028526306
Validation loss: 0.55683589996938 ROC AUC: 0.7988915662650602
Validation loss: 0.5522948312377165 ROC AUC: 0.8013734939759036
Validation loss: 0.5398268703826683 ROC AUC: 0.8005140562248996
37 8 0.6134893894195557
Validation loss: 0.5725906491279602 ROC AUC: 0.8035582329317268
Validation loss: 0.5438469294794576 ROC AUC: 0.8062891566265059
Validation loss: 0.5599036004118069 ROC AUC: 0.804867469879518
40 10 0.5000522136688232
Validation loss: 0.544741609889663 ROC AUC: 0.8175421686746989
Validation loss: 0.5323965518412466 ROC AUC: 0.8164096385542168
Validation loss: 0.5560228246486258 ROC AUC: 0.8069156626506023
43 12 0.5356942415237427
Validation loss: 0.5703464023216454 ROC AUC: 0.8043453815261045
Validation loss: 0.5571468557886227 ROC AUC: 0.8177349397590361
Validation loss: 0.5427448146926138 ROC AUC: 0.812008032128514
46 14 0.6298521757125854
Validation loss: 0.5255185781953808 ROC AUC: 0.8170682730923694
Validation loss: 0.527430352562654 ROC AUC: 0.8251967871485943
Validation loss: 0.5129413860952687 ROC AUC: 0.8300642570281125
Validation loss: 0.5234306864365786 ROC AUC: 0.8259437751004016
50 0 0.5509274005889893
Validation loss: 0.5277707759507434 ROC AUC: 0.8247630522088354
Validation loss: 0.5266596888731381 ROC AUC: 0.8246907630522088
Validation loss: 0.5447523587930179 ROC AUC: 0.8245140562248996
53 2 0.49004414677619934
Validation loss: 0.49165729858832274 ROC AUC: 0.8409156626506025
Validation loss: 0.5003759463229972 ROC AUC: 0.8384417670682731
Validation loss: 0.5400004646104419 ROC AUC: 0.8216224899598394
56 4 0.44231975078582764
Validation loss: 0.5344482720017673 ROC AUC: 0.8292530120481929
Validation loss: 0.5934676646230694 ROC AUC: 0.8212289156626505
Validation loss: 0.5223129713583088 ROC AUC: 0.8309236947791164
59 6 0.4818587601184845
Validation loss: 0.6184561171369227 ROC AUC: 0.8124417670682731
Validation loss: 0.5428084708406834 ROC AUC: 0.8203052208835342
Validation loss: 0.5568356175938685 ROC AUC: 0.8244979919678715
62 8 0.4332613945007324
Validation loss: 0.7600298778327529 ROC AUC: 0.8
Validation loss: 0.5245897255106298 ROC AUC: 0.8326024096385543
Validation loss: 0.49847379386544466 ROC AUC: 0.8382650602409638
65 10 0.5261548161506653
Validation loss: 0.6407545054842809 ROC AUC: 0.8271004016064256
Validation loss: 0.5671614747128649 ROC AUC: 0.8239839357429719
Validation loss: 0.5346460282683133 ROC AUC: 0.8351084337349398
68 12 0.5797669291496277
Validation loss: 0.555792967339078 ROC AUC: 0.8340401606425705
Validation loss: 0.48070974704736696 ROC AUC: 0.8551646586345382
Validation loss: 0.4848088999549468 ROC AUC: 0.8598634538152612
71 14 0.5445865392684937
Validation loss: 0.48877737863747056 ROC AUC: 0.8632690763052209
Validation loss: 0.5060923588060903 ROC AUC: 0.8546184738955823
Validation loss: 0.48555066876994346 ROC AUC: 0.8624417670682731
Validation loss: 0.44777944552635623 ROC AUC: 0.8789558232931727
75 0 0.42801544070243835
Validation loss: 0.4943267938369262 ROC AUC: 0.8552851405622489
Validation loss: 0.4623740560903339 ROC AUC: 0.8684016064257027
Validation loss: 0.4416287059416035 ROC AUC: 0.8812048192771084
78 2 0.5715543627738953
Validation loss: 0.4503843734761278 ROC AUC: 0.8726746987951806
Validation loss: 0.44695818675066046 ROC AUC: 0.8810281124497992
Validation loss: 0.4556802436560094 ROC AUC: 0.8744096385542168
81 4 0.5468010902404785
Validation loss: 0.44791578380521646 ROC AUC: 0.8813975903614458
Validation loss: 0.5127418913201005 ROC AUC: 0.8600160642570281
Validation loss: 0.45703020656037185 ROC AUC: 0.8754377510040161
84 6 0.4143266975879669
Validation loss: 0.49392355300620466 ROC AUC: 0.8725863453815261
Validation loss: 0.434117105179177 ROC AUC: 0.8793654618473896
Validation loss: 0.5202166961285777 ROC AUC: 0.8599678714859438
87 8 0.3757370412349701
Validation loss: 0.5278165298019478 ROC AUC: 0.8618714859437752
Validation loss: 0.5351158594917916 ROC AUC: 0.8559277108433735
Validation loss: 0.4591235999831695 ROC AUC: 0.8860883534136546
90 10 0.6131358742713928
Validation loss: 0.4775560689056087 ROC AUC: 0.86714859437751
Validation loss: 0.45859637384663127 ROC AUC: 0.8720321285140562
Validation loss: 0.4683759502752988 ROC AUC: 0.8786746987951808
93 12 0.45981186628341675
Validation loss: 0.4368397064342766 ROC AUC: 0.8929397590361445
Validation loss: 0.4652171105086684 ROC AUC: 0.8731566265060242
Validation loss: 0.44609475625540784 ROC AUC: 0.8780803212851406
96 14 0.3986150026321411
Validation loss: 0.4386490132502898 ROC AUC: 0.8896385542168675
Validation loss: 0.44321483815600254 ROC AUC: 0.8812530120481927
Validation loss: 0.40369721321400276 ROC AUC: 0.8994859437751005
Validation loss: 0.5015351003062032 ROC AUC: 0.8753092369477912
Loaded trained model with success.
Test loss: 0.6797411708927473 Test ROC AUC: 0.7338564445587857
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.6777139902114868
Validation loss: 1.6388463973999023 ROC AUC: 0.35
Validation loss: 1.6475948095321655 ROC AUC: 0.325
Validation loss: 1.6768245697021484 ROC AUC: 0.425
Validation loss: 1.6925733089447021 ROC AUC: 0.45
Validation loss: 1.7295225858688354 ROC AUC: 0.5625
Validation loss: 1.8004069328308105 ROC AUC: 0.65
Validation loss: 1.91978919506073 ROC AUC: 0.6875
Validation loss: 2.0476813316345215 ROC AUC: 0.7125
Validation loss: 2.1667542457580566 ROC AUC: 0.7125
Validation loss: 2.2908451557159424 ROC AUC: 0.7625
Validation loss: 2.3999710083007812 ROC AUC: 0.7375
Validation loss: 2.455787420272827 ROC AUC: 0.75
Validation loss: 2.503490686416626 ROC AUC: 0.7875
Validation loss: 2.5391433238983154 ROC AUC: 0.725
Validation loss: 2.5635056495666504 ROC AUC: 0.725
Validation loss: 2.5443902015686035 ROC AUC: 0.725
Validation loss: 2.546130657196045 ROC AUC: 0.725
Validation loss: 2.576066017150879 ROC AUC: 0.725
Validation loss: 2.6342413425445557 ROC AUC: 0.7
Validation loss: 2.6966447830200195 ROC AUC: 0.7
Validation loss: 2.7584385871887207 ROC AUC: 0.7
Validation loss: 2.804503917694092 ROC AUC: 0.7
Validation loss: 2.862520456314087 ROC AUC: 0.7
Validation loss: 2.9395718574523926 ROC AUC: 0.6875
Validation loss: 3.016019344329834 ROC AUC: 0.6125
Validation loss: 3.1484036445617676 ROC AUC: 0.6375
Validation loss: 3.209371328353882 ROC AUC: 0.6
Validation loss: 3.235065460205078 ROC AUC: 0.55
Validation loss: 3.305598258972168 ROC AUC: 0.475
Validation loss: 3.3316893577575684 ROC AUC: 0.625
Validation loss: 3.298523187637329 ROC AUC: 0.625
Validation loss: 3.1235404014587402 ROC AUC: 0.675
Validation loss: 3.047792673110962 ROC AUC: 0.6875
Validation loss: 2.8071813583374023 ROC AUC: 0.7
Validation loss: 2.2806007862091064 ROC AUC: 0.7125
Validation loss: 1.8933160305023193 ROC AUC: 0.8
Validation loss: 1.737451195716858 ROC AUC: 0.8
Validation loss: 1.6070685386657715 ROC AUC: 0.8
Validation loss: 1.4528393745422363 ROC AUC: 0.8
Validation loss: 1.5559582710266113 ROC AUC: 0.8
Validation loss: 1.5502021312713623 ROC AUC: 0.8
Validation loss: 1.5740511417388916 ROC AUC: 0.8
Validation loss: 1.3436065912246704 ROC AUC: 0.8
Validation loss: 1.2100192308425903 ROC AUC: 0.825
Validation loss: 1.21278715133667 ROC AUC: 0.9
Validation loss: 1.2716444730758667 ROC AUC: 0.85
Validation loss: 1.335668921470642 ROC AUC: 0.85
Validation loss: 1.4161508083343506 ROC AUC: 0.875
Validation loss: 1.4712241888046265 ROC AUC: 0.8875
Validation loss: 1.4834293127059937 ROC AUC: 0.8625
50 0 1.3109204769134521
Validation loss: 1.4783421754837036 ROC AUC: 0.85
Validation loss: 1.498435378074646 ROC AUC: 0.85
Validation loss: 1.4983394145965576 ROC AUC: 0.85
Validation loss: 1.5208449363708496 ROC AUC: 0.825
Validation loss: 1.5236440896987915 ROC AUC: 0.825
Validation loss: 1.5217276811599731 ROC AUC: 0.825
Validation loss: 1.5286533832550049 ROC AUC: 0.8125
Validation loss: 1.5468413829803467 ROC AUC: 0.825
Validation loss: 1.581070065498352 ROC AUC: 0.725
Validation loss: 1.5885119438171387 ROC AUC: 0.7
Validation loss: 1.5851054191589355 ROC AUC: 0.7
Validation loss: 1.5713675022125244 ROC AUC: 0.7
Validation loss: 1.54679536819458 ROC AUC: 0.7125
Validation loss: 1.4513742923736572 ROC AUC: 0.825
Validation loss: 1.3846287727355957 ROC AUC: 0.9125
Validation loss: 1.3366438150405884 ROC AUC: 0.9125
Validation loss: 1.2894082069396973 ROC AUC: 0.9125
Validation loss: 1.257563829421997 ROC AUC: 0.9125
Validation loss: 1.2433736324310303 ROC AUC: 0.9125
Validation loss: 1.1825300455093384 ROC AUC: 0.875
Validation loss: 1.1356706619262695 ROC AUC: 0.8625
Validation loss: 1.1023467779159546 ROC AUC: 0.8625
Validation loss: 1.0816574096679688 ROC AUC: 0.875
Validation loss: 1.0651978254318237 ROC AUC: 0.925
Validation loss: 1.056365966796875 ROC AUC: 0.9
Validation loss: 1.052445411682129 ROC AUC: 0.875
Validation loss: 1.0474998950958252 ROC AUC: 0.875
Validation loss: 1.027646541595459 ROC AUC: 0.9125
Validation loss: 1.0048670768737793 ROC AUC: 0.9375
Validation loss: 0.9869192838668823 ROC AUC: 0.9375
Validation loss: 0.9718210697174072 ROC AUC: 0.9375
Validation loss: 0.9777251482009888 ROC AUC: 0.925
Validation loss: 1.0914661884307861 ROC AUC: 0.8875
Validation loss: 1.1348062753677368 ROC AUC: 0.8625
Validation loss: 1.2327758073806763 ROC AUC: 0.8
Validation loss: 1.2705801725387573 ROC AUC: 0.7875
Validation loss: 1.180245041847229 ROC AUC: 0.8125
Validation loss: 1.155105710029602 ROC AUC: 0.8125
Validation loss: 1.207048773765564 ROC AUC: 0.7875
Validation loss: 1.3018885850906372 ROC AUC: 0.7875
Validation loss: 1.3463799953460693 ROC AUC: 0.7875
Validation loss: 1.3768115043640137 ROC AUC: 0.7875
Validation loss: 1.3860223293304443 ROC AUC: 0.7875
Validation loss: 1.43135666847229 ROC AUC: 0.7875
Validation loss: 1.5133323669433594 ROC AUC: 0.7625
Validation loss: 1.5790870189666748 ROC AUC: 0.7625
Validation loss: 1.6915606260299683 ROC AUC: 0.7625
Validation loss: 1.804608702659607 ROC AUC: 0.7625
Validation loss: 1.9621469974517822 ROC AUC: 0.7625
Validation loss: 1.9992578029632568 ROC AUC: 0.7625
Loaded trained model with success.
Test loss: 2.287358241922715 Test ROC AUC: 0.5367227499583143
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.6690170764923096
Validation loss: 1.6216511726379395 ROC AUC: 0.44427777777777777
Validation loss: 1.6867050078450416 ROC AUC: 0.5204444444444445
Validation loss: 1.716806774236718 ROC AUC: 0.5512222222222223
Validation loss: 1.730805255928818 ROC AUC: 0.623388888888889
Validation loss: 1.7231498129513798 ROC AUC: 0.6247777777777778
Validation loss: 1.711894346743214 ROC AUC: 0.6305555555555555
Validation loss: 1.7264525549752372 ROC AUC: 0.6245
Validation loss: 1.730831530629372 ROC AUC: 0.6242777777777778
Validation loss: 1.7569947315722096 ROC AUC: 0.6428333333333333
Validation loss: 1.7636290131783 ROC AUC: 0.655388888888889
Validation loss: 1.7497318204568357 ROC AUC: 0.6118333333333333
Validation loss: 1.7379018992793804 ROC AUC: 0.5755
Validation loss: 1.6804939751722374 ROC AUC: 0.5425
Validation loss: 1.6534647065766004 ROC AUC: 0.5606111111111111
Validation loss: 1.6362228904451643 ROC AUC: 0.5502222222222223
Validation loss: 1.6300471193936406 ROC AUC: 0.5895555555555556
Validation loss: 1.6005572494195432 ROC AUC: 0.5987222222222222
Validation loss: 1.5754868667952868 ROC AUC: 0.5854444444444444
Validation loss: 1.5551455166875099 ROC AUC: 0.5961111111111111
Validation loss: 1.5498887714074583 ROC AUC: 0.6129444444444445
Validation loss: 1.5658758732737328 ROC AUC: 0.6628333333333334
Validation loss: 1.6045551981244768 ROC AUC: 0.657388888888889
Validation loss: 1.636803641611216 ROC AUC: 0.6446666666666666
Validation loss: 1.6607640860032062 ROC AUC: 0.6375555555555555
Validation loss: 1.6909304103072809 ROC AUC: 0.6338888888888888
25 0 1.560487985610962
Validation loss: 1.709956407546997 ROC AUC: 0.6225
Validation loss: 1.7344957127863048 ROC AUC: 0.6062222222222223
Validation loss: 1.7304390887824856 ROC AUC: 0.6037222222222222
Validation loss: 1.6917736603289235 ROC AUC: 0.6141111111111112
Validation loss: 1.6427705652859745 ROC AUC: 0.6420555555555556
Validation loss: 1.565148995847118 ROC AUC: 0.6772777777777776
Validation loss: 1.5583079445118806 ROC AUC: 0.6707777777777777
Validation loss: 1.5654346796931053 ROC AUC: 0.6645
Validation loss: 1.5809193508965629 ROC AUC: 0.6628888888888889
Validation loss: 1.6043270607383884 ROC AUC: 0.6634444444444443
Validation loss: 1.5919967743815209 ROC AUC: 0.6685555555555556
Validation loss: 1.6420761857713972 ROC AUC: 0.6456666666666667
Validation loss: 1.661276785694823 ROC AUC: 0.6257777777777778
Validation loss: 1.647780501112646 ROC AUC: 0.6260555555555556
Validation loss: 1.6255487130612742 ROC AUC: 0.6346666666666667
Validation loss: 1.5983444719898456 ROC AUC: 0.6471666666666667
Validation loss: 1.5504640608417743 ROC AUC: 0.6775
Validation loss: 1.5428761706060292 ROC AUC: 0.6767222222222222
Validation loss: 1.538939609819529 ROC AUC: 0.6671111111111111
Validation loss: 1.5715853340771733 ROC AUC: 0.6442777777777777
Validation loss: 1.624909218476743 ROC AUC: 0.6355555555555557
Validation loss: 1.675289927696695 ROC AUC: 0.6322777777777778
Validation loss: 1.6817122259918524 ROC AUC: 0.6327777777777777
Validation loss: 1.6539986182232291 ROC AUC: 0.6393888888888888
Validation loss: 1.6222606313471892 ROC AUC: 0.6495555555555556
50 0 1.4049274921417236
Validation loss: 1.6236368052813472 ROC AUC: 0.6538333333333333
Validation loss: 1.6441936419934642 ROC AUC: 0.6583888888888889
Validation loss: 1.617736045195132 ROC AUC: 0.6643333333333333
Validation loss: 1.6011750990030718 ROC AUC: 0.6717222222222223
Validation loss: 1.5519622904913766 ROC AUC: 0.6846666666666666
Validation loss: 1.508407371384757 ROC AUC: 0.7101111111111111
Validation loss: 1.4872453504679155 ROC AUC: 0.7181111111111111
Validation loss: 1.5173944478132286 ROC AUC: 0.7087777777777778
Validation loss: 1.543987935903121 ROC AUC: 0.6937222222222222
Validation loss: 1.5568718423648757 ROC AUC: 0.6835
Validation loss: 1.5815226228869692 ROC AUC: 0.681888888888889
Validation loss: 1.5648923966349388 ROC AUC: 0.6877222222222222
Validation loss: 1.5398265658592691 ROC AUC: 0.6982222222222223
Validation loss: 1.5564391248080196 ROC AUC: 0.6966111111111112
Validation loss: 1.5610807185270348 ROC AUC: 0.7031111111111111
Validation loss: 1.5294309100326227 ROC AUC: 0.7050000000000002
Validation loss: 1.5355909795177227 ROC AUC: 0.6963333333333334
Validation loss: 1.5120872843022248 ROC AUC: 0.6901666666666668
Validation loss: 1.5253218777325688 ROC AUC: 0.7009444444444445
Validation loss: 1.5556760345186507 ROC AUC: 0.7304999999999999
Validation loss: 1.5822249553641494 ROC AUC: 0.7492777777777778
Validation loss: 1.6388273239135742 ROC AUC: 0.7601666666666667
Validation loss: 1.651077847091519 ROC AUC: 0.7561111111111112
Validation loss: 1.6394215578935585 ROC AUC: 0.7513888888888889
Validation loss: 1.503268059419126 ROC AUC: 0.7647777777777777
75 0 1.147557258605957
Validation loss: 1.4455755048868608 ROC AUC: 0.7640555555555555
Validation loss: 1.4954859967134437 ROC AUC: 0.7561111111111111
Validation loss: 1.520157874846945 ROC AUC: 0.7513333333333334
Validation loss: 1.4438054999526666 ROC AUC: 0.7779444444444444
Validation loss: 1.4889038874178517 ROC AUC: 0.7852222222222223
Validation loss: 1.5140055977568334 ROC AUC: 0.7867222222222223
Validation loss: 1.4907774025080156 ROC AUC: 0.7892777777777779
Validation loss: 1.4714820603935086 ROC AUC: 0.7935000000000001
Validation loss: 1.4633829739629005 ROC AUC: 0.7926111111111112
Validation loss: 1.425609853802895 ROC AUC: 0.7965
Validation loss: 1.2764827353613717 ROC AUC: 0.8188888888888888
Validation loss: 1.1803265822177031 ROC AUC: 0.8248333333333333
Validation loss: 1.0951834625127363 ROC AUC: 0.8299444444444445
Validation loss: 1.046378062695873 ROC AUC: 0.8485555555555555
Validation loss: 0.9977209349067844 ROC AUC: 0.8643333333333333
Validation loss: 0.9736324548721313 ROC AUC: 0.869
Validation loss: 0.9958613794677111 ROC AUC: 0.8681666666666666
Validation loss: 1.0467657459025481 ROC AUC: 0.8602777777777778
Validation loss: 1.1411642225421206 ROC AUC: 0.8488333333333333
Validation loss: 1.2377175846878363 ROC AUC: 0.8347777777777778
Validation loss: 1.2873232972865203 ROC AUC: 0.8327222222222221
Validation loss: 1.2579308188691432 ROC AUC: 0.8373333333333333
Validation loss: 1.1086839364499461 ROC AUC: 0.8411666666666667
Validation loss: 1.029684572803731 ROC AUC: 0.8568333333333333
Validation loss: 1.0775232850288858 ROC AUC: 0.8602777777777778
Loaded trained model with success.
Test loss: 2.3374414034472166 Test ROC AUC: 0.5644034870695847
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.6187039613723755
Validation loss: 1.6736577436177418 ROC AUC: 0.5385657894736842
Validation loss: 1.7041419539788756 ROC AUC: 0.5407565789473684
Validation loss: 1.7403323554029368 ROC AUC: 0.5513486842105263
Validation loss: 1.7539760849692605 ROC AUC: 0.5556842105263158
Validation loss: 1.6285748156634243 ROC AUC: 0.562078947368421
Validation loss: 1.598938555428476 ROC AUC: 0.5673684210526315
Validation loss: 1.6199940756113842 ROC AUC: 0.573875
Validation loss: 1.6138706893631907 ROC AUC: 0.5612105263157894
Validation loss: 1.6176768276426527 ROC AUC: 0.5576315789473684
Validation loss: 1.6608616800019236 ROC AUC: 0.5666973684210527
Validation loss: 1.6787247573486481 ROC AUC: 0.545328947368421
Validation loss: 1.7272511010218148 ROC AUC: 0.5313684210526316
12 2 1.6213974952697754
Validation loss: 1.802576685192609 ROC AUC: 0.5365197368421054
Validation loss: 1.8788954212207987 ROC AUC: 0.5420723684210526
Validation loss: 1.9094359031831376 ROC AUC: 0.5057105263157894
Validation loss: 2.021505751995125 ROC AUC: 0.4885
Validation loss: 1.9304771977241593 ROC AUC: 0.500157894736842
Validation loss: 1.8677182582893757 ROC AUC: 0.5259934210526315
Validation loss: 1.8595423746590662 ROC AUC: 0.549953947368421
Validation loss: 1.8280084253561617 ROC AUC: 0.5401578947368422
Validation loss: 1.7776632694282917 ROC AUC: 0.5320986842105262
Validation loss: 1.7607424524095323 ROC AUC: 0.5347697368421053
Validation loss: 1.6819486028016215 ROC AUC: 0.5638618421052631
Validation loss: 1.6741931980306453 ROC AUC: 0.5760197368421054
Validation loss: 1.6874900309726446 ROC AUC: 0.572375
25 0 1.6930822134017944
Validation loss: 1.662576219048163 ROC AUC: 0.5721184210526316
Validation loss: 1.6297352699318317 ROC AUC: 0.5737828947368421
Validation loss: 1.6349903308984004 ROC AUC: 0.5743223684210528
Validation loss: 1.627104847118108 ROC AUC: 0.5766842105263158
Validation loss: 1.6777556062948824 ROC AUC: 0.573828947368421
Validation loss: 1.7583976767279885 ROC AUC: 0.5729605263157895
Validation loss: 1.795476343896654 ROC AUC: 0.581953947368421
Validation loss: 1.7369774038141423 ROC AUC: 0.5806973684210526
Validation loss: 1.7003957779720575 ROC AUC: 0.5783618421052632
Validation loss: 1.6262653668721516 ROC AUC: 0.5846973684210526
Validation loss: 1.604556133048703 ROC AUC: 0.5843618421052632
Validation loss: 1.5967254795209327 ROC AUC: 0.5879934210526316
37 2 1.5961027145385742
Validation loss: 1.63620658715566 ROC AUC: 0.5804276315789474
Validation loss: 1.7268058747956248 ROC AUC: 0.5767302631578948
Validation loss: 1.7359076906936337 ROC AUC: 0.5827631578947369
Validation loss: 1.7031376410012293 ROC AUC: 0.5875657894736843
Validation loss: 1.664039458891358 ROC AUC: 0.5916184210526315
Validation loss: 1.6228648195363053 ROC AUC: 0.5945065789473684
Validation loss: 1.6148714573696406 ROC AUC: 0.5826710526315789
Validation loss: 1.613421381121934 ROC AUC: 0.5683684210526316
Validation loss: 1.635654583121791 ROC AUC: 0.5486513157894737
Validation loss: 1.7405124710063742 ROC AUC: 0.5356381578947369
Validation loss: 1.817594092301648 ROC AUC: 0.553828947368421
Validation loss: 1.846861649041224 ROC AUC: 0.5569342105263158
Validation loss: 1.870793919370632 ROC AUC: 0.554717105263158
50 0 1.5645285844802856
Validation loss: 1.8294587267769709 ROC AUC: 0.5935460526315789
Validation loss: 1.713871829437487 ROC AUC: 0.6115723684210527
Validation loss: 1.6116315957271692 ROC AUC: 0.6188355263157895
Validation loss: 1.600053401908489 ROC AUC: 0.626625
Validation loss: 1.641874495178762 ROC AUC: 0.6308026315789473
Validation loss: 1.7033762955906415 ROC AUC: 0.6099210526315788
Validation loss: 1.679864151309235 ROC AUC: 0.6119802631578948
Validation loss: 1.6400799233504015 ROC AUC: 0.6266381578947369
Validation loss: 1.6249228571400498 ROC AUC: 0.6358421052631579
Validation loss: 1.6296304729249742 ROC AUC: 0.6298618421052631
Validation loss: 1.6286024517483182 ROC AUC: 0.624953947368421
Validation loss: 1.6363304118917446 ROC AUC: 0.6347039473684211
62 2 1.4463753700256348
Validation loss: 1.6422101897422714 ROC AUC: 0.6585197368421054
Validation loss: 1.8839647023364752 ROC AUC: 0.6428881578947369
Validation loss: 1.6328503170398752 ROC AUC: 0.679078947368421
Validation loss: 1.5802474322945181 ROC AUC: 0.6903881578947368
Validation loss: 1.57213607340148 ROC AUC: 0.6905328947368421
Validation loss: 1.5453748233390576 ROC AUC: 0.6832302631578948
Validation loss: 1.4348249724417022 ROC AUC: 0.7073223684210527
Validation loss: 1.4330146782325976 ROC AUC: 0.7045197368421053
Validation loss: 1.4343747225674717 ROC AUC: 0.7187236842105262
Validation loss: 1.5749069030838783 ROC AUC: 0.7172960526315789
Validation loss: 1.8273934258355036 ROC AUC: 0.695328947368421
Validation loss: 1.7852170816575639 ROC AUC: 0.6986315789473684
Validation loss: 1.7348649929268192 ROC AUC: 0.7088355263157895
75 0 1.2890019416809082
Validation loss: 1.9036659508040457 ROC AUC: 0.6969671052631579
Validation loss: 1.8969098570370915 ROC AUC: 0.6920328947368419
Validation loss: 1.7498039031269574 ROC AUC: 0.7037894736842105
Validation loss: 1.568681214794968 ROC AUC: 0.7148092105263157
Validation loss: 1.463876136625656 ROC AUC: 0.7103815789473684
Validation loss: 1.4701749748653836 ROC AUC: 0.6998486842105264
Validation loss: 1.5281882538939968 ROC AUC: 0.6917500000000001
Validation loss: 1.477535074407404 ROC AUC: 0.7042697368421053
Validation loss: 1.4677878919273917 ROC AUC: 0.7155197368421052
Validation loss: 1.535828093085626 ROC AUC: 0.7242894736842106
Validation loss: 1.5425324680829289 ROC AUC: 0.7241381578947368
Validation loss: 1.5571279272888645 ROC AUC: 0.7261907894736843
87 2 1.369551658630371
Validation loss: 1.620448056495551 ROC AUC: 0.721046052631579
Validation loss: 1.649546696682169 ROC AUC: 0.7250328947368422
Validation loss: 1.5680672905661843 ROC AUC: 0.730467105263158
Validation loss: 1.5510269210796164 ROC AUC: 0.7318289473684211
Validation loss: 1.560857426036488 ROC AUC: 0.7305789473684211
Validation loss: 1.494190928911922 ROC AUC: 0.7362171052631579
Validation loss: 1.4073887352991585 ROC AUC: 0.738907894736842
Validation loss: 1.4227675693203705 ROC AUC: 0.7262302631578947
Validation loss: 1.6293641930878764 ROC AUC: 0.6906447368421053
Validation loss: 1.91079145489317 ROC AUC: 0.6691447368421052
Validation loss: 2.2121542150324043 ROC AUC: 0.6542105263157895
Validation loss: 2.192114899856876 ROC AUC: 0.6563881578947369
Validation loss: 2.118095304026748 ROC AUC: 0.6693618421052632
Loaded trained model with success.
Test loss: 1.9614974355888748 Test ROC AUC: 0.5529861669594504
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.7391166687011719
Validation loss: 1.636255430815807 ROC AUC: 0.4964615384615385
Validation loss: 1.6410365386224872 ROC AUC: 0.5367239583333333
Validation loss: 1.7242977181870733 ROC AUC: 0.5221041666666666
Validation loss: 1.7218684401344415 ROC AUC: 0.5685849358974359
Validation loss: 1.6653712957947697 ROC AUC: 0.5716370192307692
Validation loss: 1.6114774067797253 ROC AUC: 0.568318108974359
Validation loss: 1.5945195055487167 ROC AUC: 0.5804407051282051
7 1 1.552502155303955
Validation loss: 1.5767752591089987 ROC AUC: 0.5882572115384616
Validation loss: 1.5892787416975702 ROC AUC: 0.6058068910256411
Validation loss: 1.6219844836086483 ROC AUC: 0.608423076923077
Validation loss: 1.5917989153358805 ROC AUC: 0.6139495192307691
Validation loss: 1.587382141669192 ROC AUC: 0.6151642628205128
Validation loss: 1.5987542987468855 ROC AUC: 0.6219407051282051
Validation loss: 1.6012145101125517 ROC AUC: 0.6300344551282052
14 2 1.5549544095993042
Validation loss: 1.5519793986076087 ROC AUC: 0.6371434294871795
Validation loss: 1.5310378146530994 ROC AUC: 0.6409230769230769
Validation loss: 1.5318714703746776 ROC AUC: 0.6421915064102565
Validation loss: 1.524944899070203 ROC AUC: 0.6456794871794872
Validation loss: 1.501874951261971 ROC AUC: 0.65853125
Validation loss: 1.5035381508832002 ROC AUC: 0.6682171474358974
Validation loss: 1.4757662676087575 ROC AUC: 0.6779559294871794
21 3 1.6154730319976807
Validation loss: 1.465430442412295 ROC AUC: 0.683213141025641
Validation loss: 1.463270303592011 ROC AUC: 0.6791698717948719
Validation loss: 1.4542477556209468 ROC AUC: 0.6883357371794872
Validation loss: 1.4932418851996188 ROC AUC: 0.6924559294871795
Validation loss: 1.5508307757689126 ROC AUC: 0.6858597756410256
Validation loss: 1.4880461734742974 ROC AUC: 0.6934879807692308
Validation loss: 1.5929349199611338 ROC AUC: 0.6774879807692307
28 4 1.3808631896972656
Validation loss: 1.4945415246426759 ROC AUC: 0.7009126602564103
Validation loss: 1.4198659388863262 ROC AUC: 0.7047315705128205
Validation loss: 1.4411364985470796 ROC AUC: 0.6994607371794872
Validation loss: 1.4329566925614323 ROC AUC: 0.6997363782051281
Validation loss: 1.4122095820891798 ROC AUC: 0.7227331730769231
Validation loss: 1.4411288284177157 ROC AUC: 0.7275985576923077
Validation loss: 1.4463671344009477 ROC AUC: 0.7109567307692308
35 5 1.6672494411468506
Validation loss: 1.4072545593108363 ROC AUC: 0.7188733974358975
Validation loss: 1.3832576179025162 ROC AUC: 0.7234070512820512
Validation loss: 1.3816066339387367 ROC AUC: 0.7244326923076922
Validation loss: 1.3687582165751624 ROC AUC: 0.7293613782051283
Validation loss: 1.3784547217527228 ROC AUC: 0.7214150641025641
Validation loss: 1.35785410212512 ROC AUC: 0.7289286858974359
Validation loss: 1.352151461582088 ROC AUC: 0.7375056089743589
42 6 1.444040298461914
Validation loss: 1.3776644785799572 ROC AUC: 0.735383814102564
Validation loss: 1.3385768925125276 ROC AUC: 0.7447147435897437
Validation loss: 1.3378820173704444 ROC AUC: 0.744897435897436
Validation loss: 1.3887827336488656 ROC AUC: 0.7293509615384616
Validation loss: 1.3696115370371833 ROC AUC: 0.7346161858974358
Validation loss: 1.3506532134722227 ROC AUC: 0.7366522435897437
Validation loss: 1.3344557698647581 ROC AUC: 0.7424751602564102
Validation loss: 1.370001820463631 ROC AUC: 0.7356402243589744
50 0 1.349958896636963
Validation loss: 1.3451536127071284 ROC AUC: 0.7432612179487179
Validation loss: 1.3625617824008118 ROC AUC: 0.7380504807692307
Validation loss: 1.3724696019187046 ROC AUC: 0.7413461538461539
Validation loss: 1.4761299853348853 ROC AUC: 0.7286466346153847
Validation loss: 1.4973016617885186 ROC AUC: 0.7187091346153845
Validation loss: 1.337116939937649 ROC AUC: 0.7430641025641025
Validation loss: 1.3598889987073353 ROC AUC: 0.7354070512820512
57 1 1.4005930423736572
Validation loss: 1.3764878601285082 ROC AUC: 0.7498966346153846
Validation loss: 1.4226967066376652 ROC AUC: 0.7393493589743589
Validation loss: 1.499446587346906 ROC AUC: 0.7340128205128205
Validation loss: 1.3759186854913605 ROC AUC: 0.7553092948717949
Validation loss: 1.3000458562793444 ROC AUC: 0.7667884615384615
Validation loss: 1.3220044104897197 ROC AUC: 0.7664631410256411
Validation loss: 1.3527353055513085 ROC AUC: 0.7695328525641025
64 2 1.496491551399231
Validation loss: 1.442521546354246 ROC AUC: 0.7500745192307692
Validation loss: 1.3457218420565429 ROC AUC: 0.7699759615384616
Validation loss: 1.2752286135850839 ROC AUC: 0.781121794871795
Validation loss: 1.299949347673349 ROC AUC: 0.7793301282051284
Validation loss: 1.299642693457292 ROC AUC: 0.777556891025641
Validation loss: 1.3588172407006498 ROC AUC: 0.769165064102564
Validation loss: 1.299671304285826 ROC AUC: 0.7833052884615385
71 3 1.4178372621536255
Validation loss: 1.3107139207609935 ROC AUC: 0.7847019230769231
Validation loss: 1.3632075552964331 ROC AUC: 0.7806033653846154
Validation loss: 1.392742752429828 ROC AUC: 0.7644607371794871
Validation loss: 1.5962751570658469 ROC AUC: 0.755880608974359
Validation loss: 1.6706512884878033 ROC AUC: 0.7408677884615384
Validation loss: 1.5889010561171488 ROC AUC: 0.7529046474358975
Validation loss: 1.5728771593702497 ROC AUC: 0.7666482371794873
78 4 1.2309355735778809
Validation loss: 1.427851302539883 ROC AUC: 0.7807003205128205
Validation loss: 1.3955734944223759 ROC AUC: 0.7836426282051281
Validation loss: 1.3241944043480571 ROC AUC: 0.7892379807692307
Validation loss: 1.376179345888109 ROC AUC: 0.7867171474358975
Validation loss: 1.483069168862386 ROC AUC: 0.7760721153846154
Validation loss: 1.398970609334246 ROC AUC: 0.7795328525641025
Validation loss: 1.3465100934158019 ROC AUC: 0.7868261217948718
85 5 1.4164808988571167
Validation loss: 1.473735901578587 ROC AUC: 0.7749975961538462
Validation loss: 1.4469554876562338 ROC AUC: 0.7767764423076923
Validation loss: 1.276877160048365 ROC AUC: 0.7997868589743591
Validation loss: 1.2206539646464976 ROC AUC: 0.8133221153846154
Validation loss: 1.2423072879637904 ROC AUC: 0.8060536858974359
Validation loss: 1.2492408494853495 ROC AUC: 0.8069455128205127
Validation loss: 1.2449501860680892 ROC AUC: 0.8100945512820512
92 6 1.527145504951477
Validation loss: 1.3364663501480716 ROC AUC: 0.7991915064102565
Validation loss: 1.2511503235179575 ROC AUC: 0.8073814102564102
Validation loss: 1.276654987478975 ROC AUC: 0.8036610576923078
Validation loss: 1.333571737136074 ROC AUC: 0.7985400641025642
Validation loss: 1.2701656309204485 ROC AUC: 0.8035977564102564
Validation loss: 1.2045058497232408 ROC AUC: 0.8178902243589743
Validation loss: 1.2478012571382762 ROC AUC: 0.8085576923076923
Validation loss: 1.2869806062037021 ROC AUC: 0.8085857371794873
Loaded trained model with success.
Test loss: 1.954982735797398 Test ROC AUC: 0.6192589563873895
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.6643110513687134
Validation loss: 1.6134126172037067 ROC AUC: 0.5554625000000001
Validation loss: 1.6084380441294883 ROC AUC: 0.5643992676767676
Validation loss: 1.7272586798620129 ROC AUC: 0.579787398989899
3 2 1.6689764261245728
Validation loss: 1.7419730967175746 ROC AUC: 0.5716297474747474
Validation loss: 1.6725643225805553 ROC AUC: 0.5779482323232323
Validation loss: 1.910237887579358 ROC AUC: 0.5581167424242424
6 4 1.6049420833587646
Validation loss: 1.7721413228220357 ROC AUC: 0.5748214898989898
Validation loss: 1.6663472812495872 ROC AUC: 0.5958858838383838
Validation loss: 1.6748201854243308 ROC AUC: 0.6042701767676768
9 6 1.5618116855621338
Validation loss: 1.5692482357751392 ROC AUC: 0.6368353282828283
Validation loss: 2.0150218449518054 ROC AUC: 0.5976702777777778
Validation loss: 2.8361064393916924 ROC AUC: 0.5784725
12 8 1.4904847145080566
Validation loss: 1.9145457118689895 ROC AUC: 0.5987128535353536
Validation loss: 1.7433356995095233 ROC AUC: 0.6351792676767676
Validation loss: 2.0236991966415743 ROC AUC: 0.6183888383838384
15 10 1.5206751823425293
Validation loss: 1.937059971516978 ROC AUC: 0.6258686363636364
Validation loss: 1.810313800054944 ROC AUC: 0.6426881818181818
Validation loss: 1.4794448203218724 ROC AUC: 0.6869521212121212
18 12 1.3933712244033813
Validation loss: 2.1542372125423026 ROC AUC: 0.6241470454545455
Validation loss: 1.645228625538354 ROC AUC: 0.658541994949495
Validation loss: 1.8840297873846754 ROC AUC: 0.639654898989899
21 14 1.471722960472107
Validation loss: 1.615567754170221 ROC AUC: 0.6630024242424243
Validation loss: 1.731816431802356 ROC AUC: 0.6686977525252525
Validation loss: 1.872774112678482 ROC AUC: 0.6511483333333333
Validation loss: 1.697562245185485 ROC AUC: 0.667395202020202
25 0 1.4853850603103638
Validation loss: 1.8105656966895523 ROC AUC: 0.6679658585858587
Validation loss: 1.7166875636649275 ROC AUC: 0.6595730303030303
Validation loss: 2.013186008036734 ROC AUC: 0.6424425
28 2 1.5588306188583374
Validation loss: 1.9330042777415029 ROC AUC: 0.6551197474747475
Validation loss: 1.6075032039252455 ROC AUC: 0.6926849747474748
Validation loss: 1.707753488200461 ROC AUC: 0.6855877020202021
31 4 1.5073294639587402
Validation loss: 1.5057098036538623 ROC AUC: 0.7076262373737373
Validation loss: 1.5462866959447612 ROC AUC: 0.6976056818181818
Validation loss: 1.6204737489352485 ROC AUC: 0.6880352272727273
34 6 1.3814586400985718
Validation loss: 1.6037733100936982 ROC AUC: 0.6911940151515152
Validation loss: 1.5149629417067778 ROC AUC: 0.7102524747474748
Validation loss: 1.6703492374362832 ROC AUC: 0.6922622979797979
37 8 1.4396600723266602
Validation loss: 1.5972407604745011 ROC AUC: 0.6952926767676768
Validation loss: 1.8149252929286155 ROC AUC: 0.669531792929293
Validation loss: 1.7931763729255998 ROC AUC: 0.6748001262626262
40 10 1.2942876815795898
Validation loss: 1.5226077333480896 ROC AUC: 0.715795202020202
Validation loss: 1.5400284595623284 ROC AUC: 0.7054670454545455
Validation loss: 1.3601222915018727 ROC AUC: 0.7364310101010101
43 12 1.4040377140045166
Validation loss: 1.4161142485891889 ROC AUC: 0.7203213636363637
Validation loss: 1.340415598156457 ROC AUC: 0.7475662626262626
Validation loss: 1.348973704722219 ROC AUC: 0.7433320707070707
46 14 1.3101632595062256
Validation loss: 1.3217161186711344 ROC AUC: 0.7549706565656565
Validation loss: 1.3036549406682323 ROC AUC: 0.7620623232323231
Validation loss: 1.362605694300665 ROC AUC: 0.7450709848484849
Validation loss: 1.5087044473162634 ROC AUC: 0.7195499747474747
50 0 1.3003907203674316
Validation loss: 1.6961953327029884 ROC AUC: 0.7050852020202021
Validation loss: 1.4628051263774804 ROC AUC: 0.7167538888888888
Validation loss: 1.6021154536035114 ROC AUC: 0.7108943434343434
53 2 1.3997745513916016
Validation loss: 1.5216736220166773 ROC AUC: 0.7244791666666666
Validation loss: 1.3791973999363627 ROC AUC: 0.7469425757575757
Validation loss: 1.4906164479399013 ROC AUC: 0.7311065151515151
56 4 1.1344130039215088
Validation loss: 1.43073054831587 ROC AUC: 0.7385091666666668
Validation loss: 1.390935517265228 ROC AUC: 0.7476945202020201
Validation loss: 1.4411898653110664 ROC AUC: 0.7399505050505051
59 6 1.338918924331665
Validation loss: 1.3394038216145578 ROC AUC: 0.7635930050505052
Validation loss: 1.300027379530943 ROC AUC: 0.7686223737373739
Validation loss: 1.4288829266427754 ROC AUC: 0.7377807323232324
62 8 1.2454264163970947
Validation loss: 1.3229971352464451 ROC AUC: 0.7569841919191919
Validation loss: 1.4747769376319013 ROC AUC: 0.7375056818181818
Validation loss: 1.4580084701817118 ROC AUC: 0.7338915151515152
65 10 1.5156161785125732
Validation loss: 1.501222394750209 ROC AUC: 0.7334664141414141
Validation loss: 1.380277573704003 ROC AUC: 0.7549877525252524
Validation loss: 1.3705016233639153 ROC AUC: 0.7576579797979799
68 12 1.4165641069412231
Validation loss: 1.4612677207212887 ROC AUC: 0.739370782828283
Validation loss: 1.290846503330376 ROC AUC: 0.7761724747474747
Validation loss: 1.41202029508197 ROC AUC: 0.749336212121212
71 14 1.2546647787094116
Validation loss: 1.347495851631394 ROC AUC: 0.7634592171717172
Validation loss: 1.291093348740098 ROC AUC: 0.7763972474747475
Validation loss: 1.4375758257084237 ROC AUC: 0.7523197222222222
Validation loss: 1.2691446045835415 ROC AUC: 0.7798063131313132
75 0 1.328678846359253
Validation loss: 1.3289536381054499 ROC AUC: 0.7759433585858586
Validation loss: 1.2812361647944173 ROC AUC: 0.7808339141414142
Validation loss: 1.482258087647463 ROC AUC: 0.7436659848484849
78 2 1.1325089931488037
Validation loss: 1.3913421700139323 ROC AUC: 0.7597617929292929
Validation loss: 1.3795669993800008 ROC AUC: 0.7667896969696969
Validation loss: 1.3213689081176727 ROC AUC: 0.774963611111111
81 4 1.0029470920562744
Validation loss: 1.3174251788603757 ROC AUC: 0.7766575757575758
Validation loss: 1.3181670027409862 ROC AUC: 0.7771695454545454
Validation loss: 1.2718186146749524 ROC AUC: 0.7840408333333333
84 6 1.0826908349990845
Validation loss: 1.296662637370383 ROC AUC: 0.7818754797979798
Validation loss: 1.4255839844266016 ROC AUC: 0.7580911363636363
Validation loss: 1.3475807644800097 ROC AUC: 0.7715212373737373
87 8 1.2420425415039062
Validation loss: 1.2914355852322015 ROC AUC: 0.7880284090909091
Validation loss: 1.2742543865540223 ROC AUC: 0.7749230050505052
Validation loss: 1.3152517328759235 ROC AUC: 0.7779355555555557
90 10 1.449355125427246
Validation loss: 1.3144869090082172 ROC AUC: 0.7720942676767677
Validation loss: 1.299704110694075 ROC AUC: 0.7837011111111112
Validation loss: 1.2169118336064066 ROC AUC: 0.8003639646464646
93 12 1.1740401983261108
Validation loss: 1.3222401204233418 ROC AUC: 0.7700638888888889
Validation loss: 1.2677641567104088 ROC AUC: 0.7886110606060606
Validation loss: 1.2356957581812489 ROC AUC: 0.8028178282828282
96 14 1.2293938398361206
Validation loss: 1.3081241905808687 ROC AUC: 0.7862527777777778
Validation loss: 1.2850956161896547 ROC AUC: 0.7846697727272728
Validation loss: 1.2348972114627967 ROC AUC: 0.8024181565656565
Validation loss: 1.1488394173448215 ROC AUC: 0.81797101010101
Loaded trained model with success.
2023-02-13 20:30:23.512 | ERROR    | __main__:<module>:208 - With n_samples=5000, test_size=0.9999848297979177 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 10
    │        └ 'qmug'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061c33c8d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c324950>
                                              └ <finetune.FineTune object at 0x7f061c33c8d0>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 217, in get_data_loaders
    train_loader, valid_loader, test_loader = self.get_train_validation_data_loaders(train_dataset)
                                              │    │                                 └ MolTestDataset(5000)
                                              │    └ <function MolTestDatasetWrapper.get_train_validation_data_loaders at 0x7f061ef52680>
                                              └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c324950>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 241, in get_train_validation_data_loaders
    train_idx, test_idx, stratify_train, stratify_test = train_test_split(indices, ys, test_size=1 - train_ratio, stratify=ys)
                                                         │                │        │                 │                     └ array([2, 1, 2, ..., 2, 2, 2])
                                                         │                │        │                 └ 1.517020208230413e-05
                                                         │                │        └ array([2, 1, 2, ..., 2, 2, 2])
                                                         │                └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                                                         └ <function train_test_split at 0x7f0646e448c0>

  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2421, in train_test_split
    n_samples, test_size, train_size, default_test_size=0.25
    │          │          └ None
    │          └ 0.9999848297979177
    └ 5000
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2101, in _validate_shuffle_split
    "aforementioned parameters.".format(n_samples, test_size, train_size)
                                        │          │          └ None
                                        │          └ 0.9999848297979177
                                        └ 5000

ValueError: With n_samples=5000, test_size=0.9999848297979177 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
2023-02-13 20:32:39.979 | ERROR    | __main__:<module>:208 - With n_samples=5000, test_size=0.9999241489895887 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 50
    │        └ 'qmug'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061c33c6d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061f5a0410>
                                              └ <finetune.FineTune object at 0x7f061c33c6d0>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 217, in get_data_loaders
    train_loader, valid_loader, test_loader = self.get_train_validation_data_loaders(train_dataset)
                                              │    │                                 └ MolTestDataset(5000)
                                              │    └ <function MolTestDatasetWrapper.get_train_validation_data_loaders at 0x7f061ef52680>
                                              └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061f5a0410>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 241, in get_train_validation_data_loaders
    train_idx, test_idx, stratify_train, stratify_test = train_test_split(indices, ys, test_size=1 - train_ratio, stratify=ys)
                                                         │                │        │                 │                     └ array([2, 1, 2, ..., 2, 2, 2])
                                                         │                │        │                 └ 7.58510104112986e-05
                                                         │                │        └ array([2, 1, 2, ..., 2, 2, 2])
                                                         │                └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                                                         └ <function train_test_split at 0x7f0646e448c0>

  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2421, in train_test_split
    n_samples, test_size, train_size, default_test_size=0.25
    │          │          └ None
    │          └ 0.9999241489895887
    └ 5000
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2101, in _validate_shuffle_split
    "aforementioned parameters.".format(n_samples, test_size, train_size)
                                        │          │          └ None
                                        │          └ 0.9999241489895887
                                        └ 5000

ValueError: With n_samples=5000, test_size=0.9999241489895887 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
2023-02-13 20:34:56.688 | ERROR    | __main__:<module>:208 - With n_samples=5000, test_size=0.9998482979791774 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 100
    │        └ 'qmug'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed69910>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f06201772d0>
                                              └ <finetune.FineTune object at 0x7f061ed69910>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 217, in get_data_loaders
    train_loader, valid_loader, test_loader = self.get_train_validation_data_loaders(train_dataset)
                                              │    │                                 └ MolTestDataset(5000)
                                              │    └ <function MolTestDatasetWrapper.get_train_validation_data_loaders at 0x7f061ef52680>
                                              └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f06201772d0>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 241, in get_train_validation_data_loaders
    train_idx, test_idx, stratify_train, stratify_test = train_test_split(indices, ys, test_size=1 - train_ratio, stratify=ys)
                                                         │                │        │                 │                     └ array([2, 1, 2, ..., 2, 2, 2])
                                                         │                │        │                 └ 0.0001517020208225972
                                                         │                │        └ array([2, 1, 2, ..., 2, 2, 2])
                                                         │                └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                                                         └ <function train_test_split at 0x7f0646e448c0>

  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2421, in train_test_split
    n_samples, test_size, train_size, default_test_size=0.25
    │          │          └ None
    │          └ 0.9998482979791774
    └ 5000
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2101, in _validate_shuffle_split
    "aforementioned parameters.".format(n_samples, test_size, train_size)
                                        │          │          └ None
                                        │          └ 0.9998482979791774
                                        └ 5000

ValueError: With n_samples=5000, test_size=0.9998482979791774 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
2023-02-13 20:37:13.157 | ERROR    | __main__:<module>:208 - The train_size = 1 should be greater or equal to the number of classes = 5
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 200
    │        └ 'qmug'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed73ad0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed55090>
                                              └ <finetune.FineTune object at 0x7f061ed73ad0>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 217, in get_data_loaders
    train_loader, valid_loader, test_loader = self.get_train_validation_data_loaders(train_dataset)
                                              │    │                                 └ MolTestDataset(5000)
                                              │    └ <function MolTestDatasetWrapper.get_train_validation_data_loaders at 0x7f061ef52680>
                                              └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed55090>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 241, in get_train_validation_data_loaders
    train_idx, test_idx, stratify_train, stratify_test = train_test_split(indices, ys, test_size=1 - train_ratio, stratify=ys)
                                                         │                │        │                 │                     └ array([2, 1, 2, ..., 2, 2, 2])
                                                         │                │        │                 └ 0.0003034040416451944
                                                         │                │        └ array([2, 1, 2, ..., 2, 2, 2])
                                                         │                └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                                                         └ <function train_test_split at 0x7f0646e448c0>

  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2441, in train_test_split
    train, test = next(cv.split(X=arrays[0], y=stratify))
                       │  │       │            └ array([2, 1, 2, ..., 2, 2, 2])
                       │  │       └ [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 3...
                       │  └ <function StratifiedShuffleSplit.split at 0x7f0646e443b0>
                       └ StratifiedShuffleSplit(n_splits=10, random_state=None, test_size=4999,
                                     train_size=1)
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 1600, in split
    for train, test in self._iter_indices(X, y, groups):
                       │    │             │  │  └ None
                       │    │             │  └ array([2, 1, 2, ..., 2, 2, 2])
                       │    │             └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                       │    └ <function StratifiedShuffleSplit._iter_indices at 0x7f0646e44320>
                       └ StratifiedShuffleSplit(n_splits=10, random_state=None, test_size=4999,
                                     train_size=1)
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 1950, in _iter_indices
    "equal to the number of classes = %d" % (n_train, n_classes)
                                             │        └ 5
                                             └ 1

ValueError: The train_size = 1 should be greater or equal to the number of classes = 5
2023-02-13 20:39:30.050 | ERROR    | __main__:<module>:208 - The train_size = 3 should be greater or equal to the number of classes = 5
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 500
    │        └ 'qmug'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed55090>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c33c490>
                                              └ <finetune.FineTune object at 0x7f061ed55090>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 217, in get_data_loaders
    train_loader, valid_loader, test_loader = self.get_train_validation_data_loaders(train_dataset)
                                              │    │                                 └ MolTestDataset(5000)
                                              │    └ <function MolTestDatasetWrapper.get_train_validation_data_loaders at 0x7f061ef52680>
                                              └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c33c490>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 241, in get_train_validation_data_loaders
    train_idx, test_idx, stratify_train, stratify_test = train_test_split(indices, ys, test_size=1 - train_ratio, stratify=ys)
                                                         │                │        │                 │                     └ array([2, 1, 2, ..., 2, 2, 2])
                                                         │                │        │                 └ 0.000758510104113097
                                                         │                │        └ array([2, 1, 2, ..., 2, 2, 2])
                                                         │                └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                                                         └ <function train_test_split at 0x7f0646e448c0>

  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2441, in train_test_split
    train, test = next(cv.split(X=arrays[0], y=stratify))
                       │  │       │            └ array([2, 1, 2, ..., 2, 2, 2])
                       │  │       └ [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 3...
                       │  └ <function StratifiedShuffleSplit.split at 0x7f0646e443b0>
                       └ StratifiedShuffleSplit(n_splits=10, random_state=None, test_size=4997,
                                     train_size=3)
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 1600, in split
    for train, test in self._iter_indices(X, y, groups):
                       │    │             │  │  └ None
                       │    │             │  └ array([2, 1, 2, ..., 2, 2, 2])
                       │    │             └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                       │    └ <function StratifiedShuffleSplit._iter_indices at 0x7f0646e44320>
                       └ StratifiedShuffleSplit(n_splits=10, random_state=None, test_size=4997,
                                     train_size=3)
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 1950, in _iter_indices
    "equal to the number of classes = %d" % (n_train, n_classes)
                                             │        └ 5
                                             └ 3

ValueError: The train_size = 3 should be greater or equal to the number of classes = 5
Test loss: 1.758313429794184 Test ROC AUC: 0.6530988306844371
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999848297979177, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999241489895887, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9998482979791774, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9996965959583548, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9992414898958869, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9984829797917738, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 7, Valid size: 7, Test size: 4993
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 61.78226089477539
Validation loss: 54.712013244628906 MAE: 7.3512764
Validation loss: 46.696712493896484 MAE: 6.784196
Validation loss: 39.06740951538086 MAE: 6.1964984
Validation loss: 31.87281608581543 MAE: 5.5859885
Validation loss: 25.1480770111084 MAE: 4.9477224
Validation loss: 18.971525192260742 MAE: 4.2785525
Validation loss: 13.398902893066406 MAE: 3.5686803
Validation loss: 8.658795356750488 MAE: 2.827347
Validation loss: 4.724836826324463 MAE: 2.0134742
Validation loss: 2.12160587310791 MAE: 1.1919482
Validation loss: 0.8473025560379028 MAE: 0.6223353
Validation loss: 1.185778260231018 MAE: 0.93456876
Validation loss: 3.2473225593566895 MAE: 1.5788504
Validation loss: 7.1697306632995605 MAE: 2.3723679
Validation loss: 12.76805591583252 MAE: 3.2714632
Validation loss: 19.802532196044922 MAE: 4.11116
Validation loss: 26.489625930786133 MAE: 4.6605988
Validation loss: 34.1413688659668 MAE: 5.3563676
Validation loss: 36.13759231567383 MAE: 5.481007
Validation loss: 32.83836364746094 MAE: 5.0942926
Validation loss: 26.654878616333008 MAE: 4.564567
Validation loss: 19.347795486450195 MAE: 3.8520029
Validation loss: 13.28193187713623 MAE: 3.1665742
Validation loss: 8.632885932922363 MAE: 2.4866517
Validation loss: 5.568198204040527 MAE: 1.972577
Validation loss: 2.979133129119873 MAE: 1.4638479
Validation loss: 1.8150546550750732 MAE: 1.1706003
Validation loss: 1.1070197820663452 MAE: 0.9291956
Validation loss: 0.7693915367126465 MAE: 0.79509574
Validation loss: 0.608085036277771 MAE: 0.7361792
Validation loss: 0.6393834352493286 MAE: 0.719792
Validation loss: 0.7377747297286987 MAE: 0.6664256
Validation loss: 0.839643657207489 MAE: 0.68220216
Validation loss: 0.9365224838256836 MAE: 0.7340454
Validation loss: 1.0098779201507568 MAE: 0.77157676
Validation loss: 1.084973692893982 MAE: 0.85503423
Validation loss: 1.225529432296753 MAE: 0.95147026
Validation loss: 1.4025708436965942 MAE: 1.0073649
Validation loss: 1.5101884603500366 MAE: 1.0100691
Validation loss: 1.6751928329467773 MAE: 1.0187719
Validation loss: 1.9198143482208252 MAE: 1.0654863
Validation loss: 2.1627581119537354 MAE: 1.1474594
Validation loss: 2.503516674041748 MAE: 1.2420835
Validation loss: 2.6495368480682373 MAE: 1.2760146
Validation loss: 3.05472993850708 MAE: 1.3673254
Validation loss: 3.184929370880127 MAE: 1.3981946
Validation loss: 3.083000421524048 MAE: 1.383322
Validation loss: 2.638878107070923 MAE: 1.2778933
Validation loss: 2.464991807937622 MAE: 1.2321383
Validation loss: 2.0400922298431396 MAE: 1.1322178
50 0 0.5444512367248535
Validation loss: 1.523408055305481 MAE: 0.9930438
Validation loss: 1.2411507368087769 MAE: 0.90736
Validation loss: 1.0058742761611938 MAE: 0.8274642
Validation loss: 0.8570774793624878 MAE: 0.773273
Validation loss: 0.7023150324821472 MAE: 0.70424026
Validation loss: 0.6237913370132446 MAE: 0.6648385
Validation loss: 0.560823380947113 MAE: 0.6302969
Validation loss: 0.5340809226036072 MAE: 0.6141377
Validation loss: 0.4611808657646179 MAE: 0.5650925
Validation loss: 0.45527514815330505 MAE: 0.5615068
Validation loss: 0.4847070574760437 MAE: 0.58279365
Validation loss: 0.49938908219337463 MAE: 0.5935477
Validation loss: 0.48769447207450867 MAE: 0.589345
Validation loss: 0.5505335330963135 MAE: 0.626315
Validation loss: 0.6571105718612671 MAE: 0.6844427
Validation loss: 0.7644966840744019 MAE: 0.7350427
Validation loss: 0.7873231172561646 MAE: 0.74685067
Validation loss: 0.8342994451522827 MAE: 0.7679495
Validation loss: 0.8277980089187622 MAE: 0.76793677
Validation loss: 0.7644187211990356 MAE: 0.7443013
Validation loss: 0.7449390292167664 MAE: 0.7381073
Validation loss: 0.7651709318161011 MAE: 0.7495831
Validation loss: 0.7709835767745972 MAE: 0.7512271
Validation loss: 0.7833638191223145 MAE: 0.7555652
Validation loss: 0.818029522895813 MAE: 0.7691221
Validation loss: 0.8533650040626526 MAE: 0.7803706
Validation loss: 0.9237672686576843 MAE: 0.8069719
Validation loss: 1.0200872421264648 MAE: 0.84101015
Validation loss: 1.0475921630859375 MAE: 0.84668475
Validation loss: 1.1856392621994019 MAE: 0.89269733
Validation loss: 1.1157677173614502 MAE: 0.86470425
Validation loss: 1.0158027410507202 MAE: 0.8277444
Validation loss: 0.9054219126701355 MAE: 0.78329384
Validation loss: 0.9194828271865845 MAE: 0.78709364
Validation loss: 0.8729895353317261 MAE: 0.76720667
Validation loss: 0.9052239656448364 MAE: 0.7804512
Validation loss: 0.9127282500267029 MAE: 0.7843215
Validation loss: 0.8051751852035522 MAE: 0.7427902
Validation loss: 0.7627847790718079 MAE: 0.7264673
Validation loss: 0.74314945936203 MAE: 0.7190982
Validation loss: 0.6543892621994019 MAE: 0.67980546
Validation loss: 0.5576152205467224 MAE: 0.6310801
Validation loss: 0.5095788836479187 MAE: 0.6118514
Validation loss: 0.4921758472919464 MAE: 0.6057047
Validation loss: 0.4978105127811432 MAE: 0.61085635
Validation loss: 0.4921334385871887 MAE: 0.60880697
Validation loss: 0.5518513917922974 MAE: 0.6455821
Validation loss: 0.5655882954597473 MAE: 0.6546001
Validation loss: 0.5246313214302063 MAE: 0.63028604
Validation loss: 0.5307345986366272 MAE: 0.6334054
Loaded trained model with success.
2023-02-13 20:46:27.300 | ERROR    | __main__:<module>:208 - With n_samples=5000, test_size=0.9999848297979177 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 10
    │        └ 'qmug_2'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061c2e8c90>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c2e84d0>
                                              └ <finetune.FineTune object at 0x7f061c2e8c90>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 217, in get_data_loaders
    train_loader, valid_loader, test_loader = self.get_train_validation_data_loaders(train_dataset)
                                              │    │                                 └ MolTestDataset(5000)
                                              │    └ <function MolTestDatasetWrapper.get_train_validation_data_loaders at 0x7f061ef52680>
                                              └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c2e84d0>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 241, in get_train_validation_data_loaders
    train_idx, test_idx, stratify_train, stratify_test = train_test_split(indices, ys, test_size=1 - train_ratio, stratify=ys)
                                                         │                │        │                 │                     └ array([1, 0, 1, ..., 0, 0, 0])
                                                         │                │        │                 └ 1.517020208230413e-05
                                                         │                │        └ array([1, 0, 1, ..., 0, 0, 0])
                                                         │                └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                                                         └ <function train_test_split at 0x7f0646e448c0>

  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2421, in train_test_split
    n_samples, test_size, train_size, default_test_size=0.25
    │          │          └ None
    │          └ 0.9999848297979177
    └ 5000
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2101, in _validate_shuffle_split
    "aforementioned parameters.".format(n_samples, test_size, train_size)
                                        │          │          └ None
                                        │          └ 0.9999848297979177
                                        └ 5000

ValueError: With n_samples=5000, test_size=0.9999848297979177 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
2023-02-13 20:48:43.207 | ERROR    | __main__:<module>:208 - With n_samples=5000, test_size=0.9999241489895887 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 50
    │        └ 'qmug_2'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061c453dd0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c453f10>
                                              └ <finetune.FineTune object at 0x7f061c453dd0>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 217, in get_data_loaders
    train_loader, valid_loader, test_loader = self.get_train_validation_data_loaders(train_dataset)
                                              │    │                                 └ MolTestDataset(5000)
                                              │    └ <function MolTestDatasetWrapper.get_train_validation_data_loaders at 0x7f061ef52680>
                                              └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c453f10>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 241, in get_train_validation_data_loaders
    train_idx, test_idx, stratify_train, stratify_test = train_test_split(indices, ys, test_size=1 - train_ratio, stratify=ys)
                                                         │                │        │                 │                     └ array([1, 0, 1, ..., 0, 0, 0])
                                                         │                │        │                 └ 7.58510104112986e-05
                                                         │                │        └ array([1, 0, 1, ..., 0, 0, 0])
                                                         │                └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                                                         └ <function train_test_split at 0x7f0646e448c0>

  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2421, in train_test_split
    n_samples, test_size, train_size, default_test_size=0.25
    │          │          └ None
    │          └ 0.9999241489895887
    └ 5000
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2101, in _validate_shuffle_split
    "aforementioned parameters.".format(n_samples, test_size, train_size)
                                        │          │          └ None
                                        │          └ 0.9999241489895887
                                        └ 5000

ValueError: With n_samples=5000, test_size=0.9999241489895887 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
2023-02-13 20:50:58.976 | ERROR    | __main__:<module>:208 - With n_samples=5000, test_size=0.9998482979791774 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 100
    │        └ 'qmug_2'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f06201772d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c3a1550>
                                              └ <finetune.FineTune object at 0x7f06201772d0>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 217, in get_data_loaders
    train_loader, valid_loader, test_loader = self.get_train_validation_data_loaders(train_dataset)
                                              │    │                                 └ MolTestDataset(5000)
                                              │    └ <function MolTestDatasetWrapper.get_train_validation_data_loaders at 0x7f061ef52680>
                                              └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c3a1550>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 241, in get_train_validation_data_loaders
    train_idx, test_idx, stratify_train, stratify_test = train_test_split(indices, ys, test_size=1 - train_ratio, stratify=ys)
                                                         │                │        │                 │                     └ array([1, 0, 1, ..., 0, 0, 0])
                                                         │                │        │                 └ 0.0001517020208225972
                                                         │                │        └ array([1, 0, 1, ..., 0, 0, 0])
                                                         │                └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                                                         └ <function train_test_split at 0x7f0646e448c0>

  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2421, in train_test_split
    n_samples, test_size, train_size, default_test_size=0.25
    │          │          └ None
    │          └ 0.9998482979791774
    └ 5000
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2101, in _validate_shuffle_split
    "aforementioned parameters.".format(n_samples, test_size, train_size)
                                        │          │          └ None
                                        │          └ 0.9998482979791774
                                        └ 5000

ValueError: With n_samples=5000, test_size=0.9998482979791774 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
2023-02-13 20:53:15.018 | ERROR    | __main__:<module>:208 - The train_size = 1 should be greater or equal to the number of classes = 2
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 200
    │        └ 'qmug_2'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061c3a1910>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c3a1550>
                                              └ <finetune.FineTune object at 0x7f061c3a1910>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 217, in get_data_loaders
    train_loader, valid_loader, test_loader = self.get_train_validation_data_loaders(train_dataset)
                                              │    │                                 └ MolTestDataset(5000)
                                              │    └ <function MolTestDatasetWrapper.get_train_validation_data_loaders at 0x7f061ef52680>
                                              └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c3a1550>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 241, in get_train_validation_data_loaders
    train_idx, test_idx, stratify_train, stratify_test = train_test_split(indices, ys, test_size=1 - train_ratio, stratify=ys)
                                                         │                │        │                 │                     └ array([1, 0, 1, ..., 0, 0, 0])
                                                         │                │        │                 └ 0.0003034040416451944
                                                         │                │        └ array([1, 0, 1, ..., 0, 0, 0])
                                                         │                └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                                                         └ <function train_test_split at 0x7f0646e448c0>

  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2441, in train_test_split
    train, test = next(cv.split(X=arrays[0], y=stratify))
                       │  │       │            └ array([1, 0, 1, ..., 0, 0, 0])
                       │  │       └ [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 3...
                       │  └ <function StratifiedShuffleSplit.split at 0x7f0646e443b0>
                       └ StratifiedShuffleSplit(n_splits=10, random_state=None, test_size=4999,
                                     train_size=1)
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 1600, in split
    for train, test in self._iter_indices(X, y, groups):
                       │    │             │  │  └ None
                       │    │             │  └ array([1, 0, 1, ..., 0, 0, 0])
                       │    │             └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                       │    └ <function StratifiedShuffleSplit._iter_indices at 0x7f0646e44320>
                       └ StratifiedShuffleSplit(n_splits=10, random_state=None, test_size=4999,
                                     train_size=1)
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 1950, in _iter_indices
    "equal to the number of classes = %d" % (n_train, n_classes)
                                             │        └ 2
                                             └ 1

ValueError: The train_size = 1 should be greater or equal to the number of classes = 2
Test loss: 1.1411791829052464 Test MAE: 0.8832074
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999848297979177, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 2}}
Running on: cpu
659186
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999241489895887, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 2}}
Running on: cpu
659186
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9998482979791774, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 2}}
Running on: cpu
659186
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9996965959583548, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 2}}
Running on: cpu
659186
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9992414898958869, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 2}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 3, Valid size: 3, Test size: 4997
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.7477791905403137
Validation loss: 0.6787070631980896 ROC AUC: 0.5
Validation loss: 0.6432551741600037 ROC AUC: 0.0
Validation loss: 0.7309575080871582 ROC AUC: 0.0
Validation loss: 0.6956460475921631 ROC AUC: 1.0
Validation loss: 0.646436333656311 ROC AUC: 0.5
Validation loss: 0.6400500535964966 ROC AUC: 0.5
Validation loss: 0.7007182240486145 ROC AUC: 0.5
Validation loss: 0.8456711173057556 ROC AUC: 0.0
Validation loss: 1.068745493888855 ROC AUC: 0.0
Validation loss: 1.314098596572876 ROC AUC: 0.5
Validation loss: 1.5976924896240234 ROC AUC: 0.5
Validation loss: 1.8037896156311035 ROC AUC: 1.0
Validation loss: 2.0237228870391846 ROC AUC: 1.0
Validation loss: 2.180802583694458 ROC AUC: 1.0
Validation loss: 2.2742340564727783 ROC AUC: 1.0
Validation loss: 2.261282205581665 ROC AUC: 1.0
Validation loss: 2.2681660652160645 ROC AUC: 1.0
Validation loss: 1.6476587057113647 ROC AUC: 1.0
Validation loss: 1.1492630243301392 ROC AUC: 1.0
Validation loss: 0.5510755777359009 ROC AUC: 1.0
Validation loss: 0.31662222743034363 ROC AUC: 1.0
Validation loss: 0.12296146899461746 ROC AUC: 1.0
Validation loss: 0.03782088682055473 ROC AUC: 1.0
Validation loss: 0.012480215169489384 ROC AUC: 1.0
Validation loss: 0.007731787394732237 ROC AUC: 1.0
Validation loss: 0.006830334663391113 ROC AUC: 1.0
Validation loss: 0.00627966970205307 ROC AUC: 1.0
Validation loss: 0.005988267716020346 ROC AUC: 1.0
Validation loss: 0.005942180752754211 ROC AUC: 1.0
Validation loss: 0.005450533702969551 ROC AUC: 1.0
Validation loss: 0.005229638889431953 ROC AUC: 1.0
Validation loss: 0.004849949385970831 ROC AUC: 1.0
Validation loss: 0.004462484735995531 ROC AUC: 1.0
Validation loss: 0.0040472461842000484 ROC AUC: 1.0
Validation loss: 0.0038665325846523046 ROC AUC: 1.0
Validation loss: 0.003563559614121914 ROC AUC: 1.0
Validation loss: 0.0029724629130214453 ROC AUC: 1.0
Validation loss: 0.0025577705819159746 ROC AUC: 1.0
Validation loss: 0.002244054339826107 ROC AUC: 1.0
Validation loss: 0.0020556908566504717 ROC AUC: 1.0
Validation loss: 0.0017853365279734135 ROC AUC: 1.0
Validation loss: 0.0017141853459179401 ROC AUC: 1.0
Validation loss: 0.0014360761269927025 ROC AUC: 1.0
Validation loss: 0.0011748011456802487 ROC AUC: 1.0
Validation loss: 0.001021526986733079 ROC AUC: 1.0
Validation loss: 0.0008714718278497458 ROC AUC: 1.0
Validation loss: 0.0008064678986556828 ROC AUC: 1.0
Validation loss: 0.0006735667120665312 ROC AUC: 1.0
Validation loss: 0.0006095158169046044 ROC AUC: 1.0
Validation loss: 0.0005114523810334504 ROC AUC: 1.0
50 0 0.0014150593196973205
Validation loss: 0.0004432828864082694 ROC AUC: 1.0
Validation loss: 0.0004176065849605948 ROC AUC: 1.0
Validation loss: 0.00039228552486747503 ROC AUC: 1.0
Validation loss: 0.0004054225573781878 ROC AUC: 1.0
Validation loss: 0.00040605757385492325 ROC AUC: 1.0
Validation loss: 0.0003819263365585357 ROC AUC: 1.0
Validation loss: 0.0003148419491481036 ROC AUC: 1.0
Validation loss: 0.0002821681264322251 ROC AUC: 1.0
Validation loss: 0.0002610455558169633 ROC AUC: 1.0
Validation loss: 0.0002176845446228981 ROC AUC: 1.0
Validation loss: 0.0001997349172597751 ROC AUC: 1.0
Validation loss: 0.00018059287685900927 ROC AUC: 1.0
Validation loss: 0.00016470653645228595 ROC AUC: 1.0
Validation loss: 0.00017030654998961836 ROC AUC: 1.0
Validation loss: 0.00016776472330093384 ROC AUC: 1.0
Validation loss: 0.00016542144294362515 ROC AUC: 1.0
Validation loss: 0.00013869101530872285 ROC AUC: 1.0
Validation loss: 0.00012840340787079185 ROC AUC: 1.0
Validation loss: 0.00011537462705746293 ROC AUC: 1.0
Validation loss: 9.686333942227066e-05 ROC AUC: 1.0
Validation loss: 8.840183727443218e-05 ROC AUC: 1.0
Validation loss: 8.260180038632825e-05 ROC AUC: 1.0
Validation loss: 8.196617272915319e-05 ROC AUC: 1.0
Validation loss: 7.719894347246736e-05 ROC AUC: 1.0
Validation loss: 7.410020771203563e-05 ROC AUC: 1.0
Validation loss: 7.815239223418757e-05 ROC AUC: 1.0
Validation loss: 9.475791739532724e-05 ROC AUC: 1.0
Validation loss: 8.403195533901453e-05 ROC AUC: 1.0
Validation loss: 8.796484326012433e-05 ROC AUC: 1.0
Validation loss: 8.562100265407935e-05 ROC AUC: 1.0
Validation loss: 8.383332169614732e-05 ROC AUC: 1.0
Validation loss: 7.366319914581254e-05 ROC AUC: 1.0
Validation loss: 6.826019671279937e-05 ROC AUC: 1.0
Validation loss: 6.905476038809866e-05 ROC AUC: 1.0
Validation loss: 5.848689397680573e-05 ROC AUC: 1.0
Validation loss: 5.6778520956868306e-05 ROC AUC: 1.0
Validation loss: 5.4712570999981835e-05 ROC AUC: 1.0
Validation loss: 4.8196805437328294e-05 ROC AUC: 1.0
Validation loss: 4.5971875806571916e-05 ROC AUC: 1.0
Validation loss: 4.283312227926217e-05 ROC AUC: 1.0
Validation loss: 4.565402923617512e-05 ROC AUC: 1.0
Validation loss: 4.5733493607258424e-05 ROC AUC: 1.0
Validation loss: 4.922980224364437e-05 ROC AUC: 1.0
Validation loss: 4.8474918003194034e-05 ROC AUC: 1.0
Validation loss: 4.831599653698504e-05 ROC AUC: 1.0
Validation loss: 5.614284600596875e-05 ROC AUC: 1.0
Validation loss: 6.436680268961936e-05 ROC AUC: 1.0
Validation loss: 7.485503010684624e-05 ROC AUC: 1.0
Validation loss: 8.069491741480306e-05 ROC AUC: 1.0
Validation loss: 8.701142360223457e-05 ROC AUC: 1.0
Loaded trained model with success.
Test loss: 0.5912432105738759 Test ROC AUC: 0.505108480207709
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9984829797917738, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 2}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 7, Valid size: 7, Test size: 4993
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.8220146298408508
Validation loss: 0.6115679740905762 ROC AUC: 0.6
Validation loss: 0.6071850657463074 ROC AUC: 0.2
Validation loss: 0.6519462466239929 ROC AUC: 0.19999999999999996
Validation loss: 0.6720625758171082 ROC AUC: 0.5
Validation loss: 0.6665182709693909 ROC AUC: 0.5
Validation loss: 0.6410951614379883 ROC AUC: 0.7
Validation loss: 0.6073670983314514 ROC AUC: 1.0
Validation loss: 0.6002988219261169 ROC AUC: 0.5
Validation loss: 0.6531774401664734 ROC AUC: 0.4
Validation loss: 0.7494650483131409 ROC AUC: 0.4
Validation loss: 0.860616147518158 ROC AUC: 0.3
Validation loss: 0.9316098093986511 ROC AUC: 0.3
Validation loss: 0.9557852149009705 ROC AUC: 0.3
Validation loss: 0.9183302521705627 ROC AUC: 0.6
Validation loss: 0.8234836459159851 ROC AUC: 0.6
Validation loss: 0.6920523643493652 ROC AUC: 0.7
Validation loss: 0.5518656373023987 ROC AUC: 0.8
Validation loss: 0.42564278841018677 ROC AUC: 0.8
Validation loss: 0.35683345794677734 ROC AUC: 0.9
Validation loss: 0.3263954818248749 ROC AUC: 0.9
Validation loss: 0.31060928106307983 ROC AUC: 0.9
Validation loss: 0.3041877746582031 ROC AUC: 0.9
Validation loss: 0.3071208596229553 ROC AUC: 0.9
Validation loss: 0.31131261587142944 ROC AUC: 0.9
Validation loss: 0.3113059401512146 ROC AUC: 0.9
Validation loss: 0.30574989318847656 ROC AUC: 0.9
Validation loss: 0.29912689328193665 ROC AUC: 0.9
Validation loss: 0.29306560754776 ROC AUC: 0.9
Validation loss: 0.2883506417274475 ROC AUC: 0.9
Validation loss: 0.2857722342014313 ROC AUC: 0.9
Validation loss: 0.2825106084346771 ROC AUC: 0.9
Validation loss: 0.27945393323898315 ROC AUC: 0.9
Validation loss: 0.2759426534175873 ROC AUC: 0.9
Validation loss: 0.27141156792640686 ROC AUC: 0.9
Validation loss: 0.2641328275203705 ROC AUC: 0.9
Validation loss: 0.25864318013191223 ROC AUC: 0.9
Validation loss: 0.2538990080356598 ROC AUC: 0.9
Validation loss: 0.24902835488319397 ROC AUC: 0.9
Validation loss: 0.24631527066230774 ROC AUC: 0.9
Validation loss: 0.24322393536567688 ROC AUC: 1.0
Validation loss: 0.24609708786010742 ROC AUC: 1.0
Validation loss: 0.2439778596162796 ROC AUC: 1.0
Validation loss: 0.24326229095458984 ROC AUC: 1.0
Validation loss: 0.24314084649085999 ROC AUC: 1.0
Validation loss: 0.24464009702205658 ROC AUC: 1.0
Validation loss: 0.2450789213180542 ROC AUC: 1.0
Validation loss: 0.24005304276943207 ROC AUC: 1.0
Validation loss: 0.23417310416698456 ROC AUC: 1.0
Validation loss: 0.22542326152324677 ROC AUC: 1.0
Validation loss: 0.21818140149116516 ROC AUC: 1.0
50 0 0.1560669243335724
Validation loss: 0.20964384078979492 ROC AUC: 1.0
Validation loss: 0.20251645147800446 ROC AUC: 1.0
Validation loss: 0.19509635865688324 ROC AUC: 1.0
Validation loss: 0.19157733023166656 ROC AUC: 1.0
Validation loss: 0.1848866194486618 ROC AUC: 1.0
Validation loss: 0.1829937845468521 ROC AUC: 1.0
Validation loss: 0.17654968798160553 ROC AUC: 1.0
Validation loss: 0.17303623259067535 ROC AUC: 1.0
Validation loss: 0.16999688744544983 ROC AUC: 1.0
Validation loss: 0.16497685015201569 ROC AUC: 1.0
Validation loss: 0.15975956618785858 ROC AUC: 1.0
Validation loss: 0.15930019319057465 ROC AUC: 1.0
Validation loss: 0.15068452060222626 ROC AUC: 1.0
Validation loss: 0.1440119594335556 ROC AUC: 1.0
Validation loss: 0.13592049479484558 ROC AUC: 1.0
Validation loss: 0.12472627311944962 ROC AUC: 1.0
Validation loss: 0.1184174194931984 ROC AUC: 1.0
Validation loss: 0.11103156954050064 ROC AUC: 1.0
Validation loss: 0.09964212030172348 ROC AUC: 1.0
Validation loss: 0.0851796492934227 ROC AUC: 1.0
Validation loss: 0.06760670244693756 ROC AUC: 1.0
Validation loss: 0.05937463045120239 ROC AUC: 1.0
Validation loss: 0.04730691388249397 ROC AUC: 1.0
Validation loss: 0.0366482138633728 ROC AUC: 1.0
Validation loss: 0.029645992442965508 ROC AUC: 1.0
Validation loss: 0.02193492092192173 ROC AUC: 1.0
Validation loss: 0.01858353428542614 ROC AUC: 1.0
Validation loss: 0.0185621939599514 ROC AUC: 1.0
Validation loss: 0.01816193200647831 ROC AUC: 1.0
Validation loss: 0.020211918279528618 ROC AUC: 1.0
Validation loss: 0.024653542786836624 ROC AUC: 1.0
Validation loss: 0.02597726508975029 ROC AUC: 1.0
Validation loss: 0.0257563553750515 ROC AUC: 1.0
Validation loss: 0.03173359856009483 ROC AUC: 1.0
Validation loss: 0.03677942231297493 ROC AUC: 1.0
Validation loss: 0.038968004286289215 ROC AUC: 1.0
Validation loss: 0.035454653203487396 ROC AUC: 1.0
Validation loss: 0.03289492055773735 ROC AUC: 1.0
Validation loss: 0.03184826299548149 ROC AUC: 1.0
Validation loss: 0.031080562621355057 ROC AUC: 1.0
Validation loss: 0.018324190750718117 ROC AUC: 1.0
Validation loss: 0.013314833864569664 ROC AUC: 1.0
Validation loss: 0.009854086674749851 ROC AUC: 1.0
Validation loss: 0.006984876934438944 ROC AUC: 1.0
Validation loss: 0.004165871534496546 ROC AUC: 1.0
Validation loss: 0.003003520192578435 ROC AUC: 1.0
Validation loss: 0.002676662290468812 ROC AUC: 1.0
Validation loss: 0.0018652287544682622 ROC AUC: 1.0
Validation loss: 0.0013253919314593077 ROC AUC: 1.0
Validation loss: 0.0010022405767813325 ROC AUC: 1.0
Loaded trained model with success.
2023-02-13 21:04:26.876 | ERROR    | __main__:<module>:208 - With n_samples=5000, test_size=0.9999848297979177 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 10
    │        └ 'qmug_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed73290>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3c7c90>
                                              └ <finetune.FineTune object at 0x7f061ed73290>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 217, in get_data_loaders
    train_loader, valid_loader, test_loader = self.get_train_validation_data_loaders(train_dataset)
                                              │    │                                 └ MolTestDataset(5000)
                                              │    └ <function MolTestDatasetWrapper.get_train_validation_data_loaders at 0x7f061ef52680>
                                              └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f062b3c7c90>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 241, in get_train_validation_data_loaders
    train_idx, test_idx, stratify_train, stratify_test = train_test_split(indices, ys, test_size=1 - train_ratio, stratify=ys)
                                                         │                │        │                 │                     └ array([2, 0, 2, ..., 2, 1, 1])
                                                         │                │        │                 └ 1.517020208230413e-05
                                                         │                │        └ array([2, 0, 2, ..., 2, 1, 1])
                                                         │                └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                                                         └ <function train_test_split at 0x7f0646e448c0>

  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2421, in train_test_split
    n_samples, test_size, train_size, default_test_size=0.25
    │          │          └ None
    │          └ 0.9999848297979177
    └ 5000
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2101, in _validate_shuffle_split
    "aforementioned parameters.".format(n_samples, test_size, train_size)
                                        │          │          └ None
                                        │          └ 0.9999848297979177
                                        └ 5000

ValueError: With n_samples=5000, test_size=0.9999848297979177 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
2023-02-13 21:06:42.916 | ERROR    | __main__:<module>:208 - With n_samples=5000, test_size=0.9999241489895887 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 50
    │        └ 'qmug_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f062b3c7c90>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061f545390>
                                              └ <finetune.FineTune object at 0x7f062b3c7c90>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 217, in get_data_loaders
    train_loader, valid_loader, test_loader = self.get_train_validation_data_loaders(train_dataset)
                                              │    │                                 └ MolTestDataset(5000)
                                              │    └ <function MolTestDatasetWrapper.get_train_validation_data_loaders at 0x7f061ef52680>
                                              └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061f545390>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 241, in get_train_validation_data_loaders
    train_idx, test_idx, stratify_train, stratify_test = train_test_split(indices, ys, test_size=1 - train_ratio, stratify=ys)
                                                         │                │        │                 │                     └ array([2, 0, 2, ..., 2, 1, 1])
                                                         │                │        │                 └ 7.58510104112986e-05
                                                         │                │        └ array([2, 0, 2, ..., 2, 1, 1])
                                                         │                └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                                                         └ <function train_test_split at 0x7f0646e448c0>

  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2421, in train_test_split
    n_samples, test_size, train_size, default_test_size=0.25
    │          │          └ None
    │          └ 0.9999241489895887
    └ 5000
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2101, in _validate_shuffle_split
    "aforementioned parameters.".format(n_samples, test_size, train_size)
                                        │          │          └ None
                                        │          └ 0.9999241489895887
                                        └ 5000

ValueError: With n_samples=5000, test_size=0.9999241489895887 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
2023-02-13 21:08:58.700 | ERROR    | __main__:<module>:208 - With n_samples=5000, test_size=0.9998482979791774 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 100
    │        └ 'qmug_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed73290>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed73b10>
                                              └ <finetune.FineTune object at 0x7f061ed73290>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 217, in get_data_loaders
    train_loader, valid_loader, test_loader = self.get_train_validation_data_loaders(train_dataset)
                                              │    │                                 └ MolTestDataset(5000)
                                              │    └ <function MolTestDatasetWrapper.get_train_validation_data_loaders at 0x7f061ef52680>
                                              └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed73b10>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 241, in get_train_validation_data_loaders
    train_idx, test_idx, stratify_train, stratify_test = train_test_split(indices, ys, test_size=1 - train_ratio, stratify=ys)
                                                         │                │        │                 │                     └ array([2, 0, 2, ..., 2, 1, 1])
                                                         │                │        │                 └ 0.0001517020208225972
                                                         │                │        └ array([2, 0, 2, ..., 2, 1, 1])
                                                         │                └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                                                         └ <function train_test_split at 0x7f0646e448c0>

  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2421, in train_test_split
    n_samples, test_size, train_size, default_test_size=0.25
    │          │          └ None
    │          └ 0.9998482979791774
    └ 5000
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2101, in _validate_shuffle_split
    "aforementioned parameters.".format(n_samples, test_size, train_size)
                                        │          │          └ None
                                        │          └ 0.9998482979791774
                                        └ 5000

ValueError: With n_samples=5000, test_size=0.9998482979791774 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
2023-02-13 21:11:15.138 | ERROR    | __main__:<module>:208 - The train_size = 1 should be greater or equal to the number of classes = 5
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 200
    │        └ 'qmug_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f062b3be750>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ef48250>
                                              └ <finetune.FineTune object at 0x7f062b3be750>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 217, in get_data_loaders
    train_loader, valid_loader, test_loader = self.get_train_validation_data_loaders(train_dataset)
                                              │    │                                 └ MolTestDataset(5000)
                                              │    └ <function MolTestDatasetWrapper.get_train_validation_data_loaders at 0x7f061ef52680>
                                              └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ef48250>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 241, in get_train_validation_data_loaders
    train_idx, test_idx, stratify_train, stratify_test = train_test_split(indices, ys, test_size=1 - train_ratio, stratify=ys)
                                                         │                │        │                 │                     └ array([2, 0, 2, ..., 2, 1, 1])
                                                         │                │        │                 └ 0.0003034040416451944
                                                         │                │        └ array([2, 0, 2, ..., 2, 1, 1])
                                                         │                └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                                                         └ <function train_test_split at 0x7f0646e448c0>

  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2441, in train_test_split
    train, test = next(cv.split(X=arrays[0], y=stratify))
                       │  │       │            └ array([2, 0, 2, ..., 2, 1, 1])
                       │  │       └ [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 3...
                       │  └ <function StratifiedShuffleSplit.split at 0x7f0646e443b0>
                       └ StratifiedShuffleSplit(n_splits=10, random_state=None, test_size=4999,
                                     train_size=1)
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 1600, in split
    for train, test in self._iter_indices(X, y, groups):
                       │    │             │  │  └ None
                       │    │             │  └ array([2, 0, 2, ..., 2, 1, 1])
                       │    │             └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                       │    └ <function StratifiedShuffleSplit._iter_indices at 0x7f0646e44320>
                       └ StratifiedShuffleSplit(n_splits=10, random_state=None, test_size=4999,
                                     train_size=1)
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 1950, in _iter_indices
    "equal to the number of classes = %d" % (n_train, n_classes)
                                             │        └ 5
                                             └ 1

ValueError: The train_size = 1 should be greater or equal to the number of classes = 5
2023-02-13 21:13:30.546 | ERROR    | __main__:<module>:208 - The train_size = 3 should be greater or equal to the number of classes = 5
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 500
    │        └ 'qmug_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed6d150>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6d890>
                                              └ <finetune.FineTune object at 0x7f061ed6d150>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 217, in get_data_loaders
    train_loader, valid_loader, test_loader = self.get_train_validation_data_loaders(train_dataset)
                                              │    │                                 └ MolTestDataset(5000)
                                              │    └ <function MolTestDatasetWrapper.get_train_validation_data_loaders at 0x7f061ef52680>
                                              └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6d890>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 241, in get_train_validation_data_loaders
    train_idx, test_idx, stratify_train, stratify_test = train_test_split(indices, ys, test_size=1 - train_ratio, stratify=ys)
                                                         │                │        │                 │                     └ array([2, 0, 2, ..., 2, 1, 1])
                                                         │                │        │                 └ 0.000758510104113097
                                                         │                │        └ array([2, 0, 2, ..., 2, 1, 1])
                                                         │                └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                                                         └ <function train_test_split at 0x7f0646e448c0>

  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 2441, in train_test_split
    train, test = next(cv.split(X=arrays[0], y=stratify))
                       │  │       │            └ array([2, 0, 2, ..., 2, 1, 1])
                       │  │       └ [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 3...
                       │  └ <function StratifiedShuffleSplit.split at 0x7f0646e443b0>
                       └ StratifiedShuffleSplit(n_splits=10, random_state=None, test_size=4997,
                                     train_size=3)
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 1600, in split
    for train, test in self._iter_indices(X, y, groups):
                       │    │             │  │  └ None
                       │    │             │  └ array([2, 0, 2, ..., 2, 1, 1])
                       │    │             └ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...
                       │    └ <function StratifiedShuffleSplit._iter_indices at 0x7f0646e44320>
                       └ StratifiedShuffleSplit(n_splits=10, random_state=None, test_size=4997,
                                     train_size=3)
  File "/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/site-packages/sklearn/model_selection/_split.py", line 1950, in _iter_indices
    "equal to the number of classes = %d" % (n_train, n_classes)
                                             │        └ 5
                                             └ 3

ValueError: The train_size = 3 should be greater or equal to the number of classes = 5
Test loss: 0.57820712588914 Test ROC AUC: 0.6130849953981254
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999848297979177, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999241489895887, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9998482979791774, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9996965959583548, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9992414898958869, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9984829797917738, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 7, Valid size: 7, Test size: 4993
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.5755890607833862
Validation loss: 1.4861812591552734 ROC AUC: 0.55
Validation loss: 1.498962640762329 ROC AUC: 0.4333333333333333
Validation loss: 1.5405458211898804 ROC AUC: 0.5166666666666666
Validation loss: 1.5946375131607056 ROC AUC: 0.5666666666666667
Validation loss: 1.581025242805481 ROC AUC: 0.6666666666666666
Validation loss: 1.577406883239746 ROC AUC: 0.8
Validation loss: 1.579135775566101 ROC AUC: 0.85
Validation loss: 1.5865919589996338 ROC AUC: 0.8166666666666668
Validation loss: 1.60249924659729 ROC AUC: 0.8
Validation loss: 1.617984652519226 ROC AUC: 0.75
Validation loss: 1.6317559480667114 ROC AUC: 0.7166666666666666
Validation loss: 1.6384233236312866 ROC AUC: 0.5333333333333334
Validation loss: 1.6245739459991455 ROC AUC: 0.5333333333333334
Validation loss: 1.5398436784744263 ROC AUC: 0.5333333333333334
Validation loss: 1.4768403768539429 ROC AUC: 0.5333333333333334
Validation loss: 1.4189367294311523 ROC AUC: 0.5833333333333334
Validation loss: 1.3713542222976685 ROC AUC: 0.6
Validation loss: 1.3234933614730835 ROC AUC: 0.6
Validation loss: 1.3088140487670898 ROC AUC: 0.6
Validation loss: 1.2840064764022827 ROC AUC: 0.6
Validation loss: 1.2382358312606812 ROC AUC: 0.6333333333333334
Validation loss: 1.1990185976028442 ROC AUC: 0.65
Validation loss: 1.1538676023483276 ROC AUC: 0.6833333333333333
Validation loss: 1.1186386346817017 ROC AUC: 0.7166666666666667
Validation loss: 1.091697096824646 ROC AUC: 0.7166666666666667
Validation loss: 1.0649323463439941 ROC AUC: 0.7166666666666667
Validation loss: 1.0547478199005127 ROC AUC: 0.7166666666666667
Validation loss: 1.04792058467865 ROC AUC: 0.7
Validation loss: 1.064243197441101 ROC AUC: 0.6666666666666666
Validation loss: 1.076537847518921 ROC AUC: 0.6666666666666666
Validation loss: 1.0745314359664917 ROC AUC: 0.6666666666666666
Validation loss: 1.0611178874969482 ROC AUC: 0.7
Validation loss: 1.0720595121383667 ROC AUC: 0.8166666666666668
Validation loss: 1.0800940990447998 ROC AUC: 0.8166666666666668
Validation loss: 1.0925034284591675 ROC AUC: 0.8166666666666668
Validation loss: 1.104478120803833 ROC AUC: 0.8166666666666668
Validation loss: 1.1135427951812744 ROC AUC: 0.8166666666666668
Validation loss: 1.1252363920211792 ROC AUC: 0.7666666666666666
Validation loss: 1.134558081626892 ROC AUC: 0.7666666666666666
Validation loss: 1.1482598781585693 ROC AUC: 0.7666666666666666
Validation loss: 1.1963412761688232 ROC AUC: 0.75
Validation loss: 1.2433443069458008 ROC AUC: 0.75
Validation loss: 1.258096694946289 ROC AUC: 0.7166666666666667
Validation loss: 1.2673841714859009 ROC AUC: 0.7
Validation loss: 1.316963791847229 ROC AUC: 0.6833333333333333
Validation loss: 1.3426835536956787 ROC AUC: 0.6833333333333333
Validation loss: 1.3616809844970703 ROC AUC: 0.6833333333333333
Validation loss: 1.3791977167129517 ROC AUC: 0.6833333333333333
Validation loss: 1.4321234226226807 ROC AUC: 0.6833333333333333
Validation loss: 1.4241780042648315 ROC AUC: 0.6833333333333333
50 0 1.1640985012054443
Validation loss: 1.448893427848816 ROC AUC: 0.6833333333333333
Validation loss: 1.5212599039077759 ROC AUC: 0.6833333333333333
Validation loss: 1.5133752822875977 ROC AUC: 0.6833333333333333
Validation loss: 1.442133903503418 ROC AUC: 0.7
Validation loss: 1.399110198020935 ROC AUC: 0.7333333333333334
Validation loss: 1.3900905847549438 ROC AUC: 0.7166666666666667
Validation loss: 1.4554041624069214 ROC AUC: 0.7333333333333334
Validation loss: 1.566456913948059 ROC AUC: 0.65
Validation loss: 1.6082746982574463 ROC AUC: 0.6166666666666667
Validation loss: 1.5883005857467651 ROC AUC: 0.6833333333333333
Validation loss: 1.6005830764770508 ROC AUC: 0.7166666666666667
Validation loss: 1.566027283668518 ROC AUC: 0.7166666666666667
Validation loss: 1.5671679973602295 ROC AUC: 0.7666666666666666
Validation loss: 1.6160732507705688 ROC AUC: 0.7666666666666667
Validation loss: 1.6347423791885376 ROC AUC: 0.7666666666666667
Validation loss: 1.6351827383041382 ROC AUC: 0.7833333333333334
Validation loss: 1.5278522968292236 ROC AUC: 0.8
Validation loss: 1.5217195749282837 ROC AUC: 0.8
Validation loss: 1.5558500289916992 ROC AUC: 0.7833333333333334
Validation loss: 1.4845105409622192 ROC AUC: 0.7833333333333334
Validation loss: 1.4142792224884033 ROC AUC: 0.7833333333333334
Validation loss: 1.2960458993911743 ROC AUC: 0.8666666666666668
Validation loss: 1.1467121839523315 ROC AUC: 0.8833333333333334
Validation loss: 1.05393648147583 ROC AUC: 0.8833333333333334
Validation loss: 0.957438051700592 ROC AUC: 0.8833333333333334
Validation loss: 0.8752880692481995 ROC AUC: 0.8833333333333334
Validation loss: 0.783349335193634 ROC AUC: 0.8833333333333334
Validation loss: 0.7276448011398315 ROC AUC: 0.8833333333333334
Validation loss: 0.6484771370887756 ROC AUC: 0.9
Validation loss: 0.5574283003807068 ROC AUC: 1.0
Validation loss: 0.5007597208023071 ROC AUC: 1.0
Validation loss: 0.4379146993160248 ROC AUC: 1.0
Validation loss: 0.39160817861557007 ROC AUC: 1.0
Validation loss: 0.35399216413497925 ROC AUC: 1.0
Validation loss: 0.3243408799171448 ROC AUC: 1.0
Validation loss: 0.29424557089805603 ROC AUC: 1.0
Validation loss: 0.28568074107170105 ROC AUC: 1.0
Validation loss: 0.292216032743454 ROC AUC: 1.0
Validation loss: 0.2911357581615448 ROC AUC: 1.0
Validation loss: 0.28075888752937317 ROC AUC: 1.0
Validation loss: 0.25646987557411194 ROC AUC: 1.0
Validation loss: 0.24329864978790283 ROC AUC: 1.0
Validation loss: 0.23088552057743073 ROC AUC: 1.0
Validation loss: 0.2152591198682785 ROC AUC: 1.0
Validation loss: 0.20582440495491028 ROC AUC: 1.0
Validation loss: 0.20032921433448792 ROC AUC: 1.0
Validation loss: 0.20436188578605652 ROC AUC: 1.0
Validation loss: 0.20578166842460632 ROC AUC: 1.0
Validation loss: 0.2028791606426239 ROC AUC: 1.0
Validation loss: 0.20173533260822296 ROC AUC: 1.0
Loaded trained model with success.
Test loss: 1.8477945250402872 Test ROC AUC: 0.625144872787973
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9751861042183623, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 380
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 149414.171875
Validation loss: 148966.96875 MAE: 381.04718
Validation loss: 148521.875 MAE: 380.463
Validation loss: 148069.4375 MAE: 379.86813
Validation loss: 147594.765625 MAE: 379.24277
Validation loss: 147080.03125 MAE: 378.5633
Validation loss: 146524.15625 MAE: 377.82816
Validation loss: 145937.4375 MAE: 377.0506
Validation loss: 145296.84375 MAE: 376.2
Validation loss: 144635.4375 MAE: 375.31833
Validation loss: 143931.15625 MAE: 374.36975
Validation loss: 143260.15625 MAE: 373.45264
Validation loss: 142468.546875 MAE: 372.37393
Validation loss: 141604.8125 MAE: 371.19754
Validation loss: 140587.671875 MAE: 369.8087
Validation loss: 139456.078125 MAE: 368.26147
Validation loss: 138199.65625 MAE: 366.54633
Validation loss: 136514.859375 MAE: 364.28397
Validation loss: 134564.8125 MAE: 361.7052
Validation loss: 132463.1875 MAE: 358.88953
Validation loss: 130707.15625 MAE: 356.4872
Validation loss: 128890.609375 MAE: 353.93195
Validation loss: 127215.3203125 MAE: 351.5023
Validation loss: 125129.28125 MAE: 348.37982
Validation loss: 123148.890625 MAE: 345.26263
Validation loss: 121323.625 MAE: 342.2375
Validation loss: 118425.0 MAE: 337.52112
Validation loss: 115575.4921875 MAE: 332.8776
Validation loss: 112232.03125 MAE: 327.44052
Validation loss: 108401.8515625 MAE: 321.18362
Validation loss: 104915.390625 MAE: 315.3655
Validation loss: 100688.96875 MAE: 307.98615
Validation loss: 97275.71875 MAE: 301.74573
Validation loss: 92601.7890625 MAE: 292.24994
Validation loss: 87616.84375 MAE: 280.9058
Validation loss: 82889.03125 MAE: 268.76987
Validation loss: 78190.453125 MAE: 261.6213
Validation loss: 73939.1328125 MAE: 258.12354
Validation loss: 70229.78125 MAE: 257.1439
Validation loss: 68073.6328125 MAE: 257.157
Validation loss: 66006.0078125 MAE: 254.78142
Validation loss: 65660.625 MAE: 254.17464
Validation loss: 65813.3125 MAE: 251.83328
Validation loss: 69093.8671875 MAE: 251.33447
Validation loss: 69588.1953125 MAE: 245.6407
Validation loss: 74221.15625 MAE: 241.7337
Validation loss: 78931.9140625 MAE: 237.53578
Validation loss: 82175.9296875 MAE: 238.83499
Validation loss: 84132.0 MAE: 244.56207
Validation loss: 87065.046875 MAE: 254.26947
Validation loss: 86966.4609375 MAE: 259.11496
50 0 54825.71875
Validation loss: 88758.8359375 MAE: 265.24542
Validation loss: 91583.6328125 MAE: 272.85773
Validation loss: 96886.734375 MAE: 282.26486
Validation loss: 98376.9765625 MAE: 284.507
Validation loss: 95427.0703125 MAE: 279.6996
Validation loss: 83717.78125 MAE: 267.66522
Validation loss: 73119.8125 MAE: 252.21466
Validation loss: 68371.7265625 MAE: 245.33238
Validation loss: 56885.14453125 MAE: 225.40782
Validation loss: 52801.94921875 MAE: 218.20142
Validation loss: 48784.8984375 MAE: 208.06052
Validation loss: 46758.83984375 MAE: 202.9592
Validation loss: 40187.18359375 MAE: 185.59071
Validation loss: 40840.54296875 MAE: 183.98627
Validation loss: 36237.6953125 MAE: 175.05803
Validation loss: 30464.47265625 MAE: 159.87674
Validation loss: 34601.7421875 MAE: 173.62332
Validation loss: 37405.20703125 MAE: 183.76495
Validation loss: 34900.78125 MAE: 176.29361
Validation loss: 37427.015625 MAE: 179.38707
Validation loss: 39803.20703125 MAE: 181.52109
Validation loss: 39875.921875 MAE: 179.12958
Validation loss: 42498.64453125 MAE: 179.98187
Validation loss: 47817.390625 MAE: 188.78008
Validation loss: 52491.48046875 MAE: 199.78703
Validation loss: 53026.09375 MAE: 189.1996
Validation loss: 55259.24609375 MAE: 179.55743
Validation loss: 56033.5859375 MAE: 177.55737
Validation loss: 52155.7109375 MAE: 162.59065
Validation loss: 47892.453125 MAE: 148.85349
Validation loss: 41670.25390625 MAE: 134.52397
Validation loss: 41543.85546875 MAE: 133.95573
Validation loss: 39893.07421875 MAE: 132.68582
Validation loss: 41367.54296875 MAE: 135.72807
Validation loss: 42563.984375 MAE: 138.94214
Validation loss: 40931.640625 MAE: 137.81108
Validation loss: 41807.4375 MAE: 138.84761
Validation loss: 44376.88671875 MAE: 145.0824
Validation loss: 50814.328125 MAE: 159.1758
Validation loss: 50748.8359375 MAE: 166.4526
Validation loss: 51013.95703125 MAE: 169.0195
Validation loss: 56982.31640625 MAE: 179.91042
Validation loss: 62911.890625 MAE: 190.30353
Validation loss: 57075.28515625 MAE: 181.64485
Validation loss: 50627.73828125 MAE: 168.25836
Validation loss: 42386.48828125 MAE: 153.19537
Validation loss: 41227.90234375 MAE: 150.42348
Validation loss: 38630.3828125 MAE: 145.18375
Validation loss: 35066.58984375 MAE: 136.50848
Validation loss: 33898.04296875 MAE: 132.15851
Loaded trained model with success.
Test loss: 36968.31916118421 Test MAE: 160.0177
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9503722084367245, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 19, Valid size: 19, Test size: 370
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 150624.796875
Validation loss: 150130.875 MAE: 383.01688
Validation loss: 149683.078125 MAE: 382.43216
Validation loss: 149216.1875 MAE: 381.8216
Validation loss: 148718.203125 MAE: 381.16934
Validation loss: 148189.078125 MAE: 380.47476
Validation loss: 147616.421875 MAE: 379.72147
Validation loss: 147010.046875 MAE: 378.92224
Validation loss: 146349.40625 MAE: 378.0493
Validation loss: 145622.671875 MAE: 377.08685
Validation loss: 144870.140625 MAE: 376.08887
Validation loss: 144067.796875 MAE: 375.02252
Validation loss: 143215.140625 MAE: 373.89218
Validation loss: 142425.546875 MAE: 372.85028
Validation loss: 141500.28125 MAE: 371.62033
Validation loss: 140734.4375 MAE: 370.6133
Validation loss: 139918.703125 MAE: 369.53915
Validation loss: 139333.96875 MAE: 368.77295
Validation loss: 139445.796875 MAE: 368.87634
Validation loss: 139301.0 MAE: 368.5585
Validation loss: 138713.765625 MAE: 367.6081
Validation loss: 137757.453125 MAE: 366.18106
Validation loss: 136383.453125 MAE: 364.18173
Validation loss: 134890.921875 MAE: 362.03006
Validation loss: 133250.734375 MAE: 359.63058
Validation loss: 131314.921875 MAE: 356.7813
Validation loss: 128452.3828125 MAE: 352.53223
Validation loss: 124695.6015625 MAE: 346.9412
Validation loss: 121189.75 MAE: 341.6672
Validation loss: 117691.484375 MAE: 336.33374
Validation loss: 115515.3984375 MAE: 332.8967
Validation loss: 112875.40625 MAE: 328.69736
Validation loss: 108387.8671875 MAE: 321.55038
Validation loss: 103927.328125 MAE: 314.25137
Validation loss: 98439.4765625 MAE: 304.92822
Validation loss: 89819.78125 MAE: 289.63608
Validation loss: 82733.4375 MAE: 276.39197
Validation loss: 78951.0859375 MAE: 268.93628
Validation loss: 76056.8828125 MAE: 263.01733
Validation loss: 69389.8671875 MAE: 248.96887
Validation loss: 62847.40625 MAE: 234.07921
Validation loss: 56683.30859375 MAE: 219.21294
Validation loss: 46881.6015625 MAE: 191.42198
Validation loss: 41614.953125 MAE: 175.6443
Validation loss: 34330.875 MAE: 148.39201
Validation loss: 30214.322265625 MAE: 139.50037
Validation loss: 29816.966796875 MAE: 140.87538
Validation loss: 30545.9609375 MAE: 144.62965
Validation loss: 32825.80859375 MAE: 153.51189
Validation loss: 37863.140625 MAE: 165.84926
Validation loss: 38063.21875 MAE: 164.16869
50 0 59491.61328125
Validation loss: 35358.78125 MAE: 159.41956
Validation loss: 34892.65234375 MAE: 157.93933
Validation loss: 32662.6875 MAE: 150.65442
Validation loss: 36724.15625 MAE: 155.86201
Validation loss: 42883.11328125 MAE: 167.4674
Validation loss: 45036.57421875 MAE: 172.94388
Validation loss: 38567.71875 MAE: 156.76779
Validation loss: 35252.17578125 MAE: 157.49265
Validation loss: 35443.07421875 MAE: 158.49301
Validation loss: 36807.27734375 MAE: 161.87201
Validation loss: 36523.98046875 MAE: 162.46655
Validation loss: 35422.05078125 MAE: 157.20776
Validation loss: 36491.49609375 MAE: 155.25728
Validation loss: 36650.9375 MAE: 152.92522
Validation loss: 35812.640625 MAE: 147.85179
Validation loss: 39162.9140625 MAE: 160.6982
Validation loss: 42023.26171875 MAE: 170.25134
Validation loss: 40261.9609375 MAE: 163.72583
Validation loss: 40331.28125 MAE: 164.49931
Validation loss: 35025.1015625 MAE: 147.48135
Validation loss: 33266.6875 MAE: 141.89172
Validation loss: 32961.12890625 MAE: 141.39423
Validation loss: 32917.34375 MAE: 141.3188
Validation loss: 32738.56640625 MAE: 141.02556
Validation loss: 35415.38671875 MAE: 151.38492
Validation loss: 31714.43359375 MAE: 138.55788
Validation loss: 26996.50390625 MAE: 125.636536
Validation loss: 26145.01953125 MAE: 123.711555
Validation loss: 24252.283203125 MAE: 117.18059
Validation loss: 24622.30859375 MAE: 120.05072
Validation loss: 25054.607421875 MAE: 122.18646
Validation loss: 23552.48046875 MAE: 116.696106
Validation loss: 23534.49609375 MAE: 117.57666
Validation loss: 23283.826171875 MAE: 118.17137
Validation loss: 22923.853515625 MAE: 118.40764
Validation loss: 22839.607421875 MAE: 117.34634
Validation loss: 23321.734375 MAE: 118.54599
Validation loss: 24403.513671875 MAE: 120.85834
Validation loss: 26765.537109375 MAE: 126.56992
Validation loss: 28148.80859375 MAE: 132.63899
Validation loss: 26412.6484375 MAE: 123.88849
Validation loss: 25473.900390625 MAE: 120.87697
Validation loss: 24764.353515625 MAE: 119.03253
Validation loss: 23776.8359375 MAE: 122.219215
Validation loss: 23830.40625 MAE: 122.414246
Validation loss: 24166.80078125 MAE: 124.398865
Validation loss: 24349.748046875 MAE: 125.41673
Validation loss: 24555.70703125 MAE: 126.343636
Validation loss: 25383.57421875 MAE: 127.62348
Validation loss: 24993.21484375 MAE: 128.46793
Loaded trained model with success.
Test loss: 47111.33994932433 Test MAE: 179.78822
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8759305210918115, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 48, Valid size: 48, Test size: 341
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 139786.875
Validation loss: 147714.13020833334 MAE: 378.93262
Validation loss: 146719.859375 MAE: 377.6196
Validation loss: 145552.3125 MAE: 376.06992
Validation loss: 144240.65625 MAE: 374.32272
Validation loss: 142806.66666666666 MAE: 372.41196
Validation loss: 141443.51041666666 MAE: 370.61172
Validation loss: 140170.828125 MAE: 368.93945
Validation loss: 138795.28645833334 MAE: 367.10123
Validation loss: 137113.25260416666 MAE: 364.77798
Validation loss: 134977.83854166666 MAE: 361.795
Validation loss: 132227.296875 MAE: 357.92355
Validation loss: 129140.66927083333 MAE: 353.49692
Validation loss: 125313.57291666667 MAE: 347.85168
Validation loss: 120220.59895833333 MAE: 339.70163
Validation loss: 114005.984375 MAE: 329.30325
Validation loss: 106570.625 MAE: 315.8859
Validation loss: 98998.52864583333 MAE: 301.35556
Validation loss: 85467.984375 MAE: 271.18298
Validation loss: 70244.92708333333 MAE: 234.0912
Validation loss: 61961.791666666664 MAE: 214.51775
Validation loss: 62569.188802083336 MAE: 213.49834
Validation loss: 74520.0625 MAE: 229.25061
Validation loss: 105200.5546875 MAE: 268.75604
Validation loss: 141598.33854166666 MAE: 301.0463
Validation loss: 160405.31770833334 MAE: 316.1327
25 0 71229.53125
Validation loss: 163870.53125 MAE: 319.28494
Validation loss: 131705.82291666666 MAE: 293.47205
Validation loss: 102209.71875 MAE: 264.21695
Validation loss: 76568.859375 MAE: 230.15039
Validation loss: 60952.348958333336 MAE: 205.29285
Validation loss: 53639.526041666664 MAE: 195.51595
Validation loss: 48508.227864583336 MAE: 188.08952
Validation loss: 46583.721354166664 MAE: 185.14705
Validation loss: 45768.048177083336 MAE: 183.95564
Validation loss: 45190.889322916664 MAE: 182.95703
Validation loss: 44162.26171875 MAE: 180.4411
Validation loss: 42270.819010416664 MAE: 176.45323
Validation loss: 39503.951822916664 MAE: 171.6709
Validation loss: 37268.16796875 MAE: 167.05833
Validation loss: 35104.266927083336 MAE: 161.6992
Validation loss: 34043.118489583336 MAE: 158.48781
Validation loss: 32914.334635416664 MAE: 154.79527
Validation loss: 32684.231770833332 MAE: 152.05025
Validation loss: 35131.959635416664 MAE: 155.76271
Validation loss: 38143.966145833336 MAE: 162.60448
Validation loss: 38367.53125 MAE: 163.44774
Validation loss: 36282.92578125 MAE: 156.8921
Validation loss: 31593.796223958332 MAE: 142.57722
Validation loss: 29972.650390625 MAE: 141.84155
Validation loss: 28222.271484375 MAE: 137.8536
50 0 50424.39453125
Validation loss: 27642.043619791668 MAE: 136.74413
Validation loss: 27390.149088541668 MAE: 136.2723
Validation loss: 27307.09375 MAE: 136.44176
Validation loss: 27875.587239583332 MAE: 138.91478
Validation loss: 29388.423828125 MAE: 143.447
Validation loss: 31471.714192708332 MAE: 150.068
Validation loss: 33781.5625 MAE: 155.90936
Validation loss: 36900.309895833336 MAE: 165.23322
Validation loss: 35783.07421875 MAE: 161.85107
Validation loss: 37235.131510416664 MAE: 165.71382
Validation loss: 39816.091145833336 MAE: 171.41742
Validation loss: 41112.852864583336 MAE: 174.89983
Validation loss: 40555.1953125 MAE: 173.09209
Validation loss: 40291.196614583336 MAE: 172.17754
Validation loss: 38927.6484375 MAE: 168.26393
Validation loss: 37814.920572916664 MAE: 165.157
Validation loss: 35987.981770833336 MAE: 160.54688
Validation loss: 34216.59765625 MAE: 156.43282
Validation loss: 33412.845052083336 MAE: 154.37341
Validation loss: 32875.493489583336 MAE: 152.16785
Validation loss: 31929.44140625 MAE: 149.76118
Validation loss: 30175.447916666668 MAE: 145.0372
Validation loss: 29069.44140625 MAE: 142.09442
Validation loss: 27421.301432291668 MAE: 136.74518
Validation loss: 24908.5390625 MAE: 130.368
75 0 32794.87109375
Validation loss: 21457.821614583332 MAE: 119.71763
Validation loss: 19511.58203125 MAE: 113.5505
Validation loss: 17520.515625 MAE: 103.91644
Validation loss: 16316.434895833334 MAE: 98.409424
Validation loss: 15787.134114583334 MAE: 96.59924
Validation loss: 15299.3955078125 MAE: 94.951416
Validation loss: 14709.0986328125 MAE: 92.00904
Validation loss: 14826.5791015625 MAE: 91.28039
Validation loss: 15066.669270833334 MAE: 92.07624
Validation loss: 14789.8720703125 MAE: 91.29958
Validation loss: 14348.055338541666 MAE: 90.40006
Validation loss: 13932.604817708334 MAE: 89.49247
Validation loss: 13697.578125 MAE: 90.04679
Validation loss: 14202.275390625 MAE: 95.32434
Validation loss: 14667.103352864584 MAE: 95.858025
Validation loss: 15089.150065104166 MAE: 96.21133
Validation loss: 15557.958333333334 MAE: 97.32764
Validation loss: 15291.694986979166 MAE: 96.66925
Validation loss: 15556.609049479166 MAE: 96.09194
Validation loss: 18329.643880208332 MAE: 104.452354
Validation loss: 18483.763671875 MAE: 105.02712
Validation loss: 17384.771484375 MAE: 100.96466
Validation loss: 18148.2451171875 MAE: 103.19132
Validation loss: 18670.43359375 MAE: 104.743675
Validation loss: 19490.596354166668 MAE: 106.5408
Loaded trained model with success.
Test loss: 11155.33479769978 Test MAE: 81.81706
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7518610421836228, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 96, Valid size: 96, Test size: 293
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 146354.921875
Validation loss: 151748.02604166666 MAE: 384.52197
Validation loss: 149860.453125 MAE: 382.06055
Validation loss: 147564.52083333334 MAE: 379.05444
Validation loss: 145837.77083333334 MAE: 376.91116
Validation loss: 144186.140625 MAE: 374.66513
Validation loss: 141382.390625 MAE: 370.7855
Validation loss: 137296.72395833334 MAE: 365.04565
Validation loss: 131476.8984375 MAE: 356.27774
Validation loss: 123398.875 MAE: 343.5093
Validation loss: 111339.99479166667 MAE: 322.7599
Validation loss: 97003.95572916667 MAE: 294.5284
Validation loss: 80117.17447916667 MAE: 254.1584
Validation loss: 69089.78125 MAE: 229.42212
Validation loss: 64652.825520833336 MAE: 223.67192
Validation loss: 59114.2578125 MAE: 215.59283
Validation loss: 58989.856770833336 MAE: 214.75307
16 2 44678.3046875
Validation loss: 62553.065104166664 MAE: 217.30908
Validation loss: 58094.919270833336 MAE: 207.46404
Validation loss: 52838.291666666664 MAE: 196.04756
Validation loss: 50500.036458333336 MAE: 192.54034
Validation loss: 48036.75390625 MAE: 190.3357
Validation loss: 49688.2890625 MAE: 194.88867
Validation loss: 50725.296875 MAE: 198.03996
Validation loss: 51054.821614583336 MAE: 200.28748
Validation loss: 53385.666666666664 MAE: 204.44759
Validation loss: 52033.209635416664 MAE: 200.4591
Validation loss: 51309.244791666664 MAE: 198.54486
Validation loss: 45030.965494791664 MAE: 182.74059
Validation loss: 41977.274739583336 MAE: 174.90013
Validation loss: 41591.06640625 MAE: 172.84386
Validation loss: 36881.714192708336 MAE: 159.30724
Validation loss: 35402.205729166664 MAE: 155.45917
Validation loss: 36795.864583333336 MAE: 158.0273
33 1 54750.23046875
Validation loss: 31871.743489583332 MAE: 147.85579
Validation loss: 28048.389973958332 MAE: 138.7393
Validation loss: 23989.197916666668 MAE: 127.22001
Validation loss: 25014.841145833332 MAE: 126.62568
Validation loss: 25490.21484375 MAE: 128.93459
Validation loss: 26584.531901041668 MAE: 130.85857
Validation loss: 26569.184895833332 MAE: 130.70045
Validation loss: 27863.06640625 MAE: 137.08307
Validation loss: 27931.920572916668 MAE: 137.57466
Validation loss: 29023.434895833332 MAE: 141.94205
Validation loss: 28829.862630208332 MAE: 141.20447
Validation loss: 27852.361979166668 MAE: 137.74828
Validation loss: 26780.029296875 MAE: 134.60966
Validation loss: 26343.327473958332 MAE: 134.70338
Validation loss: 27087.75390625 MAE: 138.2256
Validation loss: 28500.026692708332 MAE: 143.67119
Validation loss: 27646.440755208332 MAE: 142.18965
50 0 29045.62109375
Validation loss: 24938.837890625 MAE: 134.85812
Validation loss: 22019.337565104168 MAE: 126.26786
Validation loss: 20180.2392578125 MAE: 117.24732
Validation loss: 19169.1962890625 MAE: 110.93284
Validation loss: 19141.061848958332 MAE: 109.54431
Validation loss: 18536.731119791668 MAE: 107.112755
Validation loss: 17694.238932291668 MAE: 103.77145
Validation loss: 16722.693684895832 MAE: 100.32593
Validation loss: 16202.5 MAE: 98.861145
Validation loss: 15737.392903645834 MAE: 95.85513
Validation loss: 15874.58203125 MAE: 94.66703
Validation loss: 15590.091145833334 MAE: 92.39443
Validation loss: 14873.340494791666 MAE: 90.37097
Validation loss: 14943.082356770834 MAE: 88.56844
Validation loss: 14609.9638671875 MAE: 86.75336
Validation loss: 13804.2861328125 MAE: 84.697975
66 2 13697.9140625
Validation loss: 13905.892578125 MAE: 84.24011
Validation loss: 13624.567545572916 MAE: 83.07423
Validation loss: 14042.9609375 MAE: 83.30114
Validation loss: 12701.111328125 MAE: 78.86552
Validation loss: 11872.435872395834 MAE: 76.15148
Validation loss: 11186.998697916666 MAE: 74.18989
Validation loss: 10931.236979166666 MAE: 75.70589
Validation loss: 10753.75634765625 MAE: 76.52749
Validation loss: 10377.486979166666 MAE: 77.870575
Validation loss: 10011.276692708334 MAE: 78.66883
Validation loss: 9680.258626302084 MAE: 77.24332
Validation loss: 9358.998372395834 MAE: 76.631935
Validation loss: 9144.205403645834 MAE: 74.68861
Validation loss: 9003.212727864584 MAE: 75.059006
Validation loss: 9313.016438802084 MAE: 75.90991
Validation loss: 9303.770833333334 MAE: 74.630585
Validation loss: 8526.923177083334 MAE: 71.703384
83 1 5002.3994140625
Validation loss: 8463.97802734375 MAE: 70.744774
Validation loss: 8293.58642578125 MAE: 68.63204
Validation loss: 7771.139973958333 MAE: 65.56138
Validation loss: 6914.652180989583 MAE: 63.172756
Validation loss: 6563.53857421875 MAE: 60.73555
Validation loss: 5972.8505859375 MAE: 57.420807
Validation loss: 5599.897379557292 MAE: 56.098156
Validation loss: 5427.587076822917 MAE: 56.061916
Validation loss: 5098.6953125 MAE: 53.597828
Validation loss: 4389.788818359375 MAE: 47.439037
Validation loss: 4862.134033203125 MAE: 47.303402
Validation loss: 6154.521077473958 MAE: 51.085358
Validation loss: 4583.3769938151045 MAE: 43.34242
Validation loss: 3534.251708984375 MAE: 43.197773
Validation loss: 3885.4773763020835 MAE: 50.444324
Validation loss: 3412.693359375 MAE: 45.402576
Validation loss: 3546.6443684895835 MAE: 45.199066
Loaded trained model with success.
Test loss: 4630.302527730375 Test MAE: 53.247967
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5037220843672456, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 193, Valid size: 193, Test size: 196
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 158084.484375
Validation loss: 151223.92608484457 MAE: 383.35168
Validation loss: 146509.62686204663 MAE: 377.2641
Validation loss: 140413.73239151554 MAE: 368.60904
Validation loss: 130309.97389086787 MAE: 354.02963
Validation loss: 107545.90689766839 MAE: 316.36444
Validation loss: 59197.02784974093 MAE: 208.41513
Validation loss: 81622.18813248866 MAE: 240.50279
7 1 57679.5
Validation loss: 121050.31422036917 MAE: 279.04233
Validation loss: 91692.51631065724 MAE: 253.03232
Validation loss: 49002.659602822416 MAE: 184.86035
Validation loss: 53341.53072376943 MAE: 205.25043
Validation loss: 53442.016960816065 MAE: 203.42264
Validation loss: 28599.95027121114 MAE: 134.61311
Validation loss: 29450.040784766636 MAE: 137.1776
14 2 36436.90625
Validation loss: 31219.47445757772 MAE: 145.03442
Validation loss: 31400.329986611796 MAE: 148.65553
Validation loss: 31236.759351977413 MAE: 144.87584
Validation loss: 30321.20440009715 MAE: 150.1269
Validation loss: 27936.09199927137 MAE: 145.3089
Validation loss: 25796.658901392486 MAE: 138.77922
Validation loss: 24402.655953995305 MAE: 134.53497
21 3 20009.40234375
Validation loss: 26778.62754292068 MAE: 138.50522
Validation loss: 28932.56294527202 MAE: 142.82019
Validation loss: 31828.398903011657 MAE: 153.15332
Validation loss: 19007.34172603627 MAE: 117.28264
Validation loss: 16043.446567357512 MAE: 100.014206
Validation loss: 16889.506089600873 MAE: 100.46697
Validation loss: 14228.037516697701 MAE: 92.26678
28 4 7445.87646484375
Validation loss: 10389.61622042483 MAE: 75.084236
Validation loss: 11085.327725267163 MAE: 80.553566
Validation loss: 8951.780673170337 MAE: 72.459595
Validation loss: 7276.244917953571 MAE: 65.246086
Validation loss: 7970.3634026878235 MAE: 71.58198
Validation loss: 8624.213624311853 MAE: 74.38599
Validation loss: 4178.835318767962 MAE: 49.05893
35 5 6821.29833984375
Validation loss: 4565.599910439605 MAE: 49.921074
Validation loss: 4007.842989116135 MAE: 47.909733
Validation loss: 3147.575557096017 MAE: 43.67984
Validation loss: 2085.0239510807965 MAE: 34.503376
Validation loss: 2180.8909994332903 MAE: 36.863564
Validation loss: 1672.7937716554484 MAE: 31.519865
Validation loss: 1642.9011935545373 MAE: 31.070475
42 6 4040.722900390625
Validation loss: 1610.9171038217496 MAE: 31.044031
Validation loss: 2355.772663254812 MAE: 37.093407
Validation loss: 1584.864598882013 MAE: 30.236303
Validation loss: 1450.75240345693 MAE: 28.582153
Validation loss: 1654.5355026956668 MAE: 31.222246
Validation loss: 1585.0580034601874 MAE: 29.684252
Validation loss: 1656.2283613570614 MAE: 31.136187
Validation loss: 1586.7012977402444 MAE: 30.634865
50 0 2198.50146484375
Validation loss: 1453.2590433229436 MAE: 29.232958
Validation loss: 1296.9455936412119 MAE: 27.999912
Validation loss: 1271.9974169162888 MAE: 27.605524
Validation loss: 1388.2117559403337 MAE: 29.058659
Validation loss: 1781.8721791796115 MAE: 32.788406
Validation loss: 1347.5965000607189 MAE: 28.508764
Validation loss: 1380.9572138514543 MAE: 29.044193
57 1 1835.1890869140625
Validation loss: 1232.9012881264168 MAE: 27.224098
Validation loss: 1474.9336597660044 MAE: 30.167665
Validation loss: 1998.5934970045337 MAE: 35.45102
Validation loss: 1259.2502990880778 MAE: 27.705336
Validation loss: 1375.9022969458388 MAE: 28.938982
Validation loss: 1431.8245749992411 MAE: 29.218124
Validation loss: 1495.3016468107392 MAE: 30.593992
64 2 1421.323486328125
Validation loss: 1149.3043406812637 MAE: 25.043722
Validation loss: 1272.9786437434855 MAE: 26.6218
Validation loss: 1262.262978865075 MAE: 27.899282
Validation loss: 1521.8111113958407 MAE: 30.944002
Validation loss: 1421.643364624656 MAE: 29.993366
Validation loss: 1885.027859702629 MAE: 36.14887
Validation loss: 1492.372698215623 MAE: 30.214725
71 3 1383.73779296875
Validation loss: 1604.5034301169796 MAE: 32.471188
Validation loss: 1305.2060538573587 MAE: 27.386976
Validation loss: 2212.6137176671796 MAE: 39.16757
Validation loss: 1744.055041496 MAE: 34.28506
Validation loss: 1417.1037528873107 MAE: 30.11049
Validation loss: 1199.7192855597777 MAE: 26.679134
Validation loss: 1041.0087353009635 MAE: 24.290728
78 4 1893.93212890625
Validation loss: 1104.9613335960269 MAE: 25.59975
Validation loss: 1097.0716344013115 MAE: 25.589237
Validation loss: 1081.1410158779954 MAE: 25.585632
Validation loss: 979.5464259330473 MAE: 24.026157
Validation loss: 910.0513846441871 MAE: 23.12881
Validation loss: 1066.113536617299 MAE: 24.627388
Validation loss: 937.9709637103304 MAE: 22.478685
85 5 1020.686279296875
Validation loss: 2024.9692963911461 MAE: 38.378506
Validation loss: 2270.6734789912566 MAE: 40.787525
Validation loss: 854.4648927678716 MAE: 21.992117
Validation loss: 968.5041010565091 MAE: 23.107414
Validation loss: 979.6079000364314 MAE: 24.083147
Validation loss: 1079.7562395797493 MAE: 25.633982
Validation loss: 923.7751694911502 MAE: 23.11994
92 6 2218.824462890625
Validation loss: 1027.6237932116258 MAE: 24.360443
Validation loss: 1392.204430298484 MAE: 31.193768
Validation loss: 921.6383882828944 MAE: 23.087503
Validation loss: 845.0008295088852 MAE: 21.770588
Validation loss: 779.5903855556033 MAE: 20.38631
Validation loss: 807.6816654501802 MAE: 21.70461
Validation loss: 903.7061451333792 MAE: 23.023823
Validation loss: 1128.1595805667225 MAE: 26.600454
Loaded trained model with success.
Test loss: 1628.272064831792 Test MAE: 26.978172
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9751861042183623, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 2}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 380
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.7159310579299927
Validation loss: 0.6962940096855164 ROC AUC: 0.55
Validation loss: 0.694282054901123 ROC AUC: 0.75
Validation loss: 0.6907923817634583 ROC AUC: 0.85
Validation loss: 0.7000594735145569 ROC AUC: 0.95
Validation loss: 0.7365450263023376 ROC AUC: 0.95
Validation loss: 0.763695478439331 ROC AUC: 0.9
Validation loss: 0.779961109161377 ROC AUC: 0.9
Validation loss: 0.8039891719818115 ROC AUC: 0.95
Validation loss: 0.7738116979598999 ROC AUC: 1.0
Validation loss: 0.7288886904716492 ROC AUC: 1.0
Validation loss: 0.6985231041908264 ROC AUC: 1.0
Validation loss: 0.6884818077087402 ROC AUC: 0.5
Validation loss: 0.689938485622406 ROC AUC: 0.3
Validation loss: 0.6979877948760986 ROC AUC: 0.15000000000000002
Validation loss: 0.7061587572097778 ROC AUC: 0.15000000000000002
Validation loss: 0.7035182118415833 ROC AUC: 0.25
Validation loss: 0.7029018402099609 ROC AUC: 0.30000000000000004
Validation loss: 0.7039029598236084 ROC AUC: 0.4
Validation loss: 0.6976597309112549 ROC AUC: 0.45000000000000007
Validation loss: 0.6879469752311707 ROC AUC: 0.45
Validation loss: 0.6777266263961792 ROC AUC: 0.55
Validation loss: 0.6722328662872314 ROC AUC: 0.6
Validation loss: 0.68033766746521 ROC AUC: 0.6
Validation loss: 0.6945120692253113 ROC AUC: 0.6
Validation loss: 0.7059142589569092 ROC AUC: 0.6
Validation loss: 0.6982306838035583 ROC AUC: 0.6
Validation loss: 0.7085131406784058 ROC AUC: 0.6
Validation loss: 0.7141801118850708 ROC AUC: 0.6
Validation loss: 0.7367628216743469 ROC AUC: 0.6
Validation loss: 0.752617597579956 ROC AUC: 0.6
Validation loss: 0.763921856880188 ROC AUC: 0.6
Validation loss: 0.7619539499282837 ROC AUC: 0.6
Validation loss: 0.7685530185699463 ROC AUC: 0.6
Validation loss: 0.7634716033935547 ROC AUC: 0.6
Validation loss: 0.7465869784355164 ROC AUC: 0.6
Validation loss: 0.7253444194793701 ROC AUC: 0.6
Validation loss: 0.7048455476760864 ROC AUC: 0.6
Validation loss: 0.6822817921638489 ROC AUC: 0.65
Validation loss: 0.6682120561599731 ROC AUC: 0.65
Validation loss: 0.65348219871521 ROC AUC: 0.7
Validation loss: 0.6422123908996582 ROC AUC: 0.7
Validation loss: 0.6144688725471497 ROC AUC: 0.75
Validation loss: 0.6501150131225586 ROC AUC: 0.75
Validation loss: 0.678993821144104 ROC AUC: 0.75
Validation loss: 0.6984530091285706 ROC AUC: 0.8
Validation loss: 0.6944567561149597 ROC AUC: 0.9
Validation loss: 0.6828386187553406 ROC AUC: 0.9
Validation loss: 0.6905249357223511 ROC AUC: 1.0
Validation loss: 0.6553951501846313 ROC AUC: 1.0
Validation loss: 0.6602261066436768 ROC AUC: 1.0
50 0 0.880135178565979
Validation loss: 0.6612575054168701 ROC AUC: 1.0
Validation loss: 0.6294189095497131 ROC AUC: 1.0
Validation loss: 0.6157343983650208 ROC AUC: 1.0
Validation loss: 0.5736604332923889 ROC AUC: 1.0
Validation loss: 0.5031490921974182 ROC AUC: 1.0
Validation loss: 0.4703010320663452 ROC AUC: 1.0
Validation loss: 0.45772784948349 ROC AUC: 1.0
Validation loss: 0.4722331762313843 ROC AUC: 1.0
Validation loss: 0.4572441279888153 ROC AUC: 1.0
Validation loss: 0.45694196224212646 ROC AUC: 1.0
Validation loss: 0.47169727087020874 ROC AUC: 1.0
Validation loss: 0.4335847795009613 ROC AUC: 1.0
Validation loss: 0.3483802378177643 ROC AUC: 1.0
Validation loss: 0.2845810651779175 ROC AUC: 1.0
Validation loss: 0.21836267411708832 ROC AUC: 1.0
Validation loss: 0.17248967289924622 ROC AUC: 1.0
Validation loss: 0.13194391131401062 ROC AUC: 1.0
Validation loss: 0.10317779332399368 ROC AUC: 1.0
Validation loss: 0.0873970091342926 ROC AUC: 1.0
Validation loss: 0.08295955508947372 ROC AUC: 1.0
Validation loss: 0.08808693289756775 ROC AUC: 1.0
Validation loss: 0.10718746483325958 ROC AUC: 1.0
Validation loss: 0.12679830193519592 ROC AUC: 1.0
Validation loss: 0.1355317234992981 ROC AUC: 1.0
Validation loss: 0.1312035620212555 ROC AUC: 1.0
Validation loss: 0.10210457444190979 ROC AUC: 1.0
Validation loss: 0.09421388804912567 ROC AUC: 1.0
Validation loss: 0.08294114470481873 ROC AUC: 1.0
Validation loss: 0.06387109309434891 ROC AUC: 1.0
Validation loss: 0.0709482729434967 ROC AUC: 1.0
Validation loss: 0.07281096279621124 ROC AUC: 1.0
Validation loss: 0.0635000467300415 ROC AUC: 1.0
Validation loss: 0.061353325843811035 ROC AUC: 1.0
Validation loss: 0.05841836705803871 ROC AUC: 1.0
Validation loss: 0.04499340429902077 ROC AUC: 1.0
Validation loss: 0.04285946860909462 ROC AUC: 1.0
Validation loss: 0.036651160567998886 ROC AUC: 1.0
Validation loss: 0.03431042656302452 ROC AUC: 1.0
Validation loss: 0.032500218600034714 ROC AUC: 1.0
Validation loss: 0.032696597278118134 ROC AUC: 1.0
Validation loss: 0.04007340595126152 ROC AUC: 1.0
Validation loss: 0.03892146050930023 ROC AUC: 1.0
Validation loss: 0.03463030606508255 ROC AUC: 1.0
Validation loss: 0.03203479200601578 ROC AUC: 1.0
Validation loss: 0.01978917419910431 ROC AUC: 1.0
Validation loss: 0.013109542429447174 ROC AUC: 1.0
Validation loss: 0.016306830570101738 ROC AUC: 1.0
Validation loss: 0.02331363968551159 ROC AUC: 1.0
Validation loss: 0.028698524460196495 ROC AUC: 1.0
Validation loss: 0.044168561697006226 ROC AUC: 1.0
Loaded trained model with success.
Test loss: 0.8346443220188743 Test ROC AUC: 0.7438919667590027
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9503722084367245, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 2}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 19, Valid size: 19, Test size: 370
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.6992864608764648
Validation loss: 0.6941512823104858 ROC AUC: 0.7555555555555555
Validation loss: 0.6929383873939514 ROC AUC: 0.7444444444444445
Validation loss: 0.7120384573936462 ROC AUC: 0.03333333333333335
Validation loss: 0.7389571666717529 ROC AUC: 0.022222222222222223
Validation loss: 0.7102107405662537 ROC AUC: 0.044444444444444446
Validation loss: 0.7079806327819824 ROC AUC: 0.24444444444444444
Validation loss: 0.7399871349334717 ROC AUC: 0.34444444444444444
Validation loss: 0.7882593274116516 ROC AUC: 0.43333333333333335
Validation loss: 0.8033503293991089 ROC AUC: 0.6000000000000001
Validation loss: 0.760607123374939 ROC AUC: 0.788888888888889
Validation loss: 0.719089686870575 ROC AUC: 0.8777777777777778
Validation loss: 0.7105472683906555 ROC AUC: 0.9111111111111111
Validation loss: 0.708030641078949 ROC AUC: 0.9222222222222223
Validation loss: 0.7140040993690491 ROC AUC: 0.9222222222222223
Validation loss: 0.7384059429168701 ROC AUC: 0.9
Validation loss: 0.7510650753974915 ROC AUC: 0.9111111111111111
Validation loss: 0.7637151479721069 ROC AUC: 0.8555555555555556
Validation loss: 0.7580809593200684 ROC AUC: 0.8444444444444444
Validation loss: 0.764936625957489 ROC AUC: 0.8444444444444444
Validation loss: 0.7477736473083496 ROC AUC: 0.8333333333333333
Validation loss: 0.7030742764472961 ROC AUC: 0.8333333333333334
Validation loss: 0.6281196475028992 ROC AUC: 0.8444444444444444
Validation loss: 0.5803853869438171 ROC AUC: 0.8555555555555556
Validation loss: 0.5362581014633179 ROC AUC: 0.8555555555555556
Validation loss: 0.48856061697006226 ROC AUC: 0.8666666666666667
Validation loss: 0.4615810811519623 ROC AUC: 0.8666666666666667
Validation loss: 0.44689691066741943 ROC AUC: 0.8777777777777778
Validation loss: 0.431205153465271 ROC AUC: 0.8777777777777778
Validation loss: 0.4098488688468933 ROC AUC: 0.8888888888888888
Validation loss: 0.38412928581237793 ROC AUC: 0.8888888888888888
Validation loss: 0.36376893520355225 ROC AUC: 0.8888888888888888
Validation loss: 0.36564046144485474 ROC AUC: 0.9
Validation loss: 0.3724035620689392 ROC AUC: 0.9
Validation loss: 0.38983818888664246 ROC AUC: 0.9
Validation loss: 0.3818163573741913 ROC AUC: 0.9222222222222223
Validation loss: 0.383370965719223 ROC AUC: 0.9222222222222223
Validation loss: 0.37463757395744324 ROC AUC: 0.9222222222222223
Validation loss: 0.3826654553413391 ROC AUC: 0.9222222222222223
Validation loss: 0.380310595035553 ROC AUC: 0.9444444444444444
Validation loss: 0.3624027669429779 ROC AUC: 0.9444444444444444
Validation loss: 0.3373768627643585 ROC AUC: 0.9444444444444444
Validation loss: 0.31588810682296753 ROC AUC: 0.9444444444444444
Validation loss: 0.3007781505584717 ROC AUC: 0.9444444444444444
Validation loss: 0.2932007908821106 ROC AUC: 0.9666666666666666
Validation loss: 0.2905551493167877 ROC AUC: 0.9666666666666666
Validation loss: 0.29087144136428833 ROC AUC: 0.9666666666666666
Validation loss: 0.2930835485458374 ROC AUC: 0.9666666666666666
Validation loss: 0.2866303622722626 ROC AUC: 0.9666666666666666
Validation loss: 0.2873620092868805 ROC AUC: 0.9666666666666666
Validation loss: 0.28153374791145325 ROC AUC: 0.9666666666666666
50 0 0.37402841448783875
Validation loss: 0.2727264165878296 ROC AUC: 0.9666666666666666
Validation loss: 0.25964030623435974 ROC AUC: 0.9666666666666666
Validation loss: 0.2506555914878845 ROC AUC: 0.9777777777777777
Validation loss: 0.24699732661247253 ROC AUC: 0.9777777777777777
Validation loss: 0.2419312447309494 ROC AUC: 0.9777777777777777
Validation loss: 0.246721088886261 ROC AUC: 0.9777777777777777
Validation loss: 0.25074753165245056 ROC AUC: 0.9777777777777777
Validation loss: 0.2679603695869446 ROC AUC: 0.9777777777777777
Validation loss: 0.28769972920417786 ROC AUC: 0.9777777777777777
Validation loss: 0.3072659969329834 ROC AUC: 0.9777777777777777
Validation loss: 0.31038329005241394 ROC AUC: 0.9777777777777777
Validation loss: 0.3148285150527954 ROC AUC: 0.9777777777777777
Validation loss: 0.32755348086357117 ROC AUC: 0.9777777777777777
Validation loss: 0.3228529095649719 ROC AUC: 0.9777777777777777
Validation loss: 0.319828599691391 ROC AUC: 0.9777777777777777
Validation loss: 0.3129366636276245 ROC AUC: 0.9777777777777777
Validation loss: 0.3015976548194885 ROC AUC: 0.9777777777777777
Validation loss: 0.28311991691589355 ROC AUC: 0.9777777777777777
Validation loss: 0.2557922601699829 ROC AUC: 0.9777777777777777
Validation loss: 0.2351911962032318 ROC AUC: 0.9777777777777777
Validation loss: 0.21987739205360413 ROC AUC: 0.9777777777777777
Validation loss: 0.20905236899852753 ROC AUC: 0.9777777777777777
Validation loss: 0.20233704149723053 ROC AUC: 0.9777777777777777
Validation loss: 0.19822941720485687 ROC AUC: 0.9777777777777777
Validation loss: 0.19588503241539001 ROC AUC: 0.9777777777777777
Validation loss: 0.19414502382278442 ROC AUC: 0.9777777777777777
Validation loss: 0.19454096257686615 ROC AUC: 0.9777777777777777
Validation loss: 0.1922626942396164 ROC AUC: 0.9777777777777777
Validation loss: 0.19544726610183716 ROC AUC: 0.9777777777777777
Validation loss: 0.19936664402484894 ROC AUC: 0.9777777777777777
Validation loss: 0.19853471219539642 ROC AUC: 0.9777777777777777
Validation loss: 0.20050446689128876 ROC AUC: 0.9888888888888888
Validation loss: 0.19567647576332092 ROC AUC: 0.9888888888888888
Validation loss: 0.19253966212272644 ROC AUC: 0.9888888888888888
Validation loss: 0.19279572367668152 ROC AUC: 0.9888888888888888
Validation loss: 0.1885603368282318 ROC AUC: 0.9888888888888888
Validation loss: 0.20004616677761078 ROC AUC: 0.9888888888888888
Validation loss: 0.20986825227737427 ROC AUC: 0.9888888888888888
Validation loss: 0.22100874781608582 ROC AUC: 0.9888888888888888
Validation loss: 0.2445453554391861 ROC AUC: 0.9888888888888888
Validation loss: 0.2590785324573517 ROC AUC: 0.9777777777777777
Validation loss: 0.28666579723358154 ROC AUC: 0.9777777777777777
Validation loss: 0.3221847414970398 ROC AUC: 0.9777777777777777
Validation loss: 0.3665447533130646 ROC AUC: 0.9777777777777777
Validation loss: 0.38085758686065674 ROC AUC: 0.9777777777777777
Validation loss: 0.3768550157546997 ROC AUC: 0.9777777777777777
Validation loss: 0.3697713017463684 ROC AUC: 0.9777777777777777
Validation loss: 0.3454005718231201 ROC AUC: 0.9777777777777777
Validation loss: 0.3105597496032715 ROC AUC: 0.9777777777777777
Validation loss: 0.2988876700401306 ROC AUC: 0.9777777777777777
Loaded trained model with success.
Test loss: 0.519235049389504 Test ROC AUC: 0.9180277574872169
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8759305210918115, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 2}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 48, Valid size: 48, Test size: 341
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.7149527668952942
Validation loss: 0.8378269076347351 ROC AUC: 0.6545138888888888
Validation loss: 0.897452712059021 ROC AUC: 0.6631944444444444
Validation loss: 0.7194791833559672 ROC AUC: 0.6354166666666667
Validation loss: 0.6946722269058228 ROC AUC: 0.8802083333333334
Validation loss: 0.7032599449157715 ROC AUC: 0.732638888888889
Validation loss: 0.6899421811103821 ROC AUC: 0.8663194444444444
Validation loss: 0.6973784367243449 ROC AUC: 0.8229166666666666
Validation loss: 0.707604169845581 ROC AUC: 0.7638888888888888
Validation loss: 0.650074283281962 ROC AUC: 0.7604166666666666
Validation loss: 0.5901068647702535 ROC AUC: 0.7621527777777778
Validation loss: 0.5787006616592407 ROC AUC: 0.765625
Validation loss: 0.6008058389027914 ROC AUC: 0.763888888888889
Validation loss: 0.6284980376561483 ROC AUC: 0.7638888888888888
Validation loss: 0.6332701444625854 ROC AUC: 0.7899305555555556
Validation loss: 0.60699462890625 ROC AUC: 0.8038194444444444
Validation loss: 0.5587967038154602 ROC AUC: 0.8194444444444444
Validation loss: 0.5395742456118265 ROC AUC: 0.8333333333333334
Validation loss: 0.5386106868584951 ROC AUC: 0.845486111111111
Validation loss: 0.5399569670359293 ROC AUC: 0.8576388888888888
Validation loss: 0.5437805851300558 ROC AUC: 0.8680555555555555
Validation loss: 0.5529913902282715 ROC AUC: 0.8802083333333334
Validation loss: 0.577949603398641 ROC AUC: 0.8888888888888888
Validation loss: 0.5999709169069926 ROC AUC: 0.8993055555555556
Validation loss: 0.6013074318567911 ROC AUC: 0.9027777777777778
Validation loss: 0.5488420327504476 ROC AUC: 0.9079861111111112
25 0 0.44894832372665405
Validation loss: 0.48625391721725464 ROC AUC: 0.9131944444444445
Validation loss: 0.40447978178660077 ROC AUC: 0.9184027777777779
Validation loss: 0.3831302722295125 ROC AUC: 0.9392361111111112
Validation loss: 0.3850821256637573 ROC AUC: 0.9496527777777777
Validation loss: 0.3657626310984294 ROC AUC: 0.9618055555555555
Validation loss: 0.3657887578010559 ROC AUC: 0.9704861111111112
Validation loss: 0.3570781151453654 ROC AUC: 0.9670138888888888
Validation loss: 0.36257150769233704 ROC AUC: 0.9756944444444444
Validation loss: 0.35728369156519574 ROC AUC: 0.9809027777777777
Validation loss: 0.3305666248003642 ROC AUC: 0.9861111111111112
Validation loss: 0.30463974674542743 ROC AUC: 0.9878472222222221
Validation loss: 0.28589573750893277 ROC AUC: 0.9878472222222221
Validation loss: 0.24344361821810404 ROC AUC: 0.9895833333333334
Validation loss: 0.23208112517992655 ROC AUC: 0.9930555555555556
Validation loss: 0.23757567505041757 ROC AUC: 0.9965277777777777
Validation loss: 0.2858935097853343 ROC AUC: 0.998263888888889
Validation loss: 0.3517332176367442 ROC AUC: 1.0
Validation loss: 0.40715410312016803 ROC AUC: 1.0
Validation loss: 0.4783097406228383 ROC AUC: 1.0
Validation loss: 0.4715505043665568 ROC AUC: 1.0
Validation loss: 0.39068061113357544 ROC AUC: 1.0
Validation loss: 0.29131312171618146 ROC AUC: 1.0
Validation loss: 0.22400436302026114 ROC AUC: 0.998263888888889
Validation loss: 0.20869746804237366 ROC AUC: 0.9965277777777777
Validation loss: 0.22666089236736298 ROC AUC: 0.9965277777777777
50 0 0.20683063566684723
Validation loss: 0.24403046071529388 ROC AUC: 0.9947916666666666
Validation loss: 0.22468359271685281 ROC AUC: 0.9947916666666666
Validation loss: 0.21440239747365317 ROC AUC: 0.9965277777777777
Validation loss: 0.21132500966389975 ROC AUC: 0.9947916666666666
Validation loss: 0.20937342941761017 ROC AUC: 0.9947916666666666
Validation loss: 0.2129022628068924 ROC AUC: 0.9947916666666666
Validation loss: 0.22013643880685171 ROC AUC: 0.9947916666666666
Validation loss: 0.2401463290055593 ROC AUC: 0.9965277777777777
Validation loss: 0.24006807307402292 ROC AUC: 0.998263888888889
Validation loss: 0.24365878105163574 ROC AUC: 0.998263888888889
Validation loss: 0.23982639610767365 ROC AUC: 0.998263888888889
Validation loss: 0.22206678986549377 ROC AUC: 0.998263888888889
Validation loss: 0.21398481478293738 ROC AUC: 1.0
Validation loss: 0.20385257403055826 ROC AUC: 1.0
Validation loss: 0.1962534710764885 ROC AUC: 1.0
Validation loss: 0.18111248314380646 ROC AUC: 1.0
Validation loss: 0.15961162249247232 ROC AUC: 1.0
Validation loss: 0.14593602965275446 ROC AUC: 1.0
Validation loss: 0.12121044797822833 ROC AUC: 1.0
Validation loss: 0.11587341502308846 ROC AUC: 1.0
Validation loss: 0.11047648017605145 ROC AUC: 1.0
Validation loss: 0.10676932955781619 ROC AUC: 1.0
Validation loss: 0.11237272371848424 ROC AUC: 1.0
Validation loss: 0.11490227778752644 ROC AUC: 1.0
Validation loss: 0.10827891590694587 ROC AUC: 1.0
75 0 0.01741088554263115
Validation loss: 0.10281594408055146 ROC AUC: 1.0
Validation loss: 0.09742960209647815 ROC AUC: 1.0
Validation loss: 0.09976507226626079 ROC AUC: 1.0
Validation loss: 0.10134532457838456 ROC AUC: 1.0
Validation loss: 0.09909732639789581 ROC AUC: 1.0
Validation loss: 0.08228084320823352 ROC AUC: 1.0
Validation loss: 0.07772068221432467 ROC AUC: 1.0
Validation loss: 0.07505416280279557 ROC AUC: 1.0
Validation loss: 0.07193596350649993 ROC AUC: 1.0
Validation loss: 0.06505126692354679 ROC AUC: 1.0
Validation loss: 0.05784506412843863 ROC AUC: 1.0
Validation loss: 0.04901726388682922 ROC AUC: 1.0
Validation loss: 0.0445075158495456 ROC AUC: 1.0
Validation loss: 0.03734814662796756 ROC AUC: 1.0
Validation loss: 0.0310920729340675 ROC AUC: 1.0
Validation loss: 0.026382441942890484 ROC AUC: 1.0
Validation loss: 0.022530653203527134 ROC AUC: 1.0
Validation loss: 0.021381085369891178 ROC AUC: 1.0
Validation loss: 0.021821807138621807 ROC AUC: 1.0
Validation loss: 0.022321209932367008 ROC AUC: 1.0
Validation loss: 0.014936727394039432 ROC AUC: 1.0
Validation loss: 0.012060456967446953 ROC AUC: 1.0
Validation loss: 0.011544683637718359 ROC AUC: 1.0
Validation loss: 0.014823044475633651 ROC AUC: 1.0
Validation loss: 0.015185158389310041 ROC AUC: 1.0
Loaded trained model with success.
Test loss: 0.6855918310604487 Test ROC AUC: 0.9203302373581012
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7518610421836228, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 2}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 96, Valid size: 96, Test size: 293
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.7391737699508667
Validation loss: 0.7532150149345398 ROC AUC: 0.7838541666666666
Validation loss: 0.7177379528681437 ROC AUC: 0.7599826388888888
Validation loss: 0.6935515801111857 ROC AUC: 0.38585069444444436
Validation loss: 0.729685107866923 ROC AUC: 0.35026041666666663
Validation loss: 0.7412863572438558 ROC AUC: 0.3611111111111111
Validation loss: 0.7212320566177368 ROC AUC: 0.3515625
Validation loss: 0.6889653205871582 ROC AUC: 0.45572916666666674
Validation loss: 0.6530075867970785 ROC AUC: 0.6028645833333334
Validation loss: 0.6444026629130045 ROC AUC: 0.6666666666666666
Validation loss: 0.645697017510732 ROC AUC: 0.6519097222222222
Validation loss: 0.6403868595759074 ROC AUC: 0.6671006944444444
Validation loss: 0.6337956587473551 ROC AUC: 0.6944444444444444
Validation loss: 0.6300151149431864 ROC AUC: 0.7209201388888888
Validation loss: 0.6224363048871359 ROC AUC: 0.7378472222222222
Validation loss: 0.6106380621592203 ROC AUC: 0.728298611111111
Validation loss: 0.6040904720624288 ROC AUC: 0.7287326388888888
16 2 0.6372803449630737
Validation loss: 0.607381006081899 ROC AUC: 0.7369791666666666
Validation loss: 0.6175717711448669 ROC AUC: 0.7296006944444444
Validation loss: 0.6134184002876282 ROC AUC: 0.7352430555555556
Validation loss: 0.6133716702461243 ROC AUC: 0.7430555555555556
Validation loss: 0.611412525177002 ROC AUC: 0.7556423611111112
Validation loss: 0.6015367309252421 ROC AUC: 0.7608506944444444
Validation loss: 0.5838993787765503 ROC AUC: 0.7743055555555555
Validation loss: 0.5545662045478821 ROC AUC: 0.7994791666666665
Validation loss: 0.5161805848280588 ROC AUC: 0.8489583333333333
Validation loss: 0.5249570111433665 ROC AUC: 0.8897569444444444
Validation loss: 0.5196144878864288 ROC AUC: 0.9184027777777779
Validation loss: 0.49269797404607135 ROC AUC: 0.9288194444444444
Validation loss: 0.46525763471921283 ROC AUC: 0.9288194444444445
Validation loss: 0.41685714324315387 ROC AUC: 0.9331597222222221
Validation loss: 0.34842607378959656 ROC AUC: 0.9405381944444445
Validation loss: 0.299743394056956 ROC AUC: 0.9509548611111112
Validation loss: 0.2851763268311818 ROC AUC: 0.9561631944444444
33 1 0.30182063579559326
Validation loss: 0.26881642639636993 ROC AUC: 0.9626736111111112
Validation loss: 0.25450971225897473 ROC AUC: 0.9657118055555556
Validation loss: 0.24854154388109842 ROC AUC: 0.9691840277777778
Validation loss: 0.255590096116066 ROC AUC: 0.9717881944444444
Validation loss: 0.23229811092217764 ROC AUC: 0.9761284722222222
Validation loss: 0.22869111597537994 ROC AUC: 0.9778645833333333
Validation loss: 0.22659803926944733 ROC AUC: 0.9774305555555556
Validation loss: 0.23304332296053568 ROC AUC: 0.9761284722222222
Validation loss: 0.2334972843527794 ROC AUC: 0.978732638888889
Validation loss: 0.25799641758203506 ROC AUC: 0.98046875
Validation loss: 0.33067044119040173 ROC AUC: 0.9809027777777777
Validation loss: 0.3775550325711568 ROC AUC: 0.9835069444444444
Validation loss: 0.34828145305315655 ROC AUC: 0.9835069444444444
Validation loss: 0.2521831889947255 ROC AUC: 0.9835069444444444
Validation loss: 0.21041900167862573 ROC AUC: 0.9839409722222223
Validation loss: 0.22024375200271606 ROC AUC: 0.9830729166666666
Validation loss: 0.20616648346185684 ROC AUC: 0.9852430555555556
50 0 0.2839544713497162
Validation loss: 0.19804493089516959 ROC AUC: 0.9848090277777778
Validation loss: 0.18065664172172546 ROC AUC: 0.9839409722222223
Validation loss: 0.16466664522886276 ROC AUC: 0.984375
Validation loss: 0.15787548323472342 ROC AUC: 0.9839409722222222
Validation loss: 0.1554278458158175 ROC AUC: 0.9839409722222222
Validation loss: 0.1560592676202456 ROC AUC: 0.9848090277777778
Validation loss: 0.15142415215571722 ROC AUC: 0.9848090277777778
Validation loss: 0.1470386485258738 ROC AUC: 0.9852430555555556
Validation loss: 0.14209518705805144 ROC AUC: 0.9856770833333334
Validation loss: 0.14063906172911325 ROC AUC: 0.9861111111111112
Validation loss: 0.1537590908507506 ROC AUC: 0.9891493055555556
Validation loss: 0.17039535442988077 ROC AUC: 0.990017361111111
Validation loss: 0.19427593052387238 ROC AUC: 0.9904513888888888
Validation loss: 0.19358617067337036 ROC AUC: 0.990017361111111
Validation loss: 0.18039934088786444 ROC AUC: 0.9904513888888888
Validation loss: 0.1412914109726747 ROC AUC: 0.9900173611111112
66 2 0.13933293521404266
Validation loss: 0.1386385957400004 ROC AUC: 0.9874131944444444
Validation loss: 0.13772941629091898 ROC AUC: 0.9874131944444444
Validation loss: 0.13347248857220015 ROC AUC: 0.9878472222222222
Validation loss: 0.1406890923778216 ROC AUC: 0.9891493055555556
Validation loss: 0.1465209424495697 ROC AUC: 0.9904513888888888
Validation loss: 0.14412242422501245 ROC AUC: 0.9891493055555556
Validation loss: 0.13723403960466385 ROC AUC: 0.98828125
Validation loss: 0.13975067188342413 ROC AUC: 0.9874131944444444
Validation loss: 0.15721854443351427 ROC AUC: 0.9869791666666666
Validation loss: 0.17304165661334991 ROC AUC: 0.9865451388888888
Validation loss: 0.16961350043614706 ROC AUC: 0.9878472222222221
Validation loss: 0.16164624691009521 ROC AUC: 0.9887152777777778
Validation loss: 0.15258321166038513 ROC AUC: 0.9895833333333334
Validation loss: 0.150556743144989 ROC AUC: 0.98828125
Validation loss: 0.151068905989329 ROC AUC: 0.9887152777777778
Validation loss: 0.15587409089008966 ROC AUC: 0.9900173611111112
Validation loss: 0.15890596061944962 ROC AUC: 0.9908854166666666
83 1 0.07053254544734955
Validation loss: 0.1546428290506204 ROC AUC: 0.9913194444444444
Validation loss: 0.15086436768372855 ROC AUC: 0.9913194444444444
Validation loss: 0.15675384551286697 ROC AUC: 0.9908854166666666
Validation loss: 0.14860653380552927 ROC AUC: 0.9913194444444444
Validation loss: 0.14740727096796036 ROC AUC: 0.9913194444444444
Validation loss: 0.12974752361575762 ROC AUC: 0.9913194444444444
Validation loss: 0.11909494052330653 ROC AUC: 0.9913194444444444
Validation loss: 0.12121119722723961 ROC AUC: 0.9913194444444444
Validation loss: 0.11402252813180287 ROC AUC: 0.9917534722222222
Validation loss: 0.11378450940052669 ROC AUC: 0.9921875
Validation loss: 0.1110857551296552 ROC AUC: 0.9917534722222222
Validation loss: 0.11304745823144913 ROC AUC: 0.9926215277777777
Validation loss: 0.11208090434471767 ROC AUC: 0.9926215277777777
Validation loss: 0.10625465090076129 ROC AUC: 0.9921875
Validation loss: 0.10614065825939178 ROC AUC: 0.9921875
Validation loss: 0.10915222484618425 ROC AUC: 0.9917534722222222
Validation loss: 0.11219506897032261 ROC AUC: 0.9917534722222222
Loaded trained model with success.
Test loss: 0.29812483659885036 Test ROC AUC: 0.9497250955176592
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5037220843672456, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 2}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 193, Valid size: 193, Test size: 196
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.7680774927139282
Validation loss: 0.7073796153686207 ROC AUC: 0.7073131443298969
Validation loss: 0.7009149891724858 ROC AUC: 0.46746134020618557
Validation loss: 0.7064371905796268 ROC AUC: 0.4161834192439863
Validation loss: 0.6950480533387376 ROC AUC: 0.6863187285223367
Validation loss: 0.6525600549470575 ROC AUC: 0.6565721649484536
Validation loss: 0.7041995364767282 ROC AUC: 0.6912048969072164
Validation loss: 0.6263125307201721 ROC AUC: 0.7274484536082474
7 1 0.6274901032447815
Validation loss: 0.6096078864651023 ROC AUC: 0.7824849656357389
Validation loss: 0.6070867770694081 ROC AUC: 0.8776310137457044
Validation loss: 0.5251197407282696 ROC AUC: 0.9201567869415808
Validation loss: 0.362169626000014 ROC AUC: 0.9351911512027491
Validation loss: 0.34144696380962364 ROC AUC: 0.9470038659793815
Validation loss: 0.4219704039510668 ROC AUC: 0.9619308419243986
Validation loss: 0.4372190150572228 ROC AUC: 0.9662800687285223
14 2 0.13596303761005402
Validation loss: 0.5011531632644525 ROC AUC: 0.9721327319587629
Validation loss: 0.41402945513089084 ROC AUC: 0.976428264604811
Validation loss: 0.41360036140896494 ROC AUC: 0.9761060996563574
Validation loss: 0.5048548421699532 ROC AUC: 0.9755154639175257
Validation loss: 0.3512890310282457 ROC AUC: 0.9767504295532646
Validation loss: 0.30581226852273696 ROC AUC: 0.9805090206185567
Validation loss: 0.403176570571766 ROC AUC: 0.9826030927835051
21 3 0.20790286362171173
Validation loss: 0.36607711881138577 ROC AUC: 0.9812070446735395
Validation loss: 0.2443371883405305 ROC AUC: 0.9768578178694158
Validation loss: 0.18124942960207943 ROC AUC: 0.9798646907216495
Validation loss: 0.17074651462194834 ROC AUC: 0.9815829037800687
Validation loss: 0.2298412651518466 ROC AUC: 0.9829252577319587
Validation loss: 0.39000460775713847 ROC AUC: 0.9853414948453608
Validation loss: 0.28166981619413894 ROC AUC: 0.9846971649484537
28 4 0.19604000449180603
Validation loss: 0.23749507577616935 ROC AUC: 0.9838380584192441
Validation loss: 0.2860431819374475 ROC AUC: 0.9831937285223368
Validation loss: 0.1941480718195979 ROC AUC: 0.9831937285223368
Validation loss: 0.2015562122241338 ROC AUC: 0.9854488831615119
Validation loss: 0.31340214935338867 ROC AUC: 0.9862006013745706
Validation loss: 0.23796878006174157 ROC AUC: 0.986522766323024
Validation loss: 0.19830285514574594 ROC AUC: 0.986522766323024
35 5 0.2612159252166748
Validation loss: 0.16898863722565416 ROC AUC: 0.9883483676975945
Validation loss: 0.2388933625239927 ROC AUC: 0.9882946735395188
Validation loss: 0.3872444617315895 ROC AUC: 0.9881335910652921
Validation loss: 0.26209192695658606 ROC AUC: 0.9871134020618557
Validation loss: 0.1618034533886094 ROC AUC: 0.9875966494845361
Validation loss: 0.14051487713984642 ROC AUC: 0.9874892611683848
Validation loss: 0.18976076830533173 ROC AUC: 0.9879188144329897
42 6 0.6081646084785461
Validation loss: 0.21215124154847037 ROC AUC: 0.9893148625429553
Validation loss: 0.20691051507860886 ROC AUC: 0.9888853092783505
Validation loss: 0.19186878883678868 ROC AUC: 0.9859858247422681
Validation loss: 0.16736763931926668 ROC AUC: 0.9850193298969073
Validation loss: 0.1481619744412022 ROC AUC: 0.9875966494845361
Validation loss: 0.1754319565515444 ROC AUC: 0.9895296391752577
Validation loss: 0.1838814042402441 ROC AUC: 0.9916774054982819
Validation loss: 0.17573432203555972 ROC AUC: 0.9924828178694157
50 0 0.13653922080993652
Validation loss: 0.174635154750063 ROC AUC: 0.9927512886597938
Validation loss: 0.29954880939239625 ROC AUC: 0.9918921821305843
Validation loss: 0.1808749431927587 ROC AUC: 0.9919995704467354
Validation loss: 0.26005042331868367 ROC AUC: 0.9913552405498282
Validation loss: 0.1533974998973194 ROC AUC: 0.9919995704467354
Validation loss: 0.16680023469841543 ROC AUC: 0.9911404639175257
Validation loss: 0.16314448398861242 ROC AUC: 0.990710910652921
57 1 0.30224543809890747
Validation loss: 0.1417881887734245 ROC AUC: 0.992858676975945
Validation loss: 0.20087730699252587 ROC AUC: 0.9929660652920963
Validation loss: 0.2055169475395136 ROC AUC: 0.9927512886597938
Validation loss: 0.13337473733437494 ROC AUC: 0.9931808419243987
Validation loss: 0.1991981642388309 ROC AUC: 0.9926439003436426
Validation loss: 0.15104671034942638 ROC AUC: 0.9919995704467354
Validation loss: 0.13050629726944038 ROC AUC: 0.9916774054982816
64 2 0.10813995450735092
Validation loss: 0.1206472939072176 ROC AUC: 0.992858676975945
Validation loss: 0.18513980878449474 ROC AUC: 0.9918384879725085
Validation loss: 0.13130333015953788 ROC AUC: 0.9930734536082474
Validation loss: 0.12886947843878302 ROC AUC: 0.9937714776632303
Validation loss: 0.16085166415595328 ROC AUC: 0.9940399484536082
Validation loss: 0.1548651001884221 ROC AUC: 0.9931808419243986
Validation loss: 0.1217456358084407 ROC AUC: 0.9946842783505154
71 3 0.1286676973104477
Validation loss: 0.177593859636413 ROC AUC: 0.9945231958762887
Validation loss: 0.11421600354767834 ROC AUC: 0.9943621134020618
Validation loss: 0.13352993238775224 ROC AUC: 0.9935030068728522
Validation loss: 0.13235539842609298 ROC AUC: 0.9915700171821307
Validation loss: 0.12152768737584331 ROC AUC: 0.9911404639175259
Validation loss: 0.16557392091948753 ROC AUC: 0.9927512886597938
Validation loss: 0.17299240733463067 ROC AUC: 0.9943621134020618
78 4 0.15609760582447052
Validation loss: 0.162707116705766 ROC AUC: 0.9946842783505154
Validation loss: 0.14118991738141254 ROC AUC: 0.994469501718213
Validation loss: 0.15266143031649948 ROC AUC: 0.9938251718213058
Validation loss: 0.15459290146827698 ROC AUC: 0.9937177835051547
Validation loss: 0.12337385472441044 ROC AUC: 0.9940399484536082
Validation loss: 0.10416449506048094 ROC AUC: 0.9937177835051546
Validation loss: 0.11064665241364795 ROC AUC: 0.9942547250859106
85 5 0.24231673777103424
Validation loss: 0.15151631760403728 ROC AUC: 0.9942547250859106
Validation loss: 0.24930808758797424 ROC AUC: 0.9952212199312714
Validation loss: 0.14026270443468414 ROC AUC: 0.9948990549828178
Validation loss: 0.10929159328270308 ROC AUC: 0.9948990549828178
Validation loss: 0.08389886313011276 ROC AUC: 0.9953286082474226
Validation loss: 0.08286872390631123 ROC AUC: 0.9953286082474226
Validation loss: 0.08217220184986765 ROC AUC: 0.9957581615120275
92 6 0.26998424530029297
Validation loss: 0.08722460223603125 ROC AUC: 0.9959729381443299
Validation loss: 0.08638657181682982 ROC AUC: 0.9957581615120275
Validation loss: 0.08321902985440886 ROC AUC: 0.9947916666666667
Validation loss: 0.09312616874478333 ROC AUC: 0.9952212199312716
Validation loss: 0.12015393453558491 ROC AUC: 0.9961877147766323
Validation loss: 0.12104829296545129 ROC AUC: 0.9952212199312714
Validation loss: 0.15202379226683863 ROC AUC: 0.9952212199312716
Validation loss: 0.17299664787793714 ROC AUC: 0.9951138316151202
Loaded trained model with success.
Test loss: 0.3206780446427209 Test ROC AUC: 0.9721990837151187
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9751861042183623, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 380
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.660984992980957
Validation loss: 1.592648983001709 ROC AUC: 0.35
Validation loss: 1.5936133861541748 ROC AUC: 0.525
Validation loss: 1.6212959289550781 ROC AUC: 0.5875
Validation loss: 1.6404989957809448 ROC AUC: 0.6875
Validation loss: 1.6460987329483032 ROC AUC: 0.7125
Validation loss: 1.6627225875854492 ROC AUC: 0.6625
Validation loss: 1.686336636543274 ROC AUC: 0.6875
Validation loss: 1.7113761901855469 ROC AUC: 0.7375
Validation loss: 1.6950124502182007 ROC AUC: 0.775
Validation loss: 1.6175172328948975 ROC AUC: 0.7375
Validation loss: 1.5310360193252563 ROC AUC: 0.75
Validation loss: 1.467054843902588 ROC AUC: 0.8375
Validation loss: 1.4366254806518555 ROC AUC: 0.8375
Validation loss: 1.3533594608306885 ROC AUC: 0.825
Validation loss: 1.3006665706634521 ROC AUC: 0.825
Validation loss: 1.225091814994812 ROC AUC: 0.8
Validation loss: 1.14970862865448 ROC AUC: 0.8375
Validation loss: 1.0627005100250244 ROC AUC: 0.8375
Validation loss: 0.9868307113647461 ROC AUC: 0.7875
Validation loss: 0.9743780493736267 ROC AUC: 0.7875
Validation loss: 0.9734057188034058 ROC AUC: 0.7875
Validation loss: 1.0022377967834473 ROC AUC: 0.8
Validation loss: 1.021248698234558 ROC AUC: 0.8
Validation loss: 1.0528548955917358 ROC AUC: 0.8
Validation loss: 1.104907512664795 ROC AUC: 0.8
Validation loss: 1.1802557706832886 ROC AUC: 0.775
Validation loss: 1.2270572185516357 ROC AUC: 0.7625
Validation loss: 1.2678625583648682 ROC AUC: 0.7625
Validation loss: 1.2546517848968506 ROC AUC: 0.7625
Validation loss: 1.303449034690857 ROC AUC: 0.7625
Validation loss: 1.3254551887512207 ROC AUC: 0.7625
Validation loss: 1.3522719144821167 ROC AUC: 0.7625
Validation loss: 1.3776201009750366 ROC AUC: 0.7625
Validation loss: 1.3390542268753052 ROC AUC: 0.7625
Validation loss: 1.3285558223724365 ROC AUC: 0.7625
Validation loss: 1.3103301525115967 ROC AUC: 0.7625
Validation loss: 1.2784013748168945 ROC AUC: 0.7625
Validation loss: 1.2645725011825562 ROC AUC: 0.7625
Validation loss: 1.2548563480377197 ROC AUC: 0.7625
Validation loss: 1.22819185256958 ROC AUC: 0.7625
Validation loss: 1.1998250484466553 ROC AUC: 0.8
Validation loss: 1.1796420812606812 ROC AUC: 0.775
Validation loss: 1.1278400421142578 ROC AUC: 0.8125
Validation loss: 1.0255178213119507 ROC AUC: 0.8625
Validation loss: 0.9937782287597656 ROC AUC: 0.8625
Validation loss: 0.9643754959106445 ROC AUC: 0.8375
Validation loss: 0.942732572555542 ROC AUC: 0.8375
Validation loss: 0.9280650615692139 ROC AUC: 0.85
Validation loss: 0.937402069568634 ROC AUC: 0.8625
Validation loss: 0.9352219700813293 ROC AUC: 0.8625
50 0 0.9390743970870972
Validation loss: 0.9232972264289856 ROC AUC: 0.8625
Validation loss: 0.9052412509918213 ROC AUC: 0.8375
Validation loss: 0.8980066776275635 ROC AUC: 0.85
Validation loss: 0.8700875043869019 ROC AUC: 0.85
Validation loss: 0.8836298584938049 ROC AUC: 0.875
Validation loss: 0.8830428719520569 ROC AUC: 0.875
Validation loss: 0.8886480927467346 ROC AUC: 0.875
Validation loss: 0.8601122498512268 ROC AUC: 0.875
Validation loss: 0.8024991750717163 ROC AUC: 0.875
Validation loss: 0.7465806007385254 ROC AUC: 0.9125
Validation loss: 0.7255920767784119 ROC AUC: 0.9125
Validation loss: 0.6807721853256226 ROC AUC: 0.925
Validation loss: 0.6656347513198853 ROC AUC: 0.925
Validation loss: 0.6406286358833313 ROC AUC: 0.95
Validation loss: 0.6269754767417908 ROC AUC: 0.95
Validation loss: 0.611815333366394 ROC AUC: 0.95
Validation loss: 0.6039391756057739 ROC AUC: 0.95
Validation loss: 0.6126759052276611 ROC AUC: 0.925
Validation loss: 0.6021175384521484 ROC AUC: 0.925
Validation loss: 0.5892981290817261 ROC AUC: 0.95
Validation loss: 0.5730791687965393 ROC AUC: 0.95
Validation loss: 0.5659122467041016 ROC AUC: 0.95
Validation loss: 0.5809808373451233 ROC AUC: 0.95
Validation loss: 0.6049147248268127 ROC AUC: 0.9
Validation loss: 0.612980842590332 ROC AUC: 0.925
Validation loss: 0.6260152459144592 ROC AUC: 0.9125
Validation loss: 0.6477984189987183 ROC AUC: 0.8875
Validation loss: 0.6829738020896912 ROC AUC: 0.9
Validation loss: 0.7483265995979309 ROC AUC: 0.875
Validation loss: 0.9068712592124939 ROC AUC: 0.8375
Validation loss: 1.0303815603256226 ROC AUC: 0.8125
Validation loss: 1.202765941619873 ROC AUC: 0.8125
Validation loss: 1.2960028648376465 ROC AUC: 0.8125
Validation loss: 1.3717883825302124 ROC AUC: 0.8125
Validation loss: 1.4182450771331787 ROC AUC: 0.8125
Validation loss: 1.4086841344833374 ROC AUC: 0.8125
Validation loss: 1.2513495683670044 ROC AUC: 0.8125
Validation loss: 1.131136178970337 ROC AUC: 0.8125
Validation loss: 1.0510520935058594 ROC AUC: 0.8125
Validation loss: 0.9316149950027466 ROC AUC: 0.825
Validation loss: 0.8766775131225586 ROC AUC: 0.875
Validation loss: 0.8232574462890625 ROC AUC: 0.875
Validation loss: 0.7787447571754456 ROC AUC: 0.875
Validation loss: 0.7768242955207825 ROC AUC: 0.875
Validation loss: 0.767926037311554 ROC AUC: 0.875
Validation loss: 0.7678905129432678 ROC AUC: 0.9
Validation loss: 0.8243191838264465 ROC AUC: 0.9
Validation loss: 0.8664178252220154 ROC AUC: 0.9
Validation loss: 0.9010570049285889 ROC AUC: 0.875
Validation loss: 0.9482466578483582 ROC AUC: 0.875
Loaded trained model with success.
Test loss: 2.5999948827843915 Test ROC AUC: 0.5908277043418435
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9503722084367245, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 19, Valid size: 19, Test size: 370
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.726828932762146
Validation loss: 1.6183137893676758 ROC AUC: 0.4322916666666667
Validation loss: 1.634006381034851 ROC AUC: 0.415625
Validation loss: 1.708709955215454 ROC AUC: 0.4302083333333334
Validation loss: 1.7884318828582764 ROC AUC: 0.4541666666666667
Validation loss: 1.8558249473571777 ROC AUC: 0.3854166666666667
Validation loss: 1.9216625690460205 ROC AUC: 0.37916666666666665
Validation loss: 1.9204601049423218 ROC AUC: 0.4333333333333333
Validation loss: 1.9189332723617554 ROC AUC: 0.525
Validation loss: 1.909529447555542 ROC AUC: 0.5375
Validation loss: 1.8849889039993286 ROC AUC: 0.5541666666666666
Validation loss: 1.7935036420822144 ROC AUC: 0.5958333333333334
Validation loss: 1.6729296445846558 ROC AUC: 0.6208333333333333
Validation loss: 1.5267502069473267 ROC AUC: 0.5854166666666666
Validation loss: 1.4446231126785278 ROC AUC: 0.615625
Validation loss: 1.3931176662445068 ROC AUC: 0.7166666666666667
Validation loss: 1.361305594444275 ROC AUC: 0.7708333333333334
Validation loss: 1.3477842807769775 ROC AUC: 0.7729166666666666
Validation loss: 1.3710986375808716 ROC AUC: 0.7833333333333333
Validation loss: 1.4133118391036987 ROC AUC: 0.7489583333333333
Validation loss: 1.4494502544403076 ROC AUC: 0.7489583333333333
Validation loss: 1.4785828590393066 ROC AUC: 0.7489583333333333
Validation loss: 1.499800682067871 ROC AUC: 0.7395833333333334
Validation loss: 1.533372402191162 ROC AUC: 0.7395833333333334
Validation loss: 1.5513780117034912 ROC AUC: 0.7458333333333333
Validation loss: 1.5744324922561646 ROC AUC: 0.7447916666666667
Validation loss: 1.556250810623169 ROC AUC: 0.7447916666666667
Validation loss: 1.572733759880066 ROC AUC: 0.7489583333333334
Validation loss: 1.5515451431274414 ROC AUC: 0.7520833333333334
Validation loss: 1.5069957971572876 ROC AUC: 0.7520833333333334
Validation loss: 1.4891053438186646 ROC AUC: 0.7614583333333333
Validation loss: 1.4907437562942505 ROC AUC: 0.7645833333333334
Validation loss: 1.5000406503677368 ROC AUC: 0.7645833333333334
Validation loss: 1.5097841024398804 ROC AUC: 0.7645833333333334
Validation loss: 1.539737343788147 ROC AUC: 0.7645833333333334
Validation loss: 1.609742522239685 ROC AUC: 0.75625
Validation loss: 1.6575560569763184 ROC AUC: 0.7625
Validation loss: 1.6881874799728394 ROC AUC: 0.7625
Validation loss: 1.757340908050537 ROC AUC: 0.7625
Validation loss: 1.7947618961334229 ROC AUC: 0.7625
Validation loss: 1.8621864318847656 ROC AUC: 0.7625
Validation loss: 1.9461027383804321 ROC AUC: 0.759375
Validation loss: 1.9397618770599365 ROC AUC: 0.759375
Validation loss: 1.966317057609558 ROC AUC: 0.7625
Validation loss: 1.9986299276351929 ROC AUC: 0.7625
Validation loss: 1.9690190553665161 ROC AUC: 0.76875
Validation loss: 1.8974858522415161 ROC AUC: 0.76875
Validation loss: 1.87183678150177 ROC AUC: 0.76875
Validation loss: 1.880235195159912 ROC AUC: 0.7729166666666667
Validation loss: 1.769457221031189 ROC AUC: 0.7729166666666667
Validation loss: 1.6830352544784546 ROC AUC: 0.7729166666666666
50 0 1.2672449350357056
Validation loss: 1.6453073024749756 ROC AUC: 0.7802083333333334
Validation loss: 1.6798607110977173 ROC AUC: 0.7708333333333334
Validation loss: 1.7147821187973022 ROC AUC: 0.7739583333333334
Validation loss: 1.7865923643112183 ROC AUC: 0.7739583333333334
Validation loss: 1.8088704347610474 ROC AUC: 0.775
Validation loss: 1.8329951763153076 ROC AUC: 0.7791666666666666
Validation loss: 1.7881783246994019 ROC AUC: 0.7864583333333333
Validation loss: 1.7483086585998535 ROC AUC: 0.7895833333333333
Validation loss: 1.680553674697876 ROC AUC: 0.7927083333333333
Validation loss: 1.6250108480453491 ROC AUC: 0.7927083333333333
Validation loss: 1.524452805519104 ROC AUC: 0.8
Validation loss: 1.4474087953567505 ROC AUC: 0.8
Validation loss: 1.3770688772201538 ROC AUC: 0.8
Validation loss: 1.3366378545761108 ROC AUC: 0.8
Validation loss: 1.3088617324829102 ROC AUC: 0.8
Validation loss: 1.306762933731079 ROC AUC: 0.8
Validation loss: 1.282768726348877 ROC AUC: 0.8041666666666666
Validation loss: 1.2790586948394775 ROC AUC: 0.8041666666666666
Validation loss: 1.2512459754943848 ROC AUC: 0.8114583333333332
Validation loss: 1.2569689750671387 ROC AUC: 0.8104166666666666
Validation loss: 1.293986439704895 ROC AUC: 0.8104166666666666
Validation loss: 1.305938482284546 ROC AUC: 0.8104166666666666
Validation loss: 1.297702670097351 ROC AUC: 0.8104166666666666
Validation loss: 1.301340103149414 ROC AUC: 0.8145833333333332
Validation loss: 1.3058829307556152 ROC AUC: 0.8302083333333332
Validation loss: 1.2991368770599365 ROC AUC: 0.8302083333333332
Validation loss: 1.315871000289917 ROC AUC: 0.8302083333333332
Validation loss: 1.2974010705947876 ROC AUC: 0.8260416666666668
Validation loss: 1.2821455001831055 ROC AUC: 0.8260416666666668
Validation loss: 1.2368249893188477 ROC AUC: 0.8322916666666667
Validation loss: 1.2177114486694336 ROC AUC: 0.8322916666666667
Validation loss: 1.1566892862319946 ROC AUC: 0.8458333333333332
Validation loss: 1.097946047782898 ROC AUC: 0.85625
Validation loss: 1.0831223726272583 ROC AUC: 0.859375
Validation loss: 1.0794885158538818 ROC AUC: 0.8666666666666666
Validation loss: 1.0834910869598389 ROC AUC: 0.8666666666666666
Validation loss: 1.0703495740890503 ROC AUC: 0.8666666666666666
Validation loss: 1.0553359985351562 ROC AUC: 0.8666666666666666
Validation loss: 1.0573945045471191 ROC AUC: 0.8697916666666666
Validation loss: 1.077221393585205 ROC AUC: 0.8739583333333332
Validation loss: 1.0848414897918701 ROC AUC: 0.8677083333333332
Validation loss: 1.1185370683670044 ROC AUC: 0.8677083333333332
Validation loss: 1.1152607202529907 ROC AUC: 0.8677083333333332
Validation loss: 1.1093761920928955 ROC AUC: 0.8677083333333332
Validation loss: 1.0856651067733765 ROC AUC: 0.8677083333333332
Validation loss: 1.0780107975006104 ROC AUC: 0.8677083333333332
Validation loss: 1.047252893447876 ROC AUC: 0.8739583333333332
Validation loss: 1.010913372039795 ROC AUC: 0.8885416666666668
Validation loss: 0.9828966856002808 ROC AUC: 0.8885416666666668
Validation loss: 0.953728199005127 ROC AUC: 0.8916666666666668
Loaded trained model with success.
Test loss: 3.1465909171748807 Test ROC AUC: 0.6157054314470337
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8759305210918115, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 48, Valid size: 48, Test size: 341
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.589447259902954
Validation loss: 1.6167774597803752 ROC AUC: 0.48133557800224464
Validation loss: 1.6542353630065918 ROC AUC: 0.4461391694725029
Validation loss: 1.6458897590637207 ROC AUC: 0.42631874298540967
Validation loss: 1.62931227684021 ROC AUC: 0.445
Validation loss: 1.6236992279688518 ROC AUC: 0.4163804713804714
Validation loss: 1.6199219226837158 ROC AUC: 0.45099887766554436
Validation loss: 1.627743403116862 ROC AUC: 0.4481705948372615
Validation loss: 1.6326388518015544 ROC AUC: 0.44593714927048256
Validation loss: 1.646499474843343 ROC AUC: 0.44117845117845117
Validation loss: 1.6536181370417278 ROC AUC: 0.46340067340067337
Validation loss: 1.6428443590799968 ROC AUC: 0.5096296296296297
Validation loss: 1.6309394439061482 ROC AUC: 0.5376038159371492
Validation loss: 1.5910228888193767 ROC AUC: 0.5754601571268239
Validation loss: 1.5482869545618694 ROC AUC: 0.6167564534231202
Validation loss: 1.5051732063293457 ROC AUC: 0.649320987654321
Validation loss: 1.4851669470469158 ROC AUC: 0.6731257014590347
Validation loss: 1.4692621231079102 ROC AUC: 0.6892199775533109
Validation loss: 1.4569717248280842 ROC AUC: 0.6890852974186308
Validation loss: 1.4500244855880737 ROC AUC: 0.6828507295173962
Validation loss: 1.4405755599339802 ROC AUC: 0.6861111111111111
Validation loss: 1.4255999724070232 ROC AUC: 0.6939898989898989
Validation loss: 1.4192267258961995 ROC AUC: 0.693905723905724
Validation loss: 1.4150617122650146 ROC AUC: 0.6972222222222223
Validation loss: 1.4102772076924641 ROC AUC: 0.7014197530864198
Validation loss: 1.404660940170288 ROC AUC: 0.7036363636363636
25 0 1.4790560007095337
Validation loss: 1.4064665635426838 ROC AUC: 0.7067901234567902
Validation loss: 1.4082081317901611 ROC AUC: 0.7100000000000001
Validation loss: 1.3978167374928792 ROC AUC: 0.7206341189674523
Validation loss: 1.3824533224105835 ROC AUC: 0.7351010101010101
Validation loss: 1.3762044509251912 ROC AUC: 0.7335914702581369
Validation loss: 1.362871487935384 ROC AUC: 0.7401010101010101
Validation loss: 1.353101134300232 ROC AUC: 0.7480639730639731
Validation loss: 1.3352715571721394 ROC AUC: 0.754337822671156
Validation loss: 1.3178399006525676 ROC AUC: 0.7622502805836139
Validation loss: 1.300049106280009 ROC AUC: 0.7650056116722783
Validation loss: 1.285005251566569 ROC AUC: 0.7726374859708193
Validation loss: 1.284592628479004 ROC AUC: 0.7759427609427609
Validation loss: 1.289444128672282 ROC AUC: 0.7814253647586982
Validation loss: 1.2898317178090413 ROC AUC: 0.7758361391694726
Validation loss: 1.281926194826762 ROC AUC: 0.7832042648709315
Validation loss: 1.282571792602539 ROC AUC: 0.7829012345679013
Validation loss: 1.2810334364573162 ROC AUC: 0.7797586980920314
Validation loss: 1.2787059942881267 ROC AUC: 0.7722502805836139
Validation loss: 1.2684773604075115 ROC AUC: 0.7743827160493827
Validation loss: 1.2507505019505818 ROC AUC: 0.7769360269360269
Validation loss: 1.2477957407633464 ROC AUC: 0.7778451178451178
Validation loss: 1.2511876026789348 ROC AUC: 0.7919023569023569
Validation loss: 1.2302485704421997 ROC AUC: 0.8014534231200898
Validation loss: 1.2190274397532146 ROC AUC: 0.8026038159371491
Validation loss: 1.2078706820805867 ROC AUC: 0.8024915824915825
50 0 1.2990809679031372
Validation loss: 1.1851948499679565 ROC AUC: 0.8080976430976431
Validation loss: 1.1557705799738567 ROC AUC: 0.8125925925925925
Validation loss: 1.1431780656178792 ROC AUC: 0.8151459034792368
Validation loss: 1.130841334660848 ROC AUC: 0.8196240179573513
Validation loss: 1.1208968957265217 ROC AUC: 0.8236588103254769
Validation loss: 1.1124860048294067 ROC AUC: 0.8254096520763188
Validation loss: 1.1017305652300518 ROC AUC: 0.829270482603816
Validation loss: 1.0839913686116536 ROC AUC: 0.8423456790123456
Validation loss: 1.059862772623698 ROC AUC: 0.8481986531986532
Validation loss: 1.0358892679214478 ROC AUC: 0.8637934904601572
Validation loss: 1.0095036029815674 ROC AUC: 0.8695005611672277
Validation loss: 0.9757290283838908 ROC AUC: 0.8712065095398429
Validation loss: 0.9478685061136881 ROC AUC: 0.8731593714927047
Validation loss: 0.935062567392985 ROC AUC: 0.8742873176206508
Validation loss: 0.9195186098416647 ROC AUC: 0.8758810325476991
Validation loss: 0.9019858042399088 ROC AUC: 0.8822109988776654
Validation loss: 0.8730680147806803 ROC AUC: 0.8921604938271605
Validation loss: 0.8577682971954346 ROC AUC: 0.8987766554433222
Validation loss: 0.8420850038528442 ROC AUC: 0.9032323232323233
Validation loss: 0.821952740351359 ROC AUC: 0.9124523007856341
Validation loss: 0.7969924211502075 ROC AUC: 0.917979797979798
Validation loss: 0.7834330995877584 ROC AUC: 0.9185072951739619
Validation loss: 0.7944725354512533 ROC AUC: 0.918529741863075
Validation loss: 0.8026800553003947 ROC AUC: 0.9191077441077441
Validation loss: 0.8009443481763204 ROC AUC: 0.9192817059483727
75 0 0.8645416498184204
Validation loss: 0.7925832867622375 ROC AUC: 0.9168967452300786
Validation loss: 0.7800541917483012 ROC AUC: 0.9209932659932658
Validation loss: 0.761540432771047 ROC AUC: 0.9225589225589225
Validation loss: 0.7657803297042847 ROC AUC: 0.9229517396184062
Validation loss: 0.7539184093475342 ROC AUC: 0.9230134680134678
Validation loss: 0.7593341668446859 ROC AUC: 0.9219640852974187
Validation loss: 0.7331507007280985 ROC AUC: 0.9257182940516273
Validation loss: 0.7568629582722982 ROC AUC: 0.9219416386083052
Validation loss: 0.7558887004852295 ROC AUC: 0.9208922558922559
Validation loss: 0.7546228766441345 ROC AUC: 0.9119304152637486
Validation loss: 0.7735430796941122 ROC AUC: 0.9144219977553311
Validation loss: 0.7721559405326843 ROC AUC: 0.9171997755331089
Validation loss: 0.7731960813204447 ROC AUC: 0.9157407407407406
Validation loss: 0.7640864054361979 ROC AUC: 0.9155667789001123
Validation loss: 0.7522960106531779 ROC AUC: 0.9197643097643098
Validation loss: 0.6938464244206747 ROC AUC: 0.9299831649831649
Validation loss: 0.6471892992655436 ROC AUC: 0.939006734006734
Validation loss: 0.6254416306813558 ROC AUC: 0.9434511784511784
Validation loss: 0.6126043597857157 ROC AUC: 0.9441694725028057
Validation loss: 0.6248852014541626 ROC AUC: 0.9420594837261504
Validation loss: 0.6866157154242197 ROC AUC: 0.9347138047138047
Validation loss: 0.7781102458635966 ROC AUC: 0.9301964085297418
Validation loss: 0.880819300810496 ROC AUC: 0.9215937149270482
Validation loss: 0.9582298000653585 ROC AUC: 0.9155555555555555
Validation loss: 1.0055946509043376 ROC AUC: 0.9031930415263748
Loaded trained model with success.
Test loss: 1.5559506905743103 Test ROC AUC: 0.7973760994145411
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7518610421836228, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 96, Valid size: 96, Test size: 293
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.610040307044983
Validation loss: 1.6797208388646443 ROC AUC: 0.6043062200956937
Validation loss: 1.7265836397806804 ROC AUC: 0.5835998489045581
Validation loss: 1.6437313556671143 ROC AUC: 0.4906535618528448
Validation loss: 1.6529967387517293 ROC AUC: 0.4879234746026338
Validation loss: 1.6978824536005657 ROC AUC: 0.4958011761743227
Validation loss: 1.662754734357198 ROC AUC: 0.5514879938376761
Validation loss: 1.5592952966690063 ROC AUC: 0.6005751255425362
Validation loss: 1.5280653635660808 ROC AUC: 0.6124768542521516
Validation loss: 1.5166662534077961 ROC AUC: 0.6625027774897417
Validation loss: 1.5248139301935832 ROC AUC: 0.6566889359621966
Validation loss: 1.5471925338109334 ROC AUC: 0.6741637904217341
Validation loss: 1.5772103071212769 ROC AUC: 0.6029856163064571
Validation loss: 1.5800950129826863 ROC AUC: 0.5941069074318219
Validation loss: 1.5912196636199951 ROC AUC: 0.5809416060556682
Validation loss: 1.5977411270141602 ROC AUC: 0.5968251440591346
Validation loss: 1.605185588200887 ROC AUC: 0.6293188113825233
16 2 1.4287922382354736
Validation loss: 1.6113953590393066 ROC AUC: 0.6383363947442487
Validation loss: 1.5518125693003337 ROC AUC: 0.6696598130564239
Validation loss: 1.5429061651229858 ROC AUC: 0.6692661501770186
Validation loss: 1.4700947999954224 ROC AUC: 0.706957056305272
Validation loss: 1.4218109448750813 ROC AUC: 0.7319611299568933
Validation loss: 1.39482843875885 ROC AUC: 0.746431851511695
Validation loss: 1.3611987034479778 ROC AUC: 0.7642607433303213
Validation loss: 1.3226096232732136 ROC AUC: 0.7799757802894514
Validation loss: 1.28032382329305 ROC AUC: 0.7847741715673929
Validation loss: 1.2375595569610596 ROC AUC: 0.799564489608485
Validation loss: 1.226423978805542 ROC AUC: 0.8056631164175567
Validation loss: 1.2414499521255493 ROC AUC: 0.7980879760617418
Validation loss: 1.2475548187891643 ROC AUC: 0.7874005658672434
Validation loss: 1.204975962638855 ROC AUC: 0.8022071785148206
Validation loss: 1.2021471659342449 ROC AUC: 0.7939358140637267
Validation loss: 1.2580626805623372 ROC AUC: 0.7829099204526937
Validation loss: 1.3850408792495728 ROC AUC: 0.7517846297421008
33 1 1.3718373775482178
Validation loss: 1.3900905847549438 ROC AUC: 0.7555983083235812
Validation loss: 1.3380676905314128 ROC AUC: 0.7723821233353577
Validation loss: 1.241454283396403 ROC AUC: 0.796498881597464
Validation loss: 1.1857231458028157 ROC AUC: 0.8117417453004874
Validation loss: 1.1766329606374104 ROC AUC: 0.8218014428133378
Validation loss: 1.120572845141093 ROC AUC: 0.8458545039773654
Validation loss: 1.0907658537228901 ROC AUC: 0.8426744633889818
Validation loss: 1.0842205286026 ROC AUC: 0.8372316944909416
Validation loss: 0.999392588933309 ROC AUC: 0.8626223947146222
Validation loss: 0.9633832573890686 ROC AUC: 0.8729061430666449
Validation loss: 0.9746365149815878 ROC AUC: 0.8673489415912423
Validation loss: 1.0629987120628357 ROC AUC: 0.841440146947724
Validation loss: 1.158721923828125 ROC AUC: 0.8244989408505784
Validation loss: 1.1873346169789631 ROC AUC: 0.8250085176352082
Validation loss: 1.1635806560516357 ROC AUC: 0.8412768305509057
Validation loss: 1.0915533304214478 ROC AUC: 0.8537296132252952
Validation loss: 1.0677287181218464 ROC AUC: 0.8565622824299701
50 0 0.8662334680557251
Validation loss: 0.9642450213432312 ROC AUC: 0.8786499918526969
Validation loss: 0.9739293853441874 ROC AUC: 0.8794436132549217
Validation loss: 0.9378246665000916 ROC AUC: 0.8851415408772423
Validation loss: 0.9873738686243693 ROC AUC: 0.8803609255336482
Validation loss: 0.9920052488644918 ROC AUC: 0.8816489401099146
Validation loss: 0.9027003447214762 ROC AUC: 0.8956167508554668
Validation loss: 0.8708514968554179 ROC AUC: 0.9062430562756454
Validation loss: 0.8639986515045166 ROC AUC: 0.9115228791088331
Validation loss: 0.9119951725006104 ROC AUC: 0.912397603211519
Validation loss: 0.890937864780426 ROC AUC: 0.9117965544313924
Validation loss: 0.7943802277247111 ROC AUC: 0.9227994874605596
Validation loss: 0.6855422854423523 ROC AUC: 0.9403498896410742
Validation loss: 0.7015382846196493 ROC AUC: 0.9469103204112166
Validation loss: 0.7271595199902853 ROC AUC: 0.9473450901388005
Validation loss: 0.7406677802403768 ROC AUC: 0.9413738575258861
Validation loss: 0.7271582881609598 ROC AUC: 0.9366180544239857
66 2 0.8149169087409973
Validation loss: 0.7870004375775655 ROC AUC: 0.9255240197312871
Validation loss: 0.8381623228391012 ROC AUC: 0.918681766335343
Validation loss: 0.917441189289093 ROC AUC: 0.9164020027552697
Validation loss: 0.8704935709635416 ROC AUC: 0.9251259128682952
Validation loss: 0.7516919374465942 ROC AUC: 0.9299935562237989
Validation loss: 0.6771562496821085 ROC AUC: 0.9349482275912127
Validation loss: 0.7299620509147644 ROC AUC: 0.9364565896869955
Validation loss: 0.737526019414266 ROC AUC: 0.9382341831217502
Validation loss: 0.7140023907025655 ROC AUC: 0.9399891863066052
Validation loss: 0.6262668371200562 ROC AUC: 0.9460344853126342
Validation loss: 0.5683701435724894 ROC AUC: 0.9510113765979824
Validation loss: 0.5674272378285726 ROC AUC: 0.9518231442665204
Validation loss: 0.5861670474211375 ROC AUC: 0.953604441020931
Validation loss: 0.5661786397298177 ROC AUC: 0.9567770749700031
Validation loss: 0.5431094964345297 ROC AUC: 0.9573755314263707
Validation loss: 0.5502846638361613 ROC AUC: 0.9560486319937193
Validation loss: 0.6085346341133118 ROC AUC: 0.9504569896455184
83 1 0.7121424078941345
Validation loss: 0.5846587916215261 ROC AUC: 0.9560064141496438
Validation loss: 0.5767497519652048 ROC AUC: 0.9516727894884974
Validation loss: 0.57128044962883 ROC AUC: 0.9518623994548714
Validation loss: 0.6160124142964681 ROC AUC: 0.9464903639622559
Validation loss: 0.5723122557004293 ROC AUC: 0.9497381753003392
Validation loss: 0.5798470477263132 ROC AUC: 0.9497207696979573
Validation loss: 0.625028391679128 ROC AUC: 0.946453701097664
Validation loss: 0.652595063050588 ROC AUC: 0.9448194261335863
Validation loss: 0.6222162842750549 ROC AUC: 0.9460722591731228
Validation loss: 0.6154171625773112 ROC AUC: 0.9472943546595168
Validation loss: 0.5989296237627665 ROC AUC: 0.9480002073859006
Validation loss: 0.6107016404469808 ROC AUC: 0.9493641400151096
Validation loss: 0.5468003948529562 ROC AUC: 0.9578032648466085
Validation loss: 0.5530228416124979 ROC AUC: 0.9589616632349237
Validation loss: 0.5987680355707804 ROC AUC: 0.9544299109721954
Validation loss: 0.5797509749730428 ROC AUC: 0.9527582324795949
Validation loss: 0.5386990209420522 ROC AUC: 0.9559586413260848
Loaded trained model with success.
Test loss: 1.2315896810525107 Test ROC AUC: 0.8714302971955444
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5037220843672456, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 193, Valid size: 193, Test size: 196
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.6418585777282715
Validation loss: 1.6455655987398612 ROC AUC: 0.5203180734530989
Validation loss: 1.646909164023523 ROC AUC: 0.5451246407611157
Validation loss: 1.6447598724167583 ROC AUC: 0.5734510317786746
Validation loss: 1.6489646922739059 ROC AUC: 0.562479814898323
Validation loss: 1.668990135192871 ROC AUC: 0.5588066561517249
Validation loss: 1.6714951646142673 ROC AUC: 0.5690586820360382
Validation loss: 1.6256444429486527 ROC AUC: 0.5424463132692856
7 1 1.5893484354019165
Validation loss: 1.6144410995621756 ROC AUC: 0.5589122049545292
Validation loss: 1.6346022205649262 ROC AUC: 0.5751945913177634
Validation loss: 1.5808502225678203 ROC AUC: 0.626920956708691
Validation loss: 1.5855754150627808 ROC AUC: 0.6938560540792713
Validation loss: 1.5046681400407782 ROC AUC: 0.7091686954416453
Validation loss: 1.3633916699206892 ROC AUC: 0.742459787308399
Validation loss: 1.23367839526636 ROC AUC: 0.7918333288498527
14 2 1.280966877937317
Validation loss: 1.2179082150286344 ROC AUC: 0.7943363428107034
Validation loss: 1.1389298213578258 ROC AUC: 0.8319111313968944
Validation loss: 1.1003923919534435 ROC AUC: 0.8299049425418362
Validation loss: 1.1727430252213553 ROC AUC: 0.8137239866684883
Validation loss: 1.1268738431016398 ROC AUC: 0.8231604414718181
Validation loss: 1.1304193852478976 ROC AUC: 0.8421202828179574
Validation loss: 1.1142494851443434 ROC AUC: 0.8479587963411968
21 3 1.1458237171173096
Validation loss: 1.0615205789477096 ROC AUC: 0.8505848558879544
Validation loss: 1.0660399068822515 ROC AUC: 0.8584198061059813
Validation loss: 1.062949102159609 ROC AUC: 0.8580607253233357
Validation loss: 1.0339415283400777 ROC AUC: 0.8741716274019954
Validation loss: 1.0102502206446593 ROC AUC: 0.8737858610607112
Validation loss: 0.9776597328754286 ROC AUC: 0.88045746132585
Validation loss: 0.995394131989059 ROC AUC: 0.8698032890577823
28 4 1.0207321643829346
Validation loss: 0.9804242077269085 ROC AUC: 0.8910634975301921
Validation loss: 0.9790428588118578 ROC AUC: 0.891017912330964
Validation loss: 0.9713770390483382 ROC AUC: 0.8987303213546529
Validation loss: 0.9338471240947901 ROC AUC: 0.8968287409513331
Validation loss: 0.9650440385922249 ROC AUC: 0.8915287689612883
Validation loss: 0.9681231600324107 ROC AUC: 0.8974499372194726
Validation loss: 0.87198323953337 ROC AUC: 0.9111613831207338
35 5 1.2407513856887817
Validation loss: 0.8527419071432223 ROC AUC: 0.9104316913411482
Validation loss: 0.8677943089465403 ROC AUC: 0.9117505614379608
Validation loss: 0.8289303127965779 ROC AUC: 0.9110071059628169
Validation loss: 0.8248510058062064 ROC AUC: 0.9194292989322944
Validation loss: 0.8459155349533792 ROC AUC: 0.9201917472572306
Validation loss: 0.7991932117877228 ROC AUC: 0.9197671114987356
Validation loss: 0.8202790336905366 ROC AUC: 0.9192651781746995
42 6 1.3337655067443848
Validation loss: 0.7912758508494481 ROC AUC: 0.9253932466747322
Validation loss: 0.7434883849608466 ROC AUC: 0.9276357509440676
Validation loss: 0.7349855300676019 ROC AUC: 0.9310156039283785
Validation loss: 0.7487592649274539 ROC AUC: 0.9351203218714332
Validation loss: 0.6849308037078442 ROC AUC: 0.9414046827359333
Validation loss: 0.6952117200496901 ROC AUC: 0.9399274513843219
Validation loss: 0.6667370905067019 ROC AUC: 0.9440866731134399
Validation loss: 0.7421758063716591 ROC AUC: 0.9394628389068899
50 0 0.7849379181861877
Validation loss: 0.64372430255376 ROC AUC: 0.9487131696815714
Validation loss: 0.6760836522061127 ROC AUC: 0.9443511843114045
Validation loss: 0.6514987297394733 ROC AUC: 0.9439278346039283
Validation loss: 0.6485573262593907 ROC AUC: 0.945244861754235
Validation loss: 0.6461915133395497 ROC AUC: 0.9483458363449344
Validation loss: 0.6209763053785334 ROC AUC: 0.9516503768837403
Validation loss: 0.6716067852751578 ROC AUC: 0.9445468050599146
57 1 0.8550578951835632
Validation loss: 0.6380316920848708 ROC AUC: 0.9509499297863337
Validation loss: 0.7016157950298774 ROC AUC: 0.9444764757671413
Validation loss: 0.5886418807074196 ROC AUC: 0.9556536195021025
Validation loss: 0.6287071562801618 ROC AUC: 0.9521610529949769
Validation loss: 0.5891782718860192 ROC AUC: 0.9531489714305537
Validation loss: 0.6225038840980728 ROC AUC: 0.9523524433435533
Validation loss: 0.6101657056100087 ROC AUC: 0.9523574312157381
64 2 0.46511125564575195
Validation loss: 0.6219918746404697 ROC AUC: 0.9495283284003249
Validation loss: 0.6436670116809984 ROC AUC: 0.9490654007677135
Validation loss: 0.6163752279751041 ROC AUC: 0.9572355749320576
Validation loss: 0.596097738091192 ROC AUC: 0.9544534731518561
Validation loss: 0.5898424522864386 ROC AUC: 0.9557058260942819
Validation loss: 0.5796255600720721 ROC AUC: 0.9554948034099938
Validation loss: 0.5352087184555172 ROC AUC: 0.9622912361640378
71 3 0.9507361054420471
Validation loss: 0.5704086105594981 ROC AUC: 0.9566979342245077
Validation loss: 0.5202009690240257 ROC AUC: 0.9646925287986938
Validation loss: 0.5333396153128827 ROC AUC: 0.9658138980347962
Validation loss: 0.5384962052261274 ROC AUC: 0.9645964059239521
Validation loss: 0.5626367006277173 ROC AUC: 0.9594700950663071
Validation loss: 0.5671817080498976 ROC AUC: 0.9582341994473993
Validation loss: 0.5512084275329668 ROC AUC: 0.9631395844379803
78 4 0.5050227046012878
Validation loss: 0.6138792827464833 ROC AUC: 0.9555800585636958
Validation loss: 0.5411525020095969 ROC AUC: 0.9615583870702082
Validation loss: 0.5248829398999096 ROC AUC: 0.9636205722384297
Validation loss: 0.5604822087666222 ROC AUC: 0.9640605220328856
Validation loss: 0.5501402459382393 ROC AUC: 0.9655662317454496
Validation loss: 0.47602819404299396 ROC AUC: 0.969299404829747
Validation loss: 0.45560586545133835 ROC AUC: 0.9717471286256314
85 5 0.8911278247833252
Validation loss: 0.5288092023041582 ROC AUC: 0.9656322858034834
Validation loss: 0.49154199896232675 ROC AUC: 0.9662000796879686
Validation loss: 0.46849624758557334 ROC AUC: 0.9689321068890097
Validation loss: 0.47765504520560176 ROC AUC: 0.9690138112440503
Validation loss: 0.4737973568932071 ROC AUC: 0.9683838167351343
Validation loss: 0.460097261270209 ROC AUC: 0.9700819002123516
Validation loss: 0.42139420866811833 ROC AUC: 0.9746076311435778
92 6 0.7492002248764038
Validation loss: 0.4056330320130976 ROC AUC: 0.974737735851728
Validation loss: 0.4072603012768098 ROC AUC: 0.9750124876733779
Validation loss: 0.40225531114506596 ROC AUC: 0.9774596356959624
Validation loss: 0.3813259632500381 ROC AUC: 0.9792561032559742
Validation loss: 0.43999747852818955 ROC AUC: 0.9744689682968366
Validation loss: 0.4245304904800931 ROC AUC: 0.977347506205491
Validation loss: 0.44216863201072176 ROC AUC: 0.9763668651668717
Validation loss: 0.4012349333633413 ROC AUC: 0.9774134694140493
Loaded trained model with success.
Test loss: 1.199874498406235 Test ROC AUC: 0.87179190467652
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.46062567421790723, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 5}}
Running on: cpu
926
926
55
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 13.934340476989746
Validation loss: 4.548482727026064 MAE: 1.6530274
1 21 3.7182765007019043
Validation loss: 3.8770918557762326 MAE: 1.5907339
Validation loss: 2.9410646677532153 MAE: 1.3255185
3 13 2.297610282897949
Validation loss: 1.8675561219003236 MAE: 1.0779791
Validation loss: 1.5711517976375686 MAE: 0.9559638
5 5 2.307255744934082
Validation loss: 1.4190817867962897 MAE: 0.87682307
6 26 2.013336420059204
Validation loss: 1.388757159848965 MAE: 0.84907055
Validation loss: 1.9156973516451874 MAE: 1.0330522
8 18 1.3022316694259644
Validation loss: 1.0221643375783966 MAE: 0.74229294
Validation loss: 1.260351996313676 MAE: 0.7952926
10 10 1.628936529159546
Validation loss: 1.0330129359762303 MAE: 0.7611216
Validation loss: 1.7371881456148548 MAE: 0.964878
12 2 1.6106104850769043
Validation loss: 0.9518786446064647 MAE: 0.72582084
13 23 1.199631690979004
Validation loss: 0.9667302908186779 MAE: 0.7174216
Validation loss: 0.8330149201286019 MAE: 0.66577226
15 15 0.591275691986084
Validation loss: 1.0237512724960856 MAE: 0.7764666
Validation loss: 0.8274838462246674 MAE: 0.6644199
17 7 1.472601056098938
Validation loss: 0.917014041420708 MAE: 0.69105613
18 28 0.8539572954177856
Validation loss: 0.834314667251661 MAE: 0.665671
Validation loss: 0.9090835873045623 MAE: 0.6991221
20 20 1.2165693044662476
Validation loss: 0.8243351783402281 MAE: 0.673103
Validation loss: 0.7933320726225752 MAE: 0.661865
22 12 0.8788056373596191
Validation loss: 0.8928834931124364 MAE: 0.72258973
Validation loss: 0.9922825128934296 MAE: 0.73600566
24 4 1.0703808069229126
Validation loss: 0.85558696712325 MAE: 0.6975826
25 25 0.9357830882072449
Validation loss: 0.7864288670970349 MAE: 0.65059346
Validation loss: 0.6324451754984022 MAE: 0.5773537
27 17 1.3964359760284424
Validation loss: 0.7763866997177091 MAE: 0.63571876
Validation loss: 0.8886265803619285 MAE: 0.7084543
29 9 0.7862097024917603
Validation loss: 0.682752586852912 MAE: 0.5984691
Validation loss: 0.7012896745045293 MAE: 0.60963744
31 1 0.8848068714141846
Validation loss: 0.6544684266941079 MAE: 0.5914408
32 22 0.6987805366516113
Validation loss: 0.6157715287115867 MAE: 0.5803908
Validation loss: 0.644726161307959 MAE: 0.583437
34 14 0.6795921325683594
Validation loss: 0.5757702872897328 MAE: 0.5435774
Validation loss: 0.7120835200499253 MAE: 0.6054497
36 6 0.8585778474807739
Validation loss: 0.5981841419479502 MAE: 0.5717507
37 27 0.6185277104377747
Validation loss: 0.5925498840360868 MAE: 0.55181026
Validation loss: 0.624824731061577 MAE: 0.58371836
39 19 0.677341639995575
Validation loss: 0.9175321752000318 MAE: 0.70827425
Validation loss: 0.6588101564357399 MAE: 0.60344374
41 11 0.8548880815505981
Validation loss: 0.545179547295457 MAE: 0.5340192
Validation loss: 0.6404006273906123 MAE: 0.5702081
43 3 0.7375691533088684
Validation loss: 0.6248136971218282 MAE: 0.5715146
44 24 0.9560633301734924
Validation loss: 0.5620121140974387 MAE: 0.5454044
Validation loss: 0.5149720737280135 MAE: 0.52726257
46 16 0.902959942817688
Validation loss: 0.6612951559845366 MAE: 0.5878682
Validation loss: 0.4804103533147993 MAE: 0.49381217
48 8 0.47052693367004395
Validation loss: 0.5836070046697786 MAE: 0.53905964
Validation loss: 0.6172486963333887 MAE: 0.56242645
50 0 0.6529852151870728
Validation loss: 0.5424462141022569 MAE: 0.53364885
51 21 1.1003957986831665
Validation loss: 0.5726922866335183 MAE: 0.53751284
Validation loss: 0.6924877302564246 MAE: 0.621978
53 13 0.8967977166175842
Validation loss: 0.5466988535988151 MAE: 0.5183079
Validation loss: 0.5171480931293372 MAE: 0.51574415
55 5 0.555722713470459
Validation loss: 0.5814185587942728 MAE: 0.55977607
56 26 0.795985221862793
Validation loss: 0.4800982023418336 MAE: 0.49147445
Validation loss: 0.4997139419258027 MAE: 0.5102242
58 18 1.0775880813598633
Validation loss: 0.45916591130889 MAE: 0.4948354
Validation loss: 0.5750829672710427 MAE: 0.5640965
60 10 0.9747588038444519
Validation loss: 0.409510255503603 MAE: 0.4607514
Validation loss: 0.5556203316148878 MAE: 0.5598471
62 2 1.8879241943359375
Validation loss: 0.5098659830654672 MAE: 0.5208341
63 23 0.8620060086250305
Validation loss: 0.5267621185429411 MAE: 0.52101296
Validation loss: 0.4384152918860928 MAE: 0.47410712
65 15 0.6731053590774536
Validation loss: 0.46376941850324427 MAE: 0.4793557
Validation loss: 0.4443500837548505 MAE: 0.47441778
67 7 0.3767446279525757
Validation loss: 0.5496576813976914 MAE: 0.53866386
68 28 1.2920479774475098
Validation loss: 0.42910344361229025 MAE: 0.46167466
Validation loss: 0.42943016177377225 MAE: 0.47006938
70 20 0.48867595195770264
Validation loss: 0.489426681985093 MAE: 0.50176054
Validation loss: 0.45069718792165586 MAE: 0.48169369
72 12 0.3365684449672699
Validation loss: 0.44470529538251413 MAE: 0.48618582
Validation loss: 0.5704216500724109 MAE: 0.57086736
74 4 0.411155641078949
Validation loss: 0.42824287509815223 MAE: 0.4631327
75 25 1.2761473655700684
Validation loss: 0.46524916637536 MAE: 0.4939526
Validation loss: 0.5287360514858114 MAE: 0.5445308
77 17 1.613385796546936
Validation loss: 0.3849198708137735 MAE: 0.43963578
Validation loss: 0.4553173730234348 MAE: 0.48277602
79 9 1.1361782550811768
Validation loss: 0.38486743262983036 MAE: 0.4345016
Validation loss: 0.4443145461267838 MAE: 0.500345
81 1 0.9282807111740112
Validation loss: 0.46021641987188844 MAE: 0.4869911
82 22 0.8772053122520447
Validation loss: 0.3691776498476321 MAE: 0.43636364
Validation loss: 0.4100704742816818 MAE: 0.46524635
84 14 0.4098590612411499
Validation loss: 0.3674347114228275 MAE: 0.43200025
Validation loss: 0.4098628145314705 MAE: 0.45737323
86 6 0.5760157108306885
Validation loss: 0.4485026869609083 MAE: 0.47673717
87 27 1.1957969665527344
Validation loss: 0.4525563707876926 MAE: 0.49504873
Validation loss: 0.36833680055826323 MAE: 0.41786355
89 19 0.597723662853241
Validation loss: 0.3836845698289686 MAE: 0.4381411
Validation loss: 0.3281429086854082 MAE: 0.4060062
91 11 1.2155948877334595
Validation loss: 0.4277273130082157 MAE: 0.48012018
Validation loss: 0.45641957876749223 MAE: 0.4996605
93 3 0.4719758629798889
Validation loss: 0.3442699402956932 MAE: 0.42077252
94 24 0.34270310401916504
Validation loss: 0.3513412844413815 MAE: 0.42449087
Validation loss: 0.3510485427458137 MAE: 0.40972176
96 16 0.6685933470726013
Validation loss: 0.42594340417863996 MAE: 0.48473522
Validation loss: 0.38695718608716134 MAE: 0.4516852
98 8 0.6015414595603943
Validation loss: 0.3262907481605497 MAE: 0.4002456
Validation loss: 0.4002580029918102 MAE: 0.44862187
Loaded trained model with success.
Test loss: 1.3897580688649958 Test MAE: 0.9204156
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7842502696871629, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 5}}
Running on: cpu
926
926
55
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 11.928239822387695
Validation loss: 4.817295784054256 MAE: 1.7306883
1 21 3.5957577228546143
Validation loss: 3.818577599062003 MAE: 1.5799526
Validation loss: 3.3093672452683585 MAE: 1.4886072
3 13 4.0906243324279785
Validation loss: 2.2705480372674005 MAE: 1.1832695
Validation loss: 1.814457120957179 MAE: 1.0707709
5 5 2.41257905960083
Validation loss: 1.9429255252780462 MAE: 1.011242
6 26 1.7432600259780884
Validation loss: 1.3693822593977334 MAE: 0.89760745
Validation loss: 1.2997700503783916 MAE: 0.88373506
8 18 0.8436373472213745
Validation loss: 1.3141958803646507 MAE: 0.86942685
Validation loss: 1.396117279390537 MAE: 0.8321037
10 10 1.1337436437606812
Validation loss: 0.9900852803535132 MAE: 0.7420355
Validation loss: 1.0113718543145362 MAE: 0.7547065
12 2 1.8337678909301758
Validation loss: 1.325037396494822 MAE: 0.8228375
13 23 1.9491405487060547
Validation loss: 0.8707116620844435 MAE: 0.70350665
Validation loss: 1.048178487668542 MAE: 0.72276753
15 15 1.3894118070602417
Validation loss: 0.906449332350531 MAE: 0.7016456
Validation loss: 0.9084464235645648 MAE: 0.68807304
17 7 0.9478481411933899
Validation loss: 0.8011227677501819 MAE: 0.6470597
18 28 1.4106003046035767
Validation loss: 0.9237105406128819 MAE: 0.71984166
Validation loss: 1.2856598716575178 MAE: 0.8121219
20 20 1.0314934253692627
Validation loss: 0.9273309811917546 MAE: 0.6777678
Validation loss: 0.995194358650603 MAE: 0.7448756
22 12 1.4236984252929688
Validation loss: 0.9093686996216908 MAE: 0.69683266
Validation loss: 0.6924453409907627 MAE: 0.6062853
24 4 1.2176449298858643
Validation loss: 0.7573865643072849 MAE: 0.6237308
25 25 0.994581401348114
Validation loss: 0.750513003081019 MAE: 0.62512517
Validation loss: 0.7872868565194807 MAE: 0.63329446
27 17 0.7611395120620728
Validation loss: 0.8694556909040035 MAE: 0.6886535
Validation loss: 0.749566172613696 MAE: 0.63297004
29 9 1.2006309032440186
Validation loss: 0.8318355228936956 MAE: 0.6630087
Validation loss: 0.7232316389969564 MAE: 0.6352588
31 1 0.5534524321556091
Validation loss: 0.7837694288587467 MAE: 0.63288534
32 22 0.9932677745819092
Validation loss: 0.647272142684228 MAE: 0.5844861
Validation loss: 0.6382729234113549 MAE: 0.5875536
34 14 1.503026008605957
Validation loss: 0.5832769738160251 MAE: 0.554506
Validation loss: 0.6819419634264953 MAE: 0.5917682
36 6 1.0158123970031738
Validation loss: 0.6636115479932748 MAE: 0.5916557
37 27 1.2791086435317993
Validation loss: 0.7226797182668105 MAE: 0.6297067
Validation loss: 0.5671866932646502 MAE: 0.54582816
39 19 0.9009484052658081
Validation loss: 0.5586855627161895 MAE: 0.5331036
Validation loss: 0.5615674619025854 MAE: 0.53476703
41 11 0.959414541721344
Validation loss: 0.7744879364709875 MAE: 0.6663263
Validation loss: 0.665615359598823 MAE: 0.6002615
43 3 0.8901099562644958
Validation loss: 0.57666110528983 MAE: 0.55004275
44 24 1.120048999786377
Validation loss: 0.6522613404636507 MAE: 0.5906274
Validation loss: 0.8834299034485291 MAE: 0.7133764
46 16 1.0600395202636719
Validation loss: 0.5799534490118788 MAE: 0.56906164
Validation loss: 0.6920206226875149 MAE: 0.5795069
48 8 0.40756016969680786
Validation loss: 0.7583795444754236 MAE: 0.59267044
Validation loss: 0.5153794615624018 MAE: 0.5021926
50 0 0.7019954323768616
Validation loss: 0.6211611320854006 MAE: 0.55642736
51 21 0.5619910359382629
Validation loss: 0.5104365518747087 MAE: 0.528115
Validation loss: 0.6574959517426419 MAE: 0.60960877
53 13 0.6566455364227295
Validation loss: 0.5401473335648201 MAE: 0.55197376
Validation loss: 0.5695339468333943 MAE: 0.543819
55 5 1.779019832611084
Validation loss: 0.5232472342819169 MAE: 0.5188905
56 26 0.9723302721977234
Validation loss: 0.5339525896838623 MAE: 0.533768
Validation loss: 0.5299380033500252 MAE: 0.54865724
58 18 0.8696070313453674
Validation loss: 0.5326126083956939 MAE: 0.53223175
Validation loss: 0.5225668561123875 MAE: 0.5429331
60 10 0.8010256290435791
Validation loss: 0.4227833958990373 MAE: 0.44617683
Validation loss: 0.48428707548918015 MAE: 0.48011044
62 2 0.6061097383499146
Validation loss: 0.4224487364807088 MAE: 0.46847856
63 23 2.186579704284668
Validation loss: 0.5017783594182964 MAE: 0.5259037
Validation loss: 0.459276961327629 MAE: 0.48695898
65 15 0.561380922794342
Validation loss: 0.45353969294360597 MAE: 0.48858774
Validation loss: 0.4568879556707378 MAE: 0.49735987
67 7 0.25864923000335693
Validation loss: 0.43255726017910767 MAE: 0.45356926
68 28 0.9538533091545105
Validation loss: 0.40715643589748934 MAE: 0.44993788
Validation loss: 0.4234382765081995 MAE: 0.47244877
70 20 0.9664186239242554
Validation loss: 0.4503317250675053 MAE: 0.48425257
Validation loss: 0.4790209596151925 MAE: 0.5087506
72 12 1.1283831596374512
Validation loss: 0.557220814037529 MAE: 0.52442604
Validation loss: 0.4151854597466553 MAE: 0.46142966
74 4 0.6803371906280518
Validation loss: 0.3903756560053733 MAE: 0.44356993
75 25 0.8871061205863953
Validation loss: 0.46145174879234757 MAE: 0.48192054
Validation loss: 0.40041408312887145 MAE: 0.46123728
77 17 0.4823123812675476
Validation loss: 0.5395069628245888 MAE: 0.5320348
Validation loss: 0.4345010159855012 MAE: 0.46220282
79 9 0.6687873601913452
Validation loss: 0.40903788341559294 MAE: 0.46544906
Validation loss: 0.4376817323734127 MAE: 0.4857324
81 1 1.0137746334075928
Validation loss: 0.4767247422982498 MAE: 0.5000785
82 22 0.7048665285110474
Validation loss: 0.40632353340060356 MAE: 0.45789146
Validation loss: 0.4404256432669209 MAE: 0.48593974
84 14 0.9576497077941895
Validation loss: 0.4168591669259782 MAE: 0.45649552
Validation loss: 0.48810041555833095 MAE: 0.5213376
86 6 0.8185495138168335
Validation loss: 0.36892761286855 MAE: 0.42966044
87 27 0.7891502976417542
Validation loss: 0.3817585890802915 MAE: 0.44397843
Validation loss: 0.5106049606146101 MAE: 0.5167146
89 19 0.9137192368507385
Validation loss: 0.3980598485753037 MAE: 0.45069295
Validation loss: 0.33293247985659613 MAE: 0.42286217
91 11 1.211952567100525
Validation loss: 0.34859257260615056 MAE: 0.4261851
Validation loss: 0.4064779922398326 MAE: 0.47170871
93 3 0.35200586915016174
Validation loss: 0.403427128142981 MAE: 0.4586562
94 24 0.5101854801177979
Validation loss: 0.378835880730631 MAE: 0.43334642
Validation loss: 0.3885577536041227 MAE: 0.453463
96 16 1.1670446395874023
Validation loss: 0.48697598043579776 MAE: 0.5162914
Validation loss: 0.38921296052618626 MAE: 0.44035184
98 8 0.3797298073768616
Validation loss: 0.3812801958289054 MAE: 0.45061293
Validation loss: 0.42439048598896606 MAE: 0.45779857
Loaded trained model with success.
Test loss: 1.4945688897913152 Test MAE: 0.9458918
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8921251348435815, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 5}}
Running on: cpu
926
926
55
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 13.700334548950195
Validation loss: 5.433245643426224 MAE: 1.8648356
1 21 2.5661652088165283
Validation loss: 3.5148321696543023 MAE: 1.4820509
Validation loss: 2.921476191629859 MAE: 1.3320642
3 13 4.366018772125244
Validation loss: 2.517698561398566 MAE: 1.292192
Validation loss: 2.221457413926753 MAE: 1.1868446
5 5 2.217074394226074
Validation loss: 1.5396177034913592 MAE: 0.92427635
6 26 1.105965495109558
Validation loss: 1.563936910155525 MAE: 0.8924033
Validation loss: 1.5209578355496698 MAE: 0.85940695
8 18 1.8577014207839966
Validation loss: 1.250354456335113 MAE: 0.8458009
Validation loss: 1.1042160699485961 MAE: 0.8027979
10 10 1.8372259140014648
Validation loss: 1.1982319738643474 MAE: 0.7688505
Validation loss: 1.0942049943087684 MAE: 0.72996235
12 2 1.3778427839279175
Validation loss: 0.9041913124706523 MAE: 0.7218977
13 23 1.3107306957244873
Validation loss: 0.9226169301675669 MAE: 0.705292
Validation loss: 0.8546894707638553 MAE: 0.66900885
15 15 1.3220274448394775
Validation loss: 1.0601670252839124 MAE: 0.75427973
Validation loss: 0.8616736246751657 MAE: 0.6569338
17 7 1.5538463592529297
Validation loss: 0.7613916267071635 MAE: 0.63137114
18 28 1.6729332208633423
Validation loss: 0.9198368561190612 MAE: 0.6746632
Validation loss: 1.146198125173927 MAE: 0.76476777
20 20 1.4333794116973877
Validation loss: 0.8243261459836692 MAE: 0.6375022
Validation loss: 0.7193280361898517 MAE: 0.63383114
22 12 1.3828414678573608
Validation loss: 0.8914306080109615 MAE: 0.6643007
Validation loss: 0.7069761368162432 MAE: 0.60644186
24 4 1.2942897081375122
Validation loss: 0.8829709573389387 MAE: 0.67212075
25 25 0.9379306435585022
Validation loss: 0.698872742076157 MAE: 0.60516065
Validation loss: 0.721833913681574 MAE: 0.62807953
27 17 0.9533326029777527
Validation loss: 0.6139696792701408 MAE: 0.5631295
Validation loss: 0.6997695263982077 MAE: 0.5930508
29 9 1.06413733959198
Validation loss: 1.1930257205571777 MAE: 0.76359636
Validation loss: 1.0724216214266502 MAE: 0.7017519
31 1 0.9808210134506226
Validation loss: 0.9976094636752333 MAE: 0.7200986
32 22 0.7430300116539001
Validation loss: 0.636125638726978 MAE: 0.5683297
Validation loss: 0.6321554270212902 MAE: 0.5712923
34 14 1.4091042280197144
Validation loss: 0.7928426673808829 MAE: 0.61193174
Validation loss: 0.6525158380071752 MAE: 0.57416946
36 6 0.9342483282089233
Validation loss: 0.7174886653026803 MAE: 0.6022276
37 27 1.2599549293518066
Validation loss: 0.7574180385206482 MAE: 0.6109424
Validation loss: 0.6044078572265015 MAE: 0.5599332
39 19 1.0940556526184082
Validation loss: 0.7077208796021233 MAE: 0.60524714
Validation loss: 0.5267611501927509 MAE: 0.5347294
41 11 0.5882697701454163
Validation loss: 0.6094376474425808 MAE: 0.57809794
Validation loss: 1.1183270374333112 MAE: 0.7879628
43 3 0.7285389304161072
Validation loss: 0.6280707651286609 MAE: 0.57670337
44 24 0.7140023708343506
Validation loss: 0.858325780339169 MAE: 0.65467846
Validation loss: 0.5664214206050848 MAE: 0.5578218
46 16 0.8082462549209595
Validation loss: 0.5459190862611355 MAE: 0.5271785
Validation loss: 0.8652682306957039 MAE: 0.6537315
48 8 0.7563489079475403
Validation loss: 0.6508756152496997 MAE: 0.602024
Validation loss: 0.660425684621988 MAE: 0.5655163
50 0 1.3078954219818115
Validation loss: 0.863245895820354 MAE: 0.6510397
51 21 0.7171348333358765
Validation loss: 0.6839898195174033 MAE: 0.5681227
Validation loss: 0.6757647218122338 MAE: 0.6126116
53 13 0.7228143811225891
Validation loss: 0.692733992768158 MAE: 0.59883755
Validation loss: 0.5509361294510555 MAE: 0.5467851
55 5 1.1938116550445557
Validation loss: 0.668574821228085 MAE: 0.5860439
56 26 1.4026949405670166
Validation loss: 0.8881649011927083 MAE: 0.66723925
Validation loss: 0.6627701251862116 MAE: 0.5710852
58 18 0.5883164405822754
Validation loss: 0.5116146554442256 MAE: 0.50980055
Validation loss: 0.5534468877006555 MAE: 0.54264766
60 10 0.6704623103141785
Validation loss: 0.5588591729590496 MAE: 0.5519962
Validation loss: 0.5525848972359693 MAE: 0.54591626
62 2 0.5371119379997253
Validation loss: 0.5500275407702567 MAE: 0.52027255
63 23 1.115131139755249
Validation loss: 0.6292407203055355 MAE: 0.57379913
Validation loss: 0.5138205204875114 MAE: 0.5118129
65 15 0.5780699253082275
Validation loss: 0.42116821481651157 MAE: 0.4570634
Validation loss: 0.5507226254203664 MAE: 0.52428454
67 7 0.9555748105049133
Validation loss: 0.40962162903524113 MAE: 0.4451955
68 28 0.7964104413986206
Validation loss: 0.9775509432634061 MAE: 0.69987774
Validation loss: 0.3881303727884272 MAE: 0.44009283
70 20 0.817081868648529
Validation loss: 0.4865098063940621 MAE: 0.49588
Validation loss: 0.4695366677661179 MAE: 0.4702352
72 12 0.6169302463531494
Validation loss: 0.4703194750050489 MAE: 0.47671053
Validation loss: 0.4850646449216756 MAE: 0.49025774
74 4 1.0087445974349976
Validation loss: 0.49213251877037034 MAE: 0.5049689
75 25 0.8927389979362488
Validation loss: 0.4211106086009007 MAE: 0.45602804
Validation loss: 0.5512308108883851 MAE: 0.5186673
77 17 0.5433799028396606
Validation loss: 0.5132698098732638 MAE: 0.51904345
Validation loss: 0.6609798810137013 MAE: 0.575296
79 9 0.7577630281448364
Validation loss: 0.4429987536393283 MAE: 0.47278953
Validation loss: 0.6158539892916546 MAE: 0.5686422
81 1 1.082547664642334
Validation loss: 0.7274611296200598 MAE: 0.587683
82 22 0.9518842101097107
Validation loss: 0.4284659842950479 MAE: 0.47571886
Validation loss: 0.4010592588981851 MAE: 0.45681491
84 14 0.7916290163993835
Validation loss: 0.3779226103173991 MAE: 0.45028338
Validation loss: 0.4205022302353614 MAE: 0.4899364
86 6 0.7397500276565552
Validation loss: 0.4631258639995789 MAE: 0.474835
87 27 0.5867171883583069
Validation loss: 0.371831895594463 MAE: 0.43802598
Validation loss: 0.5615769852572332 MAE: 0.53086144
89 19 0.4175789952278137
Validation loss: 0.4860355630034247 MAE: 0.48606223
Validation loss: 0.5399052518104116 MAE: 0.5114778
91 11 0.6907088160514832
Validation loss: 0.4482042763068403 MAE: 0.47534353
Validation loss: 0.40192937136468826 MAE: 0.4718653
93 3 0.4517630636692047
Validation loss: 0.5064192494099907 MAE: 0.50237536
94 24 0.6972166895866394
Validation loss: 0.43356377420621095 MAE: 0.4825825
Validation loss: 0.35891636568835694 MAE: 0.41633385
96 16 0.9032080173492432
Validation loss: 0.33223067391382183 MAE: 0.42652938
Validation loss: 0.5429846980401816 MAE: 0.5214708
98 8 0.9110279679298401
Validation loss: 0.36892659102866254 MAE: 0.42926311
Validation loss: 0.41170016516877045 MAE: 0.44966552
Loaded trained model with success.
Test loss: 1.4997044173153964 Test MAE: 0.9802983
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9460625674217907, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 5}}
Running on: cpu
926
926
55
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 13.211958885192871
Validation loss: 4.760968767541016 MAE: 1.7671307
1 21 3.3183014392852783
Validation loss: 3.3512772550850656 MAE: 1.4672278
Validation loss: 2.6077073088989917 MAE: 1.2813879
3 13 4.110648155212402
Validation loss: 2.1722986422656163 MAE: 1.18101
Validation loss: 1.8224920526179074 MAE: 1.0610305
5 5 2.132763624191284
Validation loss: 1.3370100661436373 MAE: 0.85895705
6 26 1.95034921169281
Validation loss: 1.4945586677761367 MAE: 0.91922516
Validation loss: 1.2330132146118526 MAE: 0.8531908
8 18 1.7706342935562134
Validation loss: 1.1795912817538943 MAE: 0.811263
Validation loss: 1.0746852777431644 MAE: 0.7655483
10 10 1.1746834516525269
Validation loss: 0.9881445706276862 MAE: 0.7465282
Validation loss: 0.8723443650014973 MAE: 0.70066404
12 2 1.92747163772583
Validation loss: 0.9020779835740125 MAE: 0.71846116
13 23 1.9716548919677734
Validation loss: 1.2057756839509144 MAE: 0.78441155
Validation loss: 0.8819044774345909 MAE: 0.7060082
15 15 1.2695285081863403
Validation loss: 0.8972691297531128 MAE: 0.7108818
Validation loss: 1.0012565721188456 MAE: 0.7346264
17 7 2.211276054382324
Validation loss: 0.6973656015571199 MAE: 0.613122
18 28 0.5921400785446167
Validation loss: 0.7723765530287576 MAE: 0.64279646
Validation loss: 1.3443761752439627 MAE: 0.8349918
20 20 1.9687262773513794
Validation loss: 0.8036413085254686 MAE: 0.67529285
Validation loss: 0.8648549807509387 MAE: 0.6662499
22 12 1.1593619585037231
Validation loss: 0.8438409891293321 MAE: 0.7177422
Validation loss: 0.9775128777804694 MAE: 0.7239884
24 4 0.7566171884536743
Validation loss: 1.0908062012612691 MAE: 0.746669
25 25 1.327548623085022
Validation loss: 0.7977734146313843 MAE: 0.6516088
Validation loss: 1.0188277040650469 MAE: 0.7428416
27 17 0.7966211438179016
Validation loss: 0.7705003633354961 MAE: 0.65441096
Validation loss: 0.7199377126621633 MAE: 0.6343288
29 9 0.42876121401786804
Validation loss: 0.6850500579271667 MAE: 0.6182768
Validation loss: 0.6005627914587314 MAE: 0.573623
31 1 1.1347784996032715
Validation loss: 0.6874009000044919 MAE: 0.61242294
32 22 0.6687572002410889
Validation loss: 0.624799373211665 MAE: 0.5913573
Validation loss: 0.6188280775531579 MAE: 0.5727072
34 14 1.5528347492218018
Validation loss: 0.9427515161475146 MAE: 0.71030873
Validation loss: 0.7042754919431122 MAE: 0.6177656
36 6 0.5645800232887268
Validation loss: 1.073101539977426 MAE: 0.7776936
37 27 0.6733760833740234
Validation loss: 0.7158691296052212 MAE: 0.6257717
Validation loss: 0.6439820311754363 MAE: 0.5926328
39 19 0.8968228101730347
Validation loss: 1.048349320116105 MAE: 0.70715225
Validation loss: 0.6409137874648586 MAE: 0.58044845
41 11 0.5425992012023926
Validation loss: 0.6435843025118949 MAE: 0.57196915
Validation loss: 0.5706143453878152 MAE: 0.5432619
43 3 0.8684297204017639
Validation loss: 0.5000599550634429 MAE: 0.51267797
44 24 0.9647431373596191
Validation loss: 0.7314197297487609 MAE: 0.60112715
Validation loss: 0.5117634807755571 MAE: 0.52374905
46 16 1.5505859851837158
Validation loss: 0.6205217831850567 MAE: 0.55748916
Validation loss: 0.47976318941517987 MAE: 0.49886173
48 8 0.9084076285362244
Validation loss: 0.812184438077214 MAE: 0.65841585
Validation loss: 0.8305137875785581 MAE: 0.64607537
50 0 0.4256173074245453
Validation loss: 0.5120355077490178 MAE: 0.5194577
51 21 0.8149012327194214
Validation loss: 0.7869471272948494 MAE: 0.65418905
Validation loss: 0.5875117193030487 MAE: 0.5598306
53 13 1.072399616241455
Validation loss: 0.49551188237723726 MAE: 0.5123957
Validation loss: 0.5856095154651041 MAE: 0.5424144
55 5 0.560355007648468
Validation loss: 0.6002775854219886 MAE: 0.55341893
56 26 0.9046745896339417
Validation loss: 0.4675577377526343 MAE: 0.4992924
Validation loss: 0.5550406898329634 MAE: 0.53298986
58 18 1.45442795753479
Validation loss: 0.4854713426037947 MAE: 0.4925497
Validation loss: 0.5842145895082543 MAE: 0.5670617
60 10 0.31882596015930176
Validation loss: 0.6462899961430362 MAE: 0.5870146
Validation loss: 0.4189428216566535 MAE: 0.46070164
62 2 1.0261934995651245
Validation loss: 0.44442309178492423 MAE: 0.48480284
63 23 1.1849174499511719
Validation loss: 0.524496864036659 MAE: 0.5398123
Validation loss: 0.4633842345576564 MAE: 0.481136
65 15 0.7998227477073669
Validation loss: 0.4511888986916058 MAE: 0.47399116
Validation loss: 0.48818659872524683 MAE: 0.49771625
67 7 0.912289559841156
Validation loss: 0.4384929931060799 MAE: 0.49362412
68 28 0.8751252889633179
Validation loss: 0.643782034291047 MAE: 0.5565783
Validation loss: 0.4944594192195917 MAE: 0.49756283
70 20 0.5338696837425232
Validation loss: 0.5443216895696669 MAE: 0.5401998
Validation loss: 0.5330938345734553 MAE: 0.5309213
72 12 0.984611988067627
Validation loss: 0.5512777376380904 MAE: 0.53109634
Validation loss: 0.547831202300012 MAE: 0.53823125
74 4 0.8060722947120667
Validation loss: 0.45351798417243794 MAE: 0.465731
75 25 0.45970189571380615
Validation loss: 0.40183072999023206 MAE: 0.4514162
Validation loss: 0.5229317330258454 MAE: 0.5094797
77 17 0.5275492668151855
Validation loss: 0.4629996984102814 MAE: 0.47679332
Validation loss: 0.5366625526425133 MAE: 0.5410347
79 9 1.667431354522705
Validation loss: 0.44887397472080864 MAE: 0.48899034
Validation loss: 0.4372672829978152 MAE: 0.4608453
81 1 0.7377645373344421
Validation loss: 0.3835849635801871 MAE: 0.44976062
82 22 1.0900901556015015
Validation loss: 0.44695460806011383 MAE: 0.47649178
Validation loss: 0.4738042361020527 MAE: 0.49233145
84 14 0.622372031211853
Validation loss: 0.5146783802730733 MAE: 0.5006386
Validation loss: 0.5402886111844436 MAE: 0.52291894
86 6 0.7648209929466248
Validation loss: 0.6623253219843426 MAE: 0.57132494
87 27 0.6908708214759827
Validation loss: 0.41980097470221717 MAE: 0.47546846
Validation loss: 0.5797089492785493 MAE: 0.5690118
89 19 0.9853888750076294
Validation loss: 0.3529336329541505 MAE: 0.42309472
Validation loss: 0.36131884675818954 MAE: 0.4290736
91 11 0.35413211584091187
Validation loss: 0.39628547391417734 MAE: 0.45058307
Validation loss: 0.42908203646894666 MAE: 0.4657151
93 3 0.4379320442676544
Validation loss: 0.3494988334230419 MAE: 0.42761716
94 24 1.090174674987793
Validation loss: 0.36240969916914245 MAE: 0.44496018
Validation loss: 0.45187610632400016 MAE: 0.48082113
96 16 0.5739707946777344
Validation loss: 0.3754571342828722 MAE: 0.42281625
Validation loss: 0.40467749339715453 MAE: 0.4580653
98 8 0.944516122341156
Validation loss: 0.5379478297403513 MAE: 0.5240754
Validation loss: 0.46623417979697684 MAE: 0.49224243
Loaded trained model with success.
Test loss: 1.4499059308658946 Test MAE: 0.96743464
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9784250269687162, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 5}}
Running on: cpu
926
926
55
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 21.208955764770508
Validation loss: 4.687582475320309 MAE: 1.7017444
1 21 7.411134243011475
Validation loss: 4.259415483371743 MAE: 1.66533
Validation loss: 3.0237035421779295 MAE: 1.3696184
3 13 3.241295576095581
Validation loss: 2.1324166399356357 MAE: 1.1579821
Validation loss: 1.745344550769221 MAE: 1.0289277
5 5 2.130825996398926
Validation loss: 1.6245815462994009 MAE: 0.9400086
6 26 1.3612256050109863
Validation loss: 1.2897659069003606 MAE: 0.84376925
Validation loss: 1.3752055822129383 MAE: 0.907334
8 18 1.0570478439331055
Validation loss: 1.0384511463585477 MAE: 0.75739455
Validation loss: 1.0346541252815955 MAE: 0.7318323
10 10 0.9756637811660767
Validation loss: 0.9081675408983334 MAE: 0.6988724
Validation loss: 1.2397281028024578 MAE: 0.8028664
12 2 1.5821993350982666
Validation loss: 0.9742374770327211 MAE: 0.69528204
13 23 1.7311477661132812
Validation loss: 0.8379713461671998 MAE: 0.66828287
Validation loss: 0.8483142149886096 MAE: 0.6784106
15 15 1.466791033744812
Validation loss: 0.7925075109782538 MAE: 0.6445767
Validation loss: 1.3290737903401353 MAE: 0.79664373
17 7 1.0982508659362793
Validation loss: 0.8228915625977979 MAE: 0.6734989
18 28 0.8615297675132751
Validation loss: 0.7358110582468061 MAE: 0.6194606
Validation loss: 1.080992183275923 MAE: 0.7305553
20 20 1.308059811592102
Validation loss: 0.7636109148966829 MAE: 0.6349173
Validation loss: 0.9145182104656557 MAE: 0.6829156
22 12 0.775050699710846
Validation loss: 0.7570278272515497 MAE: 0.64294064
Validation loss: 0.6546860699004797 MAE: 0.57829136
24 4 0.9170432090759277
Validation loss: 0.7091867546540872 MAE: 0.60816616
25 25 0.5968521237373352
Validation loss: 0.8041669750831555 MAE: 0.6586128
Validation loss: 0.6997483918527805 MAE: 0.60015196
27 17 1.220275640487671
Validation loss: 0.6815765141539646 MAE: 0.5945054
Validation loss: 0.7632771498698653 MAE: 0.62947834
29 9 0.9165796637535095
Validation loss: 0.6733872675483736 MAE: 0.6031916
Validation loss: 0.6471580897757611 MAE: 0.5967324
31 1 0.6007395386695862
Validation loss: 0.7428937264704035 MAE: 0.62318486
32 22 0.8730064630508423
Validation loss: 0.7187769595799127 MAE: 0.61331713
Validation loss: 0.6219840257008183 MAE: 0.5618375
34 14 0.36992305517196655
Validation loss: 0.6203716873607676 MAE: 0.59770936
Validation loss: 0.6030193813483092 MAE: 0.5529345
36 6 0.9132880568504333
Validation loss: 0.598290713379244 MAE: 0.56830096
37 27 0.7060176134109497
Validation loss: 0.5908794249236969 MAE: 0.5577497
Validation loss: 0.8690603329090011 MAE: 0.6772967
39 19 0.6606566905975342
Validation loss: 0.5404345831526021 MAE: 0.5369063
Validation loss: 0.5807545134882175 MAE: 0.5640116
41 11 1.0826170444488525
Validation loss: 0.5852451960417416 MAE: 0.5483779
Validation loss: 0.5538463678782238 MAE: 0.5316188
43 3 1.1415648460388184
Validation loss: 0.6150668080630621 MAE: 0.5859583
44 24 1.0261152982711792
Validation loss: 0.5445457561742152 MAE: 0.5411406
Validation loss: 0.6488612538151298 MAE: 0.5703098
46 16 0.8676886558532715
Validation loss: 0.5483966664799347 MAE: 0.57317084
Validation loss: 0.7046262926983267 MAE: 0.6307054
48 8 0.6086733341217041
Validation loss: 0.49078566634114307 MAE: 0.50850713
Validation loss: 0.512320045582934 MAE: 0.51346505
50 0 0.7676923871040344
Validation loss: 0.5037830204222167 MAE: 0.5090814
51 21 0.9435786604881287
Validation loss: 0.47111945404604755 MAE: 0.48820373
Validation loss: 0.5338296156465107 MAE: 0.5149505
53 13 1.0824881792068481
Validation loss: 0.5061903592062306 MAE: 0.51310515
Validation loss: 0.5282596634222159 MAE: 0.53392977
55 5 0.8145391345024109
Validation loss: 0.7127932256035362 MAE: 0.62215084
56 26 1.1788983345031738
Validation loss: 0.5417015186911268 MAE: 0.52640814
Validation loss: 0.5343248273847427 MAE: 0.5238542
58 18 1.4657870531082153
Validation loss: 0.5810814035119042 MAE: 0.5452471
Validation loss: 0.4285916985368626 MAE: 0.49011162
60 10 1.760833978652954
Validation loss: 0.5002354016571786 MAE: 0.5225886
Validation loss: 0.5907850519112325 MAE: 0.5747208
62 2 0.6570352911949158
Validation loss: 0.42177744637812703 MAE: 0.4580601
63 23 0.8725127577781677
Validation loss: 0.4080027648555537 MAE: 0.46572125
Validation loss: 0.5194145345790855 MAE: 0.5106395
65 15 0.49391603469848633
Validation loss: 0.44391850338641303 MAE: 0.4912011
Validation loss: 0.3897522315222038 MAE: 0.45063257
67 7 0.7663223147392273
Validation loss: 0.4059597877524069 MAE: 0.4652899
68 28 0.657309889793396
Validation loss: 0.39755382470899214 MAE: 0.45768338
Validation loss: 0.388311523211955 MAE: 0.44669792
70 20 1.220264196395874
Validation loss: 0.44463241892036043 MAE: 0.48632187
Validation loss: 0.5338076091739581 MAE: 0.512183
72 12 0.4528709053993225
Validation loss: 0.35987149317372696 MAE: 0.43780753
Validation loss: 0.37066120346987996 MAE: 0.44228142
74 4 0.8279672265052795
Validation loss: 0.4060292844509718 MAE: 0.47761166
75 25 0.9140526652336121
Validation loss: 0.584060438894556 MAE: 0.59326434
Validation loss: 0.43604312409077556 MAE: 0.47736558
77 17 0.4969552457332611
Validation loss: 0.41459704217848975 MAE: 0.47558904
Validation loss: 0.3791329932135588 MAE: 0.44167963
79 9 0.5365057587623596
Validation loss: 0.5114821313395613 MAE: 0.5420578
Validation loss: 0.4466153311162994 MAE: 0.5065264
81 1 0.8180369138717651
Validation loss: 0.35636859070147603 MAE: 0.44145474
82 22 1.1378446817398071
Validation loss: 0.46392786464217417 MAE: 0.48162907
Validation loss: 0.4781703525434045 MAE: 0.5140278
84 14 0.4251039922237396
Validation loss: 0.3877785862393307 MAE: 0.44569218
Validation loss: 0.4598434459313461 MAE: 0.50843865
86 6 0.5548909902572632
Validation loss: 0.4855597583058071 MAE: 0.5294639
87 27 1.2628684043884277
Validation loss: 0.3779733069643346 MAE: 0.4442861
Validation loss: 0.4199468403346595 MAE: 0.47519594
89 19 0.6912307739257812
Validation loss: 0.4284749543435115 MAE: 0.46392858
Validation loss: 0.3661882012245722 MAE: 0.43308055
91 11 0.4955335259437561
Validation loss: 0.4263990831684088 MAE: 0.46273494
Validation loss: 0.3768622966615994 MAE: 0.4463266
93 3 1.2334396839141846
Validation loss: 0.32636884640154007 MAE: 0.41212368
94 24 0.9462452530860901
Validation loss: 0.312136247271338 MAE: 0.40917408
Validation loss: 0.39871876775317266 MAE: 0.46564972
96 16 1.7625494003295898
Validation loss: 0.3302198717970055 MAE: 0.40869004
Validation loss: 0.45187829708435107 MAE: 0.50287443
98 8 1.0693188905715942
Validation loss: 0.45465135233191123 MAE: 0.48529732
Validation loss: 0.5340719141918948 MAE: 0.50587714
Loaded trained model with success.
Test loss: 1.5625023776834661 Test MAE: 1.002729
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9892125134843581, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 5}}
Running on: cpu
926
926
55
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 8.882859230041504
Validation loss: 3.871138190605213 MAE: 1.584326
1 21 2.9588451385498047
Validation loss: 3.820537182991242 MAE: 1.54105
Validation loss: 2.756681124540951 MAE: 1.3179942
3 13 1.8300893306732178
Validation loss: 2.313741204548088 MAE: 1.2257692
Validation loss: 1.630183319036183 MAE: 0.95031446
5 5 2.415228843688965
Validation loss: 1.445649950602142 MAE: 0.9363497
6 26 1.1708409786224365
Validation loss: 1.8774517862122209 MAE: 1.0454766
Validation loss: 1.3250365105355018 MAE: 0.86745507
8 18 1.306597113609314
Validation loss: 1.218887532504022 MAE: 0.7778738
Validation loss: 1.1079362632131473 MAE: 0.78226227
10 10 1.3890576362609863
Validation loss: 1.194652908049186 MAE: 0.77251935
Validation loss: 0.9804122571553834 MAE: 0.72621363
12 2 1.79716157913208
Validation loss: 1.034797792429543 MAE: 0.7221818
13 23 0.8826192021369934
Validation loss: 1.206314246288901 MAE: 0.7759466
Validation loss: 1.0536947993171395 MAE: 0.80833447
15 15 0.8013744950294495
Validation loss: 1.282230140967194 MAE: 0.773546
Validation loss: 1.1947280426004794 MAE: 0.7853289
17 7 1.1662566661834717
Validation loss: 1.0110544705236448 MAE: 0.75202274
18 28 2.3200583457946777
Validation loss: 0.8997175093603443 MAE: 0.66528124
Validation loss: 0.8420160165615782 MAE: 0.65090275
20 20 0.9839368462562561
Validation loss: 0.7491981822265147 MAE: 0.626844
Validation loss: 0.74274907938605 MAE: 0.6299595
22 12 2.1763980388641357
Validation loss: 0.7113892470786175 MAE: 0.640055
Validation loss: 0.7487793488842365 MAE: 0.6102212
24 4 1.1389410495758057
Validation loss: 0.7838149746602349 MAE: 0.6356272
25 25 0.887527346611023
Validation loss: 0.7692639735038543 MAE: 0.62451214
Validation loss: 0.6122237331280183 MAE: 0.57494193
27 17 1.4414018392562866
Validation loss: 0.8422340041360381 MAE: 0.68441975
Validation loss: 0.6750858813588614 MAE: 0.59709966
29 9 0.968643069267273
Validation loss: 0.7272886088033474 MAE: 0.61264455
Validation loss: 0.6264658660404625 MAE: 0.5833331
31 1 1.2343456745147705
Validation loss: 0.5971738335638272 MAE: 0.55160725
32 22 1.0075021982192993
Validation loss: 0.5814803269717915 MAE: 0.5501202
Validation loss: 0.677196348331402 MAE: 0.60488534
34 14 0.7773497700691223
Validation loss: 0.7682737324459249 MAE: 0.6399006
Validation loss: 0.844270877781491 MAE: 0.70934886
36 6 1.3390352725982666
Validation loss: 0.7045333686709147 MAE: 0.6113109
37 27 1.2394829988479614
Validation loss: 0.6224995636528048 MAE: 0.5594369
Validation loss: 0.739171201286769 MAE: 0.6197116
39 19 1.2958414554595947
Validation loss: 0.7325816462158384 MAE: 0.6337216
Validation loss: 0.8411304812966877 MAE: 0.669647
41 11 0.7514243125915527
Validation loss: 0.9192526376530624 MAE: 0.68084484
Validation loss: 0.7785007137459247 MAE: 0.64258707
43 3 0.413440465927124
Validation loss: 0.5865504012702608 MAE: 0.5499671
44 24 1.3628795146942139
Validation loss: 0.5099010583391458 MAE: 0.51923066
Validation loss: 0.614588510140487 MAE: 0.5611446
46 16 1.3951750993728638
Validation loss: 0.47955289373645 MAE: 0.48916933
Validation loss: 0.6120472809150976 MAE: 0.5671652
48 8 1.3018971681594849
Validation loss: 0.7756128286697437 MAE: 0.6176198
Validation loss: 0.5248889101118043 MAE: 0.5244413
50 0 1.0514276027679443
Validation loss: 0.7217206993576775 MAE: 0.6202883
51 21 1.0965086221694946
Validation loss: 0.7597896270051631 MAE: 0.6128158
Validation loss: 0.5792658065101756 MAE: 0.5103928
53 13 0.6124863028526306
Validation loss: 0.5961110259106556 MAE: 0.5377024
Validation loss: 0.6877900676129961 MAE: 0.6189367
55 5 0.6492761969566345
Validation loss: 0.6172726230281476 MAE: 0.56375974
56 26 2.0857832431793213
Validation loss: 0.5371683595247454 MAE: 0.5101255
Validation loss: 0.5520297031423186 MAE: 0.5443616
58 18 0.8404796123504639
Validation loss: 0.5026734277573827 MAE: 0.504359
Validation loss: 0.45655440550386006 MAE: 0.48439923
60 10 2.8839480876922607
Validation loss: 0.5442868120984434 MAE: 0.5405383
Validation loss: 0.4480450886500834 MAE: 0.4887193
62 2 0.3757173418998718
Validation loss: 0.47906636290622323 MAE: 0.48212117
63 23 0.6497870087623596
Validation loss: 0.4675223766856266 MAE: 0.4711207
Validation loss: 0.37384110682726424 MAE: 0.433239
65 15 0.2253357321023941
Validation loss: 0.4249300149553023 MAE: 0.4616356
Validation loss: 0.5386301866102939 MAE: 0.5106258
67 7 0.4176523685455322
Validation loss: 0.49390546452921874 MAE: 0.49624205
68 28 2.1434433460235596
Validation loss: 0.4703574438718174 MAE: 0.4839434
Validation loss: 0.49446606301334456 MAE: 0.50259316
70 20 0.43669867515563965
Validation loss: 0.4022860957015925 MAE: 0.45014074
Validation loss: 0.46706616839888804 MAE: 0.48268956
72 12 0.6998497843742371
Validation loss: 0.5178653147900336 MAE: 0.51379776
Validation loss: 0.3915960158887229 MAE: 0.44681817
74 4 0.7818911075592041
Validation loss: 0.4485504707687617 MAE: 0.47644907
75 25 1.604379415512085
Validation loss: 0.4648288537951319 MAE: 0.5247163
Validation loss: 0.4314198679015137 MAE: 0.45479438
77 17 1.223583459854126
Validation loss: 0.38405571997036947 MAE: 0.42771107
Validation loss: 0.45480501986476823 MAE: 0.46405306
79 9 0.44215768575668335
Validation loss: 0.43255748173330566 MAE: 0.46632394
Validation loss: 0.38539081683169174 MAE: 0.4366087
81 1 0.579928994178772
Validation loss: 0.3681587603900654 MAE: 0.42746177
82 22 0.5026901364326477
Validation loss: 0.4779111569180087 MAE: 0.48691252
Validation loss: 0.4000659091941224 MAE: 0.43839002
84 14 0.35893887281417847
Validation loss: 0.4743488705827659 MAE: 0.49181977
Validation loss: 0.40790563979493877 MAE: 0.448452
86 6 1.02904212474823
Validation loss: 0.4380195098355831 MAE: 0.45852596
87 27 0.4124297797679901
Validation loss: 0.5042036200187634 MAE: 0.5184269
Validation loss: 0.5091036482519001 MAE: 0.5003477
89 19 0.559187650680542
Validation loss: 0.4450068019378777 MAE: 0.4759416
Validation loss: 0.4797051910705237 MAE: 0.50926495
91 11 0.31533190608024597
Validation loss: 0.3934191133883293 MAE: 0.4465114
Validation loss: 0.3576865928734353 MAE: 0.4101233
93 3 0.7799268364906311
Validation loss: 0.3679075850008888 MAE: 0.44055268
94 24 0.534278392791748
Validation loss: 0.39508590848862996 MAE: 0.438052
Validation loss: 0.3712487895339406 MAE: 0.40809074
96 16 0.714897632598877
Validation loss: 0.36844581288343886 MAE: 0.42523226
Validation loss: 0.44172056952640254 MAE: 0.47732398
98 8 0.8789708018302917
Validation loss: 0.34341030482597024 MAE: 0.42289296
Validation loss: 0.34705097931507595 MAE: 0.4251567
Loaded trained model with success.
Test loss: 1.4111716974865307 Test MAE: 0.9533254
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.46062567421790723, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 2}}
Running on: cpu
926
926
55
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.6984635591506958
Validation loss: 0.641856948835031 ROC AUC: 0.7080913259903057
1 21 0.6388636231422424
Validation loss: 0.603239160634529 ROC AUC: 0.7501597831614206
Validation loss: 0.5043070156682388 ROC AUC: 0.845714778892761
3 13 0.5209405422210693
Validation loss: 0.49043282885788325 ROC AUC: 0.8762788484415893
Validation loss: 0.4257723601538986 ROC AUC: 0.9032950320266104
5 5 0.3606778681278229
Validation loss: 0.3942568483028247 ROC AUC: 0.9297443935937449
6 26 0.4105510413646698
Validation loss: 0.3177304325814381 ROC AUC: 0.9547242165959888
Validation loss: 0.30318695596433354 ROC AUC: 0.9602478155192602
8 18 0.3347807824611664
Validation loss: 0.2670866050485916 ROC AUC: 0.96394732054135
Validation loss: 0.28622204850610855 ROC AUC: 0.9617966625146369
10 10 0.36546432971954346
Validation loss: 0.25124585786210796 ROC AUC: 0.9707515173568834
Validation loss: 0.22732898943753788 ROC AUC: 0.9744160333655232
12 2 0.22000843286514282
Validation loss: 0.22581117836754472 ROC AUC: 0.9728718515719398
13 23 0.3890813887119293
Validation loss: 0.24587794308013586 ROC AUC: 0.9719831306303154
Validation loss: 0.20583815573358638 ROC AUC: 0.9785144131409405
15 15 0.3792036771774292
Validation loss: 0.2502022016125673 ROC AUC: 0.9766040130065826
Validation loss: 0.20461657479180115 ROC AUC: 0.97646638955368
17 7 0.1822207123041153
Validation loss: 0.2610682700287961 ROC AUC: 0.968274295204639
18 28 0.21057134866714478
Validation loss: 0.23068907058779672 ROC AUC: 0.9720041240383853
Validation loss: 0.21093441291710213 ROC AUC: 0.9792258564144193
20 20 0.2957693338394165
Validation loss: 0.19837624314150595 ROC AUC: 0.9776560160109726
Validation loss: 0.2651800731474586 ROC AUC: 0.9670403493303102
22 12 0.23977814614772797
Validation loss: 0.20193974065471673 ROC AUC: 0.9808003620196591
Validation loss: 0.20262954192594113 ROC AUC: 0.9846094992838914
24 4 0.2829867899417877
Validation loss: 0.21409078724440953 ROC AUC: 0.9839610362346223
25 25 0.40714138746261597
Validation loss: 0.1983557444218683 ROC AUC: 0.9828553834096093
Validation loss: 0.21936966855376638 ROC AUC: 0.9787733318404688
27 17 0.3200487792491913
Validation loss: 0.19268692294477643 ROC AUC: 0.9852136429161243
Validation loss: 0.20917168536402495 ROC AUC: 0.9828343900015395
29 9 0.19702006876468658
Validation loss: 0.18614438240522957 ROC AUC: 0.9849174026022495
Validation loss: 0.2528858475757212 ROC AUC: 0.9830676500912047
31 1 0.28620436787605286
Validation loss: 0.15981159705193976 ROC AUC: 0.9869514305841299
32 22 0.43478652834892273
Validation loss: 0.1923069774975787 ROC AUC: 0.985953077400363
Validation loss: 0.18591447068342123 ROC AUC: 0.9853279403600603
34 14 0.16900742053985596
Validation loss: 0.16018051493180752 ROC AUC: 0.9865525558308025
Validation loss: 0.1917485240082504 ROC AUC: 0.9838140823781333
36 6 0.14613978564739227
Validation loss: 0.16036798623159174 ROC AUC: 0.9871007170415156
37 27 0.22885653376579285
Validation loss: 0.16180225276663804 ROC AUC: 0.9873153163240075
Validation loss: 0.15585910865220343 ROC AUC: 0.9872570013015912
39 19 0.2449977695941925
Validation loss: 0.18914155066657015 ROC AUC: 0.9858597733644968
Validation loss: 0.18706731929506132 ROC AUC: 0.9872966555168343
41 11 0.17608782649040222
Validation loss: 0.18367540125069298 ROC AUC: 0.986274976324101
Validation loss: 0.1736032873971416 ROC AUC: 0.9877841691042346
43 3 0.19000278413295746
Validation loss: 0.1620024405661206 ROC AUC: 0.9876628738576088
44 24 0.3686988055706024
Validation loss: 0.18661139731659487 ROC AUC: 0.9864312605841766
Validation loss: 0.1533325290062 ROC AUC: 0.9886962160548255
46 16 0.5005099177360535
Validation loss: 0.17017449628457137 ROC AUC: 0.9874412767724268
Validation loss: 0.1362161362628185 ROC AUC: 0.9911547773998964
48 8 0.3084574043750763
Validation loss: 0.12912500373713398 ROC AUC: 0.9913367202698352
Validation loss: 0.15884673223704035 ROC AUC: 0.985731480315181
50 0 0.2013068050146103
Validation loss: 0.15818720534604774 ROC AUC: 0.9901097721981964
51 21 0.13678111135959625
Validation loss: 0.15536036775256337 ROC AUC: 0.9911057927810667
Validation loss: 0.17672928070275368 ROC AUC: 0.9851786539026746
53 13 0.21880140900611877
Validation loss: 0.13766025740564772 ROC AUC: 0.991593306368467
Validation loss: 0.14294296309963417 ROC AUC: 0.9908422088797451
55 5 0.41576284170150757
Validation loss: 0.18706415777072535 ROC AUC: 0.9862563155169277
56 26 0.18537886440753937
Validation loss: 0.13547932734757212 ROC AUC: 0.9923257430500156
Validation loss: 0.15077398551656154 ROC AUC: 0.9909705019290609
58 18 0.47846293449401855
Validation loss: 0.1336595404321895 ROC AUC: 0.9923770602697419
Validation loss: 0.1867782325518054 ROC AUC: 0.9919338660993782
60 10 0.17079763114452362
Validation loss: 0.1417760007067324 ROC AUC: 0.9914486851128745
Validation loss: 0.12530082139160412 ROC AUC: 0.9925590031396807
62 2 0.09448583424091339
Validation loss: 0.1313122073208539 ROC AUC: 0.9928179218392091
63 23 0.440772145986557
Validation loss: 0.13073487602351294 ROC AUC: 0.9913040638572821
Validation loss: 0.1262428508689285 ROC AUC: 0.9928599086553489
65 15 0.2805573344230652
Validation loss: 0.17293699552379468 ROC AUC: 0.9905856227811134
Validation loss: 0.14013389451328673 ROC AUC: 0.9925310119289209
67 7 0.13793432712554932
Validation loss: 0.1356129971519917 ROC AUC: 0.9936040083413809
68 28 0.2566714584827423
Validation loss: 0.16872555085057575 ROC AUC: 0.9876628738576088
Validation loss: 0.10579455075845863 ROC AUC: 0.9945277182964549
70 20 0.1897471398115158
Validation loss: 0.19363509012349997 ROC AUC: 0.9929951995073547
Validation loss: 0.1293525988674576 ROC AUC: 0.9939538984758786
72 12 0.19119660556316376
Validation loss: 0.09857835157193066 ROC AUC: 0.9951808465475174
Validation loss: 0.12849290427584886 ROC AUC: 0.9947399849780503
74 4 0.14317339658737183
Validation loss: 0.1325893231524762 ROC AUC: 0.9945930311215612
75 25 0.15382805466651917
Validation loss: 0.14957034385101325 ROC AUC: 0.9957476685654038
Validation loss: 0.11136967024200678 ROC AUC: 0.9946443483412875
77 17 0.15107719600200653
Validation loss: 0.11891941972414824 ROC AUC: 0.9946490135430808
Validation loss: 0.11965425103323506 ROC AUC: 0.9945883659197678
79 9 0.06814742833375931
Validation loss: 0.13819828785585792 ROC AUC: 0.9935480259198612
Validation loss: 0.10865805381768208 ROC AUC: 0.9945697051125947
81 1 0.05099598318338394
Validation loss: 0.10555739602633223 ROC AUC: 0.9948309564130198
82 22 0.46210479736328125
Validation loss: 0.15389022778228859 ROC AUC: 0.9913880374895616
Validation loss: 0.1314644428295914 ROC AUC: 0.9959459396416191
84 14 0.10308258980512619
Validation loss: 0.12529244732522038 ROC AUC: 0.9944694032740387
Validation loss: 0.1210758491513796 ROC AUC: 0.9957266751573339
86 6 0.10212673991918564
Validation loss: 0.0897886729588004 ROC AUC: 0.9961652041259045
87 27 0.07392231374979019
Validation loss: 0.12426049215618529 ROC AUC: 0.9948239586103297
Validation loss: 0.1397374115449821 ROC AUC: 0.9964917682514357
89 19 0.08409225195646286
Validation loss: 0.08776010175438731 ROC AUC: 0.9967460217491708
Validation loss: 0.11457439643968516 ROC AUC: 0.9951668509421374
91 11 0.4197552800178528
Validation loss: 0.13798350530232004 ROC AUC: 0.9942781300005132
Validation loss: 0.11070105132544272 ROC AUC: 0.9966223939016482
93 3 0.2782689034938812
Validation loss: 0.10857360720731012 ROC AUC: 0.9965104290586089
94 24 0.13569635152816772
Validation loss: 0.1276205623960907 ROC AUC: 0.9966760437222711
Validation loss: 0.09417363795296935 ROC AUC: 0.9963984642155697
96 16 0.07743852585554123
Validation loss: 0.10220862357006218 ROC AUC: 0.9953441286102831
Validation loss: 0.1100029898063153 ROC AUC: 0.9944110882516223
98 8 0.25258535146713257
Validation loss: 0.10158566495737556 ROC AUC: 0.9959156158299628
Validation loss: 0.13366625799151785 ROC AUC: 0.9955773886999482
Loaded trained model with success.
Test loss: 0.6645023248412393 Test ROC AUC: 0.9019607843137255
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7842502696871629, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 2}}
Running on: cpu
926
926
55
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.7339877486228943
Validation loss: 0.6280944741312937 ROC AUC: 0.6767388373384091
1 21 0.5885105133056641
Validation loss: 0.5994700098140708 ROC AUC: 0.7580719654028635
Validation loss: 0.5537838225874478 ROC AUC: 0.8365919767859559
3 13 0.5053669214248657
Validation loss: 0.4810191703795357 ROC AUC: 0.8597127168735684
Validation loss: 0.43326649101970005 ROC AUC: 0.9105027687972643
5 5 0.3539672791957855
Validation loss: 0.40840819239873866 ROC AUC: 0.9445913983009334
6 26 0.3780057430267334
Validation loss: 0.3551393106869436 ROC AUC: 0.949055996417125
Validation loss: 0.32010642891311236 ROC AUC: 0.9538564890624344
8 18 0.4082493782043457
Validation loss: 0.3185640683570639 ROC AUC: 0.9397629144448644
Validation loss: 0.29067778065961586 ROC AUC: 0.9547382122013687
10 10 0.2542937695980072
Validation loss: 0.2437915599886851 ROC AUC: 0.9649573367296003
Validation loss: 0.2661278469902393 ROC AUC: 0.9661609587922726
12 2 0.33361053466796875
Validation loss: 0.2217468043576049 ROC AUC: 0.9731587614822279
13 23 0.42331141233444214
Validation loss: 0.2461932451176592 ROC AUC: 0.9721953973119107
Validation loss: 0.20369170599699535 ROC AUC: 0.9779732497329172
15 15 0.24697965383529663
Validation loss: 0.25511765853375135 ROC AUC: 0.9649083521107705
Validation loss: 0.22842408320816238 ROC AUC: 0.9742457535000677
17 7 0.47157955169677734
Validation loss: 0.2194299119530692 ROC AUC: 0.9754866971770862
18 28 0.29163017868995667
Validation loss: 0.19376046488918444 ROC AUC: 0.9797926784323056
Validation loss: 0.1873003820653353 ROC AUC: 0.9809589788806314
20 20 0.22898094356060028
Validation loss: 0.19577277562788187 ROC AUC: 0.978871301078128
Validation loss: 0.21731130199478718 ROC AUC: 0.9724799746213022
22 12 0.20389795303344727
Validation loss: 0.19269014463697604 ROC AUC: 0.9803175136340523
Validation loss: 0.1847203389679124 ROC AUC: 0.9816820851585936
24 4 0.25207117199897766
Validation loss: 0.1676006965644931 ROC AUC: 0.9833055753826632
25 25 0.43553075194358826
Validation loss: 0.17743363155788272 ROC AUC: 0.9827924031853997
Validation loss: 0.16962790325058716 ROC AUC: 0.9847494553376906
27 17 0.3212256133556366
Validation loss: 0.21218863663869078 ROC AUC: 0.9810686111227741
Validation loss: 0.16264658953922098 ROC AUC: 0.9849733850237692
29 9 0.2425372153520584
Validation loss: 0.21782499764187033 ROC AUC: 0.9810639459209808
Validation loss: 0.16051973754914223 ROC AUC: 0.9852183081179176
31 1 0.24635034799575806
Validation loss: 0.16997825835487498 ROC AUC: 0.9825778039029078
32 22 0.6367590427398682
Validation loss: 0.19193848957897006 ROC AUC: 0.9843739065933297
Validation loss: 0.20154472739791768 ROC AUC: 0.9779732497329172
34 14 0.27593734860420227
Validation loss: 0.17916467863076707 ROC AUC: 0.9827877379836065
Validation loss: 0.16260876949096087 ROC AUC: 0.9869281045751633
36 6 0.46992403268814087
Validation loss: 0.17206952127086936 ROC AUC: 0.9868161397321241
37 27 0.09554293751716614
Validation loss: 0.15760064849199537 ROC AUC: 0.9858084561447705
Validation loss: 0.1518389736151335 ROC AUC: 0.9870004152029596
39 19 0.34388336539268494
Validation loss: 0.15632095823535136 ROC AUC: 0.9895452827812067
Validation loss: 0.15186187497804798 ROC AUC: 0.9901424286107496
41 11 0.3156062066555023
Validation loss: 0.1547699988403279 ROC AUC: 0.9871077148442056
Validation loss: 0.1564923834144168 ROC AUC: 0.9888221765032446
43 3 0.1678512990474701
Validation loss: 0.14429863400709037 ROC AUC: 0.9890251127812533
44 24 0.4396258294582367
Validation loss: 0.13425719178006149 ROC AUC: 0.9899674835435007
Validation loss: 0.1461388960030115 ROC AUC: 0.9891510732296726
46 16 0.20581768453121185
Validation loss: 0.1488533188985182 ROC AUC: 0.987674536862092
Validation loss: 0.1921642339641538 ROC AUC: 0.9860207228263659
48 8 0.32920265197753906
Validation loss: 0.1515292415866069 ROC AUC: 0.9871100474451021
Validation loss: 0.14691587262354452 ROC AUC: 0.9892467098664353
50 0 0.25867798924446106
Validation loss: 0.15807506660920756 ROC AUC: 0.9897062322430756
51 21 0.333485871553421
Validation loss: 0.14427512995979183 ROC AUC: 0.9902777194627553
Validation loss: 0.14384872377819943 ROC AUC: 0.9911641078034831
53 13 0.20586822926998138
Validation loss: 0.14277754434370324 ROC AUC: 0.9894053267274077
Validation loss: 0.1447813678894908 ROC AUC: 0.989335348700508
55 5 0.19418063759803772
Validation loss: 0.12747141585301117 ROC AUC: 0.9902543934537887
56 26 0.2316901832818985
Validation loss: 0.16914566369731276 ROC AUC: 0.9887312050682752
Validation loss: 0.11953344250793849 ROC AUC: 0.9919618573101379
58 18 0.49895039200782776
Validation loss: 0.17465645937373778 ROC AUC: 0.9891907274449155
Validation loss: 0.1313445819119398 ROC AUC: 0.9914440199110812
60 10 0.12183704227209091
Validation loss: 0.13599690553565263 ROC AUC: 0.9916819452025398
Validation loss: 0.1549738641208758 ROC AUC: 0.9912434162339692
62 2 0.10184065252542496
Validation loss: 0.12564534895105958 ROC AUC: 0.9913950352922516
63 23 0.21082578599452972
Validation loss: 0.12240059178153588 ROC AUC: 0.99266397018003
Validation loss: 0.13452862668179025 ROC AUC: 0.9925683335432675
65 15 0.22765547037124634
Validation loss: 0.13055613097889635 ROC AUC: 0.9911454469963098
Validation loss: 0.1367338569130805 ROC AUC: 0.9919968463235878
67 7 0.22599206864833832
Validation loss: 0.11927827937653204 ROC AUC: 0.9929275540813518
68 28 0.17436376214027405
Validation loss: 0.1271829065699814 ROC AUC: 0.9928832346643154
Validation loss: 0.11025427608523461 ROC AUC: 0.9930441841261842
70 20 0.3225027620792389
Validation loss: 0.12698189550548084 ROC AUC: 0.9930861709423242
Validation loss: 0.1243174857345307 ROC AUC: 0.9935993431395875
72 12 0.23492585122585297
Validation loss: 0.11030884624557413 ROC AUC: 0.9940075482965016
Validation loss: 0.12393536178906071 ROC AUC: 0.9942151497763035
74 4 0.14580805599689484
Validation loss: 0.1219361916860288 ROC AUC: 0.9926663027809268
75 25 0.25726690888404846
Validation loss: 0.15338515890983476 ROC AUC: 0.9894893003596871
Validation loss: 0.10925529271235476 ROC AUC: 0.9941358413458173
77 17 0.17939747869968414
Validation loss: 0.10703886103198801 ROC AUC: 0.994896269238126
Validation loss: 0.11802626257967486 ROC AUC: 0.9932377900006065
79 9 0.10869041085243225
Validation loss: 0.15636088423125172 ROC AUC: 0.9912480814357625
Validation loss: 0.10115109467738133 ROC AUC: 0.9956427015250545
81 1 0.42218485474586487
Validation loss: 0.09746624960626434 ROC AUC: 0.996242179955494
82 22 0.2808583676815033
Validation loss: 0.10862528465961792 ROC AUC: 0.996020582870312
Validation loss: 0.12234734199925067 ROC AUC: 0.993247120404193
84 14 0.117862269282341
Validation loss: 0.11277576910882996 ROC AUC: 0.9954351000452525
Validation loss: 0.1279939635944418 ROC AUC: 0.9952018399555873
86 6 0.10238911211490631
Validation loss: 0.10385956401186422 ROC AUC: 0.9953837828255261
87 27 0.11971794068813324
Validation loss: 0.09059982537643956 ROC AUC: 0.9961068891034881
Validation loss: 0.0998270589190477 ROC AUC: 0.9955354018838085
89 19 0.09616626799106598
Validation loss: 0.0926711268191976 ROC AUC: 0.9951271967268944
Validation loss: 0.10765940446575568 ROC AUC: 0.9964801052469524
91 11 0.1273130178451538
Validation loss: 0.08177037519396768 ROC AUC: 0.9966807089240645
Validation loss: 0.11354893668037769 ROC AUC: 0.996134880314248
93 3 0.08772744238376617
Validation loss: 0.11307024547013557 ROC AUC: 0.9935923453368976
94 24 0.16948170959949493
Validation loss: 0.08693455433227588 ROC AUC: 0.9967763455608272
Validation loss: 0.10368005297353922 ROC AUC: 0.9965337550675755
96 16 0.26292476058006287
Validation loss: 0.11888321334612807 ROC AUC: 0.9954490956506324
Validation loss: 0.0919482989908552 ROC AUC: 0.9968673169957967
98 8 0.2893703579902649
Validation loss: 0.10703531533608426 ROC AUC: 0.9971658899105681
Validation loss: 0.09604621957786397 ROC AUC: 0.9964661096415725
Loaded trained model with success.
Test loss: 0.789082903211767 Test ROC AUC: 0.8935574229691877
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8921251348435815, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 2}}
Running on: cpu
926
926
55
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.7595803141593933
Validation loss: 0.7301501235230695 ROC AUC: 0.7110443987254669
1 21 0.543707013130188
Validation loss: 0.6373429813343814 ROC AUC: 0.7732385364328933
Validation loss: 0.5518487743373566 ROC AUC: 0.8232261736481411
3 13 0.49979254603385925
Validation loss: 0.48684434254792547 ROC AUC: 0.8522227353944194
Validation loss: 0.4611180230299288 ROC AUC: 0.9160753523393654
5 5 0.42612823843955994
Validation loss: 0.34526848889581585 ROC AUC: 0.9312302603649121
6 26 0.5779078602790833
Validation loss: 0.31403287041522 ROC AUC: 0.9436420297359962
Validation loss: 0.28043780174935096 ROC AUC: 0.9539964451162335
8 18 0.45406123995780945
Validation loss: 0.3250553814883366 ROC AUC: 0.9525082457441697
Validation loss: 0.3358217985660932 ROC AUC: 0.9457040489286364
10 10 0.295558363199234
Validation loss: 0.34069739352935846 ROC AUC: 0.954896829062341
Validation loss: 0.2938814291300063 ROC AUC: 0.9656104649806627
12 2 0.1981109231710434
Validation loss: 0.24865814670115774 ROC AUC: 0.966881732469338
13 23 0.36306917667388916
Validation loss: 0.24307820593564095 ROC AUC: 0.969494245473588
Validation loss: 0.2216973340150862 ROC AUC: 0.9762447924684982
15 15 0.31367215514183044
Validation loss: 0.22746872834330242 ROC AUC: 0.9745046721995959
Validation loss: 0.23201324213014565 ROC AUC: 0.9742574165045509
17 7 0.1732678860425949
Validation loss: 0.22553686079917148 ROC AUC: 0.9721114236796312
18 28 0.22395266592502594
Validation loss: 0.2030292344209185 ROC AUC: 0.9776000335894528
Validation loss: 0.21757541854360962 ROC AUC: 0.9720087892401786
20 20 0.3330281972885132
Validation loss: 0.18623132707619514 ROC AUC: 0.9802591986116359
Validation loss: 0.2169922456370574 ROC AUC: 0.9758739089259305
22 12 0.3077314496040344
Validation loss: 0.20815835896372537 ROC AUC: 0.9774297537239973
Validation loss: 0.18248504940943377 ROC AUC: 0.9810592807191876
24 4 0.14928153157234192
Validation loss: 0.19054814730620023 ROC AUC: 0.9774904013473102
25 25 0.14637066423892975
Validation loss: 0.21610464947398744 ROC AUC: 0.9743623835449002
Validation loss: 0.19618627512686712 ROC AUC: 0.9797273656071993
27 17 0.3400840759277344
Validation loss: 0.18533004747932982 ROC AUC: 0.9800282711228674
Validation loss: 0.1937338212589466 ROC AUC: 0.9819433364590187
29 9 0.13829968869686127
Validation loss: 0.1989130600965049 ROC AUC: 0.9827760749791232
Validation loss: 0.16527292479964106 ROC AUC: 0.9843459153825699
31 1 0.25079721212387085
Validation loss: 0.1709441355958613 ROC AUC: 0.9827294229611901
32 22 0.29008156061172485
Validation loss: 0.1713729031528819 ROC AUC: 0.9843482479834664
Validation loss: 0.17242555906010498 ROC AUC: 0.9842689395529804
34 14 0.5735876560211182
Validation loss: 0.2400716361680247 ROC AUC: 0.9660140049357835
Validation loss: 0.15087577000614377 ROC AUC: 0.9864032693734167
36 6 0.24244572222232819
Validation loss: 0.17187051603783798 ROC AUC: 0.9843505805843632
37 27 0.34018489718437195
Validation loss: 0.1646188668761861 ROC AUC: 0.9871566994630353
Validation loss: 0.18300331935898018 ROC AUC: 0.9853862553824765
39 19 0.3689800202846527
Validation loss: 0.18095976069215564 ROC AUC: 0.9856148502703485
Validation loss: 0.193518659820052 ROC AUC: 0.978845642468265
41 11 0.12086530774831772
Validation loss: 0.1610927722752738 ROC AUC: 0.9880430878037629
Validation loss: 0.1491044611382433 ROC AUC: 0.9875625720190526
43 3 0.3625798225402832
Validation loss: 0.15300542787200175 ROC AUC: 0.9873106511222143
44 24 0.2676255404949188
Validation loss: 0.15709509140536285 ROC AUC: 0.9874342789697368
Validation loss: 0.15087333926629298 ROC AUC: 0.9902217370412356
46 16 0.1750166416168213
Validation loss: 0.14994861652217725 ROC AUC: 0.9893563421085779
Validation loss: 0.16344680949305354 ROC AUC: 0.9854492356066862
48 8 0.2302478700876236
Validation loss: 0.14205736597722343 ROC AUC: 0.9889714629606304
Validation loss: 0.14529005980388648 ROC AUC: 0.989496298162377
50 0 0.23509860038757324
Validation loss: 0.13049482465691495 ROC AUC: 0.9915233283415674
51 21 0.332401305437088
Validation loss: 0.15144983220435115 ROC AUC: 0.9865922100460456
Validation loss: 0.1570082041022587 ROC AUC: 0.9863216283420339
53 13 0.15902337431907654
Validation loss: 0.1285664172718386 ROC AUC: 0.9916959408079197
Validation loss: 0.1368938976532697 ROC AUC: 0.9904549971309009
55 5 0.26690396666526794
Validation loss: 0.1525965024984681 ROC AUC: 0.9901004417946099
56 26 0.17291347682476044
Validation loss: 0.14165838856097174 ROC AUC: 0.9904293385210376
Validation loss: 0.15887355231569344 ROC AUC: 0.9894706395525139
58 18 0.12608329951763153
Validation loss: 0.14082961183516046 ROC AUC: 0.9913390528707319
Validation loss: 0.13560875574404427 ROC AUC: 0.9897878732744585
60 10 0.45380547642707825
Validation loss: 0.12631497330979705 ROC AUC: 0.991332055068042
Validation loss: 0.1310150523873179 ROC AUC: 0.9897202278484556
62 2 0.1458025425672531
Validation loss: 0.13992466582850296 ROC AUC: 0.9912060946196227
63 23 0.13578200340270996
Validation loss: 0.12591189043053283 ROC AUC: 0.9923420712562921
Validation loss: 0.12155710376364623 ROC AUC: 0.9917239320186794
65 15 0.2663685083389282
Validation loss: 0.12524519274996887 ROC AUC: 0.9926499745746503
Validation loss: 0.11585051098086149 ROC AUC: 0.9925473401351975
67 7 0.25004422664642334
Validation loss: 0.13247128210752623 ROC AUC: 0.9906649312115996
68 28 0.33196592330932617
Validation loss: 0.12891117398090032 ROC AUC: 0.9907745634537422
Validation loss: 0.13370309074934306 ROC AUC: 0.9910708037676169
70 20 0.18243101239204407
Validation loss: 0.13401880546535322 ROC AUC: 0.9931631467719136
Validation loss: 0.12137440435958476 ROC AUC: 0.9944694032740387
72 12 0.2877177596092224
Validation loss: 0.1012270259097637 ROC AUC: 0.9953767850228362
Validation loss: 0.13044814350280598 ROC AUC: 0.9932821094176427
74 4 0.16045543551445007
Validation loss: 0.11715341003744442 ROC AUC: 0.9934360610768219
75 25 0.19879069924354553
Validation loss: 0.13735852691447503 ROC AUC: 0.9918778836778585
Validation loss: 0.11117411700940287 ROC AUC: 0.9940542003144346
77 17 0.1463852971792221
Validation loss: 0.1218510680463865 ROC AUC: 0.993254118206883
Validation loss: 0.13955228095049477 ROC AUC: 0.9922510998213229
79 9 0.04817718639969826
Validation loss: 0.10836076379208534 ROC AUC: 0.9945090574892818
Validation loss: 0.10029870473636922 ROC AUC: 0.9946443483412876
81 1 0.1224590614438057
Validation loss: 0.11495522111976121 ROC AUC: 0.9944204186552089
82 22 0.18187710642814636
Validation loss: 0.10810740089313516 ROC AUC: 0.9952484919735204
Validation loss: 0.1046755324976748 ROC AUC: 0.9936040083413807
84 14 0.22056834399700165
Validation loss: 0.12114787640826491 ROC AUC: 0.9947469827807401
Validation loss: 0.10415536781559753 ROC AUC: 0.9950222296865451
86 6 0.1914364993572235
Validation loss: 0.11873272988245245 ROC AUC: 0.9944344142605889
87 27 0.3370843529701233
Validation loss: 0.11207041821038234 ROC AUC: 0.9947423175789468
Validation loss: 0.09531432621937333 ROC AUC: 0.9949405886551622
89 19 0.18768741190433502
Validation loss: 0.1022235417726488 ROC AUC: 0.9946653417493574
Validation loss: 0.10783223151259494 ROC AUC: 0.9938885856507722
91 11 0.10897289961576462
Validation loss: 0.1278533557868416 ROC AUC: 0.9938372684310459
Validation loss: 0.11390328677632638 ROC AUC: 0.995029227489235
93 3 0.1530185043811798
Validation loss: 0.09126544441247347 ROC AUC: 0.9951645183412409
94 24 0.1259227842092514
Validation loss: 0.10329288200799126 ROC AUC: 0.995766329372577
Validation loss: 0.08871227855236948 ROC AUC: 0.9966363895070282
96 16 0.10886165499687195
Validation loss: 0.09592062482694828 ROC AUC: 0.9954560934533223
Validation loss: 0.0976744870741733 ROC AUC: 0.9965780744846118
98 8 0.2754036486148834
Validation loss: 0.10347932477362985 ROC AUC: 0.9965664114801285
Validation loss: 0.096603182894751 ROC AUC: 0.9966667133186845
Loaded trained model with success.
Test loss: 0.9141026236794212 Test ROC AUC: 0.8921568627450981
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9460625674217907, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 2}}
Running on: cpu
926
926
55
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.8202366828918457
Validation loss: 0.7108967372459676 ROC AUC: 0.6284633291813038
1 21 0.6034967303276062
Validation loss: 0.6135616698996295 ROC AUC: 0.6630534678777531
Validation loss: 0.5541630763214557 ROC AUC: 0.8088176979095231
3 13 0.6454730033874512
Validation loss: 0.5379267197190815 ROC AUC: 0.8118290856671004
Validation loss: 0.5169450322057465 ROC AUC: 0.8842563435081384
5 5 0.6033618450164795
Validation loss: 0.38115437686057124 ROC AUC: 0.9254664035492857
6 26 0.5232741832733154
Validation loss: 0.35934492488659225 ROC AUC: 0.9248505969125694
Validation loss: 0.33134290170463576 ROC AUC: 0.9474838234127817
8 18 0.6928060054779053
Validation loss: 0.3046812711858852 ROC AUC: 0.9557762196003788
Validation loss: 0.3646664011169458 ROC AUC: 0.9476914248925837
10 10 0.32677343487739563
Validation loss: 0.2790525393403632 ROC AUC: 0.9631519036355918
Validation loss: 0.2821814602896668 ROC AUC: 0.9722117255181874
12 2 0.4473998546600342
Validation loss: 0.2461734295663772 ROC AUC: 0.972039113051835
13 23 0.374410480260849
Validation loss: 0.23570721099237643 ROC AUC: 0.9737582399126673
Validation loss: 0.251232071713289 ROC AUC: 0.9709661166393752
15 15 0.24771346151828766
Validation loss: 0.26026868343868215 ROC AUC: 0.9708308257873695
Validation loss: 0.25773505811814873 ROC AUC: 0.97334536955396
17 7 0.1450316607952118
Validation loss: 0.2348175444046828 ROC AUC: 0.9791255545758631
18 28 0.34929904341697693
Validation loss: 0.23903261553134053 ROC AUC: 0.9789762681184774
Validation loss: 0.23147687505826064 ROC AUC: 0.9781668556073392
20 20 0.2315130978822708
Validation loss: 0.2431446631191616 ROC AUC: 0.9688434498234221
Validation loss: 0.22131236438231128 ROC AUC: 0.9805647693290974
22 12 0.21605071425437927
Validation loss: 0.20292236245605394 ROC AUC: 0.9795920747551935
Validation loss: 0.2232284755094005 ROC AUC: 0.9798253348448588
24 4 0.14458568394184113
Validation loss: 0.19904160985550148 ROC AUC: 0.9798556586565152
25 25 0.3682205080986023
Validation loss: 0.2073203457547573 ROC AUC: 0.9792608454278691
Validation loss: 0.1945922287506882 ROC AUC: 0.9835504984768116
27 17 0.31774798035621643
Validation loss: 0.2063464112338443 ROC AUC: 0.9826244559208408
Validation loss: 0.1901802302179275 ROC AUC: 0.9824565086562819
29 9 0.3016952872276306
Validation loss: 0.19374690463939445 ROC AUC: 0.9849873806291491
Validation loss: 0.23711429771285336 ROC AUC: 0.9791232219749665
31 1 0.3905631899833679
Validation loss: 0.18302885946650743 ROC AUC: 0.9834968486561887
32 22 0.1922600120306015
Validation loss: 0.18465270607311834 ROC AUC: 0.9832519255620402
Validation loss: 0.21172915418384913 ROC AUC: 0.9823375460105527
34 14 0.28099483251571655
Validation loss: 0.18551907812287433 ROC AUC: 0.984404230404986
Validation loss: 0.18879011160740328 ROC AUC: 0.9851809865035713
36 6 0.16534890234470367
Validation loss: 0.20967768142341794 ROC AUC: 0.9823188852033795
37 27 0.13680611550807953
Validation loss: 0.15699497624813352 ROC AUC: 0.9880127639921066
Validation loss: 0.17483735831200947 ROC AUC: 0.9875509090145694
39 19 0.4175553619861603
Validation loss: 0.26983013131191097 ROC AUC: 0.9819549994635017
Validation loss: 0.18027503592149227 ROC AUC: 0.9877048606737484
41 11 0.2729281187057495
Validation loss: 0.16748755119467398 ROC AUC: 0.9878588123329274
Validation loss: 0.15588432663074064 ROC AUC: 0.9907442396420857
43 3 0.25533634424209595
Validation loss: 0.1738659966712894 ROC AUC: 0.9841336487009745
44 24 0.4263075590133667
Validation loss: 0.14352943534212545 ROC AUC: 0.9902987128708253
Validation loss: 0.16220668354121964 ROC AUC: 0.9894099919292009
46 16 0.13395391404628754
Validation loss: 0.14615327856839347 ROC AUC: 0.9877258540818182
Validation loss: 0.18015997591337943 ROC AUC: 0.9887428680727586
48 8 0.1465226411819458
Validation loss: 0.1947275762552834 ROC AUC: 0.9865292298218359
Validation loss: 0.15574135219368512 ROC AUC: 0.9861700092837516
50 0 0.15415653586387634
Validation loss: 0.15381350389180895 ROC AUC: 0.9912480814357626
51 21 0.2807665467262268
Validation loss: 0.18112457751197897 ROC AUC: 0.9895919347991398
Validation loss: 0.17578473020964513 ROC AUC: 0.989911501121981
53 13 0.2978276014328003
Validation loss: 0.17647456643262124 ROC AUC: 0.9917845796419924
Validation loss: 0.18635047627834214 ROC AUC: 0.9901214352026798
55 5 0.10723049938678741
Validation loss: 0.13797061460708182 ROC AUC: 0.9915163305388774
56 26 0.14104025065898895
Validation loss: 0.15071942430335553 ROC AUC: 0.9900211333641237
Validation loss: 0.15243371395840757 ROC AUC: 0.9907815612564321
58 18 0.2638981342315674
Validation loss: 0.1282139820716551 ROC AUC: 0.9925426749334042
Validation loss: 0.14616050733732097 ROC AUC: 0.9928669064580389
60 10 0.09193605929613113
Validation loss: 0.1163814244047612 ROC AUC: 0.9930325211217012
Validation loss: 0.12101122878540155 ROC AUC: 0.9933031028257127
62 2 0.143877312541008
Validation loss: 0.11989300160570227 ROC AUC: 0.9925496727360943
63 23 0.18477992713451385
Validation loss: 0.11995818436177966 ROC AUC: 0.9935946779377942
Validation loss: 0.1270071232357499 ROC AUC: 0.9932401226015032
65 15 0.22853520512580872
Validation loss: 0.09963750097796031 ROC AUC: 0.9936110061440708
Validation loss: 0.12105314050585868 ROC AUC: 0.9930955013459107
67 7 0.2881486713886261
Validation loss: 0.12222217243832595 ROC AUC: 0.9932891072203328
68 28 0.11897328495979309
Validation loss: 0.1550164753430348 ROC AUC: 0.9897622146645954
Validation loss: 0.14615788219042009 ROC AUC: 0.9919991789244844
70 20 0.047935906797647476
Validation loss: 0.10816094678370021 ROC AUC: 0.9939329050678087
Validation loss: 0.11746332757416349 ROC AUC: 0.9919268682966882
72 12 0.28230854868888855
Validation loss: 0.11067480284953993 ROC AUC: 0.9938629270409092
Validation loss: 0.12857290507006594 ROC AUC: 0.9933031028257128
74 4 0.1684541553258896
Validation loss: 0.1130265891712891 ROC AUC: 0.9948496172201928
75 25 0.06792909651994705
Validation loss: 0.15873474072560378 ROC AUC: 0.9920085093280709
Validation loss: 0.12294262311306679 ROC AUC: 0.9944787336776252
77 17 0.06270193308591843
Validation loss: 0.104213050645062 ROC AUC: 0.9953068069959367
Validation loss: 0.12325093134046888 ROC AUC: 0.9942571365924433
79 9 0.2946131229400635
Validation loss: 0.09218654924798475 ROC AUC: 0.9963891338119831
Validation loss: 0.10831465671888953 ROC AUC: 0.9947656435879134
81 1 0.2881353497505188
Validation loss: 0.10602160313892828 ROC AUC: 0.9944554076686587
82 22 0.08508486300706863
Validation loss: 0.09698471664320316 ROC AUC: 0.9956683601349177
Validation loss: 0.1714681565890302 ROC AUC: 0.9914953371308076
84 14 0.1962267905473709
Validation loss: 0.10536004419460668 ROC AUC: 0.9960462414801753
Validation loss: 0.10380320456965181 ROC AUC: 0.9961838649330778
86 6 0.048709023743867874
Validation loss: 0.0885126649625358 ROC AUC: 0.9961605389241112
87 27 0.12721624970436096
Validation loss: 0.09265127905179821 ROC AUC: 0.9960928934981083
Validation loss: 0.09678204600612751 ROC AUC: 0.9965384202693688
89 19 0.2642630338668823
Validation loss: 0.11733196360374887 ROC AUC: 0.9943994252471391
Validation loss: 0.11067092038900239 ROC AUC: 0.9954467630497358
91 11 0.23663191497325897
Validation loss: 0.10980711381713464 ROC AUC: 0.9958946224218929
Validation loss: 0.08717527791664616 ROC AUC: 0.9965547484756454
93 3 0.20413421094417572
Validation loss: 0.09696385393937 ROC AUC: 0.9967203631393076
94 24 0.21759933233261108
Validation loss: 0.09432331863670061 ROC AUC: 0.996911636412833
Validation loss: 0.11687943635440028 ROC AUC: 0.9947866369959832
96 16 0.5234874486923218
Validation loss: 0.08538961856269939 ROC AUC: 0.99687898000028
Validation loss: 0.10400550333746823 ROC AUC: 0.9972008789240179
98 8 0.2359544038772583
Validation loss: 0.08538232907878142 ROC AUC: 0.9967460217491708
Validation loss: 0.09309827554045691 ROC AUC: 0.9965034312559191
Loaded trained model with success.
Test loss: 0.6958017435940829 Test ROC AUC: 0.8921568627450981
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9784250269687162, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 2}}
Running on: cpu
926
926
55
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.7726537585258484
Validation loss: 0.6321789527042381 ROC AUC: 0.7016090280985103
1 21 0.6582867503166199
Validation loss: 0.5997385534560449 ROC AUC: 0.7119447826715746
Validation loss: 0.5392005699757109 ROC AUC: 0.8103198928869668
3 13 0.4765777885913849
Validation loss: 0.4688488501838165 ROC AUC: 0.8757376850335663
Validation loss: 0.4418883363577511 ROC AUC: 0.9143935470928796
5 5 0.48291030526161194
Validation loss: 0.35480879823280975 ROC AUC: 0.9405816573595892
6 26 0.4322821795940399
Validation loss: 0.3072391223830229 ROC AUC: 0.9517244918428946
Validation loss: 0.31978062290867254 ROC AUC: 0.9534249578965538
8 18 0.527110755443573
Validation loss: 0.26397354392330796 ROC AUC: 0.9676328299580598
Validation loss: 0.2675129835600472 ROC AUC: 0.9627623592858509
10 10 0.3223089873790741
Validation loss: 0.2481216868751765 ROC AUC: 0.9653095594649946
Validation loss: 0.2550167551437155 ROC AUC: 0.9701706997336169
12 2 0.33164334297180176
Validation loss: 0.2399762601110899 ROC AUC: 0.9747659235000211
13 23 0.693731427192688
Validation loss: 0.2423930928336364 ROC AUC: 0.9725312918410286
Validation loss: 0.24818781481705782 ROC AUC: 0.9715795906751946
15 15 0.2189558893442154
Validation loss: 0.2316433918978174 ROC AUC: 0.9733616977602366
Validation loss: 0.24604493836604752 ROC AUC: 0.974336724935037
17 7 0.2548028230667114
Validation loss: 0.2056840491475091 ROC AUC: 0.9779032717060177
18 28 0.3814789652824402
Validation loss: 0.21031295751134985 ROC AUC: 0.9761981404505652
Validation loss: 0.20694522092975756 ROC AUC: 0.9797180352036128
20 20 0.4496893286705017
Validation loss: 0.1982322348438638 ROC AUC: 0.9821229467280608
Validation loss: 0.1975867903065218 ROC AUC: 0.9800819209434903
22 12 0.3014271557331085
Validation loss: 0.18637672494734853 ROC AUC: 0.982610460315461
Validation loss: 0.17455817392140177 ROC AUC: 0.9817404001810098
24 4 0.310636430978775
Validation loss: 0.24293347121443656 ROC AUC: 0.9838117497772366
25 25 0.35705384612083435
Validation loss: 0.18425993286636427 ROC AUC: 0.9822209159657201
Validation loss: 0.18971988626355488 ROC AUC: 0.9860557118398156
27 17 0.3508637547492981
Validation loss: 0.17574078057033712 ROC AUC: 0.984063670674075
Validation loss: 0.1777387968149865 ROC AUC: 0.983849071391583
29 9 0.27177363634109497
Validation loss: 0.17376821875958412 ROC AUC: 0.9869094437679903
Validation loss: 0.19801984914049475 ROC AUC: 0.9809239898671818
31 1 0.2395826131105423
Validation loss: 0.15269713174575864 ROC AUC: 0.9868604591491605
32 22 0.28127387166023254
Validation loss: 0.18874284042524211 ROC AUC: 0.9816797525576969
Validation loss: 0.16608216582956375 ROC AUC: 0.986039383633539
34 14 0.07638149708509445
Validation loss: 0.17101067890358795 ROC AUC: 0.9860020620191927
Validation loss: 0.2163051393518695 ROC AUC: 0.9792841714368354
36 6 0.2969402074813843
Validation loss: 0.15513059767224618 ROC AUC: 0.9857151521089046
37 27 0.3448725640773773
Validation loss: 0.1556689244238398 ROC AUC: 0.9872756621087645
Validation loss: 0.13784474833641144 ROC AUC: 0.9884536255615737
39 19 0.2787763178348541
Validation loss: 0.1749635792576726 ROC AUC: 0.9829253614365089
Validation loss: 0.13826372952363403 ROC AUC: 0.9896759084314192
41 11 0.36599284410476685
Validation loss: 0.15734610656682668 ROC AUC: 0.9870913866379291
Validation loss: 0.15720172950567488 ROC AUC: 0.9854399052030995
43 3 0.14278697967529297
Validation loss: 0.17343561158195686 ROC AUC: 0.9841523095081478
44 24 0.2076224535703659
Validation loss: 0.14640899247149927 ROC AUC: 0.9895476153821035
Validation loss: 0.17426635756219694 ROC AUC: 0.9861676766828549
46 16 0.4111281633377075
Validation loss: 0.1643381093670946 ROC AUC: 0.9869094437679902
Validation loss: 0.15121746352887824 ROC AUC: 0.9881410570414224
48 8 0.12445946037769318
Validation loss: 0.13936730989176563 ROC AUC: 0.9887288724673787
Validation loss: 0.1892714986726481 ROC AUC: 0.9850293674452888
50 0 0.2021544873714447
Validation loss: 0.14072797568132758 ROC AUC: 0.9892607054718151
51 21 0.13251793384552002
Validation loss: 0.1354320394941334 ROC AUC: 0.9901144373999897
Validation loss: 0.18080380011840722 ROC AUC: 0.9862983023330675
53 13 0.192515566945076
Validation loss: 0.14007062913918342 ROC AUC: 0.9893236856960248
Validation loss: 0.14457188009185873 ROC AUC: 0.9889504695525605
55 5 0.09217465668916702
Validation loss: 0.1459524369844865 ROC AUC: 0.9894193223327875
56 26 0.5492040514945984
Validation loss: 0.15652619197675013 ROC AUC: 0.9861186920640254
Validation loss: 0.14324511841872856 ROC AUC: 0.9898415230950814
58 18 0.22575484216213226
Validation loss: 0.13712427525360693 ROC AUC: 0.9912200902250027
Validation loss: 0.1266630025777652 ROC AUC: 0.99161896497833
60 10 0.2424335479736328
Validation loss: 0.1618515958538838 ROC AUC: 0.9863962715707267
Validation loss: 0.16726207198901002 ROC AUC: 0.9908538718842282
62 2 0.17821307480335236
Validation loss: 0.12109368478730481 ROC AUC: 0.9921228067720069
63 23 0.2611231803894043
Validation loss: 0.14356327473666705 ROC AUC: 0.9899674835435006
Validation loss: 0.12184059218408995 ROC AUC: 0.9917612536330259
65 15 0.14293625950813293
Validation loss: 0.12379506174032426 ROC AUC: 0.9914906719290143
Validation loss: 0.1870953013907241 ROC AUC: 0.9835994830956414
67 7 0.23937392234802246
Validation loss: 0.1263384797628446 ROC AUC: 0.9925076859199545
68 28 0.1695484071969986
Validation loss: 0.11459380581363489 ROC AUC: 0.9927176200006531
Validation loss: 0.11922677187953087 ROC AUC: 0.9919851833191045
70 20 0.18870855867862701
Validation loss: 0.17318368820598265 ROC AUC: 0.9881410570414223
Validation loss: 0.1506411135518525 ROC AUC: 0.989335348700508
72 12 0.19049681723117828
Validation loss: 0.12366338642253731 ROC AUC: 0.9941475043503007
Validation loss: 0.11667132287509498 ROC AUC: 0.9941778281619571
74 4 0.24809373915195465
Validation loss: 0.1512064226856757 ROC AUC: 0.9925193489244376
75 25 0.22096386551856995
Validation loss: 0.14206655056378753 ROC AUC: 0.9944927292830053
Validation loss: 0.12260926903484964 ROC AUC: 0.9916376257855033
77 17 0.15170639753341675
Validation loss: 0.13580906659879644 ROC AUC: 0.9916119671756402
Validation loss: 0.11967429702148066 ROC AUC: 0.9945697051125947
79 9 0.08727635443210602
Validation loss: 0.14731647614912646 ROC AUC: 0.9930768405387375
Validation loss: 0.141029543772372 ROC AUC: 0.9945650399108014
81 1 0.0947728306055069
Validation loss: 0.10496802328729732 ROC AUC: 0.9946093593278378
82 22 0.11513935029506683
Validation loss: 0.10982135599619884 ROC AUC: 0.9944250838570022
Validation loss: 0.12688184223795554 ROC AUC: 0.9941171805386442
84 14 0.16333995759487152
Validation loss: 0.11754110331604857 ROC AUC: 0.9947493153816369
Validation loss: 0.11730072748712536 ROC AUC: 0.9945160552919716
86 6 0.16890238225460052
Validation loss: 0.11333097511858199 ROC AUC: 0.9951598531394475
87 27 0.1419259011745453
Validation loss: 0.10060773432640999 ROC AUC: 0.994460072870452
Validation loss: 0.10195153571874482 ROC AUC: 0.9954700890587022
89 19 0.09547226130962372
Validation loss: 0.10475467941995316 ROC AUC: 0.99424547358796
Validation loss: 0.10492681013520799 ROC AUC: 0.9949499190587487
91 11 0.14219115674495697
Validation loss: 0.10458434957278727 ROC AUC: 0.9953114721977298
Validation loss: 0.11080398106420529 ROC AUC: 0.9962141887447342
93 3 0.24435923993587494
Validation loss: 0.09826331812542406 ROC AUC: 0.9952181681618638
94 24 0.17690056562423706
Validation loss: 0.08687412765351794 ROC AUC: 0.996489435650539
Validation loss: 0.11766122926839227 ROC AUC: 0.9956403689241579
96 16 0.19033239781856537
Validation loss: 0.11828630666206259 ROC AUC: 0.9961092217043849
Validation loss: 0.09337803719818721 ROC AUC: 0.99632848618867
98 8 0.2807953357696533
Validation loss: 0.08046283848084847 ROC AUC: 0.9968393257850369
Validation loss: 0.08962565858407875 ROC AUC: 0.9961791997312844
Loaded trained model with success.
Test loss: 0.9497244986620816 Test ROC AUC: 0.8865546218487395
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9892125134843581, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 2}}
Running on: cpu
926
926
55
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.7553979158401489
Validation loss: 0.6500686987687393 ROC AUC: 0.7051499162596278
1 21 0.5622251033782959
Validation loss: 0.5884378637402413 ROC AUC: 0.7534907372418395
Validation loss: 0.5218401647798443 ROC AUC: 0.8282949153965653
3 13 0.6783011555671692
Validation loss: 0.5947196984394065 ROC AUC: 0.8863183627007787
Validation loss: 0.38282039471887874 ROC AUC: 0.9206565805003895
5 5 0.5597056746482849
Validation loss: 0.3694146453819316 ROC AUC: 0.9243607507242725
6 26 0.3603805601596832
Validation loss: 0.4292656768346708 ROC AUC: 0.9466627478971603
Validation loss: 0.33065095363631364 ROC AUC: 0.9562077507662594
8 18 0.37692826986312866
Validation loss: 0.29934148152497625 ROC AUC: 0.9579665318423348
Validation loss: 0.334046733559594 ROC AUC: 0.9578802256091586
10 10 0.3525397479534149
Validation loss: 0.31195998970684685 ROC AUC: 0.9581811311248268
Validation loss: 0.26678175596645015 ROC AUC: 0.9646051139942058
12 2 0.2215161770582199
Validation loss: 0.3124666524886055 ROC AUC: 0.9629512999584797
13 23 0.4090113043785095
Validation loss: 0.26361480249055774 ROC AUC: 0.9677168035903393
Validation loss: 0.2470204545663706 ROC AUC: 0.9727925431414536
15 15 0.4410191774368286
Validation loss: 0.2486860286726035 ROC AUC: 0.9697928183883594
Validation loss: 0.24305569903510693 ROC AUC: 0.9684818966844411
17 7 0.25966906547546387
Validation loss: 0.22851047357524187 ROC AUC: 0.9741057974462686
18 28 0.23931486904621124
Validation loss: 0.24977213639934945 ROC AUC: 0.9734316757871362
Validation loss: 0.23801501224030686 ROC AUC: 0.9729908142176691
20 20 0.2661971151828766
Validation loss: 0.20671778643749186 ROC AUC: 0.9774367515266873
Validation loss: 0.2554502268975548 ROC AUC: 0.970371303410729
22 12 0.27703404426574707
Validation loss: 0.22135139921314 ROC AUC: 0.9761654840380122
Validation loss: 0.21155547770645397 ROC AUC: 0.9765526957868562
24 4 0.16732217371463776
Validation loss: 0.23569310232836022 ROC AUC: 0.9734923234104491
25 25 0.2273438721895218
Validation loss: 0.25637382130514724 ROC AUC: 0.9837254435440606
Validation loss: 0.17397283592118556 ROC AUC: 0.9824798346652485
27 17 0.20850969851016998
Validation loss: 0.21769965699115532 ROC AUC: 0.9828367226024362
Validation loss: 0.20723387689106407 ROC AUC: 0.9805437759210274
29 9 0.23005247116088867
Validation loss: 0.20762477284116312 ROC AUC: 0.9848520897771433
Validation loss: 0.19453567247153875 ROC AUC: 0.9792771736341457
31 1 0.344979852437973
Validation loss: 0.1814602522851324 ROC AUC: 0.9840496750686951
32 22 0.29065436124801636
Validation loss: 0.17158593733032632 ROC AUC: 0.9850713542614286
Validation loss: 0.1761612196977916 ROC AUC: 0.9839866948444855
34 14 0.24404901266098022
Validation loss: 0.1887147852076825 ROC AUC: 0.9860277206290559
Validation loss: 0.15568860283938135 ROC AUC: 0.986876787355437
36 6 0.32135653495788574
Validation loss: 0.16206079504209256 ROC AUC: 0.9866318642612887
37 27 0.31222689151763916
Validation loss: 0.17141479416297786 ROC AUC: 0.9877515126916815
Validation loss: 0.17200664427638312 ROC AUC: 0.988458290763367
39 19 0.2745850682258606
Validation loss: 0.15674927837132893 ROC AUC: 0.9885609252028197
Validation loss: 0.1470937928261304 ROC AUC: 0.9881830438575622
41 11 0.10736631602048874
Validation loss: 0.18408688146532484 ROC AUC: 0.9839400428265525
Validation loss: 0.14987769665007458 ROC AUC: 0.9891767318395357
43 3 0.4342876076698303
Validation loss: 0.18894882097872492 ROC AUC: 0.9883999757409506
44 24 0.32180431485176086
Validation loss: 0.15751854531450868 ROC AUC: 0.98798244018045
Validation loss: 0.1615328494274333 ROC AUC: 0.988952802153457
46 16 0.26854225993156433
Validation loss: 0.1691484587431984 ROC AUC: 0.9892327142610555
Validation loss: 0.1624417264762759 ROC AUC: 0.9864429235886599
48 8 0.13651981949806213
Validation loss: 0.16157154297983156 ROC AUC: 0.9882320284763918
Validation loss: 0.1803857173376413 ROC AUC: 0.9875742350235359
50 0 0.16316939890384674
Validation loss: 0.1619709225826078 ROC AUC: 0.9902007436331658
51 21 0.08245610445737839
Validation loss: 0.1501389237897185 ROC AUC: 0.990548301166767
Validation loss: 0.14974623799452771 ROC AUC: 0.991357713677905
53 13 0.22264719009399414
Validation loss: 0.14846614057894145 ROC AUC: 0.9900164681623305
Validation loss: 0.16196628085480397 ROC AUC: 0.9884302995526071
55 5 0.05289314687252045
Validation loss: 0.19904145418181532 ROC AUC: 0.9911571100007931
56 26 0.36436039209365845
Validation loss: 0.17977662947728876 ROC AUC: 0.9898345252923916
Validation loss: 0.16682828566940505 ROC AUC: 0.9916329605837101
58 18 0.17126233875751495
Validation loss: 0.14274031866832634 ROC AUC: 0.9911174557855501
Validation loss: 0.14618556240078698 ROC AUC: 0.9910568081622371
60 10 0.09729829430580139
Validation loss: 0.1358289542903653 ROC AUC: 0.9901424286107495
Validation loss: 0.1878099749850403 ROC AUC: 0.988927143543594
62 2 0.2789366543292999
Validation loss: 0.11418886011220981 ROC AUC: 0.9920971481621438
63 23 0.04130023717880249
Validation loss: 0.12235309846586594 ROC AUC: 0.9923444038571888
Validation loss: 0.15487650291064903 ROC AUC: 0.9882390262790817
65 15 0.3237176835536957
Validation loss: 0.12851672926937788 ROC AUC: 0.9923957210769151
Validation loss: 0.14107844340524459 ROC AUC: 0.9924750295074014
67 7 0.1587093323469162
Validation loss: 0.1393362414373435 ROC AUC: 0.9928342500454856
68 28 0.13625936210155487
Validation loss: 0.14429343245585588 ROC AUC: 0.9907349092384992
Validation loss: 0.13879948587319763 ROC AUC: 0.992423712287675
70 20 0.48988059163093567
Validation loss: 0.11481055269745977 ROC AUC: 0.9929695408974916
Validation loss: 0.14546735549333545 ROC AUC: 0.9936553255611072
72 12 0.14424903690814972
Validation loss: 0.11478453144012724 ROC AUC: 0.993153816368327
Validation loss: 0.1237412782035945 ROC AUC: 0.9939072464579456
74 4 0.07803815603256226
Validation loss: 0.11849296786550827 ROC AUC: 0.9947843043950867
75 25 0.2067718803882599
Validation loss: 0.13062811945414182 ROC AUC: 0.9943014560094796
Validation loss: 0.14184950668662466 ROC AUC: 0.9941101827359543
77 17 0.2723340094089508
Validation loss: 0.1065876481664361 ROC AUC: 0.9951995073546906
Validation loss: 0.11191706669961402 ROC AUC: 0.9939049138570488
79 9 0.1702389121055603
Validation loss: 0.11567036336042454 ROC AUC: 0.99476797618881
Validation loss: 0.110648268081457 ROC AUC: 0.9949405886551622
81 1 0.12151527404785156
Validation loss: 0.11534272092464933 ROC AUC: 0.994721324170877
82 22 0.19996778666973114
Validation loss: 0.10063499331345568 ROC AUC: 0.994875275830056
Validation loss: 0.1060133322140053 ROC AUC: 0.9955820539017416
84 14 0.10396375507116318
Validation loss: 0.10405927639028166 ROC AUC: 0.9951575205385509
Validation loss: 0.09811136863530326 ROC AUC: 0.9954490956506323
86 6 0.32022467255592346
Validation loss: 0.09877567754386568 ROC AUC: 0.9958852920183064
87 27 0.15340042114257812
Validation loss: 0.09209624483183702 ROC AUC: 0.9959412744398259
Validation loss: 0.11522221137200267 ROC AUC: 0.9950105666820619
89 19 0.23815351724624634
Validation loss: 0.0825676395201786 ROC AUC: 0.9960719000900383
Validation loss: 0.09768619484893704 ROC AUC: 0.995712679551954
91 11 0.09237424284219742
Validation loss: 0.10066549586168376 ROC AUC: 0.9948076304040531
Validation loss: 0.09455876873069911 ROC AUC: 0.9961768671303878
93 3 0.14693544805049896
Validation loss: 0.0868701252354144 ROC AUC: 0.9963914664128797
94 24 0.231410413980484
Validation loss: 0.08549830233416728 ROC AUC: 0.9964217902245361
Validation loss: 0.09490644988115096 ROC AUC: 0.996020582870312
96 16 0.25676262378692627
Validation loss: 0.1085640662400048 ROC AUC: 0.9952368289690371
Validation loss: 0.10639301857249268 ROC AUC: 0.996295829776117
98 8 0.09932851791381836
Validation loss: 0.10519192097447089 ROC AUC: 0.9957383381618172
Validation loss: 0.08871999271133549 ROC AUC: 0.996918634215523
Loaded trained model with success.
Test loss: 0.657057360085574 Test ROC AUC: 0.8935574229691877
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.46062567421790723, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 5}}
Running on: cpu
926
926
55
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.6653014421463013
Validation loss: 1.608140864331058 ROC AUC: 0.5759766181681412
1 21 1.5174404382705688
Validation loss: 1.5025046541160436 ROC AUC: 0.6525836291052298
Validation loss: 1.4378557403453225 ROC AUC: 0.7033156848802077
3 13 1.302722692489624
Validation loss: 1.290368546934931 ROC AUC: 0.7788446084940372
Validation loss: 1.1933647311789428 ROC AUC: 0.8066422562939506
5 5 1.338261365890503
Validation loss: 1.1803621504270747 ROC AUC: 0.8175782697836237
6 26 1.0938701629638672
Validation loss: 1.07669350601427 ROC AUC: 0.857735964798386
Validation loss: 0.9879069871572902 ROC AUC: 0.874109720668369
8 18 1.2512781620025635
Validation loss: 0.9983428876291855 ROC AUC: 0.8788696153415853
Validation loss: 0.9586923641211014 ROC AUC: 0.8757398144207478
10 10 1.0050835609436035
Validation loss: 0.8917086322673197 ROC AUC: 0.8953770039896257
Validation loss: 0.8865602329276808 ROC AUC: 0.896393811063797
12 2 1.192094087600708
Validation loss: 0.9598138305332439 ROC AUC: 0.8725668582379088
13 23 0.9847775101661682
Validation loss: 0.8941829778720699 ROC AUC: 0.8914367910827528
Validation loss: 0.830317174126726 ROC AUC: 0.9059210767552985
15 15 1.0088386535644531
Validation loss: 0.8250360228845419 ROC AUC: 0.9108195961857646
Validation loss: 0.8267639301250614 ROC AUC: 0.9057686127835332
17 7 0.8350577354431152
Validation loss: 0.8453589634040519 ROC AUC: 0.900612599082206
18 28 0.8585720658302307
Validation loss: 0.8093629998213272 ROC AUC: 0.9134786442852463
Validation loss: 0.8515896050512919 ROC AUC: 0.8981820787351753
20 20 1.4729492664337158
Validation loss: 0.805827928542061 ROC AUC: 0.907733116219559
Validation loss: 0.7845127910826171 ROC AUC: 0.9178599560307962
22 12 1.098596453666687
Validation loss: 0.8040960194225187 ROC AUC: 0.9161548319494314
Validation loss: 0.791405924066869 ROC AUC: 0.9101048933123357
24 4 1.0888792276382446
Validation loss: 0.7524447137284742 ROC AUC: 0.9202202070279437
25 25 0.8348264694213867
Validation loss: 0.7589818225051106 ROC AUC: 0.9175324964306404
Validation loss: 0.7922238986898962 ROC AUC: 0.9163830290436792
27 17 0.9379765391349792
Validation loss: 0.7602343067494634 ROC AUC: 0.9171644422468068
Validation loss: 0.7334074023990342 ROC AUC: 0.9241022821848457
29 9 0.9047395586967468
Validation loss: 0.7212601866629417 ROC AUC: 0.929323658108091
Validation loss: 0.732910321160475 ROC AUC: 0.9293325258253775
31 1 0.8865106105804443
Validation loss: 0.7248177176932794 ROC AUC: 0.9280919851805521
32 22 0.9933876395225525
Validation loss: 0.6995994197627123 ROC AUC: 0.9335331950876273
Validation loss: 0.7014463805225446 ROC AUC: 0.936863493672589
34 14 0.6155603528022766
Validation loss: 0.7123260057770665 ROC AUC: 0.9340947762278408
Validation loss: 0.7549877222104412 ROC AUC: 0.923232024199898
36 6 0.8786225914955139
Validation loss: 0.6919035825307117 ROC AUC: 0.9352863041109452
37 27 0.7794541716575623
Validation loss: 0.6703236624437583 ROC AUC: 0.9385558160032591
Validation loss: 0.6415092180408618 ROC AUC: 0.9436987578249566
39 19 0.8822212219238281
Validation loss: 0.798672052490531 ROC AUC: 0.9102659331842361
Validation loss: 0.6884564793393112 ROC AUC: 0.9359943600213722
41 11 0.7929732203483582
Validation loss: 0.6841259693996438 ROC AUC: 0.9373768943647829
Validation loss: 0.6523087464964931 ROC AUC: 0.9434621802443814
43 3 1.0369102954864502
Validation loss: 0.6755210172795323 ROC AUC: 0.9399676119962121
44 24 1.2920094728469849
Validation loss: 0.6491259255368045 ROC AUC: 0.9467702787222991
Validation loss: 0.6705970619976135 ROC AUC: 0.9430508581631212
46 16 0.6860300302505493
Validation loss: 0.6474300495491687 ROC AUC: 0.9436913913273454
Validation loss: 0.6448580398672857 ROC AUC: 0.946091266544206
48 8 0.8080409169197083
Validation loss: 0.6935242973187572 ROC AUC: 0.9360417955819091
Validation loss: 0.6580097461622169 ROC AUC: 0.9406556646009567
50 0 0.9753612875938416
Validation loss: 0.6587872667395013 ROC AUC: 0.9437182691627983
51 21 0.9714274406433105
Validation loss: 0.6484175115888113 ROC AUC: 0.9427071515860275
Validation loss: 0.6187757717095492 ROC AUC: 0.9482643804014013
53 13 1.199617624282837
Validation loss: 0.6422996120627962 ROC AUC: 0.9451949725539572
Validation loss: 0.5983340142870053 ROC AUC: 0.9525418827056464
55 5 0.9024823307991028
Validation loss: 0.6517410262872024 ROC AUC: 0.9435010637177111
56 26 0.7199510335922241
Validation loss: 0.6175847201573926 ROC AUC: 0.9487582347519423
Validation loss: 0.6080303891173706 ROC AUC: 0.9532703758352568
58 18 0.809455394744873
Validation loss: 0.6114358517057695 ROC AUC: 0.9499727494637658
Validation loss: 0.6010988437073792 ROC AUC: 0.9534466114365001
60 10 0.9683655500411987
Validation loss: 0.709499960069265 ROC AUC: 0.9282996657436027
Validation loss: 0.6001171328079108 ROC AUC: 0.9551217908329466
62 2 0.6805003881454468
Validation loss: 0.5873403317470015 ROC AUC: 0.9570507105509665
63 23 0.7644314765930176
Validation loss: 0.5849835129844962 ROC AUC: 0.9565831275819239
Validation loss: 0.6116379365550262 ROC AUC: 0.9505277833128606
65 15 1.4137109518051147
Validation loss: 0.6104313538089942 ROC AUC: 0.9530346243764708
Validation loss: 0.6040422213515246 ROC AUC: 0.9523722237219591
67 7 0.8131951689720154
Validation loss: 0.6030376628202188 ROC AUC: 0.949578927137023
68 28 0.7883273363113403
Validation loss: 0.5839758972369826 ROC AUC: 0.9547428921425501
Validation loss: 0.645739320158701 ROC AUC: 0.9472364432872279
70 20 0.6181045770645142
Validation loss: 0.5689106535963054 ROC AUC: 0.9570670647999122
Validation loss: 0.5760422256286407 ROC AUC: 0.955599152287119
72 12 0.6722774505615234
Validation loss: 0.5679909608791508 ROC AUC: 0.957448446850057
Validation loss: 0.5795680386201352 ROC AUC: 0.9569690918269395
74 4 0.9458554983139038
Validation loss: 0.5776869991943079 ROC AUC: 0.9544897627575264
75 25 0.8006275296211243
Validation loss: 0.6318956388253115 ROC AUC: 0.9477772505362342
Validation loss: 0.5578588401782075 ROC AUC: 0.9575006056433597
77 17 0.5765702724456787
Validation loss: 0.5498618202899496 ROC AUC: 0.9624208228024468
Validation loss: 0.5405014331732146 ROC AUC: 0.9626297003525263
79 9 0.6558513641357422
Validation loss: 0.5549752235283862 ROC AUC: 0.9569670725177245
Validation loss: 0.5491463025754265 ROC AUC: 0.9627172885993913
81 1 0.849747896194458
Validation loss: 0.524301172461417 ROC AUC: 0.9656627678055221
82 22 0.8809741735458374
Validation loss: 0.5709702426619973 ROC AUC: 0.958951602231472
Validation loss: 0.5416209228481639 ROC AUC: 0.959500721666665
84 14 0.7108252048492432
Validation loss: 0.5068004346305814 ROC AUC: 0.9660455234811021
Validation loss: 0.5666744380738771 ROC AUC: 0.9547314463453256
86 6 0.49875035881996155
Validation loss: 0.5065200151171592 ROC AUC: 0.968284048870143
87 27 0.6828359365463257
Validation loss: 0.5089024958033799 ROC AUC: 0.9678308498882112
Validation loss: 0.5324583679888213 ROC AUC: 0.9633694949118785
89 19 0.6321914792060852
Validation loss: 0.5314759164083082 ROC AUC: 0.9657564570085417
Validation loss: 0.5308703518840716 ROC AUC: 0.9619541394195453
91 11 0.8978577256202698
Validation loss: 0.5340484814561469 ROC AUC: 0.9627283692092077
Validation loss: 0.5135491741398756 ROC AUC: 0.9637438285675843
93 3 0.6178946495056152
Validation loss: 0.5164680086382007 ROC AUC: 0.966354688920944
94 24 0.6886624693870544
Validation loss: 0.5698690664176035 ROC AUC: 0.9560258720871664
Validation loss: 0.4971228194931928 ROC AUC: 0.9656185739395436
96 16 0.5221558809280396
Validation loss: 0.48464709790685007 ROC AUC: 0.9696260287570464
Validation loss: 0.4873304804766925 ROC AUC: 0.9680440555173648
98 8 0.6038898825645447
Validation loss: 0.6131681758693176 ROC AUC: 0.9436073983084331
Validation loss: 0.4970482105055329 ROC AUC: 0.9642179379542538
Loaded trained model with success.
Test loss: 1.5265228856693616 Test ROC AUC: 0.8085277777777777
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7842502696871629, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 5}}
Running on: cpu
926
926
55
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.67528235912323
Validation loss: 1.5300441820729629 ROC AUC: 0.640512891577943
1 21 1.5187844038009644
Validation loss: 1.51699077671084 ROC AUC: 0.6803398414139045
Validation loss: 1.4016964855255885 ROC AUC: 0.7100771429850623
3 13 1.3541922569274902
Validation loss: 1.2751916260750196 ROC AUC: 0.7669855587126871
Validation loss: 1.2228986895110128 ROC AUC: 0.8040237285261507
5 5 1.247023105621338
Validation loss: 1.2724655587266382 ROC AUC: 0.7979049699496639
6 26 1.2919455766677856
Validation loss: 1.063615377340667 ROC AUC: 0.8556912508039893
Validation loss: 1.0374141791211864 ROC AUC: 0.868367761136103
8 18 1.1811838150024414
Validation loss: 0.9968664718240693 ROC AUC: 0.873917623976667
Validation loss: 1.0044826565241969 ROC AUC: 0.8721431744737288
10 10 1.1329320669174194
Validation loss: 0.9510070968652647 ROC AUC: 0.8876480401103747
Validation loss: 0.9374429319641245 ROC AUC: 0.8943002059633756
12 2 0.9145860075950623
Validation loss: 0.9999880618204566 ROC AUC: 0.8828216000505422
13 23 1.19269597530365
Validation loss: 0.8836066319927026 ROC AUC: 0.9023760154460418
Validation loss: 0.8640427603577434 ROC AUC: 0.9069972061831043
15 15 1.222569465637207
Validation loss: 0.8653835812603681 ROC AUC: 0.9063926868108505
Validation loss: 0.968247261727088 ROC AUC: 0.8941831583292427
17 7 0.8955579996109009
Validation loss: 0.86470589189756 ROC AUC: 0.9039218664618511
18 28 0.9278019070625305
Validation loss: 0.8789313741945551 ROC AUC: 0.9020526612653621
Validation loss: 0.9128940108012947 ROC AUC: 0.8887154860566714
20 20 0.809571385383606
Validation loss: 0.9048530280461322 ROC AUC: 0.8936888079101539
Validation loss: 0.8428040190597847 ROC AUC: 0.9053425585107601
22 12 0.9644410014152527
Validation loss: 0.810019192891296 ROC AUC: 0.9088855622618601
Validation loss: 0.8350757538113687 ROC AUC: 0.9063520695603682
24 4 1.0405399799346924
Validation loss: 0.8202421828686033 ROC AUC: 0.9084365285525655
25 25 0.968844473361969
Validation loss: 0.7950825514855189 ROC AUC: 0.9164042581932712
Validation loss: 0.8164785625352715 ROC AUC: 0.9172480711468637
27 17 0.9429665803909302
Validation loss: 0.8339334363298848 ROC AUC: 0.9030723033507752
Validation loss: 0.9145173484511818 ROC AUC: 0.8853378331004972
29 9 1.0412652492523193
Validation loss: 0.7668096255792655 ROC AUC: 0.9227049552973691
Validation loss: 0.7588424726387337 ROC AUC: 0.9231493450886651
31 1 0.9446228742599487
Validation loss: 0.7457577358311762 ROC AUC: 0.921905205460807
32 22 1.037309169769287
Validation loss: 0.7364224472262174 ROC AUC: 0.9269424365620385
Validation loss: 0.7418262313560585 ROC AUC: 0.9271111859281363
34 14 0.9987879991531372
Validation loss: 0.7809849956895569 ROC AUC: 0.920410058844903
Validation loss: 0.7754444158102987 ROC AUC: 0.9192775288128809
36 6 0.8853449821472168
Validation loss: 0.7247679561827147 ROC AUC: 0.9303676970651893
37 27 0.9416833519935608
Validation loss: 0.701374265854096 ROC AUC: 0.9368993948181188
Validation loss: 0.7163536549901859 ROC AUC: 0.9331267353134262
39 19 0.9343056082725525
Validation loss: 0.7011519945980921 ROC AUC: 0.9362648793699122
Validation loss: 0.7337421015323367 ROC AUC: 0.9292876314214291
41 11 0.954383909702301
Validation loss: 0.660133778405241 ROC AUC: 0.9434316577911828
Validation loss: 0.8018854792123222 ROC AUC: 0.9099398843899053
43 3 0.7892541885375977
Validation loss: 0.6695593291688429 ROC AUC: 0.9425731238805651
44 24 0.786750853061676
Validation loss: 0.7553021009230975 ROC AUC: 0.9257686009518864
Validation loss: 0.678488556947358 ROC AUC: 0.942185654277988
46 16 0.9894936084747314
Validation loss: 0.6596549307810823 ROC AUC: 0.9421197308861531
Validation loss: 0.6769350640974601 ROC AUC: 0.9402024050034645
48 8 0.9047185778617859
Validation loss: 0.6259312824090665 ROC AUC: 0.9478416022353462
Validation loss: 0.6387078701548649 ROC AUC: 0.9474352362013694
50 0 0.6654466390609741
Validation loss: 0.7717091112878358 ROC AUC: 0.9121704547976961
51 21 0.9087398052215576
Validation loss: 0.6399442778807737 ROC AUC: 0.9435506099808195
Validation loss: 0.6338556151410674 ROC AUC: 0.9470679999447953
53 13 0.6537244915962219
Validation loss: 0.6520872596273154 ROC AUC: 0.9462831054875845
Validation loss: 0.6905869996058503 ROC AUC: 0.9322113279559116
55 5 1.1847888231277466
Validation loss: 0.6158813312810647 ROC AUC: 0.9523587964362148
56 26 0.6936208605766296
Validation loss: 0.5984055090928954 ROC AUC: 0.9530109143865824
Validation loss: 0.6155057989752833 ROC AUC: 0.950228183350406
58 18 1.0563594102859497
Validation loss: 0.6117213892370269 ROC AUC: 0.9531341990942842
Validation loss: 0.7031338198138622 ROC AUC: 0.9331924698156817
60 10 0.7080532312393188
Validation loss: 0.6453235538165462 ROC AUC: 0.9461805568935411
Validation loss: 0.6219706585546292 ROC AUC: 0.9502236458910674
62 2 1.0713579654693604
Validation loss: 0.6361394883746977 ROC AUC: 0.9452614747817073
63 23 0.7391242384910583
Validation loss: 0.5718753385492329 ROC AUC: 0.9582668694385224
Validation loss: 0.666050334342355 ROC AUC: 0.9390925362694487
65 15 0.619745671749115
Validation loss: 0.6537489718546363 ROC AUC: 0.9440570298943459
Validation loss: 0.6061982751922526 ROC AUC: 0.9513340073612901
67 7 0.592225193977356
Validation loss: 0.6003771206730127 ROC AUC: 0.9521816039628576
68 28 0.6576918959617615
Validation loss: 0.6018858360162821 ROC AUC: 0.9513016439883686
Validation loss: 0.5616687322538306 ROC AUC: 0.9593692854466992
70 20 0.7655850052833557
Validation loss: 0.6711677611517854 ROC AUC: 0.9372089864446533
Validation loss: 0.5946285015305999 ROC AUC: 0.9557555377863742
72 12 0.8811574578285217
Validation loss: 0.5791202788734024 ROC AUC: 0.9573246888714271
Validation loss: 0.6719450010851702 ROC AUC: 0.9354226568500194
74 4 0.6016503572463989
Validation loss: 0.5949052505307785 ROC AUC: 0.9542703118474224
75 25 0.748191773891449
Validation loss: 0.550422605247786 ROC AUC: 0.9621003538838867
Validation loss: 0.5850452852815583 ROC AUC: 0.9563134816946128
77 17 0.6340948343276978
Validation loss: 0.5476698495656831 ROC AUC: 0.9621649971348477
Validation loss: 0.5779216977612761 ROC AUC: 0.9567513767847334
79 9 0.7919647693634033
Validation loss: 0.5367853707165234 ROC AUC: 0.9636379730105376
Validation loss: 0.5407124397306668 ROC AUC: 0.9620358481277987
81 1 0.7721359729766846
Validation loss: 0.5598722001775037 ROC AUC: 0.9609680432631181
82 22 0.8266956210136414
Validation loss: 0.5048759898923129 ROC AUC: 0.9662517471368112
Validation loss: 0.5585741674925802 ROC AUC: 0.9568358169065163
84 14 0.7816381454467773
Validation loss: 0.5795203883756057 ROC AUC: 0.955179223137318
Validation loss: 0.5323273563359263 ROC AUC: 0.9648887634032957
86 6 0.8822543025016785
Validation loss: 0.6175743489492017 ROC AUC: 0.9447408437634784
87 27 0.7660092711448669
Validation loss: 0.5740795914349237 ROC AUC: 0.9585132223027013
Validation loss: 0.5525180487601855 ROC AUC: 0.9582235510405216
89 19 0.6371891498565674
Validation loss: 0.5407365537359184 ROC AUC: 0.9634360067442067
Validation loss: 0.5491662361451926 ROC AUC: 0.9599365648769196
91 11 0.7564350366592407
Validation loss: 0.5561047200893995 ROC AUC: 0.9585261575352313
Validation loss: 0.5497150119900961 ROC AUC: 0.958885431340328
93 3 0.736743688583374
Validation loss: 0.5058239387513237 ROC AUC: 0.9687012764868654
94 24 0.6951608657836914
Validation loss: 0.5726850112622551 ROC AUC: 0.9561070132715637
Validation loss: 0.4918634341808426 ROC AUC: 0.9691083132192121
96 16 0.6160542964935303
Validation loss: 0.5645217334220013 ROC AUC: 0.9562459270612107
Validation loss: 0.5623529991114886 ROC AUC: 0.9572290799479969
98 8 1.0366486310958862
Validation loss: 0.5253769418075842 ROC AUC: 0.9681055364289273
Validation loss: 0.4982000016496712 ROC AUC: 0.9710655259757314
Loaded trained model with success.
Test loss: 1.5372425491159611 Test ROC AUC: 0.8162182539682539
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8921251348435815, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 5}}
Running on: cpu
926
926
55
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.6363112926483154
Validation loss: 1.5640123356495768 ROC AUC: 0.6184273875681601
1 21 1.5597227811813354
Validation loss: 1.4911794057417638 ROC AUC: 0.6359010365308565
Validation loss: 1.40005156262647 ROC AUC: 0.7245753454486571
3 13 1.3790568113327026
Validation loss: 1.2636854455486488 ROC AUC: 0.7684616377002318
Validation loss: 1.2174197427654885 ROC AUC: 0.8261997207723969
5 5 1.406825304031372
Validation loss: 1.1484335506451568 ROC AUC: 0.8213953740685653
6 26 1.0268776416778564
Validation loss: 1.0709924100542172 ROC AUC: 0.8509111937200311
Validation loss: 1.072973633687903 ROC AUC: 0.8497665421374462
8 18 1.3368284702301025
Validation loss: 1.0082534108769559 ROC AUC: 0.8717837680928635
Validation loss: 0.9892780597987494 ROC AUC: 0.8790146700355479
10 10 1.038030982017517
Validation loss: 0.9402619376295843 ROC AUC: 0.8812310222112819
Validation loss: 0.9448437641815285 ROC AUC: 0.8854907161426164
12 2 0.9590002298355103
Validation loss: 0.9051437972688778 ROC AUC: 0.896229867013463
13 23 1.0168943405151367
Validation loss: 0.8492186670684403 ROC AUC: 0.9042920077386654
Validation loss: 0.8604459135630218 ROC AUC: 0.8979034780876244
15 15 1.0676883459091187
Validation loss: 0.9152757444340518 ROC AUC: 0.8841636484840695
Validation loss: 0.9272272026822067 ROC AUC: 0.8827737092320792
17 7 0.9293453693389893
Validation loss: 0.8513188100788043 ROC AUC: 0.9044692229210554
18 28 1.143897533416748
Validation loss: 0.8352639070082432 ROC AUC: 0.90407611427667
Validation loss: 0.7973954931191183 ROC AUC: 0.9143732527778148
20 20 0.7778432369232178
Validation loss: 0.7865283227893756 ROC AUC: 0.9143669222591585
Validation loss: 0.8583232623969504 ROC AUC: 0.8977657402875853
22 12 0.8311141729354858
Validation loss: 0.7813853512057475 ROC AUC: 0.914850393924306
Validation loss: 0.7784266605747956 ROC AUC: 0.9157374862204941
24 4 1.0016387701034546
Validation loss: 0.7596283002754525 ROC AUC: 0.9212706903109507
25 25 1.0023300647735596
Validation loss: 0.7919016067204157 ROC AUC: 0.9168881244645236
Validation loss: 0.7502482387983516 ROC AUC: 0.9225722055130561
27 17 0.9913244247436523
Validation loss: 0.7520258825747035 ROC AUC: 0.9256830886185945
Validation loss: 0.7679765158801563 ROC AUC: 0.9157064709002732
29 9 0.8430681824684143
Validation loss: 0.7641408108738019 ROC AUC: 0.9197150710952867
Validation loss: 0.7836290282513102 ROC AUC: 0.916781975699555
31 1 0.9011355042457581
Validation loss: 0.7621634749305428 ROC AUC: 0.921749132345582
32 22 0.7243775725364685
Validation loss: 0.7100428811417285 ROC AUC: 0.9329211582796928
Validation loss: 0.7470584222101496 ROC AUC: 0.9239624590364853
34 14 0.7605715394020081
Validation loss: 0.7000555766838931 ROC AUC: 0.9321082165758117
Validation loss: 0.6990649227704652 ROC AUC: 0.9315076685940709
36 6 0.9202147722244263
Validation loss: 0.70776884949748 ROC AUC: 0.9309377329652989
37 27 0.993699312210083
Validation loss: 0.6884605641241465 ROC AUC: 0.9374459242614016
Validation loss: 0.7385176808993709 ROC AUC: 0.920954037184605
39 19 0.9763247966766357
Validation loss: 0.6577590718768843 ROC AUC: 0.9411201590791352
Validation loss: 0.663520345806303 ROC AUC: 0.9431566696244822
41 11 0.8909162282943726
Validation loss: 0.6953651639864202 ROC AUC: 0.9338876674578067
Validation loss: 0.6842532665116741 ROC AUC: 0.9388954874645534
43 3 0.9631841778755188
Validation loss: 0.7780706260683212 ROC AUC: 0.9155027258242848
44 24 0.8774021863937378
Validation loss: 0.6868496365990031 ROC AUC: 0.938814096857177
Validation loss: 0.7626769253038691 ROC AUC: 0.9186971200954221
46 16 0.699558675289154
Validation loss: 0.6671424877566344 ROC AUC: 0.943245021456201
Validation loss: 0.648011577824537 ROC AUC: 0.9398171834271253
48 8 0.8559118509292603
Validation loss: 0.660513934126168 ROC AUC: 0.9425996212471178
Validation loss: 0.665361124032517 ROC AUC: 0.9399552178225073
50 0 0.8352378010749817
Validation loss: 0.6425947664108441 ROC AUC: 0.9469538046252917
51 21 0.6272714734077454
Validation loss: 0.6673189699006132 ROC AUC: 0.9364571787776557
Validation loss: 0.6327183267210266 ROC AUC: 0.94922231089738
53 13 0.604986310005188
Validation loss: 0.6173643934546486 ROC AUC: 0.9479617875252263
Validation loss: 0.5995238279163452 ROC AUC: 0.9526350160810522
55 5 0.9445717930793762
Validation loss: 0.6374643768141646 ROC AUC: 0.9440204799061978
56 26 0.8312822580337524
Validation loss: 0.6408235402395607 ROC AUC: 0.9458133817643123
Validation loss: 0.6050466338965085 ROC AUC: 0.9524746124531338
58 18 0.8149228096008301
Validation loss: 0.6075001295905391 ROC AUC: 0.9530192054000098
Validation loss: 0.5883873829831315 ROC AUC: 0.954230591879359
60 10 0.9053632020950317
Validation loss: 0.5901260692666468 ROC AUC: 0.952019752519473
Validation loss: 0.5828494971565757 ROC AUC: 0.9572131951281481
62 2 0.6628671288490295
Validation loss: 0.6253643513498245 ROC AUC: 0.9530506317507379
63 23 1.0019409656524658
Validation loss: 0.5931887330555762 ROC AUC: 0.9560146984196585
Validation loss: 0.604582445796571 ROC AUC: 0.953132630986811
65 15 1.0181416273117065
Validation loss: 0.5797665180964294 ROC AUC: 0.9572480985923189
Validation loss: 0.5923748245507028 ROC AUC: 0.9550171176635109
67 7 0.6308609843254089
Validation loss: 0.6500164321895294 ROC AUC: 0.9375783084314367
68 28 0.7832887768745422
Validation loss: 0.6026086581963442 ROC AUC: 0.9520038568144354
Validation loss: 0.5751360142462711 ROC AUC: 0.956756995121045
70 20 0.8182236552238464
Validation loss: 0.57623568273775 ROC AUC: 0.9583317450775896
Validation loss: 0.588683276145556 ROC AUC: 0.9541972076887166
72 12 0.7558419108390808
Validation loss: 0.5754514837368003 ROC AUC: 0.9585374177293172
Validation loss: 0.5994471459615308 ROC AUC: 0.9547796978681422
74 4 0.7740157246589661
Validation loss: 0.5472082711965425 ROC AUC: 0.9610809728268126
75 25 0.6866936087608337
Validation loss: 0.5563765450764938 ROC AUC: 0.9597332513657284
Validation loss: 0.5543903389837006 ROC AUC: 0.9623021433832907
77 17 0.6811015009880066
Validation loss: 0.5533266238723409 ROC AUC: 0.9614813501714824
Validation loss: 0.5455493341254364 ROC AUC: 0.9622907389497832
79 9 0.7971997261047363
Validation loss: 0.5794513598889048 ROC AUC: 0.9559952427062093
Validation loss: 0.5160722036083625 ROC AUC: 0.9646794060084876
81 1 0.9882848858833313
Validation loss: 0.5256734480095734 ROC AUC: 0.9642253859845212
82 22 0.6402657628059387
Validation loss: 0.5636787046366583 ROC AUC: 0.9577107613707108
Validation loss: 0.5349257863881006 ROC AUC: 0.9644581644208176
84 14 0.7147945761680603
Validation loss: 0.5530416684840719 ROC AUC: 0.9633008864641525
Validation loss: 0.5787105193405893 ROC AUC: 0.9554834685999444
86 6 0.6335196495056152
Validation loss: 0.5128668491320271 ROC AUC: 0.9638926113815192
87 27 0.9334815740585327
Validation loss: 0.5268255065378309 ROC AUC: 0.9649256776819654
Validation loss: 0.5005761911493141 ROC AUC: 0.9690771844823483
89 19 0.707640528678894
Validation loss: 0.5090746430289925 ROC AUC: 0.9654554028697968
Validation loss: 0.5373727712080236 ROC AUC: 0.9648506156833457
91 11 0.6847661733627319
Validation loss: 0.5111617854038016 ROC AUC: 0.9660386002023023
Validation loss: 0.5322785613088834 ROC AUC: 0.9648383747124176
93 3 0.6908841133117676
Validation loss: 0.5166472342050359 ROC AUC: 0.9655453123511292
94 24 0.6652904152870178
Validation loss: 0.5769479691853534 ROC AUC: 0.9567636825540905
Validation loss: 0.4846988301040287 ROC AUC: 0.9697408534107437
96 16 0.5706447958946228
Validation loss: 0.5351824071700836 ROC AUC: 0.9604966622596594
Validation loss: 0.524924562379042 ROC AUC: 0.9647765086786115
98 8 0.7594533562660217
Validation loss: 0.5026331103002536 ROC AUC: 0.969692636720531
Validation loss: 0.49223546217121267 ROC AUC: 0.9704961556074858
Loaded trained model with success.
Test loss: 1.7909463448957963 Test ROC AUC: 0.8002738095238096
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9460625674217907, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 5}}
Running on: cpu
926
926
55
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.704655647277832
Validation loss: 1.590491177196379 ROC AUC: 0.576351968383882
1 21 1.5684958696365356
Validation loss: 1.516493923205794 ROC AUC: 0.650618227421967
Validation loss: 1.4645550899835178 ROC AUC: 0.6948453248353823
3 13 1.3982239961624146
Validation loss: 1.3397613181923687 ROC AUC: 0.7435048131761415
Validation loss: 1.1811997903345985 ROC AUC: 0.8076699629822434
5 5 1.4589394330978394
Validation loss: 1.2447703904261085 ROC AUC: 0.7951798503468002
6 26 1.1855051517486572
Validation loss: 1.0993894001320166 ROC AUC: 0.8373392525070671
Validation loss: 1.0604104092002686 ROC AUC: 0.8491340417504081
8 18 1.288282036781311
Validation loss: 0.9969013962838357 ROC AUC: 0.8687840230738753
Validation loss: 0.9885677215090066 ROC AUC: 0.8780508674537432
10 10 0.9594796299934387
Validation loss: 0.9954507011059294 ROC AUC: 0.8747200448719102
Validation loss: 0.9204756747569173 ROC AUC: 0.8927207735713754
12 2 1.0889939069747925
Validation loss: 0.8984626324336421 ROC AUC: 0.9028005026808124
13 23 1.1235796213150024
Validation loss: 0.9354804745245701 ROC AUC: 0.8853167462795092
Validation loss: 0.8815438665015136 ROC AUC: 0.9022637273396535
15 15 1.0144988298416138
Validation loss: 0.8739252322178422 ROC AUC: 0.9036891666977226
Validation loss: 0.8702263953103875 ROC AUC: 0.9038278103217149
17 7 1.0246374607086182
Validation loss: 0.8446068699365044 ROC AUC: 0.9052479907653798
18 28 0.965415358543396
Validation loss: 0.8176503839297119 ROC AUC: 0.9206715711934779
Validation loss: 0.8514348026485732 ROC AUC: 0.9004722812758053
20 20 0.9826259016990662
Validation loss: 0.826564836836788 ROC AUC: 0.9076513191491855
Validation loss: 0.8041562821643656 ROC AUC: 0.9147961745434452
22 12 1.1274272203445435
Validation loss: 0.8060046828333811 ROC AUC: 0.9108635244076986
Validation loss: 0.7746297097875542 ROC AUC: 0.9187262074543439
24 4 0.977820098400116
Validation loss: 0.7797358023167686 ROC AUC: 0.912716262830895
25 25 1.223402738571167
Validation loss: 0.7703162546291722 ROC AUC: 0.9264260257945676
Validation loss: 0.7771229030761554 ROC AUC: 0.9183113435020631
27 17 0.9756013751029968
Validation loss: 0.7386126479628792 ROC AUC: 0.9277754293379121
Validation loss: 0.7170358318232049 ROC AUC: 0.9318739377763343
29 9 0.8943845629692078
Validation loss: 0.7511733548945021 ROC AUC: 0.9263033041712726
Validation loss: 0.7420517602698077 ROC AUC: 0.9286398359572188
31 1 0.9160261750221252
Validation loss: 0.7150142328013097 ROC AUC: 0.9316449568622108
32 22 0.8405447006225586
Validation loss: 0.7164450939221721 ROC AUC: 0.9294257434199675
Validation loss: 0.7922543690220069 ROC AUC: 0.9108901548292161
34 14 0.8264229893684387
Validation loss: 0.6844626267321939 ROC AUC: 0.9363718865372329
Validation loss: 0.7218888288697722 ROC AUC: 0.930154183446932
36 6 0.8025811314582825
Validation loss: 0.7570605026980456 ROC AUC: 0.9206086136504193
37 27 1.2119261026382446
Validation loss: 0.6894815595052155 ROC AUC: 0.9370874866517707
Validation loss: 0.6715786805935606 ROC AUC: 0.9402773517044583
39 19 0.8693215847015381
Validation loss: 0.7022351934121958 ROC AUC: 0.9336201235208523
Validation loss: 0.6555203581731727 ROC AUC: 0.9410432313591783
41 11 1.2455229759216309
Validation loss: 0.7520345816344474 ROC AUC: 0.9220941534669882
Validation loss: 0.6969886050111017 ROC AUC: 0.9368793955672439
43 3 0.7673872709274292
Validation loss: 0.6888581488611374 ROC AUC: 0.9382023991553435
44 24 0.7610871195793152
Validation loss: 0.6579701198872429 ROC AUC: 0.944912170528817
Validation loss: 0.6777193116317815 ROC AUC: 0.9386109876464953
46 16 0.7150285243988037
Validation loss: 0.7036082609425868 ROC AUC: 0.9313373297343059
Validation loss: 0.6408617805456239 ROC AUC: 0.943817954867308
48 8 0.7718444466590881
Validation loss: 0.694806347655426 ROC AUC: 0.9353873427794573
Validation loss: 0.6533714178828904 ROC AUC: 0.9469233803522259
50 0 0.8369318842887878
Validation loss: 0.6626578009411789 ROC AUC: 0.9388343138540535
51 21 0.79206782579422
Validation loss: 0.6956702886595839 ROC AUC: 0.9318873718920011
Validation loss: 0.6744421124458313 ROC AUC: 0.9397646992733989
53 13 0.7794710993766785
Validation loss: 0.6033161591505128 ROC AUC: 0.9504444976182354
Validation loss: 0.5868991503962687 ROC AUC: 0.9550096050477906
55 5 0.9630283713340759
Validation loss: 0.6262810001105521 ROC AUC: 0.9486513471509491
56 26 0.7743402123451233
Validation loss: 0.6554127527364645 ROC AUC: 0.9467999908905911
Validation loss: 0.634914754405135 ROC AUC: 0.9473311179626615
58 18 0.8471836447715759
Validation loss: 0.6900409860435881 ROC AUC: 0.9389345178647505
Validation loss: 0.6120059900870849 ROC AUC: 0.9506764168503062
60 10 0.7249792218208313
Validation loss: 0.6452153371425736 ROC AUC: 0.9419832855580268
Validation loss: 0.6027444096414883 ROC AUC: 0.952723272806562
62 2 0.6381863951683044
Validation loss: 0.6207540944122084 ROC AUC: 0.9506407733213672
63 23 0.5771378874778748
Validation loss: 0.6570158724393494 ROC AUC: 0.9443597545889395
Validation loss: 0.5967303705009477 ROC AUC: 0.9533856023871945
65 15 0.7173156142234802
Validation loss: 0.574911777324347 ROC AUC: 0.960595896377785
Validation loss: 0.6573056149946176 ROC AUC: 0.9393046106500345
67 7 0.8279691338539124
Validation loss: 0.6059586434075951 ROC AUC: 0.9509001264730863
68 28 0.7007082104682922
Validation loss: 0.5829539789494377 ROC AUC: 0.9580026401918389
Validation loss: 0.5947782008488286 ROC AUC: 0.9499707820619605
70 20 0.8846691250801086
Validation loss: 0.5937194698057731 ROC AUC: 0.9510855959585299
Validation loss: 0.5684203316274523 ROC AUC: 0.9560033112743918
72 12 1.0268383026123047
Validation loss: 0.5668251504135956 ROC AUC: 0.9585913928550817
Validation loss: 0.6270770205277346 ROC AUC: 0.9438849588804528
74 4 0.810987114906311
Validation loss: 0.5428289041148406 ROC AUC: 0.963012519290262
75 25 0.6927865743637085
Validation loss: 0.5756293073071259 ROC AUC: 0.9547597835648848
Validation loss: 0.576066819560708 ROC AUC: 0.9547793808316862
77 17 0.6765702962875366
Validation loss: 0.5571355094919966 ROC AUC: 0.961615470977782
Validation loss: 0.5440854896222026 ROC AUC: 0.9627952086216842
79 9 0.4649469256401062
Validation loss: 0.5915485417096198 ROC AUC: 0.9498343503514507
Validation loss: 0.6696045831264223 ROC AUC: 0.9377924229525002
81 1 0.5683820843696594
Validation loss: 0.5096807729605722 ROC AUC: 0.9653666760321977
82 22 0.5169810652732849
Validation loss: 0.5419174305949819 ROC AUC: 0.9602975821477442
Validation loss: 0.6231094278218164 ROC AUC: 0.9444050814963404
84 14 0.9765918850898743
Validation loss: 0.5663713902943077 ROC AUC: 0.9543475361567548
Validation loss: 0.5480829406505527 ROC AUC: 0.9577259884695012
86 6 0.5806815028190613
Validation loss: 0.48828406306888833 ROC AUC: 0.9685704112484039
87 27 0.7032801508903503
Validation loss: 0.5927528103020999 ROC AUC: 0.952379294868577
Validation loss: 0.48866841512416404 ROC AUC: 0.9693159522055698
89 19 0.5296186804771423
Validation loss: 0.5205211566024929 ROC AUC: 0.964871598826756
Validation loss: 0.5235010267720109 ROC AUC: 0.9617396193718453
91 11 0.8870828151702881
Validation loss: 0.5296832249051294 ROC AUC: 0.9607906378669332
Validation loss: 0.5588942930327636 ROC AUC: 0.9542635644818086
93 3 0.6635473370552063
Validation loss: 0.4851602189098012 ROC AUC: 0.9724926381121275
94 24 0.6584086418151855
Validation loss: 0.5377846930505905 ROC AUC: 0.962019642728472
Validation loss: 0.4789524971795134 ROC AUC: 0.9729191633447632
96 16 0.5484333038330078
Validation loss: 0.4797451232859692 ROC AUC: 0.971683055150598
Validation loss: 0.5026399405677169 ROC AUC: 0.9643721582400794
98 8 1.0054835081100464
Validation loss: 0.47761598615615464 ROC AUC: 0.9717011259297659
Validation loss: 0.4531069733926596 ROC AUC: 0.9736433942613626
Loaded trained model with success.
Test loss: 1.5833050120960583 Test ROC AUC: 0.8128730158730159
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9784250269687162, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 5}}
Running on: cpu
926
926
55
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.6147027015686035
Validation loss: 1.5638653601220052 ROC AUC: 0.6211574561230828
1 21 1.6887121200561523
Validation loss: 1.525833511198056 ROC AUC: 0.6579719928777461
Validation loss: 1.3803501113702104 ROC AUC: 0.7209238283230659
3 13 1.3449773788452148
Validation loss: 1.3469702885938772 ROC AUC: 0.7405066856658948
Validation loss: 1.3467323623002219 ROC AUC: 0.7610412635878779
5 5 1.1302052736282349
Validation loss: 1.1396651381292817 ROC AUC: 0.818964299517863
6 26 1.2721748352050781
Validation loss: 1.0893280866594088 ROC AUC: 0.8462558002027297
Validation loss: 1.1719492588908318 ROC AUC: 0.824199973615386
8 18 1.1978545188903809
Validation loss: 1.0184777708599428 ROC AUC: 0.8617560983715251
Validation loss: 1.0029784873546328 ROC AUC: 0.8762414728704672
10 10 1.003076195716858
Validation loss: 0.9777916538535133 ROC AUC: 0.8697514888638501
Validation loss: 0.9144037457315762 ROC AUC: 0.8915919208112886
12 2 1.1043729782104492
Validation loss: 0.9385095079053298 ROC AUC: 0.8836871254937415
13 23 1.022351622581482
Validation loss: 0.9056626929062747 ROC AUC: 0.8842829536980693
Validation loss: 0.9352057930202773 ROC AUC: 0.8788111617476408
15 15 0.8473014831542969
Validation loss: 0.927231588837395 ROC AUC: 0.8868789158932634
Validation loss: 0.8445721004745615 ROC AUC: 0.8983365834803795
17 7 1.0843288898468018
Validation loss: 0.9032722340804197 ROC AUC: 0.8862499128358706
18 28 0.9329402446746826
Validation loss: 0.817101956057497 ROC AUC: 0.9090024813961455
Validation loss: 0.8585605462992938 ROC AUC: 0.8969601699435035
20 20 0.9306718707084656
Validation loss: 0.8177382221232222 ROC AUC: 0.9097324685873238
Validation loss: 0.7887342389407477 ROC AUC: 0.9186789979206301
22 12 0.9259231090545654
Validation loss: 0.7687171232880577 ROC AUC: 0.9250461360397584
Validation loss: 0.7860471691220162 ROC AUC: 0.9140745045062119
24 4 1.1359386444091797
Validation loss: 0.7730538618487365 ROC AUC: 0.9192932422025979
25 25 1.1299296617507935
Validation loss: 0.7697542684382033 ROC AUC: 0.9210287748064385
Validation loss: 0.7925344529213709 ROC AUC: 0.9142592621861502
27 17 1.0333515405654907
Validation loss: 0.7585249724707387 ROC AUC: 0.9253821675788781
Validation loss: 0.7393785332758019 ROC AUC: 0.9277620245514374
29 9 0.9000863432884216
Validation loss: 0.7125204890387105 ROC AUC: 0.9292437754236283
Validation loss: 0.7493306528414815 ROC AUC: 0.9187747026768666
31 1 0.9171597361564636
Validation loss: 0.7213957997171719 ROC AUC: 0.9314979334789472
32 22 0.7342365384101868
Validation loss: 0.7275098150286252 ROC AUC: 0.9264747088830992
Validation loss: 0.7311604904819513 ROC AUC: 0.9267894010533789
34 14 0.718806803226471
Validation loss: 0.7243848461054314 ROC AUC: 0.9321837223500097
Validation loss: 0.7260876966089204 ROC AUC: 0.9287029119549061
36 6 0.8022031784057617
Validation loss: 0.7453143026349869 ROC AUC: 0.9239615984630627
37 27 1.406484603881836
Validation loss: 0.7414015182666078 ROC AUC: 0.9250912318396635
Validation loss: 0.7112466074992977 ROC AUC: 0.9335085020580263
39 19 0.8473935723304749
Validation loss: 0.6674892886925979 ROC AUC: 0.9390964222818019
Validation loss: 0.7066983696451455 ROC AUC: 0.928967044386982
41 11 0.7033817172050476
Validation loss: 0.672431449653263 ROC AUC: 0.9372435964782871
Validation loss: 0.6899657351151913 ROC AUC: 0.9340199738516425
43 3 0.6667605042457581
Validation loss: 0.6632360696277659 ROC AUC: 0.940273046462937
44 24 0.6646220684051514
Validation loss: 0.6800530503944496 ROC AUC: 0.9364954715053935
Validation loss: 0.641170166223662 ROC AUC: 0.9454168677651914
46 16 0.8975563049316406
Validation loss: 0.653153168846155 ROC AUC: 0.941215707216257
Validation loss: 0.6487639621061074 ROC AUC: 0.9442719206783069
48 8 0.9665306210517883
Validation loss: 0.6466598227523573 ROC AUC: 0.9448911652735331
Validation loss: 0.6237281972852176 ROC AUC: 0.9510192762177665
50 0 0.6456788778305054
Validation loss: 0.635836489643443 ROC AUC: 0.9439857386526818
51 21 0.7862709760665894
Validation loss: 0.6445763886103619 ROC AUC: 0.9469192105566011
Validation loss: 0.6214448637117835 ROC AUC: 0.9514742861535959
53 13 0.6549965143203735
Validation loss: 0.6165374172429029 ROC AUC: 0.9455765140827875
Validation loss: 0.6055160567775916 ROC AUC: 0.9512439003244555
55 5 0.9066658616065979
Validation loss: 0.6228856825416598 ROC AUC: 0.9490876564607138
56 26 0.8548172116279602
Validation loss: 0.6655971060947518 ROC AUC: 0.9356642537831794
Validation loss: 0.6367705921374953 ROC AUC: 0.9475070567184067
58 18 0.8874003887176514
Validation loss: 0.6225812487931798 ROC AUC: 0.9482765929854649
Validation loss: 0.5802766272625192 ROC AUC: 0.9559661366903086
60 10 0.8151190876960754
Validation loss: 0.6358935638586337 ROC AUC: 0.9447707687692241
Validation loss: 0.6010906053928268 ROC AUC: 0.9532648966581532
62 2 0.7795895934104919
Validation loss: 0.5977243196629551 ROC AUC: 0.9542122720214623
63 23 0.835030198097229
Validation loss: 0.568109977966251 ROC AUC: 0.9548481231458897
Validation loss: 0.6545851860139077 ROC AUC: 0.9376713802094805
65 15 0.8960236310958862
Validation loss: 0.5689439960226385 ROC AUC: 0.9604654282566181
Validation loss: 0.6265778688323678 ROC AUC: 0.9476759596296953
67 7 0.7608659267425537
Validation loss: 0.6369310366412219 ROC AUC: 0.9430395073867318
68 28 0.6797493100166321
Validation loss: 0.5637513917929153 ROC AUC: 0.9581226659167411
Validation loss: 0.5558456402617963 ROC AUC: 0.9602098900433734
70 20 0.5725306272506714
Validation loss: 0.544497988265225 ROC AUC: 0.9612506835471611
Validation loss: 0.5556804764991703 ROC AUC: 0.9597523008727616
72 12 0.5866579413414001
Validation loss: 0.5528150484062425 ROC AUC: 0.9619643108386426
Validation loss: 0.5633377824179812 ROC AUC: 0.9587513203520416
74 4 0.6897530555725098
Validation loss: 0.5514062505947591 ROC AUC: 0.9595865556906743
75 25 0.8139743804931641
Validation loss: 0.5275221303523745 ROC AUC: 0.9655739948232605
Validation loss: 0.5746962184138741 ROC AUC: 0.9547805655670834
77 17 0.6958971619606018
Validation loss: 0.5908831758324065 ROC AUC: 0.9491889470684438
Validation loss: 0.5079067861158441 ROC AUC: 0.9661646874405582
79 9 0.46865272521972656
Validation loss: 0.5537882496162315 ROC AUC: 0.9615410122747365
Validation loss: 0.531382249961919 ROC AUC: 0.9630498856244136
81 1 0.8145143985748291
Validation loss: 0.5249739869881912 ROC AUC: 0.9643175901489982
82 22 0.7619591355323792
Validation loss: 0.5124321664898751 ROC AUC: 0.9661445881317807
Validation loss: 0.5149016717597681 ROC AUC: 0.9692341038680924
84 14 0.6978389620780945
Validation loss: 0.6636660594662116 ROC AUC: 0.9348244950723819
Validation loss: 0.5118824293752469 ROC AUC: 0.9659320752274961
86 6 0.6817727088928223
Validation loss: 0.5479234018670818 ROC AUC: 0.9583043263118316
87 27 0.5060248374938965
Validation loss: 0.5017137941994884 ROC AUC: 0.9678469502347957
Validation loss: 0.5263313907912689 ROC AUC: 0.962954842261237
89 19 0.6719757914543152
Validation loss: 0.5190668874631432 ROC AUC: 0.9623326304916417
Validation loss: 0.5753549705571284 ROC AUC: 0.9566078950999064
91 11 0.8480232954025269
Validation loss: 0.5307119882647471 ROC AUC: 0.9628873010315575
Validation loss: 0.579425591758209 ROC AUC: 0.9533755539493856
93 3 0.6120742559432983
Validation loss: 0.5045373287880652 ROC AUC: 0.9665147034994132
94 24 0.6699677109718323
Validation loss: 0.521936287761507 ROC AUC: 0.9613519814116834
Validation loss: 0.4815735792495777 ROC AUC: 0.9707153862099087
96 16 0.7098405957221985
Validation loss: 0.5129711325431231 ROC AUC: 0.9657715404223829
Validation loss: 0.5828672445361094 ROC AUC: 0.9512012644491274
98 8 0.7564449906349182
Validation loss: 0.4725140694923071 ROC AUC: 0.9729492851376452
Validation loss: 0.46555540223101044 ROC AUC: 0.9736006382647762
Loaded trained model with success.
Test loss: 1.6153090823780407 Test ROC AUC: 0.8309563492063493
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9892125134843581, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/esol/esol.csv', 'regression_bin_classes': 5}}
Running on: cpu
926
926
55
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.6433792114257812
Validation loss: 1.5476495483266612 ROC AUC: 0.5739772428476145
1 21 1.6252975463867188
Validation loss: 1.4867708824623223 ROC AUC: 0.6550901310195929
Validation loss: 1.4201850206239177 ROC AUC: 0.7100449455666301
3 13 1.3940684795379639
Validation loss: 1.4458855508985582 ROC AUC: 0.7312441669746284
Validation loss: 1.226048820219596 ROC AUC: 0.7934873183439415
5 5 1.3041880130767822
Validation loss: 1.2711055634088702 ROC AUC: 0.789309911248538
6 26 1.2140944004058838
Validation loss: 1.1588529562074732 ROC AUC: 0.8403615102649894
Validation loss: 1.0421700637232407 ROC AUC: 0.8632046885356592
8 18 1.175325870513916
Validation loss: 1.0111568182642465 ROC AUC: 0.8649224228342985
Validation loss: 0.9841727480517608 ROC AUC: 0.8766495189446127
10 10 1.0840760469436646
Validation loss: 0.9526257581896195 ROC AUC: 0.8892178632602408
Validation loss: 0.9504983622106054 ROC AUC: 0.8814851785811522
12 2 1.1113176345825195
Validation loss: 0.9290776260470726 ROC AUC: 0.8926631803667948
13 23 1.8119689226150513
Validation loss: 0.9714070716892926 ROC AUC: 0.8811898069473992
Validation loss: 0.8750777988660413 ROC AUC: 0.9048007787248823
15 15 1.0186138153076172
Validation loss: 0.8292205904009018 ROC AUC: 0.9099582673428813
Validation loss: 0.8598025296985717 ROC AUC: 0.9060408376894376
17 7 1.1533223390579224
Validation loss: 0.85924615393962 ROC AUC: 0.904107944324919
18 28 1.2042994499206543
Validation loss: 0.8723182877763044 ROC AUC: 0.9048265633436021
Validation loss: 0.8166156117653486 ROC AUC: 0.9119605607844303
20 20 1.1041858196258545
Validation loss: 0.8825798952553752 ROC AUC: 0.8997031503196535
Validation loss: 0.7853019451219628 ROC AUC: 0.917749604719624
22 12 0.7708014249801636
Validation loss: 0.8332795263881559 ROC AUC: 0.9099537326122986
Validation loss: 0.822654561914069 ROC AUC: 0.9112260049062968
24 4 0.745387077331543
Validation loss: 0.7684094024013495 ROC AUC: 0.9151806094407966
25 25 0.674681544303894
Validation loss: 0.817005843889636 ROC AUC: 0.9124134399552505
Validation loss: 0.8030728708075653 ROC AUC: 0.9112318968218472
27 17 1.3919777870178223
Validation loss: 0.8017495503693368 ROC AUC: 0.9115346884496793
Validation loss: 0.7472959920345579 ROC AUC: 0.92539422426767
29 9 0.9224125146865845
Validation loss: 0.7454524896314798 ROC AUC: 0.9206010221064094
Validation loss: 0.811116988921526 ROC AUC: 0.9102227031910421
31 1 0.9477968215942383
Validation loss: 0.715557864495024 ROC AUC: 0.9307779009155853
32 22 1.072784423828125
Validation loss: 0.7702594579682237 ROC AUC: 0.9238177763284113
Validation loss: 0.7122609225256654 ROC AUC: 0.927188419072763
34 14 0.8773541450500488
Validation loss: 0.7308586423906858 ROC AUC: 0.9311776237407224
Validation loss: 0.7119215842714578 ROC AUC: 0.9332533407711189
36 6 0.8093246817588806
Validation loss: 0.7338010514271697 ROC AUC: 0.9300312098848783
37 27 0.9465987086296082
Validation loss: 0.7594966710772422 ROC AUC: 0.9262035419720924
Validation loss: 0.7437857304484489 ROC AUC: 0.9221260228244693
39 19 0.8025026321411133
Validation loss: 0.7199788183681908 ROC AUC: 0.9296305359939787
Validation loss: 0.6893996105853218 ROC AUC: 0.9361841571158742
41 11 1.1956255435943604
Validation loss: 0.7419860418362957 ROC AUC: 0.9249206767706297
Validation loss: 0.7442722781430567 ROC AUC: 0.9237911081924576
43 3 0.9454024434089661
Validation loss: 0.6786099228179223 ROC AUC: 0.940240515927208
44 24 0.6120874881744385
Validation loss: 0.6584850606341599 ROC AUC: 0.9394401787595562
Validation loss: 0.6657731670797772 ROC AUC: 0.9411376202881969
46 16 0.9133357405662537
Validation loss: 0.6843802475774777 ROC AUC: 0.9364151844459258
Validation loss: 0.7764123446483077 ROC AUC: 0.9143068359672396
48 8 0.8152258396148682
Validation loss: 0.712114693150407 ROC AUC: 0.9335424100183349
Validation loss: 0.650487159421068 ROC AUC: 0.9430040185986789
50 0 0.7511969804763794
Validation loss: 0.6452139670081581 ROC AUC: 0.9426154837843452
51 21 0.8627945780754089
Validation loss: 0.6358468030492894 ROC AUC: 0.9469089818946765
Validation loss: 0.6672741902054772 ROC AUC: 0.9382574569523123
53 13 0.8227042555809021
Validation loss: 0.6818026453578446 ROC AUC: 0.93879076187271
Validation loss: 0.6497272722921927 ROC AUC: 0.9438902680351783
55 5 0.6158151030540466
Validation loss: 0.6538173228051698 ROC AUC: 0.941551579487831
56 26 0.6858809590339661
Validation loss: 0.6495126649318967 ROC AUC: 0.9441047868022681
Validation loss: 0.6056212423687105 ROC AUC: 0.9509302501015098
58 18 0.7498584985733032
Validation loss: 0.6277978955798221 ROC AUC: 0.9465746228777618
Validation loss: 0.5932516681581542 ROC AUC: 0.9536230075836043
60 10 0.853241503238678
Validation loss: 0.604481394038602 ROC AUC: 0.9525323100572998
Validation loss: 0.6339273744988905 ROC AUC: 0.9472450833537487
62 2 0.8911776542663574
Validation loss: 0.6207131554189562 ROC AUC: 0.9541697385949689
63 23 0.6138612627983093
Validation loss: 0.60550869747063 ROC AUC: 0.9529856098232724
Validation loss: 0.6059828942589317 ROC AUC: 0.9538774597111421
65 15 0.6572887301445007
Validation loss: 0.6202277893896494 ROC AUC: 0.9505513409527946
Validation loss: 0.6281357471937752 ROC AUC: 0.9499852859995812
67 7 0.7056856155395508
Validation loss: 0.6151896737049259 ROC AUC: 0.9522939711678244
68 28 0.8856498599052429
Validation loss: 0.5991679054099591 ROC AUC: 0.9517495367178329
Validation loss: 0.5801835317591096 ROC AUC: 0.9589984096099057
70 20 0.8587809205055237
Validation loss: 0.5811579336872884 ROC AUC: 0.9585767247005166
Validation loss: 0.5953927514491277 ROC AUC: 0.9528315875625065
72 12 0.9596671462059021
Validation loss: 0.596288880055718 ROC AUC: 0.9555556602388027
Validation loss: 0.6240197964672394 ROC AUC: 0.9489331646005621
74 4 0.7877639532089233
Validation loss: 0.5622109868613999 ROC AUC: 0.9590968957234782
75 25 0.4804266691207886
Validation loss: 0.6132180250489171 ROC AUC: 0.9482777922353647
Validation loss: 0.5893092515916598 ROC AUC: 0.9555758679294509
77 17 0.5262640714645386
Validation loss: 0.5547264044537142 ROC AUC: 0.9616975370617198
Validation loss: 0.5558325709457274 ROC AUC: 0.9599974227715075
79 9 0.6330772638320923
Validation loss: 0.6163531509640408 ROC AUC: 0.9482408550328503
Validation loss: 0.563208752136766 ROC AUC: 0.9586278049637142
81 1 1.033818006515503
Validation loss: 0.5177111218866468 ROC AUC: 0.9662874262026895
82 22 1.0755679607391357
Validation loss: 0.59164628431555 ROC AUC: 0.9527826090798353
Validation loss: 0.5469452522485869 ROC AUC: 0.9618980449262043
84 14 0.5868467688560486
Validation loss: 0.60980750881055 ROC AUC: 0.9471408359859044
Validation loss: 0.5900704864549328 ROC AUC: 0.9573022161646503
86 6 0.5625149011611938
Validation loss: 0.658933953512822 ROC AUC: 0.9339331996461417
87 27 0.8282970786094666
Validation loss: 0.5491032191666877 ROC AUC: 0.9640088313029681
Validation loss: 0.5810991158753183 ROC AUC: 0.9532051976306317
89 19 0.6599751114845276
Validation loss: 0.5014747356106859 ROC AUC: 0.9657560261258187
Validation loss: 0.5563228663306514 ROC AUC: 0.9602635791661415
91 11 0.7962917685508728
Validation loss: 0.5491493068812475 ROC AUC: 0.9578079909066416
Validation loss: 0.5282485207007719 ROC AUC: 0.9656668868889738
93 3 0.6420460343360901
Validation loss: 0.5502417229164239 ROC AUC: 0.9603753245066834
94 24 0.7293569445610046
Validation loss: 0.5358980668801211 ROC AUC: 0.9588198946501558
Validation loss: 0.5454463125820036 ROC AUC: 0.9624786827026413
96 16 0.5944378972053528
Validation loss: 0.5392186059807598 ROC AUC: 0.961808260219015
Validation loss: 0.5187139919200675 ROC AUC: 0.9642343419762586
98 8 0.8369618654251099
Validation loss: 0.49408194963411944 ROC AUC: 0.9698097255788445
Validation loss: 0.5391596732077795 ROC AUC: 0.9638933196871484
Loaded trained model with success.
2023-02-14 05:22:30.950 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 10
    │        └ 'FreeSolv'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f062b3cf1d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6dc90>
                                              └ <finetune.FineTune object at 0x7f062b3cf1d0>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'regression'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6dc90>
                   │                        │  │    │    │    │    │                                            │    └ 'expt'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6dc90>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed6dc90>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'regression'
    │                 │             │           │          └ 'expt'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-14 05:22:30.991 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 50
    │        └ 'FreeSolv'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed73f10>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed73610>
                                              └ <finetune.FineTune object at 0x7f061ed73f10>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'regression'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed73610>
                   │                        │  │    │    │    │    │                                            │    └ 'expt'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed73610>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed73610>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'regression'
    │                 │             │           │          └ 'expt'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-14 05:22:31.031 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 100
    │        └ 'FreeSolv'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ece8c50>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece8d10>
                                              └ <finetune.FineTune object at 0x7f061ece8c50>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'regression'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece8d10>
                   │                        │  │    │    │    │    │                                            │    └ 'expt'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece8d10>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece8d10>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'regression'
    │                 │             │           │          └ 'expt'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-14 05:22:31.071 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 200
    │        └ 'FreeSolv'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061c3b54d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c3b5890>
                                              └ <finetune.FineTune object at 0x7f061c3b54d0>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'regression'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c3b5890>
                   │                        │  │    │    │    │    │                                            │    └ 'expt'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c3b5890>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c3b5890>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'regression'
    │                 │             │           │          └ 'expt'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-14 05:22:31.111 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 500
    │        └ 'FreeSolv'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061c0ddf10>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0ddf50>
                                              └ <finetune.FineTune object at 0x7f061c0ddf10>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'regression'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0ddf50>
                   │                        │  │    │    │    │    │                                            │    └ 'expt'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0ddf50>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0ddf50>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'regression'
    │                 │             │           │          └ 'expt'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-14 05:22:31.150 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 10
    │        └ 'FreeSolv_2'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061c0e9250>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0e98d0>
                                              └ <finetune.FineTune object at 0x7f061c0e9250>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0e98d0>
                   │                        │  │    │    │    │    │                                            │    └ 'target_2'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0e98d0>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0e98d0>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_2'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-14 05:22:31.190 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 50
    │        └ 'FreeSolv_2'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ece0710>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece0050>
                                              └ <finetune.FineTune object at 0x7f061ece0710>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece0050>
                   │                        │  │    │    │    │    │                                            │    └ 'target_2'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece0050>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece0050>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_2'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-14 05:22:31.230 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 100
    │        └ 'FreeSolv_2'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ece86d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece8fd0>
                                              └ <finetune.FineTune object at 0x7f061ece86d0>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece8fd0>
                   │                        │  │    │    │    │    │                                            │    └ 'target_2'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece8fd0>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece8fd0>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_2'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-14 05:22:31.270 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 200
    │        └ 'FreeSolv_2'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061c0dd590>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0ddad0>
                                              └ <finetune.FineTune object at 0x7f061c0dd590>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0ddad0>
                   │                        │  │    │    │    │    │                                            │    └ 'target_2'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0ddad0>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0ddad0>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_2'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-14 05:22:31.310 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 500
    │        └ 'FreeSolv_2'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061edf0250>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed51150>
                                              └ <finetune.FineTune object at 0x7f061edf0250>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed51150>
                   │                        │  │    │    │    │    │                                            │    └ 'target_2'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed51150>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed51150>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_2'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-14 05:22:31.350 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 10
    │        └ 'FreeSolv_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061c0e0f50>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0e0f90>
                                              └ <finetune.FineTune object at 0x7f061c0e0f50>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0e0f90>
                   │                        │  │    │    │    │    │                                            │    └ 'target_5'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0e0f90>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0e0f90>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_5'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-14 05:22:31.390 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 50
    │        └ 'FreeSolv_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ece8350>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece8f50>
                                              └ <finetune.FineTune object at 0x7f061ece8350>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece8f50>
                   │                        │  │    │    │    │    │                                            │    └ 'target_5'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece8f50>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ece8f50>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_5'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-14 05:22:31.430 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 100
    │        └ 'FreeSolv_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061ed8b810>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed8b650>
                                              └ <finetune.FineTune object at 0x7f061ed8b810>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed8b650>
                   │                        │  │    │    │    │    │                                            │    └ 'target_5'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed8b650>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061ed8b650>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_5'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Test loss: 1.7048487424850465 Test ROC AUC: 0.8070436507936508
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}2023-02-14 05:22:31.470 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 200
    │        └ 'FreeSolv_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f061c0dd790>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0dda90>
                                              └ <finetune.FineTune object at 0x7f061c0dd790>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0dda90>
                   │                        │  │    │    │    │    │                                            │    └ 'target_5'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0dda90>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f061c0dda90>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_5'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
2023-02-14 05:22:31.510 | ERROR    | __main__:<module>:208 - [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'
Traceback (most recent call last):

> File "finetune_lc.py", line 206, in <module>
    run_expt(task, train_points)
    │        │     └ 500
    │        └ 'FreeSolv_5'
    └ <function run_expt at 0x7f061ee01560>

  File "finetune_lc.py", line 191, in run_expt
    result = main(config)
             │    └ {'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp1...
             └ <function main at 0x7f062c30c4d0>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 361, in main
    fine_tune.train()
    │         └ <function FineTune.train at 0x7f061edf15f0>
    └ <finetune.FineTune object at 0x7f04d54ac790>

  File "/home/kjablonka/git/MolCLR/finetune.py", line 108, in train
    train_loader, valid_loader, test_loader = self.dataset.get_data_loaders()
                                              │    │       └ <function MolTestDatasetWrapper.get_data_loaders at 0x7f061ef525f0>
                                              │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f04d54acad0>
                                              └ <finetune.FineTune object at 0x7f04d54ac790>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 197, in get_data_loaders
    test_dataset = MolTestDataset(data_path=os.path.join(Path(self.data_path).parent, 'solubility.csv'), target=self.target, task=self.task)
                   │                        │  │    │    │    │    │                                            │    │            │    └ 'classification'
                   │                        │  │    │    │    │    │                                            │    │            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f04d54acad0>
                   │                        │  │    │    │    │    │                                            │    └ 'target_5'
                   │                        │  │    │    │    │    │                                            └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f04d54acad0>
                   │                        │  │    │    │    │    └ 'data/freesolv/freesolv.csv'
                   │                        │  │    │    │    └ <dataset.dataset_test.MolTestDatasetWrapper object at 0x7f04d54acad0>
                   │                        │  │    │    └ <class 'pathlib.Path'>
                   │                        │  │    └ <function join at 0x7f07808de170>
                   │                        │  └ <module 'posixpath' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/posixpath.py'>
                   │                        └ <module 'os' from '/home/kjablonka/miniconda3/envs/molclr/lib/python3.7/os.py'>
                   └ <class 'dataset.dataset_test.MolTestDataset'>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 118, in __init__
    self.smiles_data, self.labels = read_smiles(data_path, target, task)
    │                 │             │           │          │       └ 'classification'
    │                 │             │           │          └ 'target_5'
    │                 │             │           └ 'data/freesolv/solubility.csv'
    │                 │             └ <function read_smiles at 0x7f061ef4ec20>
    │                 └ <unprintable MolTestDataset object>
    └ <unprintable MolTestDataset object>

  File "/home/kjablonka/git/MolCLR/dataset/dataset_test.py", line 96, in read_smiles
    with open(data_path) as csv_file:
              └ 'data/freesolv/solubility.csv'

FileNotFoundError: [Errno 2] No such file or directory: 'data/freesolv/solubility.csv'

Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 5}}
Running on: cpu
598
598
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 5.839277744293213
Validation loss: 3.672884941101074 MAE: 1.6816095
Validation loss: 1.9963929653167725 MAE: 1.1212697
Validation loss: 1.0589449405670166 MAE: 0.86224645
Validation loss: 0.8510987162590027 MAE: 0.73986053
Validation loss: 1.2062091827392578 MAE: 0.9631778
Validation loss: 1.9327703714370728 MAE: 1.2086107
Validation loss: 2.620231866836548 MAE: 1.369245
Validation loss: 3.0680813789367676 MAE: 1.4913146
Validation loss: 3.0626044273376465 MAE: 1.4894427
Validation loss: 2.7994446754455566 MAE: 1.4132309
Validation loss: 2.3322505950927734 MAE: 1.3062173
Validation loss: 1.810526967048645 MAE: 1.1737752
Validation loss: 1.4319864511489868 MAE: 1.0511583
Validation loss: 1.1638234853744507 MAE: 0.93774456
Validation loss: 0.9958625435829163 MAE: 0.838331
Validation loss: 0.9067494869232178 MAE: 0.7653136
Validation loss: 0.8507723808288574 MAE: 0.72038543
Validation loss: 0.8354780077934265 MAE: 0.7289598
Validation loss: 0.8398693799972534 MAE: 0.7409145
Validation loss: 0.8597819805145264 MAE: 0.7654151
Validation loss: 0.8869514465332031 MAE: 0.78359413
Validation loss: 0.9111888408660889 MAE: 0.79679996
Validation loss: 0.9278445839881897 MAE: 0.8012619
Validation loss: 0.9375952482223511 MAE: 0.79930127
Validation loss: 0.9136035442352295 MAE: 0.7813816
Validation loss: 0.8840668201446533 MAE: 0.75722295
Validation loss: 0.8477524518966675 MAE: 0.72533226
Validation loss: 0.8151886463165283 MAE: 0.7230889
Validation loss: 0.7891907095909119 MAE: 0.7265607
Validation loss: 0.7787116169929504 MAE: 0.7283175
Validation loss: 0.7624905705451965 MAE: 0.72450703
Validation loss: 0.7524654269218445 MAE: 0.7173022
Validation loss: 0.7431327104568481 MAE: 0.70884764
Validation loss: 0.7353622913360596 MAE: 0.6981482
Validation loss: 0.7227901220321655 MAE: 0.68608963
Validation loss: 0.7126122117042542 MAE: 0.68142873
Validation loss: 0.7173793911933899 MAE: 0.71729535
Validation loss: 0.7495231628417969 MAE: 0.7664165
Validation loss: 0.7986472249031067 MAE: 0.812092
Validation loss: 0.8167358636856079 MAE: 0.8303742
Validation loss: 0.8186337947845459 MAE: 0.83332884
Validation loss: 0.8076479434967041 MAE: 0.82758266
Validation loss: 0.7950026988983154 MAE: 0.81873053
Validation loss: 0.8050003051757812 MAE: 0.8293193
Validation loss: 0.7943466305732727 MAE: 0.8240353
Validation loss: 0.7721188068389893 MAE: 0.81503177
Validation loss: 0.7685871124267578 MAE: 0.82031703
Validation loss: 0.7756407260894775 MAE: 0.83033204
Validation loss: 0.7570922374725342 MAE: 0.8217051
Validation loss: 0.7698519229888916 MAE: 0.829369
50 0 0.5843176245689392
Validation loss: 0.767959713935852 MAE: 0.8271536
Validation loss: 0.7894753217697144 MAE: 0.83615375
Validation loss: 0.8022133111953735 MAE: 0.84020543
Validation loss: 0.7947434782981873 MAE: 0.8342302
Validation loss: 0.7650296688079834 MAE: 0.8200302
Validation loss: 0.7669673562049866 MAE: 0.82150054
Validation loss: 0.746293306350708 MAE: 0.8131491
Validation loss: 0.7199676632881165 MAE: 0.80251706
Validation loss: 0.6721624732017517 MAE: 0.77938646
Validation loss: 0.6641924977302551 MAE: 0.77757263
Validation loss: 0.6451590061187744 MAE: 0.7716594
Validation loss: 0.6146972179412842 MAE: 0.75834566
Validation loss: 0.629794180393219 MAE: 0.76998943
Validation loss: 0.6137924194335938 MAE: 0.7619825
Validation loss: 0.6032586693763733 MAE: 0.7582814
Validation loss: 0.5862606763839722 MAE: 0.74540967
Validation loss: 0.5972930788993835 MAE: 0.7522618
Validation loss: 0.5714587569236755 MAE: 0.7354074
Validation loss: 0.5683357119560242 MAE: 0.7303884
Validation loss: 0.5618360042572021 MAE: 0.72003853
Validation loss: 0.5613630414009094 MAE: 0.71226424
Validation loss: 0.5540188550949097 MAE: 0.70394737
Validation loss: 0.5724928379058838 MAE: 0.7121097
Validation loss: 0.6126906275749207 MAE: 0.73496026
Validation loss: 0.6052443981170654 MAE: 0.7316109
Validation loss: 0.5951396822929382 MAE: 0.7284962
Validation loss: 0.5603089332580566 MAE: 0.7084911
Validation loss: 0.5249545574188232 MAE: 0.6891373
Validation loss: 0.5006031394004822 MAE: 0.6754168
Validation loss: 0.48969390988349915 MAE: 0.6743207
Validation loss: 0.4582153856754303 MAE: 0.6497581
Validation loss: 0.43353235721588135 MAE: 0.6131588
Validation loss: 0.43585920333862305 MAE: 0.61942106
Validation loss: 0.44608551263809204 MAE: 0.6349737
Validation loss: 0.44550615549087524 MAE: 0.6368782
Validation loss: 0.4363148808479309 MAE: 0.6316795
Validation loss: 0.42732110619544983 MAE: 0.6271975
Validation loss: 0.4116109013557434 MAE: 0.6172402
Validation loss: 0.3960302174091339 MAE: 0.60598356
Validation loss: 0.3964657485485077 MAE: 0.6067184
Validation loss: 0.3803376853466034 MAE: 0.5953468
Validation loss: 0.3797348439693451 MAE: 0.5946102
Validation loss: 0.36234837770462036 MAE: 0.5787686
Validation loss: 0.3494759798049927 MAE: 0.56265527
Validation loss: 0.34291577339172363 MAE: 0.54140055
Validation loss: 0.3393709063529968 MAE: 0.5328215
Validation loss: 0.33807122707366943 MAE: 0.5190456
Validation loss: 0.3293265700340271 MAE: 0.51037955
Validation loss: 0.3255963921546936 MAE: 0.50978523
Validation loss: 0.33244404196739197 MAE: 0.5215611
Loaded trained model with success.
Test loss: 2.1123538677373093 Test MAE: 1.1551638
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 7.74287748336792
Validation loss: 4.26881709390757 MAE: 1.8104706
Validation loss: 1.9365714253211508 MAE: 1.1596847
Validation loss: 1.724750068722939 MAE: 1.0463504
Validation loss: 2.393905471782295 MAE: 1.187282
Validation loss: 2.696744276552784 MAE: 1.2636818
Validation loss: 2.4085866723741804 MAE: 1.1824616
Validation loss: 1.8873817008368823 MAE: 1.0765415
Validation loss: 1.6329424235285546 MAE: 1.036178
Validation loss: 1.685207259898283 MAE: 1.0913156
Validation loss: 1.9040234161882985 MAE: 1.1582078
Validation loss: 2.0746963024139404 MAE: 1.2090648
Validation loss: 2.0155743263205705 MAE: 1.1873512
Validation loss: 1.7684121204882253 MAE: 1.10787
Validation loss: 1.4630029274492848 MAE: 1.0053173
Validation loss: 1.2366045822902603 MAE: 0.9024559
Validation loss: 1.181531385499604 MAE: 0.8500343
Validation loss: 1.332190147468022 MAE: 0.90777767
Validation loss: 1.6066569941384452 MAE: 1.0062294
Validation loss: 1.7827783847341732 MAE: 1.0669172
Validation loss: 1.750452114611256 MAE: 1.0464445
Validation loss: 1.6720481016197983 MAE: 1.0053596
Validation loss: 1.5226654909094985 MAE: 0.9502311
Validation loss: 1.4292026271625442 MAE: 0.9225085
Validation loss: 1.3929063325025597 MAE: 0.9097564
Validation loss: 1.361931392124721 MAE: 0.898321
25 0 1.6044032573699951
Validation loss: 1.3694804468933417 MAE: 0.89860934
Validation loss: 1.4468182714617983 MAE: 0.92430437
Validation loss: 1.531221601427818 MAE: 0.952257
Validation loss: 1.67941118989672 MAE: 1.0023781
Validation loss: 1.7884653076833608 MAE: 1.0430366
Validation loss: 1.8397338293036636 MAE: 1.06146
Validation loss: 1.7900454560104682 MAE: 1.0412192
Validation loss: 1.6341675446957957 MAE: 0.9817907
Validation loss: 1.4834802442667436 MAE: 0.93375355
Validation loss: 1.432617931949849 MAE: 0.9149065
Validation loss: 1.4117353327420292 MAE: 0.908553
Validation loss: 1.4399166569417836 MAE: 0.9185264
Validation loss: 1.4523080660372365 MAE: 0.923128
Validation loss: 1.4500870996591997 MAE: 0.92247087
Validation loss: 1.4647883809342677 MAE: 0.9273213
Validation loss: 1.522332240124138 MAE: 0.94759095
Validation loss: 1.5581976929489447 MAE: 0.96108484
Validation loss: 1.6051916905811854 MAE: 0.9881955
Validation loss: 1.6733066086866417 MAE: 1.0181756
Validation loss: 1.7765477433496593 MAE: 1.0630416
Validation loss: 1.757047414779663 MAE: 1.0554726
Validation loss: 1.679637383441536 MAE: 1.0192533
Validation loss: 1.5319194161162084 MAE: 0.94741774
Validation loss: 1.3731044019971574 MAE: 0.8902584
Validation loss: 1.3098340691352377 MAE: 0.86918163
50 0 1.1707240343093872
Validation loss: 1.2111585492990455 MAE: 0.8396864
Validation loss: 1.1875381858981386 MAE: 0.8411325
Validation loss: 1.1567029223150136 MAE: 0.83037364
Validation loss: 1.1380929752272002 MAE: 0.8183461
Validation loss: 1.0849962319646562 MAE: 0.78817374
Validation loss: 1.1236217849108638 MAE: 0.7798833
Validation loss: 1.1578219338339202 MAE: 0.7846107
Validation loss: 1.1664552931882897 MAE: 0.79130775
Validation loss: 1.152726767014484 MAE: 0.7902609
Validation loss: 1.1396458051642593 MAE: 0.7874741
Validation loss: 1.1063045068662993 MAE: 0.7858889
Validation loss: 1.078924147450194 MAE: 0.7954384
Validation loss: 1.0398408150186345 MAE: 0.79291433
Validation loss: 1.0233278773268875 MAE: 0.7905911
Validation loss: 1.0071991682052612 MAE: 0.78369284
Validation loss: 0.9805301853588649 MAE: 0.7708252
Validation loss: 0.9479227236339024 MAE: 0.7532469
Validation loss: 0.9364968197686332 MAE: 0.73888695
Validation loss: 0.9855862636955417 MAE: 0.75596774
Validation loss: 1.0290461705655467 MAE: 0.78067166
Validation loss: 1.14164378934977 MAE: 0.8350669
Validation loss: 1.192353598925532 MAE: 0.86662894
Validation loss: 1.1574313689251334 MAE: 0.84800017
Validation loss: 0.9773738165290988 MAE: 0.76036763
Validation loss: 0.8946004607239548 MAE: 0.71786404
75 0 0.8146634697914124
Validation loss: 0.8854800706007042 MAE: 0.7124222
Validation loss: 0.9081014066326375 MAE: 0.7210569
Validation loss: 0.9344610851638171 MAE: 0.72786665
Validation loss: 0.9305386056705397 MAE: 0.7227602
Validation loss: 0.9484582263596204 MAE: 0.7351143
Validation loss: 0.9969131532980471 MAE: 0.7631032
Validation loss: 0.9591617365272678 MAE: 0.74827266
Validation loss: 0.8832183881681792 MAE: 0.72173023
Validation loss: 0.8315787376189718 MAE: 0.7022207
Validation loss: 0.812162527016231 MAE: 0.6926119
Validation loss: 0.7987089972106778 MAE: 0.6850709
Validation loss: 0.819458328947729 MAE: 0.6949892
Validation loss: 0.8638428133361193 MAE: 0.7225457
Validation loss: 0.8528655840426075 MAE: 0.7180523
Validation loss: 0.782117805310658 MAE: 0.68292814
Validation loss: 0.7727227527268079 MAE: 0.67586756
Validation loss: 0.7766383132156061 MAE: 0.6771978
Validation loss: 0.7969525736205432 MAE: 0.6897769
Validation loss: 0.8343111836180395 MAE: 0.7101809
Validation loss: 0.8103794163587142 MAE: 0.70111537
Validation loss: 0.8003046682902745 MAE: 0.6996027
Validation loss: 0.8821289527172945 MAE: 0.7420771
Validation loss: 0.8914084361523998 MAE: 0.75065833
Validation loss: 0.8379961556317855 MAE: 0.72755075
Validation loss: 0.708466649055481 MAE: 0.66915303
Loaded trained model with success.
Test loss: 1.9377771214319603 Test MAE: 1.0887777
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 8.221742630004883
Validation loss: 1.8149576885531646 MAE: 1.0511922
Validation loss: 5.4469792144467135 MAE: 2.001019
Validation loss: 4.021999908216072 MAE: 1.644818
Validation loss: 1.8299137751261394 MAE: 1.061441
Validation loss: 1.5779971907837222 MAE: 1.0005699
Validation loss: 1.5774493289716316 MAE: 1.0015045
Validation loss: 1.5536777292839203 MAE: 0.9984815
Validation loss: 1.543703505487153 MAE: 0.9958409
Validation loss: 1.6052985131138502 MAE: 1.0194995
Validation loss: 1.6110036734378699 MAE: 1.0281953
Validation loss: 1.542074933196559 MAE: 1.0033197
Validation loss: 1.5479895081182924 MAE: 1.0020375
12 2 1.7645858526229858
Validation loss: 1.5790469601298824 MAE: 1.0104698
Validation loss: 1.7986253490953734 MAE: 1.0766424
Validation loss: 1.9584535775762615 MAE: 1.1290332
Validation loss: 1.892734422828212 MAE: 1.114399
Validation loss: 1.6701833515456228 MAE: 1.0473101
Validation loss: 1.6057066989667488 MAE: 1.0254543
Validation loss: 1.6250847635245083 MAE: 1.0314378
Validation loss: 1.6172320436347614 MAE: 1.0301815
Validation loss: 1.6700411878450951 MAE: 1.0465589
Validation loss: 1.5953829986880523 MAE: 1.0209676
Validation loss: 1.5701689094004005 MAE: 1.0056653
Validation loss: 1.5445538988017073 MAE: 0.9893691
Validation loss: 1.5473998917473688 MAE: 0.988824
25 0 1.4429031610488892
Validation loss: 1.5607898066742252 MAE: 1.004461
Validation loss: 1.5311897126111118 MAE: 0.9869854
Validation loss: 1.5467371690754939 MAE: 0.98495173
Validation loss: 1.5961630886251277 MAE: 0.9955621
Validation loss: 1.5719561336016414 MAE: 0.9926108
Validation loss: 1.5282403796610207 MAE: 0.98908573
Validation loss: 1.5804661644829645 MAE: 1.0243622
Validation loss: 1.5786341103640469 MAE: 1.0287969
Validation loss: 2.493877442798229 MAE: 1.2696775
Validation loss: 2.5626831391845086 MAE: 1.2790998
Validation loss: 1.8274941510624356 MAE: 1.0763092
Validation loss: 1.540390870110555 MAE: 0.9876617
37 2 1.526428461074829
Validation loss: 1.558370800030352 MAE: 1.0036311
Validation loss: 1.5888113903276848 MAE: 1.0169729
Validation loss: 1.553022284700413 MAE: 0.9909262
Validation loss: 1.5382491687331536 MAE: 0.9779806
Validation loss: 1.5486973448835237 MAE: 0.98713005
Validation loss: 1.5172434382968478 MAE: 0.9803438
Validation loss: 1.472062440231593 MAE: 0.97446424
Validation loss: 1.468637755422881 MAE: 0.96953344
Validation loss: 1.836573544776801 MAE: 1.0622151
Validation loss: 1.8493486088935776 MAE: 1.0657398
Validation loss: 1.4691639476352267 MAE: 0.9652702
Validation loss: 1.4336156363439079 MAE: 0.95004237
Validation loss: 1.436251259211338 MAE: 0.95659655
50 0 1.5974217653274536
Validation loss: 1.4121433291772398 MAE: 0.94803256
Validation loss: 1.3730181437550169 MAE: 0.9364769
Validation loss: 1.3267070006842565 MAE: 0.9124285
Validation loss: 1.3828049825899529 MAE: 0.91788065
Validation loss: 1.4424236985770138 MAE: 0.9258659
Validation loss: 1.4083266354570485 MAE: 0.91869456
Validation loss: 1.196757603173304 MAE: 0.85067123
Validation loss: 1.1880450826702695 MAE: 0.8671081
Validation loss: 1.182782485027506 MAE: 0.8451551
Validation loss: 1.2585124969482422 MAE: 0.8733242
Validation loss: 1.1531149150446207 MAE: 0.8460104
Validation loss: 1.1082897896718498 MAE: 0.83943444
62 2 1.601396918296814
Validation loss: 1.137519020022768 MAE: 0.8534248
Validation loss: 1.1253427908276066 MAE: 0.8488686
Validation loss: 1.0717394472372652 MAE: 0.8431557
Validation loss: 1.0564645649206759 MAE: 0.83526427
Validation loss: 1.056916733658073 MAE: 0.82449675
Validation loss: 1.034916457503733 MAE: 0.8132133
Validation loss: 1.122238556543986 MAE: 0.8426917
Validation loss: 1.1710666406034218 MAE: 0.86111337
Validation loss: 0.9783283520226527 MAE: 0.7866289
Validation loss: 0.8466731960123236 MAE: 0.73262686
Validation loss: 0.7976918437264182 MAE: 0.72432214
Validation loss: 0.7840917850985671 MAE: 0.7026331
Validation loss: 0.757340316369076 MAE: 0.7071875
75 0 0.6618123650550842
Validation loss: 1.0008680362894078 MAE: 0.81470644
Validation loss: 0.8882077703572283 MAE: 0.77386135
Validation loss: 0.6844586657755303 MAE: 0.680619
Validation loss: 0.6238797391303862 MAE: 0.64787054
Validation loss: 0.7091729854694521 MAE: 0.6830324
Validation loss: 0.6962200535668267 MAE: 0.67323613
Validation loss: 0.7112787564595541 MAE: 0.6903873
Validation loss: 0.7250512769125929 MAE: 0.6991619
Validation loss: 0.7258683286532007 MAE: 0.70076287
Validation loss: 0.5895561304959384 MAE: 0.6356069
Validation loss: 0.5804715018079738 MAE: 0.63164437
Validation loss: 0.5895395688336305 MAE: 0.636185
87 2 0.9243982434272766
Validation loss: 0.5890613336755772 MAE: 0.63626087
Validation loss: 0.5398827306549958 MAE: 0.6018763
Validation loss: 0.5262681835829609 MAE: 0.5851431
Validation loss: 0.6085453545204317 MAE: 0.6233884
Validation loss: 0.5700486588357675 MAE: 0.6055836
Validation loss: 0.5468915195176096 MAE: 0.59911746
Validation loss: 0.5872659042026057 MAE: 0.625182
Validation loss: 0.5910940615817754 MAE: 0.6255854
Validation loss: 0.5128449213625205 MAE: 0.5727644
Validation loss: 0.5793319278293185 MAE: 0.6027404
Validation loss: 0.8679520105472719 MAE: 0.7421541
Validation loss: 0.7863597340053983 MAE: 0.72990125
Validation loss: 0.6594339094378732 MAE: 0.6692066
Loaded trained model with success.
Test loss: 1.2848172696382885 Test MAE: 0.88983315
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 4.740304946899414
Validation loss: 2.44552903678549 MAE: 1.204945
Validation loss: 1.563434385175082 MAE: 1.037197
Validation loss: 1.5684448330845666 MAE: 1.0493891
Validation loss: 1.5420144290181261 MAE: 1.0219234
Validation loss: 1.6322316874810798 MAE: 1.0625072
Validation loss: 1.6294203927768536 MAE: 1.0332144
Validation loss: 1.5707623042053913 MAE: 1.0244313
7 1 2.05106782913208
Validation loss: 1.5113630414608137 MAE: 1.0161562
Validation loss: 1.5503427020868463 MAE: 1.008803
Validation loss: 1.531102725608864 MAE: 1.0123479
Validation loss: 1.604146187628933 MAE: 1.0156127
Validation loss: 1.521616107854412 MAE: 1.0049622
Validation loss: 1.5361499954108617 MAE: 0.9986658
Validation loss: 1.5309137327587186 MAE: 0.9974445
14 2 1.8748373985290527
Validation loss: 1.5148819798800215 MAE: 1.0268567
Validation loss: 1.5208891270747735 MAE: 0.99572676
Validation loss: 1.4556091215143252 MAE: 0.9834558
Validation loss: 1.4389435016929204 MAE: 0.9808138
Validation loss: 1.4833262481881146 MAE: 0.9817534
Validation loss: 1.4084121072711657 MAE: 0.96978325
Validation loss: 1.287603365116982 MAE: 0.92222965
21 3 1.1212661266326904
Validation loss: 1.6429987441954301 MAE: 0.9883228
Validation loss: 1.2193724252470775 MAE: 0.87082535
Validation loss: 1.269971613608413 MAE: 0.8819781
Validation loss: 1.0659678701180308 MAE: 0.81898737
Validation loss: 1.0495615053416496 MAE: 0.80905026
Validation loss: 1.0169583508117714 MAE: 0.7911136
Validation loss: 0.9788527311991208 MAE: 0.7884256
28 4 0.7716279029846191
Validation loss: 1.0275379395365116 MAE: 0.7981638
Validation loss: 0.911279081998758 MAE: 0.7752956
Validation loss: 0.9982881587953424 MAE: 0.7803799
Validation loss: 0.8494860973190422 MAE: 0.7416175
Validation loss: 0.7920141414781312 MAE: 0.7219461
Validation loss: 1.0059228491543526 MAE: 0.79630274
Validation loss: 0.7442386713459264 MAE: 0.6944143
35 5 0.9293104410171509
Validation loss: 0.747782794973958 MAE: 0.70129627
Validation loss: 0.7172627296280022 MAE: 0.6976185
Validation loss: 0.6522426404545655 MAE: 0.65903884
Validation loss: 0.6089345670525154 MAE: 0.6336862
Validation loss: 0.5785946185564875 MAE: 0.61000764
Validation loss: 0.5728098269383511 MAE: 0.61088765
Validation loss: 0.7065789759458609 MAE: 0.661282
42 6 1.5599628686904907
Validation loss: 0.6275250267742867 MAE: 0.6487678
Validation loss: 0.555440215459421 MAE: 0.59597224
Validation loss: 0.5527393811911194 MAE: 0.60338145
Validation loss: 0.5692768408425489 MAE: 0.60929316
Validation loss: 0.6326725842365667 MAE: 0.6241028
Validation loss: 0.5870290892807084 MAE: 0.61351234
Validation loss: 0.5873766504040915 MAE: 0.6194078
Validation loss: 0.4848816146203621 MAE: 0.5641483
50 0 0.8458760380744934
Validation loss: 0.46672665309067346 MAE: 0.5558279
Validation loss: 0.45725044383475527 MAE: 0.5393111
Validation loss: 0.4875927252985125 MAE: 0.55566376
Validation loss: 0.5644795088911775 MAE: 0.6100717
Validation loss: 0.4852001421415626 MAE: 0.5724808
Validation loss: 0.5099430298385907 MAE: 0.5827738
Validation loss: 0.44624565144879136 MAE: 0.54032105
57 1 0.45962026715278625
Validation loss: 0.49818796218939165 MAE: 0.5829723
Validation loss: 0.42499378458339365 MAE: 0.5341977
Validation loss: 0.49622202009411914 MAE: 0.5663723
Validation loss: 0.4186142605153759 MAE: 0.5276348
Validation loss: 0.44465268242299255 MAE: 0.54349923
Validation loss: 0.41416276504645994 MAE: 0.5122856
Validation loss: 0.47359969418252534 MAE: 0.54361135
64 2 0.5687485337257385
Validation loss: 0.41495181792345476 MAE: 0.51449007
Validation loss: 0.40757801320085574 MAE: 0.514199
Validation loss: 0.40004542185433545 MAE: 0.51276976
Validation loss: 0.38609403491619243 MAE: 0.4934618
Validation loss: 0.3960907677909238 MAE: 0.48930117
Validation loss: 0.3772180901100887 MAE: 0.48644653
Validation loss: 0.35758246743499333 MAE: 0.47311962
71 3 0.5570936799049377
Validation loss: 0.38040580971157134 MAE: 0.48560357
Validation loss: 0.3805472128954365 MAE: 0.49437174
Validation loss: 0.39525443165745566 MAE: 0.51489854
Validation loss: 0.3597105769955333 MAE: 0.48088565
Validation loss: 0.37263655812297036 MAE: 0.4925521
Validation loss: 0.37058826112867 MAE: 0.49591133
Validation loss: 0.3825174674915908 MAE: 0.50912225
78 4 0.7473458647727966
Validation loss: 0.3668202263626022 MAE: 0.48544127
Validation loss: 0.42941157894218385 MAE: 0.52951264
Validation loss: 0.3315589931142989 MAE: 0.4653976
Validation loss: 0.33964815855625285 MAE: 0.4649214
Validation loss: 0.32854394112999113 MAE: 0.45115474
Validation loss: 0.3098345572624973 MAE: 0.4340543
Validation loss: 0.30815403492905985 MAE: 0.44083166
85 5 0.6763240694999695
Validation loss: 0.3790108702290597 MAE: 0.507472
Validation loss: 0.34540387141944173 MAE: 0.4649595
Validation loss: 0.2968745903303875 MAE: 0.42437407
Validation loss: 0.2836750238085512 MAE: 0.42279318
Validation loss: 0.31108692303374785 MAE: 0.45344314
Validation loss: 0.327372644489734 MAE: 0.4630289
Validation loss: 0.3427825610541818 MAE: 0.4690762
92 6 0.9420422315597534
Validation loss: 0.37637213052217683 MAE: 0.49373177
Validation loss: 0.3131592151657421 MAE: 0.44520092
Validation loss: 0.32177164940977815 MAE: 0.45101216
Validation loss: 0.5150778781828569 MAE: 0.5823982
Validation loss: 0.3032262212217753 MAE: 0.43738618
Validation loss: 0.28788933217825 MAE: 0.42449814
Validation loss: 0.2905195204157326 MAE: 0.4340874
Validation loss: 0.29005104468096443 MAE: 0.43332547
Loaded trained model with success.
Test loss: 1.0088637770450137 Test MAE: 0.7843908
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 7.958549499511719
Validation loss: 1.683640673547565 MAE: 1.0483052
Validation loss: 1.601101318437733 MAE: 1.0149182
Validation loss: 1.5371940955370367 MAE: 0.9910989
3 2 1.0658764839172363
Validation loss: 1.547933389046388 MAE: 0.98971725
Validation loss: 1.5519143493476517 MAE: 0.9900224
Validation loss: 1.4875602726945896 MAE: 0.9766909
6 4 1.5311578512191772
Validation loss: 1.4960670318297729 MAE: 0.9952228
Validation loss: 1.542051792622568 MAE: 0.9859851
Validation loss: 1.4280366625241143 MAE: 0.95471215
9 6 1.5229718685150146
Validation loss: 1.3443143370156299 MAE: 0.9242949
Validation loss: 1.2441053584008992 MAE: 0.90249664
Validation loss: 1.1584324933483987 MAE: 0.8696655
12 8 0.9300223588943481
Validation loss: 1.04270375885801 MAE: 0.82158923
Validation loss: 1.0060293398543685 MAE: 0.7961234
Validation loss: 0.9507533555518172 MAE: 0.7787693
15 10 1.3272382020950317
Validation loss: 0.8560972759623326 MAE: 0.74075776
Validation loss: 0.8419618878909246 MAE: 0.7263116
Validation loss: 0.8515899454902313 MAE: 0.73957723
18 12 0.8887832164764404
Validation loss: 0.8036187243366051 MAE: 0.7117774
Validation loss: 0.7567599291553 MAE: 0.6881156
Validation loss: 0.7798964553223344 MAE: 0.7031683
21 14 1.4336578845977783
Validation loss: 0.7236866280884446 MAE: 0.6737421
Validation loss: 0.691151581928582 MAE: 0.65516275
Validation loss: 0.664289423960722 MAE: 0.6482828
Validation loss: 0.6716296647139685 MAE: 0.6511563
25 0 0.9096351861953735
Validation loss: 0.6675897160608448 MAE: 0.6478352
Validation loss: 0.6638348280547377 MAE: 0.64529943
Validation loss: 0.6571251757756502 MAE: 0.64587265
28 2 0.6778818964958191
Validation loss: 0.6765536128996847 MAE: 0.64957315
Validation loss: 0.6636292666853788 MAE: 0.64573574
Validation loss: 0.585286835869233 MAE: 0.60445714
31 4 0.8181032538414001
Validation loss: 0.5975438540349742 MAE: 0.6124285
Validation loss: 0.5642053316494745 MAE: 0.5903736
Validation loss: 0.5905153369139096 MAE: 0.61001575
34 6 0.8914610743522644
Validation loss: 0.5749507837878439 MAE: 0.6017389
Validation loss: 0.6194863721937359 MAE: 0.6263402
Validation loss: 0.6342589606741865 MAE: 0.6306468
37 8 0.5898133516311646
Validation loss: 0.5534421888764254 MAE: 0.58784777
Validation loss: 0.5305735717316667 MAE: 0.5816714
Validation loss: 0.5713090608139076 MAE: 0.5978668
40 10 0.6487671136856079
Validation loss: 0.5391992731897052 MAE: 0.5810039
Validation loss: 0.5328903987197455 MAE: 0.5806958
Validation loss: 0.5825407216568032 MAE: 0.6010983
43 12 0.36734333634376526
Validation loss: 0.5371063608444764 MAE: 0.57528645
Validation loss: 0.4948516802821226 MAE: 0.55155843
Validation loss: 0.44994338695893066 MAE: 0.5350506
46 14 0.6848094463348389
Validation loss: 0.5496809342820085 MAE: 0.59194255
Validation loss: 0.4830270457960561 MAE: 0.54962647
Validation loss: 0.5071696446749395 MAE: 0.56616396
Validation loss: 0.5465467821858928 MAE: 0.5846172
50 0 0.8449960350990295
Validation loss: 0.44951743592241244 MAE: 0.5268923
Validation loss: 0.41778950808282367 MAE: 0.5090849
Validation loss: 0.4265994038395509 MAE: 0.51185286
53 2 0.64324951171875
Validation loss: 0.43625914931058407 MAE: 0.52444595
Validation loss: 0.4197661465776707 MAE: 0.5142494
Validation loss: 0.397565205195146 MAE: 0.4962081
56 4 0.5282599925994873
Validation loss: 0.4157894788261406 MAE: 0.5077426
Validation loss: 0.46349346291326093 MAE: 0.5312331
Validation loss: 0.4196334580381313 MAE: 0.5118074
59 6 0.6473528742790222
Validation loss: 0.43187450233824504 MAE: 0.522851
Validation loss: 0.4557393567714997 MAE: 0.5261816
Validation loss: 0.43953390386634933 MAE: 0.5290953
62 8 0.7234920263290405
Validation loss: 0.41536044166656677 MAE: 0.50596887
Validation loss: 0.5032133557395132 MAE: 0.56753945
Validation loss: 0.3735358902591025 MAE: 0.4825084
65 10 0.8153151273727417
Validation loss: 0.4277759237674052 MAE: 0.5174292
Validation loss: 0.42294969432100743 MAE: 0.5204649
Validation loss: 0.3990083917945564 MAE: 0.499468
68 12 0.46640196442604065
Validation loss: 0.3846435608390816 MAE: 0.48917854
Validation loss: 0.3622391792480836 MAE: 0.4743009
Validation loss: 0.42418257930952463 MAE: 0.51797384
71 14 0.5561678409576416
Validation loss: 0.3598437199372806 MAE: 0.47472453
Validation loss: 0.38012387631890293 MAE: 0.48258486
Validation loss: 0.3604710179125379 MAE: 0.4713398
Validation loss: 0.3924782756633892 MAE: 0.489054
75 0 0.41511085629463196
Validation loss: 0.4206622041060117 MAE: 0.5150289
Validation loss: 0.41156549557655275 MAE: 0.51091605
Validation loss: 0.3642116355035969 MAE: 0.47138748
78 2 0.4735497534275055
Validation loss: 0.3950695619435014 MAE: 0.49367553
Validation loss: 0.32357621216821764 MAE: 0.44802698
Validation loss: 0.33946727741815763 MAE: 0.4618338
81 4 0.318525105714798
Validation loss: 0.35928779541848893 MAE: 0.48258138
Validation loss: 0.399029084639941 MAE: 0.49438873
Validation loss: 0.34931386239781886 MAE: 0.46719873
84 6 0.5487931370735168
Validation loss: 0.32787329979793345 MAE: 0.45231783
Validation loss: 0.351713223453753 MAE: 0.47501343
Validation loss: 0.3111158572361321 MAE: 0.44256377
87 8 0.6576057076454163
Validation loss: 0.34539469646547505 MAE: 0.46634266
Validation loss: 0.3235059267652775 MAE: 0.45138428
Validation loss: 0.377763573894042 MAE: 0.49001366
90 10 0.5051981210708618
Validation loss: 0.4643793601789073 MAE: 0.55467135
Validation loss: 0.30894133541173113 MAE: 0.4399872
Validation loss: 0.33893837987301584 MAE: 0.4615018
93 12 0.290066123008728
Validation loss: 0.35420127550442376 MAE: 0.47042894
Validation loss: 0.2956704890919114 MAE: 0.4338816
Validation loss: 0.3293701937060079 MAE: 0.45395598
96 14 0.473506897687912
Validation loss: 0.35162327410223965 MAE: 0.4695709
Validation loss: 0.2968818798571646 MAE: 0.4297884
Validation loss: 0.37686251530905285 MAE: 0.48103663
Validation loss: 0.27930957090878533 MAE: 0.41941264
Loaded trained model with success.
Test loss: 0.7389241866421239 Test MAE: 0.661378
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 2}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.7298387289047241
Validation loss: 0.694688081741333 ROC AUC: 0.19999999999999998
Validation loss: 0.7340869307518005 ROC AUC: 0.3
Validation loss: 0.7564090490341187 ROC AUC: 0.45000000000000007
Validation loss: 0.7581755518913269 ROC AUC: 0.75
Validation loss: 0.7725722193717957 ROC AUC: 0.75
Validation loss: 0.8063859939575195 ROC AUC: 0.8
Validation loss: 0.8423302173614502 ROC AUC: 1.0
Validation loss: 0.8841277360916138 ROC AUC: 0.8
Validation loss: 0.9031699299812317 ROC AUC: 0.8
Validation loss: 0.9093937277793884 ROC AUC: 0.65
Validation loss: 0.9568567276000977 ROC AUC: 0.65
Validation loss: 0.984603762626648 ROC AUC: 0.7
Validation loss: 0.9935641884803772 ROC AUC: 0.75
Validation loss: 1.0433074235916138 ROC AUC: 0.7
Validation loss: 1.0820276737213135 ROC AUC: 0.75
Validation loss: 1.123046875 ROC AUC: 0.75
Validation loss: 1.1494849920272827 ROC AUC: 0.75
Validation loss: 1.1079297065734863 ROC AUC: 0.75
Validation loss: 1.0716882944107056 ROC AUC: 0.7
Validation loss: 1.0458858013153076 ROC AUC: 0.75
Validation loss: 1.010209560394287 ROC AUC: 0.75
Validation loss: 1.0097254514694214 ROC AUC: 0.8
Validation loss: 0.9641632437705994 ROC AUC: 0.8
Validation loss: 0.9275954365730286 ROC AUC: 0.8
Validation loss: 0.8397573828697205 ROC AUC: 0.8
Validation loss: 0.8124072551727295 ROC AUC: 0.8
Validation loss: 0.6741703152656555 ROC AUC: 0.8
Validation loss: 0.5859329104423523 ROC AUC: 0.8500000000000001
Validation loss: 0.44489654898643494 ROC AUC: 0.8
Validation loss: 0.3862817585468292 ROC AUC: 0.8
Validation loss: 0.36638277769088745 ROC AUC: 0.8500000000000001
Validation loss: 0.3439638912677765 ROC AUC: 0.8500000000000001
Validation loss: 0.33321380615234375 ROC AUC: 0.8500000000000001
Validation loss: 0.3194153606891632 ROC AUC: 0.8500000000000001
Validation loss: 0.3087441325187683 ROC AUC: 0.8500000000000001
Validation loss: 0.3014443814754486 ROC AUC: 0.8500000000000001
Validation loss: 0.2949064075946808 ROC AUC: 0.8500000000000001
Validation loss: 0.29034942388534546 ROC AUC: 0.8500000000000001
Validation loss: 0.286131352186203 ROC AUC: 0.9
Validation loss: 0.28662732243537903 ROC AUC: 0.9
Validation loss: 0.29006513953208923 ROC AUC: 0.9
Validation loss: 0.29687774181365967 ROC AUC: 0.9
Validation loss: 0.30222898721694946 ROC AUC: 0.9500000000000001
Validation loss: 0.3009413480758667 ROC AUC: 1.0
Validation loss: 0.298500120639801 ROC AUC: 0.9500000000000001
Validation loss: 0.2925814092159271 ROC AUC: 0.9500000000000001
Validation loss: 0.2891455590724945 ROC AUC: 0.9500000000000001
Validation loss: 0.29172372817993164 ROC AUC: 0.9500000000000001
Validation loss: 0.30005764961242676 ROC AUC: 0.9
Validation loss: 0.3133099377155304 ROC AUC: 0.9
50 0 0.20218604803085327
Validation loss: 0.31414544582366943 ROC AUC: 0.9
Validation loss: 0.3096977770328522 ROC AUC: 0.9
Validation loss: 0.30868104100227356 ROC AUC: 0.9
Validation loss: 0.31415608525276184 ROC AUC: 0.9500000000000001
Validation loss: 0.3294444680213928 ROC AUC: 0.9500000000000001
Validation loss: 0.3399953246116638 ROC AUC: 1.0
Validation loss: 0.34774672985076904 ROC AUC: 1.0
Validation loss: 0.351865291595459 ROC AUC: 1.0
Validation loss: 0.345248818397522 ROC AUC: 1.0
Validation loss: 0.3437701463699341 ROC AUC: 1.0
Validation loss: 0.32977235317230225 ROC AUC: 1.0
Validation loss: 0.31400805711746216 ROC AUC: 1.0
Validation loss: 0.2991029918193817 ROC AUC: 1.0
Validation loss: 0.2802897095680237 ROC AUC: 1.0
Validation loss: 0.2685481905937195 ROC AUC: 1.0
Validation loss: 0.2614637315273285 ROC AUC: 1.0
Validation loss: 0.2599114179611206 ROC AUC: 1.0
Validation loss: 0.2625964879989624 ROC AUC: 1.0
Validation loss: 0.2662533223628998 ROC AUC: 1.0
Validation loss: 0.2785987854003906 ROC AUC: 1.0
Validation loss: 0.2955740690231323 ROC AUC: 1.0
Validation loss: 0.3085780739784241 ROC AUC: 1.0
Validation loss: 0.3207186460494995 ROC AUC: 1.0
Validation loss: 0.3251439034938812 ROC AUC: 1.0
Validation loss: 0.3155420422554016 ROC AUC: 1.0
Validation loss: 0.319418340921402 ROC AUC: 1.0
Validation loss: 0.30478909611701965 ROC AUC: 1.0
Validation loss: 0.26354408264160156 ROC AUC: 1.0
Validation loss: 0.22484904527664185 ROC AUC: 1.0
Validation loss: 0.17390292882919312 ROC AUC: 1.0
Validation loss: 0.14419004321098328 ROC AUC: 1.0
Validation loss: 0.12184340506792068 ROC AUC: 1.0
Validation loss: 0.11077301949262619 ROC AUC: 1.0
Validation loss: 0.10498017072677612 ROC AUC: 1.0
Validation loss: 0.12133268266916275 ROC AUC: 1.0
Validation loss: 0.1387328952550888 ROC AUC: 1.0
Validation loss: 0.13409049808979034 ROC AUC: 1.0
Validation loss: 0.1408793181180954 ROC AUC: 1.0
Validation loss: 0.1374187469482422 ROC AUC: 1.0
Validation loss: 0.12317144870758057 ROC AUC: 1.0
Validation loss: 0.1430865228176117 ROC AUC: 1.0
Validation loss: 0.16579169034957886 ROC AUC: 1.0
Validation loss: 0.1651964783668518 ROC AUC: 1.0
Validation loss: 0.17851337790489197 ROC AUC: 1.0
Validation loss: 0.1660206913948059 ROC AUC: 1.0
Validation loss: 0.1750827133655548 ROC AUC: 1.0
Validation loss: 0.19731169939041138 ROC AUC: 1.0
Validation loss: 0.20164543390274048 ROC AUC: 1.0
Validation loss: 0.166347473859787 ROC AUC: 1.0
Validation loss: 0.12683407962322235 ROC AUC: 1.0
Loaded trained model with success.
Test loss: 0.9173579901504163 Test ROC AUC: 0.43335145618007753
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 2}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.7819715142250061
Validation loss: 0.8529681551213167 ROC AUC: 0.3433333333333333
Validation loss: 0.9203102527832498 ROC AUC: 0.5666666666666667
Validation loss: 0.7583240757183153 ROC AUC: 0.5883333333333334
Validation loss: 0.7174843488907328 ROC AUC: 0.6416666666666666
Validation loss: 0.7581155421782513 ROC AUC: 0.6683333333333332
Validation loss: 0.893631285550643 ROC AUC: 0.6233333333333333
Validation loss: 1.0192345076677751 ROC AUC: 0.5583333333333332
Validation loss: 0.9709676832568889 ROC AUC: 0.6033333333333334
Validation loss: 0.7988753282293981 ROC AUC: 0.665
Validation loss: 0.6692284187492059 ROC AUC: 0.715
Validation loss: 0.638120174407959 ROC AUC: 0.725
Validation loss: 0.6398270981652396 ROC AUC: 0.7066666666666667
Validation loss: 0.6374520039071843 ROC AUC: 0.705
Validation loss: 0.6314678763856694 ROC AUC: 0.7166666666666667
Validation loss: 0.6313026389297174 ROC AUC: 0.7316666666666667
Validation loss: 0.632497428631296 ROC AUC: 0.74
Validation loss: 0.6447709713663373 ROC AUC: 0.75
Validation loss: 0.667503652523975 ROC AUC: 0.76
Validation loss: 0.681004316222911 ROC AUC: 0.7733333333333333
Validation loss: 0.676534509172245 ROC AUC: 0.78
Validation loss: 0.6546400347534491 ROC AUC: 0.7816666666666666
Validation loss: 0.6432490871877087 ROC AUC: 0.785
Validation loss: 0.6315212115949514 ROC AUC: 0.7899999999999999
Validation loss: 0.618682439838137 ROC AUC: 0.7949999999999999
Validation loss: 0.6068250865352397 ROC AUC: 0.7949999999999999
25 0 0.4395805299282074
Validation loss: 0.6000157862293477 ROC AUC: 0.7949999999999999
Validation loss: 0.5905403275879062 ROC AUC: 0.7949999999999999
Validation loss: 0.5988588539921508 ROC AUC: 0.7999999999999999
Validation loss: 0.6132425702348048 ROC AUC: 0.7966666666666665
Validation loss: 0.6052794419989294 ROC AUC: 0.7983333333333332
Validation loss: 0.5995112864338622 ROC AUC: 0.8033333333333333
Validation loss: 0.5985736773938549 ROC AUC: 0.8049999999999999
Validation loss: 0.6010859146410105 ROC AUC: 0.8066666666666666
Validation loss: 0.6083534213961387 ROC AUC: 0.81
Validation loss: 0.6231563480532899 ROC AUC: 0.8099999999999999
Validation loss: 0.6456609459555879 ROC AUC: 0.81
Validation loss: 0.6611713888693829 ROC AUC: 0.8116666666666666
Validation loss: 0.651310852595738 ROC AUC: 0.8150000000000001
Validation loss: 0.5997671010542889 ROC AUC: 0.8183333333333334
Validation loss: 0.5547967735601931 ROC AUC: 0.8266666666666668
Validation loss: 0.5307292707112371 ROC AUC: 0.8266666666666667
Validation loss: 0.5355269908905029 ROC AUC: 0.8266666666666667
Validation loss: 0.5472843002299873 ROC AUC: 0.8333333333333334
Validation loss: 0.5564945668590312 ROC AUC: 0.835
Validation loss: 0.5523506542857812 ROC AUC: 0.8366666666666667
Validation loss: 0.5469301160500974 ROC AUC: 0.845
Validation loss: 0.5378781374619932 ROC AUC: 0.8466666666666667
Validation loss: 0.501791520386326 ROC AUC: 0.8550000000000001
Validation loss: 0.4660769664511389 ROC AUC: 0.8616666666666667
Validation loss: 0.4165414450119953 ROC AUC: 0.88
50 0 0.5701838135719299
Validation loss: 0.3953554770167993 ROC AUC: 0.9033333333333333
Validation loss: 0.3893518332315951 ROC AUC: 0.9149999999999999
Validation loss: 0.3731438572309455 ROC AUC: 0.9216666666666666
Validation loss: 0.3567966526868392 ROC AUC: 0.9316666666666666
Validation loss: 0.35267066468997876 ROC AUC: 0.9416666666666668
Validation loss: 0.3557043416159494 ROC AUC: 0.9516666666666667
Validation loss: 0.3543449074638133 ROC AUC: 0.96
Validation loss: 0.34676233359745573 ROC AUC: 0.9650000000000001
Validation loss: 0.34797169359362856 ROC AUC: 0.9633333333333334
Validation loss: 0.34652923868626967 ROC AUC: 0.9600000000000001
Validation loss: 0.33589000665411656 ROC AUC: 0.9600000000000001
Validation loss: 0.3324989615654459 ROC AUC: 0.9616666666666667
Validation loss: 0.3169179327633916 ROC AUC: 0.9666666666666667
Validation loss: 0.31088449304201166 ROC AUC: 0.9633333333333334
Validation loss: 0.30880010188842305 ROC AUC: 0.9633333333333333
Validation loss: 0.317996691076123 ROC AUC: 0.9633333333333333
Validation loss: 0.33358172677001174 ROC AUC: 0.96
Validation loss: 0.33610778499622734 ROC AUC: 0.9683333333333334
Validation loss: 0.3228750289702902 ROC AUC: 0.9650000000000001
Validation loss: 0.2946844715244916 ROC AUC: 0.9733333333333334
Validation loss: 0.278394983739269 ROC AUC: 0.98
Validation loss: 0.2489074949099093 ROC AUC: 0.9883333333333333
Validation loss: 0.21526361728201107 ROC AUC: 0.9966666666666667
Validation loss: 0.192461120230811 ROC AUC: 0.9966666666666667
Validation loss: 0.17388579006097754 ROC AUC: 0.9983333333333333
75 0 0.20998120307922363
Validation loss: 0.15594064216224515 ROC AUC: 0.9983333333333333
Validation loss: 0.14953751709996438 ROC AUC: 1.0
Validation loss: 0.14965198934078217 ROC AUC: 1.0
Validation loss: 0.16813563889994912 ROC AUC: 1.0
Validation loss: 0.20131851702320333 ROC AUC: 1.0
Validation loss: 0.17578471984182084 ROC AUC: 1.0
Validation loss: 0.18076921847401833 ROC AUC: 1.0
Validation loss: 0.19937305973500621 ROC AUC: 1.0
Validation loss: 0.17819285681661295 ROC AUC: 1.0
Validation loss: 0.17321729082234052 ROC AUC: 1.0
Validation loss: 0.19901917661939347 ROC AUC: 1.0
Validation loss: 0.16912613991571931 ROC AUC: 1.0
Validation loss: 0.20253573145185197 ROC AUC: 1.0
Validation loss: 0.1921729770850162 ROC AUC: 1.0
Validation loss: 0.18700205215385982 ROC AUC: 1.0
Validation loss: 0.1842123799178065 ROC AUC: 1.0
Validation loss: 0.1868700883826431 ROC AUC: 1.0
Validation loss: 0.22478022852114268 ROC AUC: 1.0
Validation loss: 0.26599507489982915 ROC AUC: 1.0
Validation loss: 0.300065210887364 ROC AUC: 1.0
Validation loss: 0.27101667985624195 ROC AUC: 1.0
Validation loss: 0.2729655796167802 ROC AUC: 1.0
Validation loss: 0.24249367081389137 ROC AUC: 1.0
Validation loss: 0.21981211189104585 ROC AUC: 1.0
Validation loss: 0.20163682255209708 ROC AUC: 1.0
Loaded trained model with success.
Test loss: 1.04402099963199 Test ROC AUC: 0.6063754855618477
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 2}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.8273110389709473
Validation loss: 0.9876125918494331 ROC AUC: 0.3473469387755102
Validation loss: 1.0890433047757004 ROC AUC: 0.4416326530612245
Validation loss: 0.8545984053852582 ROC AUC: 0.5330612244897959
Validation loss: 0.7113700611422761 ROC AUC: 0.557142857142857
Validation loss: 0.7053939164286912 ROC AUC: 0.5412244897959184
Validation loss: 0.7227565977308485 ROC AUC: 0.5412244897959184
Validation loss: 0.7213609676168422 ROC AUC: 0.5477551020408163
Validation loss: 0.7030154692404198 ROC AUC: 0.5575510204081632
Validation loss: 0.6752671015383017 ROC AUC: 0.566530612244898
Validation loss: 0.6816424173538131 ROC AUC: 0.5726530612244898
Validation loss: 0.6772061676690073 ROC AUC: 0.6155102040816327
Validation loss: 0.6706510240381415 ROC AUC: 0.6281632653061224
12 2 0.7037246823310852
Validation loss: 0.6825544418710651 ROC AUC: 0.6216326530612245
Validation loss: 0.7838022106825703 ROC AUC: 0.6151020408163266
Validation loss: 0.8507919757053105 ROC AUC: 0.6134693877551021
Validation loss: 0.7237263523569011 ROC AUC: 0.6114285714285714
Validation loss: 0.6550136566764176 ROC AUC: 0.6016326530612244
Validation loss: 0.6588611367977026 ROC AUC: 0.5873469387755101
Validation loss: 0.6713487596222849 ROC AUC: 0.5938775510204082
Validation loss: 0.7190824873519667 ROC AUC: 0.6297959183673469
Validation loss: 0.7147352761692471 ROC AUC: 0.6289795918367347
Validation loss: 0.6634754044841035 ROC AUC: 0.6481632653061224
Validation loss: 0.6584798067507117 ROC AUC: 0.6714285714285715
Validation loss: 0.6525006228023105 ROC AUC: 0.7024489795918367
Validation loss: 0.6874222674153068 ROC AUC: 0.6493877551020408
25 0 0.6676707863807678
Validation loss: 0.7285617909046135 ROC AUC: 0.6559183673469388
Validation loss: 0.6882257214700332 ROC AUC: 0.666530612244898
Validation loss: 0.6377886900998125 ROC AUC: 0.6669387755102041
Validation loss: 0.6519000235230031 ROC AUC: 0.716734693877551
Validation loss: 0.6521601556527494 ROC AUC: 0.7195918367346938
Validation loss: 0.6979019900765082 ROC AUC: 0.670204081632653
Validation loss: 0.8033446884817548 ROC AUC: 0.6836734693877551
Validation loss: 0.8530232852155512 ROC AUC: 0.686530612244898
Validation loss: 0.7470346072105446 ROC AUC: 0.6963265306122448
Validation loss: 0.6676128356143681 ROC AUC: 0.6885714285714286
Validation loss: 0.6017049713568254 ROC AUC: 0.7093877551020408
Validation loss: 0.6192081185302349 ROC AUC: 0.6873469387755101
37 2 0.6227388381958008
Validation loss: 0.673301141069393 ROC AUC: 0.7289795918367347
Validation loss: 0.7134870808533947 ROC AUC: 0.7371428571428571
Validation loss: 0.7000245174976311 ROC AUC: 0.7583673469387755
Validation loss: 0.6463158353410586 ROC AUC: 0.7812244897959184
Validation loss: 0.621748746645571 ROC AUC: 0.7685714285714286
Validation loss: 0.6135555517793906 ROC AUC: 0.7661224489795919
Validation loss: 0.6127235522173872 ROC AUC: 0.7722448979591837
Validation loss: 0.6072887961912636 ROC AUC: 0.7759183673469388
Validation loss: 0.5801527292439432 ROC AUC: 0.7812244897959184
Validation loss: 0.5742239879839348 ROC AUC: 0.7759183673469389
Validation loss: 0.564519973415317 ROC AUC: 0.7746938775510204
Validation loss: 0.5811319137462462 ROC AUC: 0.7779591836734694
Validation loss: 0.6207497146996585 ROC AUC: 0.7746938775510204
50 0 0.634598970413208
Validation loss: 0.6032008546771426 ROC AUC: 0.7853061224489796
Validation loss: 0.5497010735550312 ROC AUC: 0.7951020408163265
Validation loss: 0.556365172068278 ROC AUC: 0.803265306122449
Validation loss: 0.5854964512165146 ROC AUC: 0.8146938775510204
Validation loss: 0.6591591464750695 ROC AUC: 0.8244897959183674
Validation loss: 0.6810133481266523 ROC AUC: 0.8269387755102041
Validation loss: 0.6540347060771904 ROC AUC: 0.8261224489795918
Validation loss: 0.5967120443931734 ROC AUC: 0.8281632653061224
Validation loss: 0.5566127029332247 ROC AUC: 0.8297959183673469
Validation loss: 0.5560406545797983 ROC AUC: 0.8391836734693878
Validation loss: 0.6073970745007197 ROC AUC: 0.8542857142857143
Validation loss: 0.6800565737666506 ROC AUC: 0.8612244897959185
62 2 0.7010356783866882
Validation loss: 0.6260514759054088 ROC AUC: 0.8591836734693878
Validation loss: 0.6159093410077722 ROC AUC: 0.856326530612245
Validation loss: 0.5917213902328954 ROC AUC: 0.8726530612244898
Validation loss: 0.5581280215822085 ROC AUC: 0.8816326530612244
Validation loss: 0.524468229274557 ROC AUC: 0.8836734693877552
Validation loss: 0.501308824076797 ROC AUC: 0.8881632653061224
Validation loss: 0.4849297943139317 ROC AUC: 0.8983673469387755
Validation loss: 0.4848237766159905 ROC AUC: 0.9008163265306122
Validation loss: 0.5019245430676624 ROC AUC: 0.8963265306122449
Validation loss: 0.5184266711726333 ROC AUC: 0.8959183673469389
Validation loss: 0.4732381984440967 ROC AUC: 0.896734693877551
Validation loss: 0.4289569954077403 ROC AUC: 0.909795918367347
Validation loss: 0.4667689228298688 ROC AUC: 0.9126530612244899
75 0 0.4137558043003082
Validation loss: 0.5071101826850815 ROC AUC: 0.9248979591836735
Validation loss: 0.4762146593344332 ROC AUC: 0.930204081632653
Validation loss: 0.4943938435930194 ROC AUC: 0.9322448979591836
Validation loss: 0.46545395345398877 ROC AUC: 0.9371428571428572
Validation loss: 0.5062502706893767 ROC AUC: 0.9416326530612245
Validation loss: 0.5444391079698548 ROC AUC: 0.9424489795918367
Validation loss: 0.4653467960429914 ROC AUC: 0.9383673469387754
Validation loss: 0.45671976455534347 ROC AUC: 0.9436734693877551
Validation loss: 0.4066495088615803 ROC AUC: 0.9489795918367347
Validation loss: 0.3885767405683344 ROC AUC: 0.9514285714285714
Validation loss: 0.41523980522396586 ROC AUC: 0.9559183673469388
Validation loss: 0.48428548947729244 ROC AUC: 0.9579591836734693
87 2 0.38626930117607117
Validation loss: 0.5428360215943269 ROC AUC: 0.9595918367346938
Validation loss: 0.5092490717317119 ROC AUC: 0.9579591836734694
Validation loss: 0.5307588083575471 ROC AUC: 0.9567346938775511
Validation loss: 0.5366469905382455 ROC AUC: 0.9559183673469388
Validation loss: 0.5387613357919635 ROC AUC: 0.9448979591836735
Validation loss: 0.5381340739702938 ROC AUC: 0.9481632653061224
Validation loss: 0.5545228298264321 ROC AUC: 0.956734693877551
Validation loss: 0.49177555905448067 ROC AUC: 0.9640816326530612
Validation loss: 0.44876856545005184 ROC AUC: 0.9706122448979592
Validation loss: 0.4704371681719115 ROC AUC: 0.9689795918367348
Validation loss: 0.47541283176402854 ROC AUC: 0.9734693877551021
Validation loss: 0.4360518895014368 ROC AUC: 0.9693877551020409
Validation loss: 0.4038109099022066 ROC AUC: 0.9620408163265306
Loaded trained model with success.
Test loss: 0.7679241323153001 Test ROC AUC: 0.6726151925643941
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 2}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.7705118060112
Validation loss: 0.8663879315457751 ROC AUC: 0.44838383838383833
Validation loss: 0.6914082513981729 ROC AUC: 0.566060606060606
Validation loss: 0.6947274585465091 ROC AUC: 0.481010101010101
Validation loss: 0.6883545469998116 ROC AUC: 0.5943434343434343
Validation loss: 0.7139044401034638 ROC AUC: 0.610909090909091
Validation loss: 0.6667623951207453 ROC AUC: 0.6314141414141414
Validation loss: 0.692188026317999 ROC AUC: 0.6426262626262627
7 1 0.6434528827667236
Validation loss: 0.6718392342179265 ROC AUC: 0.661010101010101
Validation loss: 0.6658860313233419 ROC AUC: 0.6710101010101011
Validation loss: 0.6730986977342385 ROC AUC: 0.6781818181818182
Validation loss: 0.6591535174666937 ROC AUC: 0.6842424242424243
Validation loss: 0.6837624482174015 ROC AUC: 0.6848484848484849
Validation loss: 0.6536885748556511 ROC AUC: 0.6905050505050505
Validation loss: 0.6706105448193287 ROC AUC: 0.6957575757575757
14 2 0.6422650814056396
Validation loss: 0.6381751137163172 ROC AUC: 0.7045454545454546
Validation loss: 0.6667085119228268 ROC AUC: 0.7106060606060606
Validation loss: 0.6368184865419589 ROC AUC: 0.7158585858585859
Validation loss: 0.6213417062208281 ROC AUC: 0.7151515151515152
Validation loss: 0.685335113774592 ROC AUC: 0.7074747474747475
Validation loss: 0.6398326787517299 ROC AUC: 0.6958585858585858
Validation loss: 0.6296946207183091 ROC AUC: 0.7224242424242424
21 3 0.6151705980300903
Validation loss: 0.6427903636616079 ROC AUC: 0.746969696969697
Validation loss: 0.6108628670174872 ROC AUC: 0.7487878787878788
Validation loss: 0.590756288724928 ROC AUC: 0.7679797979797981
Validation loss: 0.5710785964026523 ROC AUC: 0.7770707070707071
Validation loss: 0.5727150563019604 ROC AUC: 0.7678787878787878
Validation loss: 0.595234739421001 ROC AUC: 0.7856565656565656
Validation loss: 0.6007873496817584 ROC AUC: 0.7934343434343434
28 4 0.5756627321243286
Validation loss: 0.6381922037757222 ROC AUC: 0.797878787878788
Validation loss: 0.5483123236265613 ROC AUC: 0.8065656565656566
Validation loss: 0.5529003314037418 ROC AUC: 0.822929292929293
Validation loss: 0.583669216489073 ROC AUC: 0.8331313131313132
Validation loss: 0.5593865506313555 ROC AUC: 0.8484848484848486
Validation loss: 0.5157746042138968 ROC AUC: 0.8353535353535354
Validation loss: 0.5521914566581573 ROC AUC: 0.8350505050505052
35 5 0.47175103425979614
Validation loss: 0.49368893830620464 ROC AUC: 0.8465656565656565
Validation loss: 0.4803414022802708 ROC AUC: 0.8558585858585859
Validation loss: 0.46232132905691714 ROC AUC: 0.8655555555555556
Validation loss: 0.48525122017716643 ROC AUC: 0.8658585858585859
Validation loss: 0.4693609329324272 ROC AUC: 0.8708080808080808
Validation loss: 0.4556015882659797 ROC AUC: 0.900909090909091
Validation loss: 0.4659231652566536 ROC AUC: 0.8906060606060606
42 6 0.7725094556808472
Validation loss: 0.4491804950500852 ROC AUC: 0.8934343434343434
Validation loss: 0.46587508782070486 ROC AUC: 0.8973737373737374
Validation loss: 0.4317392762282386 ROC AUC: 0.9051515151515152
Validation loss: 0.40965375259293985 ROC AUC: 0.8975757575757576
Validation loss: 0.48491407279393184 ROC AUC: 0.9006060606060607
Validation loss: 0.44537204878414094 ROC AUC: 0.9141414141414141
Validation loss: 0.4055026676786605 ROC AUC: 0.9171717171717173
Validation loss: 0.39613244416725696 ROC AUC: 0.9182828282828284
50 0 0.6028050780296326
Validation loss: 0.4067220840621833 ROC AUC: 0.9210101010101011
Validation loss: 0.39858448550329734 ROC AUC: 0.9274747474747475
Validation loss: 0.37196945694822764 ROC AUC: 0.9316161616161617
Validation loss: 0.38780807625109226 ROC AUC: 0.9313131313131313
Validation loss: 0.381260172655834 ROC AUC: 0.9296969696969697
Validation loss: 0.37181401147914295 ROC AUC: 0.9265656565656566
Validation loss: 0.3526467389647086 ROC AUC: 0.9325252525252525
57 1 0.49434027075767517
Validation loss: 0.36546681611681703 ROC AUC: 0.9431313131313132
Validation loss: 0.40229155460194727 ROC AUC: 0.922020202020202
Validation loss: 0.39536997308982674 ROC AUC: 0.9324242424242424
Validation loss: 0.39351887199746904 ROC AUC: 0.9284848484848485
Validation loss: 0.40362137660908337 ROC AUC: 0.9217171717171717
Validation loss: 0.34076588267657026 ROC AUC: 0.9450505050505051
Validation loss: 0.3394236363957276 ROC AUC: 0.9375757575757575
64 2 0.4889179468154907
Validation loss: 0.35187000081167746 ROC AUC: 0.9450505050505051
Validation loss: 0.35015977132859544 ROC AUC: 0.9391919191919191
Validation loss: 0.3264494169896571 ROC AUC: 0.943939393939394
Validation loss: 0.29553295282562775 ROC AUC: 0.9501010101010101
Validation loss: 0.29518977736108865 ROC AUC: 0.9500000000000001
Validation loss: 0.303853728962903 ROC AUC: 0.9518181818181819
Validation loss: 0.3057150968055629 ROC AUC: 0.962020202020202
71 3 0.22345170378684998
Validation loss: 0.2900738262351434 ROC AUC: 0.9675757575757575
Validation loss: 0.3103212434143277 ROC AUC: 0.9651515151515152
Validation loss: 0.29028047538881924 ROC AUC: 0.9724242424242424
Validation loss: 0.29238798113624054 ROC AUC: 0.9697979797979798
Validation loss: 0.29812421249085336 ROC AUC: 0.9593939393939394
Validation loss: 0.28174456431712935 ROC AUC: 0.9673737373737374
Validation loss: 0.26138054792904974 ROC AUC: 0.9716161616161616
78 4 0.44656598567962646
Validation loss: 0.26255372585962766 ROC AUC: 0.9676767676767677
Validation loss: 0.25735924201994087 ROC AUC: 0.9654545454545455
Validation loss: 0.2587730958683407 ROC AUC: 0.9722222222222223
Validation loss: 0.2587815735807371 ROC AUC: 0.9714141414141415
Validation loss: 0.2541780303321292 ROC AUC: 0.9737373737373738
Validation loss: 0.2546293656879933 ROC AUC: 0.9733333333333334
Validation loss: 0.27231730213716404 ROC AUC: 0.9707070707070707
85 5 0.5630506277084351
Validation loss: 0.3140035768849167 ROC AUC: 0.9591919191919192
Validation loss: 0.2434114413944321 ROC AUC: 0.9767676767676768
Validation loss: 0.21570815190897516 ROC AUC: 0.9815151515151516
Validation loss: 0.3466608957130106 ROC AUC: 0.9507070707070706
Validation loss: 0.2495050584925479 ROC AUC: 0.9746464646464648
Validation loss: 0.24397013287747923 ROC AUC: 0.9804040404040405
Validation loss: 0.26289492665822783 ROC AUC: 0.9693939393939394
92 6 0.4114516079425812
Validation loss: 0.27473400465807124 ROC AUC: 0.9693939393939394
Validation loss: 0.24262065968321794 ROC AUC: 0.973939393939394
Validation loss: 0.2863677060933568 ROC AUC: 0.9746464646464645
Validation loss: 0.31804304547495577 ROC AUC: 0.9464646464646465
Validation loss: 0.2875670914973446 ROC AUC: 0.9537373737373737
Validation loss: 0.226443994921356 ROC AUC: 0.9766666666666667
Validation loss: 0.2134415770894918 ROC AUC: 0.9785858585858586
Validation loss: 0.21944714086738662 ROC AUC: 0.9788888888888889
Loaded trained model with success.
Test loss: 0.8121061425057491 Test ROC AUC: 0.7315882100245279
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 2}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 2}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2207846 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 0.6875055432319641
Validation loss: 0.7899897284880429 ROC AUC: 0.5947660969027118
Validation loss: 0.6702516931809022 ROC AUC: 0.6189275157434777
Validation loss: 0.7135152215948086 ROC AUC: 0.623763012466264
3 2 0.6736565828323364
Validation loss: 0.6788208251725696 ROC AUC: 0.6335303945508289
Validation loss: 0.7029033405986244 ROC AUC: 0.6396992674463436
Validation loss: 0.7503903731554448 ROC AUC: 0.6616919419097803
6 4 0.6602531671524048
Validation loss: 0.7303909576966433 ROC AUC: 0.6682463693612646
Validation loss: 0.7343615342476564 ROC AUC: 0.682736794756458
Validation loss: 0.7685652879292597 ROC AUC: 0.7045688214882406
9 6 0.7366374731063843
Validation loss: 0.6451052255286482 ROC AUC: 0.7302081994602236
Validation loss: 0.678112601230522 ROC AUC: 0.758289422953348
Validation loss: 0.6883923539178882 ROC AUC: 0.7730690142655186
12 8 0.6867247223854065
Validation loss: 0.6987527292333767 ROC AUC: 0.7791896928415372
Validation loss: 0.7242363126340037 ROC AUC: 0.7931017864027761
Validation loss: 0.5743919157074067 ROC AUC: 0.8106927130188922
15 10 0.5149550437927246
Validation loss: 0.5963410269282385 ROC AUC: 0.8263237373088292
Validation loss: 0.6463517867969367 ROC AUC: 0.8378261148952577
Validation loss: 0.5321946265941153 ROC AUC: 0.8383883819560468
18 12 0.551310122013092
Validation loss: 0.5716839122151086 ROC AUC: 0.8546941267189307
Validation loss: 0.4922470103404326 ROC AUC: 0.8655539133787431
Validation loss: 0.5177175670205233 ROC AUC: 0.8661643747590284
21 14 0.6573597192764282
Validation loss: 0.5428877405986519 ROC AUC: 0.8809600308443645
Validation loss: 0.4748918058160312 ROC AUC: 0.8849762241357152
Validation loss: 0.4630421197008274 ROC AUC: 0.87220472946922
Validation loss: 0.471912117962369 ROC AUC: 0.8922696311528081
25 0 0.6360400915145874
Validation loss: 0.4887146933642561 ROC AUC: 0.8919162061431692
Validation loss: 0.45618350669472874 ROC AUC: 0.9007678961573062
Validation loss: 0.4446516426388391 ROC AUC: 0.901796041639892
28 2 0.4473281800746918
Validation loss: 0.4122607584348422 ROC AUC: 0.9071938054234675
Validation loss: 0.4131504497929422 ROC AUC: 0.9099569464079167
Validation loss: 0.39168807894051194 ROC AUC: 0.9136197146896285
31 4 0.6019386053085327
Validation loss: 0.4097003493614808 ROC AUC: 0.9171057704665211
Validation loss: 0.4295724987505911 ROC AUC: 0.9085593111425266
Validation loss: 0.408162317080106 ROC AUC: 0.9158366533864543
34 6 0.41659584641456604
Validation loss: 0.4105015380946333 ROC AUC: 0.919017478473204
Validation loss: 0.4062158738921783 ROC AUC: 0.9168005397763783
Validation loss: 0.3656745102099761 ROC AUC: 0.9204151137385941
37 8 0.5202191472053528
Validation loss: 0.37456740776379266 ROC AUC: 0.9286884719187766
Validation loss: 0.3806196918826782 ROC AUC: 0.931258835625241
Validation loss: 0.36970636821939856 ROC AUC: 0.9363192391723429
40 10 0.368878036737442
Validation loss: 0.3673188098088534 ROC AUC: 0.9331384140855932
Validation loss: 0.3428066860817238 ROC AUC: 0.935050122092276
Validation loss: 0.34612415106836447 ROC AUC: 0.9351786402775992
43 12 0.6507542729377747
Validation loss: 0.38541450636659214 ROC AUC: 0.9323351754273229
Validation loss: 0.33861563129272154 ROC AUC: 0.9400462665467164
Validation loss: 0.333384569458111 ROC AUC: 0.9442713018892174
46 14 0.3608560264110565
Validation loss: 0.3342585485421106 ROC AUC: 0.9456368076082766
Validation loss: 0.32759722720883894 ROC AUC: 0.9500867497750931
Validation loss: 0.3045484789148839 ROC AUC: 0.9520305873281069
Validation loss: 0.30482485358844064 ROC AUC: 0.9509381827528596
50 0 0.46728405356407166
Validation loss: 0.31458470404506444 ROC AUC: 0.9532354453155121
Validation loss: 0.30691835493267416 ROC AUC: 0.9543599794370904
Validation loss: 0.2924343564347896 ROC AUC: 0.9526892430278885
53 2 0.38867542147636414
Validation loss: 0.3133377529576212 ROC AUC: 0.9501188793214239
Validation loss: 0.2965295876792533 ROC AUC: 0.9524643362035728
Validation loss: 0.3222817831144543 ROC AUC: 0.9437250996015937
56 4 0.4381389617919922
Validation loss: 0.30911908243486064 ROC AUC: 0.9568660840508931
Validation loss: 0.2980665830309262 ROC AUC: 0.9615891273615217
Validation loss: 0.27748787809230524 ROC AUC: 0.9615891273615216
59 6 0.2562781572341919
Validation loss: 0.28231479433591 ROC AUC: 0.9603200102814548
Validation loss: 0.2765997819945903 ROC AUC: 0.9652518956432334
Validation loss: 0.264298529030087 ROC AUC: 0.965267960416399
62 8 0.32960614562034607
Validation loss: 0.319965801282015 ROC AUC: 0.9565287238144198
Validation loss: 0.2929637391486005 ROC AUC: 0.9641755558411516
Validation loss: 0.26024284976756645 ROC AUC: 0.9672117979694127
65 10 0.28316113352775574
Validation loss: 0.23352919336789119 ROC AUC: 0.9711476673949364
Validation loss: 0.24305782172985688 ROC AUC: 0.9721276185580259
Validation loss: 0.25648689932956964 ROC AUC: 0.9698464207685388
68 12 0.3394429087638855
Validation loss: 0.235451242369497 ROC AUC: 0.9717420640020563
Validation loss: 0.26800129223682123 ROC AUC: 0.9696536434905538
Validation loss: 0.2594143134319711 ROC AUC: 0.972127618558026
71 14 0.21358264982700348
Validation loss: 0.23363333641885517 ROC AUC: 0.972207942423853
Validation loss: 0.2541988044379947 ROC AUC: 0.9719509060532066
Validation loss: 0.22649262036254744 ROC AUC: 0.9751959902326179
Validation loss: 0.20826980525362707 ROC AUC: 0.9779430664439017
75 0 0.6156264543533325
Validation loss: 0.21974158591641213 ROC AUC: 0.9781519084950521
Validation loss: 0.20905427088240583 ROC AUC: 0.9784732039583601
Validation loss: 0.2372391701998835 ROC AUC: 0.9742642333890246
78 2 0.1700153350830078
Validation loss: 0.22471820364495318 ROC AUC: 0.9790836653386454
Validation loss: 0.2552851971858489 ROC AUC: 0.9730272458552884
Validation loss: 0.2261105785388985 ROC AUC: 0.9761116823030459
81 4 0.36578691005706787
Validation loss: 0.22322455980256947 ROC AUC: 0.9787141755558412
Validation loss: 0.24073284538929351 ROC AUC: 0.9774771880221051
Validation loss: 0.1969013702355788 ROC AUC: 0.9784250096388639
84 6 0.42329201102256775
Validation loss: 0.20301854571622455 ROC AUC: 0.9813809279012982
Validation loss: 0.20361523527301145 ROC AUC: 0.9808668551600052
Validation loss: 0.20372298001526354 ROC AUC: 0.9772201516514587
87 8 0.37424150109291077
Validation loss: 0.21591629807600277 ROC AUC: 0.9822162961058991
Validation loss: 0.20155515311237326 ROC AUC: 0.9826179154350341
Validation loss: 0.18140747716168842 ROC AUC: 0.9831319881763269
90 10 0.5079308748245239
Validation loss: 0.2022079270863103 ROC AUC: 0.9806098187893587
Validation loss: 0.1943868524086977 ROC AUC: 0.980898984706336
Validation loss: 0.20076596844411326 ROC AUC: 0.985445315512145
93 12 0.28875666856765747
Validation loss: 0.1994758249225024 ROC AUC: 0.9835336075054619
Validation loss: 0.17668099617790842 ROC AUC: 0.9841280041125818
Validation loss: 0.20450426569443667 ROC AUC: 0.9816379642719444
96 14 0.7627753615379333
Validation loss: 0.1775652680672959 ROC AUC: 0.987597995116309
Validation loss: 0.21279296111726093 ROC AUC: 0.9837103200102815
Validation loss: 0.20304999009282412 ROC AUC: 0.9781840380413829
Validation loss: 0.18097733289660337 ROC AUC: 0.9845778177612132
Loaded trained model with success.
Test loss: 0.5995973061032599 Test ROC AUC: 0.8195296021974788
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.631002426147461
Validation loss: 1.6081453561782837 ROC AUC: 0.75
Validation loss: 1.620042324066162 ROC AUC: 0.775
Validation loss: 1.6373050212860107 ROC AUC: 0.7875
Validation loss: 1.6809848546981812 ROC AUC: 0.7
Validation loss: 1.7240184545516968 ROC AUC: 0.7875
Validation loss: 1.7963682413101196 ROC AUC: 0.7375
Validation loss: 1.8984421491622925 ROC AUC: 0.6125
Validation loss: 1.9842360019683838 ROC AUC: 0.575
Validation loss: 2.018242120742798 ROC AUC: 0.6
Validation loss: 2.0596745014190674 ROC AUC: 0.575
Validation loss: 2.0512921810150146 ROC AUC: 0.65
Validation loss: 1.9997763633728027 ROC AUC: 0.6375
Validation loss: 1.9448789358139038 ROC AUC: 0.65
Validation loss: 1.8942517042160034 ROC AUC: 0.65
Validation loss: 1.719391107559204 ROC AUC: 0.7125
Validation loss: 1.5931183099746704 ROC AUC: 0.75
Validation loss: 1.4024416208267212 ROC AUC: 0.8125
Validation loss: 1.2269556522369385 ROC AUC: 0.825
Validation loss: 1.1074808835983276 ROC AUC: 0.85
Validation loss: 1.0026698112487793 ROC AUC: 0.8625
Validation loss: 0.9197273254394531 ROC AUC: 0.9
Validation loss: 0.8864941000938416 ROC AUC: 0.9125
Validation loss: 0.8851926326751709 ROC AUC: 0.9125
Validation loss: 0.8843672275543213 ROC AUC: 0.9
Validation loss: 0.884488046169281 ROC AUC: 0.9125
Validation loss: 0.87237548828125 ROC AUC: 0.9125
Validation loss: 0.8585069179534912 ROC AUC: 0.9125
Validation loss: 0.8416194319725037 ROC AUC: 0.9125
Validation loss: 0.8308737277984619 ROC AUC: 0.925
Validation loss: 0.829742431640625 ROC AUC: 0.925
Validation loss: 0.8230255842208862 ROC AUC: 0.925
Validation loss: 0.8135789036750793 ROC AUC: 0.925
Validation loss: 0.8232266902923584 ROC AUC: 0.925
Validation loss: 0.8417688608169556 ROC AUC: 0.9
Validation loss: 0.879128634929657 ROC AUC: 0.875
Validation loss: 0.9160990118980408 ROC AUC: 0.85
Validation loss: 0.9275795817375183 ROC AUC: 0.85
Validation loss: 0.9717066884040833 ROC AUC: 0.825
Validation loss: 0.9752242565155029 ROC AUC: 0.825
Validation loss: 0.9951072335243225 ROC AUC: 0.825
Validation loss: 1.0458126068115234 ROC AUC: 0.825
Validation loss: 1.0751116275787354 ROC AUC: 0.8125
Validation loss: 1.076106071472168 ROC AUC: 0.8125
Validation loss: 1.0590533018112183 ROC AUC: 0.8
Validation loss: 1.0775835514068604 ROC AUC: 0.8
Validation loss: 1.034719705581665 ROC AUC: 0.8125
Validation loss: 1.0222172737121582 ROC AUC: 0.8125
Validation loss: 1.0239713191986084 ROC AUC: 0.8125
Validation loss: 1.0161941051483154 ROC AUC: 0.825
Validation loss: 0.9896168112754822 ROC AUC: 0.825
50 0 0.6987532377243042
Validation loss: 0.9827911853790283 ROC AUC: 0.825
Validation loss: 0.9862052202224731 ROC AUC: 0.825
Validation loss: 1.0270140171051025 ROC AUC: 0.8125
Validation loss: 1.0322175025939941 ROC AUC: 0.8125
Validation loss: 1.0319008827209473 ROC AUC: 0.8125
Validation loss: 1.0659555196762085 ROC AUC: 0.8125
Validation loss: 1.1034648418426514 ROC AUC: 0.8375
Validation loss: 1.107426404953003 ROC AUC: 0.825
Validation loss: 1.0925326347351074 ROC AUC: 0.825
Validation loss: 1.0735318660736084 ROC AUC: 0.825
Validation loss: 1.0323803424835205 ROC AUC: 0.825
Validation loss: 0.977385938167572 ROC AUC: 0.8375
Validation loss: 0.9123652577400208 ROC AUC: 0.85
Validation loss: 0.8878371715545654 ROC AUC: 0.8875
Validation loss: 0.8591986894607544 ROC AUC: 0.8875
Validation loss: 0.8352791666984558 ROC AUC: 0.9
Validation loss: 0.8204315304756165 ROC AUC: 0.925
Validation loss: 0.823278546333313 ROC AUC: 0.925
Validation loss: 0.7938549518585205 ROC AUC: 0.9375
Validation loss: 0.782310426235199 ROC AUC: 0.9375
Validation loss: 0.7671428918838501 ROC AUC: 0.9625
Validation loss: 0.7243354916572571 ROC AUC: 0.95
Validation loss: 0.7040415406227112 ROC AUC: 0.95
Validation loss: 0.6650638580322266 ROC AUC: 0.95
Validation loss: 0.626567542552948 ROC AUC: 0.975
Validation loss: 0.6085669994354248 ROC AUC: 0.975
Validation loss: 0.5872969031333923 ROC AUC: 0.975
Validation loss: 0.5770692229270935 ROC AUC: 0.975
Validation loss: 0.5421509146690369 ROC AUC: 0.975
Validation loss: 0.5175485014915466 ROC AUC: 0.975
Validation loss: 0.49481964111328125 ROC AUC: 0.975
Validation loss: 0.4817548394203186 ROC AUC: 0.975
Validation loss: 0.4760175943374634 ROC AUC: 0.975
Validation loss: 0.4706296920776367 ROC AUC: 0.975
Validation loss: 0.4736711084842682 ROC AUC: 0.975
Validation loss: 0.47854846715927124 ROC AUC: 0.975
Validation loss: 0.5229781866073608 ROC AUC: 0.9625
Validation loss: 0.5499497056007385 ROC AUC: 0.95
Validation loss: 0.6074243187904358 ROC AUC: 0.95
Validation loss: 0.6937969923019409 ROC AUC: 0.9
Validation loss: 0.7501140832901001 ROC AUC: 0.9
Validation loss: 0.7981846928596497 ROC AUC: 0.875
Validation loss: 0.8185914754867554 ROC AUC: 0.8625
Validation loss: 0.8338083624839783 ROC AUC: 0.85
Validation loss: 0.8273229598999023 ROC AUC: 0.875
Validation loss: 0.7655947208404541 ROC AUC: 0.8875
Validation loss: 0.7372348308563232 ROC AUC: 0.8875
Validation loss: 0.6998060345649719 ROC AUC: 0.9
Validation loss: 0.5960630178451538 ROC AUC: 0.9625
Validation loss: 0.5444833040237427 ROC AUC: 0.975
Loaded trained model with success.
Test loss: 5.631469976466569 Test ROC AUC: 0.5129944377671938
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.6972957849502563
Validation loss: 1.622915936976063 ROC AUC: 0.5239444444444444
Validation loss: 1.6901596662949543 ROC AUC: 0.4915555555555556
Validation loss: 1.745505539738402 ROC AUC: 0.5338333333333333
Validation loss: 1.765149240591088 ROC AUC: 0.5078888888888888
Validation loss: 1.7473885818403594 ROC AUC: 0.5138333333333334
Validation loss: 1.7091577758594436 ROC AUC: 0.5268333333333334
Validation loss: 1.6494065085235907 ROC AUC: 0.5348333333333334
Validation loss: 1.5966752864876572 ROC AUC: 0.5557222222222223
Validation loss: 1.570867499526666 ROC AUC: 0.5471111111111111
Validation loss: 1.561519243279282 ROC AUC: 0.6069444444444445
Validation loss: 1.5454283247188645 ROC AUC: 0.6399999999999999
Validation loss: 1.5199175975760635 ROC AUC: 0.6581111111111111
Validation loss: 1.500695099636 ROC AUC: 0.6648333333333334
Validation loss: 1.4915081116617943 ROC AUC: 0.6688888888888889
Validation loss: 1.5176742295829617 ROC AUC: 0.6732777777777778
Validation loss: 1.5303693571869208 ROC AUC: 0.6863888888888889
Validation loss: 1.5285970605149561 ROC AUC: 0.6852777777777778
Validation loss: 1.5262354539365184 ROC AUC: 0.6885
Validation loss: 1.5206601181808783 ROC AUC: 0.6892222222222222
Validation loss: 1.517884872397598 ROC AUC: 0.6928888888888889
Validation loss: 1.5253406349493532 ROC AUC: 0.6916111111111112
Validation loss: 1.518663114430953 ROC AUC: 0.6932777777777777
Validation loss: 1.514912138179857 ROC AUC: 0.6992222222222223
Validation loss: 1.5120902426388798 ROC AUC: 0.7032222222222222
Validation loss: 1.50061191588032 ROC AUC: 0.7022777777777778
25 0 1.5065432786941528
Validation loss: 1.4923584023300482 ROC AUC: 0.7048888888888889
Validation loss: 1.4718889703555984 ROC AUC: 0.7018333333333334
Validation loss: 1.460739145473558 ROC AUC: 0.7089444444444444
Validation loss: 1.4529085913482978 ROC AUC: 0.7047777777777778
Validation loss: 1.4531220319319744 ROC AUC: 0.7044444444444444
Validation loss: 1.4523495533028428 ROC AUC: 0.7028333333333333
Validation loss: 1.4516389223994042 ROC AUC: 0.7020555555555557
Validation loss: 1.459497449349384 ROC AUC: 0.705388888888889
Validation loss: 1.4666582418947804 ROC AUC: 0.7068888888888889
Validation loss: 1.4757730206664728 ROC AUC: 0.7085
Validation loss: 1.465833150610632 ROC AUC: 0.7138333333333333
Validation loss: 1.4400609439733076 ROC AUC: 0.7191666666666666
Validation loss: 1.4241620277871891 ROC AUC: 0.724
Validation loss: 1.422512378011431 ROC AUC: 0.7212222222222222
Validation loss: 1.4186263570980149 ROC AUC: 0.725611111111111
Validation loss: 1.4081870341787532 ROC AUC: 0.7276111111111112
Validation loss: 1.398809408654972 ROC AUC: 0.7324444444444443
Validation loss: 1.3883941441166157 ROC AUC: 0.7368333333333335
Validation loss: 1.3761860059232127 ROC AUC: 0.7426666666666667
Validation loss: 1.3545204498329941 ROC AUC: 0.7493333333333333
Validation loss: 1.3361910751887731 ROC AUC: 0.753611111111111
Validation loss: 1.3129287252620774 ROC AUC: 0.7639444444444444
Validation loss: 1.2886623095492928 ROC AUC: 0.7707777777777778
Validation loss: 1.2702549452684364 ROC AUC: 0.7750555555555556
Validation loss: 1.2558523465176017 ROC AUC: 0.78
50 0 1.2716848850250244
Validation loss: 1.2500075588420945 ROC AUC: 0.7817222222222222
Validation loss: 1.245849681143858 ROC AUC: 0.7834444444444444
Validation loss: 1.258940577507019 ROC AUC: 0.7793333333333333
Validation loss: 1.283485162014864 ROC AUC: 0.7743888888888888
Validation loss: 1.2773586876538334 ROC AUC: 0.7731666666666666
Validation loss: 1.2723722068630918 ROC AUC: 0.7777777777777777
Validation loss: 1.2395427543289808 ROC AUC: 0.7843333333333333
Validation loss: 1.1919143686489182 ROC AUC: 0.8015555555555556
Validation loss: 1.1706786861225051 ROC AUC: 0.8164444444444443
Validation loss: 1.1458326724110817 ROC AUC: 0.8246666666666667
Validation loss: 1.1205009757256021 ROC AUC: 0.8302222222222222
Validation loss: 1.123627487494021 ROC AUC: 0.8321111111111111
Validation loss: 1.1165256475915715 ROC AUC: 0.839111111111111
Validation loss: 1.095113501256826 ROC AUC: 0.8484999999999999
Validation loss: 1.0535490220906782 ROC AUC: 0.8550555555555555
Validation loss: 1.0280803478493983 ROC AUC: 0.8572222222222221
Validation loss: 0.997111685422002 ROC AUC: 0.8654999999999999
Validation loss: 0.9902267857473723 ROC AUC: 0.8609444444444444
Validation loss: 0.9826707730487901 ROC AUC: 0.8638333333333333
Validation loss: 0.9813662743081852 ROC AUC: 0.8683333333333334
Validation loss: 0.9791976310768906 ROC AUC: 0.8710555555555555
Validation loss: 1.0027297175660426 ROC AUC: 0.8719444444444445
Validation loss: 1.024563971830874 ROC AUC: 0.8709444444444443
Validation loss: 1.043665851865496 ROC AUC: 0.8689444444444444
Validation loss: 0.9951038944477938 ROC AUC: 0.8725555555555555
75 0 1.0055890083312988
Validation loss: 0.9736094097701871 ROC AUC: 0.8756666666666668
Validation loss: 0.966418127624356 ROC AUC: 0.8792777777777777
Validation loss: 0.982433403024868 ROC AUC: 0.874111111111111
Validation loss: 0.9731080264461284 ROC AUC: 0.8757222222222222
Validation loss: 0.9678174451905854 ROC AUC: 0.8792222222222221
Validation loss: 0.9655069720988371 ROC AUC: 0.8803333333333334
Validation loss: 0.9589413355807869 ROC AUC: 0.8815
Validation loss: 0.9530713923123418 ROC AUC: 0.8870555555555555
Validation loss: 0.9329920751707894 ROC AUC: 0.8905000000000001
Validation loss: 0.8972380696510782 ROC AUC: 0.9003333333333334
Validation loss: 0.8299168372640804 ROC AUC: 0.9178333333333333
Validation loss: 0.7749163496251009 ROC AUC: 0.931
Validation loss: 0.7370520878811272 ROC AUC: 0.9368333333333334
Validation loss: 0.7261501234404895 ROC AUC: 0.9419444444444445
Validation loss: 0.7338059994639182 ROC AUC: 0.9400555555555556
Validation loss: 0.7296934809003558 ROC AUC: 0.9410555555555555
Validation loss: 0.7350644444932743 ROC AUC: 0.9360555555555556
Validation loss: 0.7221128210729483 ROC AUC: 0.9341111111111111
Validation loss: 0.7019904474822842 ROC AUC: 0.9334444444444443
Validation loss: 0.7012784067465334 ROC AUC: 0.9334444444444445
Validation loss: 0.7251464627227004 ROC AUC: 0.9310555555555556
Validation loss: 0.7774026381726168 ROC AUC: 0.9273333333333333
Validation loss: 0.8241848495541787 ROC AUC: 0.9179999999999999
Validation loss: 0.8173444368401352 ROC AUC: 0.9227777777777778
Validation loss: 0.7940801467214312 ROC AUC: 0.926888888888889
Loaded trained model with success.
Test loss: 2.5175556894119784 Test ROC AUC: 0.5657945928786198
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.5842207670211792
Validation loss: 1.6554861369759146 ROC AUC: 0.4904210526315789
Validation loss: 1.8887287558931294 ROC AUC: 0.5223881578947368
Validation loss: 2.041213435356063 ROC AUC: 0.5467500000000001
Validation loss: 1.7104404442238086 ROC AUC: 0.5895986842105263
Validation loss: 1.5573842886722449 ROC AUC: 0.5890328947368422
Validation loss: 1.5831426129196629 ROC AUC: 0.5906052631578947
Validation loss: 1.5990224125409367 ROC AUC: 0.5858881578947368
Validation loss: 1.5998574471232867 ROC AUC: 0.5860921052631578
Validation loss: 1.5767310075085572 ROC AUC: 0.5903947368421052
Validation loss: 1.6326307853062947 ROC AUC: 0.5902565789473684
Validation loss: 1.6606640514701303 ROC AUC: 0.5912697368421054
Validation loss: 1.628177198496732 ROC AUC: 0.5950526315789474
12 2 1.5670599937438965
Validation loss: 1.5858140184421732 ROC AUC: 0.5977894736842104
Validation loss: 1.5932323186084478 ROC AUC: 0.6057565789473685
Validation loss: 1.6039292583561906 ROC AUC: 0.6166184210526315
Validation loss: 1.6593877703252464 ROC AUC: 0.6156118421052631
Validation loss: 1.7700814056878138 ROC AUC: 0.601361842105263
Validation loss: 1.7780189610490895 ROC AUC: 0.6017499999999999
Validation loss: 1.6101903578247687 ROC AUC: 0.604171052631579
Validation loss: 1.5944207882640338 ROC AUC: 0.6101184210526315
Validation loss: 1.5778540649799386 ROC AUC: 0.6142631578947368
Validation loss: 1.5607425167103006 ROC AUC: 0.6180526315789474
Validation loss: 1.5400515638216576 ROC AUC: 0.628796052631579
Validation loss: 1.5437917793639984 ROC AUC: 0.6296052631578948
Validation loss: 1.5556207798948192 ROC AUC: 0.6306315789473684
25 0 1.5489511489868164
Validation loss: 1.5562845865885417 ROC AUC: 0.6309605263157896
Validation loss: 1.5429073572158813 ROC AUC: 0.6520065789473685
Validation loss: 1.5666202788401131 ROC AUC: 0.6568355263157895
Validation loss: 1.6076256349833324 ROC AUC: 0.654578947368421
Validation loss: 1.570843017462528 ROC AUC: 0.6522171052631578
Validation loss: 1.5400574135057854 ROC AUC: 0.6529407894736841
Validation loss: 1.533369248563593 ROC AUC: 0.6458486842105263
Validation loss: 1.5166279366522124 ROC AUC: 0.6566315789473685
Validation loss: 1.5114017628660106 ROC AUC: 0.6777434210526316
Validation loss: 1.5157926046487056 ROC AUC: 0.6721776315789474
Validation loss: 1.4953879166131068 ROC AUC: 0.6779013157894738
Validation loss: 1.4916435504200483 ROC AUC: 0.6911578947368422
37 2 1.4714393615722656
Validation loss: 1.4780304154964408 ROC AUC: 0.6983552631578949
Validation loss: 1.4847694587225866 ROC AUC: 0.6860460526315789
Validation loss: 1.4937032786282627 ROC AUC: 0.6881447368421053
Validation loss: 1.5096778387975212 ROC AUC: 0.7042434210526315
Validation loss: 1.4964929782983027 ROC AUC: 0.7146118421052632
Validation loss: 1.4456496082171044 ROC AUC: 0.7257105263157895
Validation loss: 1.4115364130097205 ROC AUC: 0.7384671052631578
Validation loss: 1.3890514759102253 ROC AUC: 0.7457697368421052
Validation loss: 1.3689322435494624 ROC AUC: 0.7484802631578947
Validation loss: 1.3627314146118934 ROC AUC: 0.744328947368421
Validation loss: 1.3753943912910693 ROC AUC: 0.7500526315789473
Validation loss: 1.3953945383881077 ROC AUC: 0.7536447368421053
Validation loss: 1.361377730514064 ROC AUC: 0.7599276315789474
50 0 1.3204692602157593
Validation loss: 1.3365250091360072 ROC AUC: 0.7647368421052632
Validation loss: 1.3078365795540088 ROC AUC: 0.7654605263157894
Validation loss: 1.2877650694413618 ROC AUC: 0.767625
Validation loss: 1.292905199407327 ROC AUC: 0.7694144736842106
Validation loss: 1.307710673471894 ROC AUC: 0.7698421052631578
Validation loss: 1.3171761975143894 ROC AUC: 0.7708486842105262
Validation loss: 1.3008916522517349 ROC AUC: 0.7748750000000001
Validation loss: 1.3003608536238622 ROC AUC: 0.7644736842105264
Validation loss: 1.2904119816693393 ROC AUC: 0.7630657894736841
Validation loss: 1.2561290011261448 ROC AUC: 0.7773289473684211
Validation loss: 1.2016214604931648 ROC AUC: 0.8031184210526316
Validation loss: 1.1972875215790488 ROC AUC: 0.8135394736842105
62 2 1.200798511505127
Validation loss: 1.2308566829170844 ROC AUC: 0.8168289473684212
Validation loss: 1.209339875163454 ROC AUC: 0.8243157894736843
Validation loss: 1.2383809246198096 ROC AUC: 0.8256315789473684
Validation loss: 1.2579151897719412 ROC AUC: 0.8276118421052632
Validation loss: 1.2246918943193223 ROC AUC: 0.8394144736842104
Validation loss: 1.1826860928776288 ROC AUC: 0.8458881578947368
Validation loss: 1.1233297646647753 ROC AUC: 0.8486710526315789
Validation loss: 1.1102311165645868 ROC AUC: 0.8501184210526317
Validation loss: 1.120607848119254 ROC AUC: 0.8525855263157893
Validation loss: 1.1079298546819976 ROC AUC: 0.8541710526315789
Validation loss: 1.1187367872758345 ROC AUC: 0.8563289473684211
Validation loss: 1.0926402024548463 ROC AUC: 0.858907894736842
Validation loss: 1.047270042727692 ROC AUC: 0.8655394736842105
75 0 1.1615432500839233
Validation loss: 1.0250156299032347 ROC AUC: 0.8674078947368422
Validation loss: 1.0161038817781392 ROC AUC: 0.8766513157894738
Validation loss: 1.0150233982789396 ROC AUC: 0.8826907894736843
Validation loss: 1.0820677503190859 ROC AUC: 0.8768881578947368
Validation loss: 1.1754205539973095 ROC AUC: 0.8683881578947368
Validation loss: 1.1925261941823093 ROC AUC: 0.8619078947368422
Validation loss: 1.1981523380135044 ROC AUC: 0.8554868421052632
Validation loss: 1.1293908201082787 ROC AUC: 0.8635460526315789
Validation loss: 1.0881462085126625 ROC AUC: 0.8723815789473685
Validation loss: 1.0271669385409115 ROC AUC: 0.882842105263158
Validation loss: 0.9939950403541026 ROC AUC: 0.8898223684210527
Validation loss: 0.991377799799948 ROC AUC: 0.8847763157894738
87 2 1.1401985883712769
Validation loss: 1.0474672763034552 ROC AUC: 0.874532894736842
Validation loss: 1.1560043957498338 ROC AUC: 0.841611842105263
Validation loss: 1.36650287262117 ROC AUC: 0.792717105263158
Validation loss: 1.1209471815764303 ROC AUC: 0.860921052631579
Validation loss: 1.071201412966757 ROC AUC: 0.8821184210526315
Validation loss: 1.023266816982115 ROC AUC: 0.890736842105263
Validation loss: 0.9814959728356564 ROC AUC: 0.8965657894736841
Validation loss: 0.9548158296430954 ROC AUC: 0.9008486842105263
Validation loss: 0.9788858192135589 ROC AUC: 0.8919473684210526
Validation loss: 1.056535825584874 ROC AUC: 0.8784210526315789
Validation loss: 1.0745639584281228 ROC AUC: 0.873467105263158
Validation loss: 1.052682602646375 ROC AUC: 0.8825526315789475
Validation loss: 1.113160399475483 ROC AUC: 0.8834276315789473
Loaded trained model with success.
Test loss: 2.1051706456024823 Test ROC AUC: 0.5885187363274047
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.6953685283660889
Validation loss: 1.8314398730819548 ROC AUC: 0.5448934294871794
Validation loss: 1.7359483865038234 ROC AUC: 0.5339823717948718
Validation loss: 1.7396662840292083 ROC AUC: 0.5042548076923077
Validation loss: 1.6099420522325603 ROC AUC: 0.513911858974359
Validation loss: 1.6312726855877058 ROC AUC: 0.4761666666666667
Validation loss: 1.697428841686728 ROC AUC: 0.4799639423076923
Validation loss: 1.7054969096303585 ROC AUC: 0.5499366987179488
7 1 1.5752495527267456
Validation loss: 1.6786222919147817 ROC AUC: 0.5602892628205127
Validation loss: 1.6764378152300965 ROC AUC: 0.5572315705128206
Validation loss: 1.6332564395875786 ROC AUC: 0.5443589743589744
Validation loss: 1.6259351962774842 ROC AUC: 0.529261217948718
Validation loss: 1.612206206848873 ROC AUC: 0.5571209935897437
Validation loss: 1.6153193029327009 ROC AUC: 0.5903197115384615
Validation loss: 1.6159706511090148 ROC AUC: 0.610383814102564
14 2 1.5114635229110718
Validation loss: 1.6583918482814002 ROC AUC: 0.6230320512820513
Validation loss: 1.6628830145351852 ROC AUC: 0.615559294871795
Validation loss: 1.5847912643423032 ROC AUC: 0.6148669871794872
Validation loss: 1.5916223759627222 ROC AUC: 0.6151113782051282
Validation loss: 1.6274315741792995 ROC AUC: 0.6007099358974359
Validation loss: 1.6069195156720415 ROC AUC: 0.6104086538461538
Validation loss: 1.597341758521957 ROC AUC: 0.6140400641025641
21 3 1.5020865201950073
Validation loss: 1.5832147730055766 ROC AUC: 0.6291730769230769
Validation loss: 1.5539503816384166 ROC AUC: 0.6633092948717948
Validation loss: 1.5459275263637753 ROC AUC: 0.6779535256410257
Validation loss: 1.5540611264693678 ROC AUC: 0.6563245192307693
Validation loss: 1.553931314142505 ROC AUC: 0.6615985576923078
Validation loss: 1.639696572893229 ROC AUC: 0.6675056089743591
Validation loss: 1.6182068292819076 ROC AUC: 0.6820921474358974
28 4 1.479293942451477
Validation loss: 1.6220903031191034 ROC AUC: 0.7066145833333334
Validation loss: 1.5111972734556725 ROC AUC: 0.7133838141025641
Validation loss: 1.4369366019215417 ROC AUC: 0.730625
Validation loss: 1.4401173423882105 ROC AUC: 0.7305977564102565
Validation loss: 1.449804709185308 ROC AUC: 0.7329038461538462
Validation loss: 1.4264515183079782 ROC AUC: 0.7376923076923078
Validation loss: 1.4511103803788 ROC AUC: 0.7389399038461539
35 5 1.3745228052139282
Validation loss: 1.4486297614610375 ROC AUC: 0.7410897435897436
Validation loss: 1.4853509053513034 ROC AUC: 0.7271338141025641
Validation loss: 1.4516576546520443 ROC AUC: 0.7436570512820513
Validation loss: 1.4116854949213153 ROC AUC: 0.7608982371794872
Validation loss: 1.3532302349656071 ROC AUC: 0.7635016025641026
Validation loss: 1.2859037018301498 ROC AUC: 0.7832243589743589
Validation loss: 1.2802491900908888 ROC AUC: 0.789738782051282
42 6 1.5480397939682007
Validation loss: 1.2745587777851815 ROC AUC: 0.800213141025641
Validation loss: 1.3399241683471144 ROC AUC: 0.7920600961538462
Validation loss: 1.4492498815958224 ROC AUC: 0.7605128205128204
Validation loss: 1.4357255996771194 ROC AUC: 0.7653870192307692
Validation loss: 1.3629195995666274 ROC AUC: 0.7901434294871794
Validation loss: 1.3016405183466235 ROC AUC: 0.8121674679487179
Validation loss: 1.2889870872449636 ROC AUC: 0.8041209935897436
Validation loss: 1.2635281978540085 ROC AUC: 0.8138044871794872
50 0 1.278733491897583
Validation loss: 1.2343089233091729 ROC AUC: 0.8225376602564104
Validation loss: 1.2089235884460372 ROC AUC: 0.824775641025641
Validation loss: 1.2193939718768825 ROC AUC: 0.8166193910256411
Validation loss: 1.1551111454340681 ROC AUC: 0.8370889423076923
Validation loss: 1.1245943667301581 ROC AUC: 0.8519807692307693
Validation loss: 1.0631877986630003 ROC AUC: 0.8578886217948718
Validation loss: 1.0482009146081743 ROC AUC: 0.8598725961538461
57 1 1.227840542793274
Validation loss: 1.040057148765679 ROC AUC: 0.8668437500000001
Validation loss: 1.1022042305625264 ROC AUC: 0.865233173076923
Validation loss: 1.0732714333126891 ROC AUC: 0.8697451923076924
Validation loss: 1.1148209637732962 ROC AUC: 0.8608036858974358
Validation loss: 1.0595664432899436 ROC AUC: 0.8807155448717948
Validation loss: 1.0354834974710665 ROC AUC: 0.8785665064102565
Validation loss: 0.9917818601406998 ROC AUC: 0.8874086538461539
64 2 1.0134296417236328
Validation loss: 0.9692182247363144 ROC AUC: 0.8934399038461537
Validation loss: 0.9794150995249724 ROC AUC: 0.8861586538461539
Validation loss: 1.0207005547518706 ROC AUC: 0.8782059294871795
Validation loss: 0.9458276162195445 ROC AUC: 0.8967107371794872
Validation loss: 0.9290035492810772 ROC AUC: 0.8959166666666667
Validation loss: 0.9343925660579049 ROC AUC: 0.8970168269230768
Validation loss: 0.914188765700738 ROC AUC: 0.9020360576923077
71 3 1.0431082248687744
Validation loss: 0.9122162200697702 ROC AUC: 0.903900641025641
Validation loss: 0.8958952328068527 ROC AUC: 0.9045056089743589
Validation loss: 0.9205533278048338 ROC AUC: 0.9072451923076923
Validation loss: 0.9021894611305927 ROC AUC: 0.9080224358974359
Validation loss: 0.8663499960348234 ROC AUC: 0.9173741987179488
Validation loss: 0.8761958354082539 ROC AUC: 0.9174903846153845
Validation loss: 0.8874501313396435 ROC AUC: 0.9139959935897435
78 4 0.8868273496627808
Validation loss: 0.8716773106225172 ROC AUC: 0.9190889423076923
Validation loss: 0.8231346044109096 ROC AUC: 0.927300480769231
Validation loss: 0.8048620754150889 ROC AUC: 0.9296426282051282
Validation loss: 0.8100837007838877 ROC AUC: 0.9292467948717948
Validation loss: 0.8042212344294217 ROC AUC: 0.9288910256410257
Validation loss: 0.7800454042065683 ROC AUC: 0.9298357371794872
Validation loss: 0.755207579339569 ROC AUC: 0.9360048076923079
85 5 1.2456930875778198
Validation loss: 0.7389351120546236 ROC AUC: 0.9382700320512821
Validation loss: 0.7537598204073594 ROC AUC: 0.941613782051282
Validation loss: 0.7597028503765413 ROC AUC: 0.9393285256410258
Validation loss: 0.7435759024404401 ROC AUC: 0.9413798076923076
Validation loss: 0.7454989546507447 ROC AUC: 0.938020032051282
Validation loss: 0.7649381094841502 ROC AUC: 0.9336778846153846
Validation loss: 0.717379156818342 ROC AUC: 0.9428565705128206
92 6 1.1223680973052979
Validation loss: 0.6958479914233913 ROC AUC: 0.9466386217948719
Validation loss: 0.7060363273225237 ROC AUC: 0.9468974358974359
Validation loss: 0.7126718717603827 ROC AUC: 0.9430136217948718
Validation loss: 0.7203631586764925 ROC AUC: 0.9433621794871796
Validation loss: 0.7252379257475311 ROC AUC: 0.9466089743589743
Validation loss: 0.7017158126112205 ROC AUC: 0.9442836538461539
Validation loss: 0.6714160786801248 ROC AUC: 0.9474294871794872
Validation loss: 0.6637236988125135 ROC AUC: 0.9508782051282051
Loaded trained model with success.
Test loss: 1.9468436827724158 Test ROC AUC: 0.6656605658235815
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_5', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 5}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2208617 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 1.616786241531372
Validation loss: 1.6478613411974095 ROC AUC: 0.48834637249949486
Validation loss: 1.6117011545177453 ROC AUC: 0.5285737664174581
Validation loss: 1.6163155509379201 ROC AUC: 0.5391515609213984
3 2 1.6092844009399414
Validation loss: 1.603202254595403 ROC AUC: 0.5362028227924833
Validation loss: 1.6141264259456871 ROC AUC: 0.5366472115578904
Validation loss: 1.6037139997692529 ROC AUC: 0.5383176702364114
6 4 1.5465353727340698
Validation loss: 1.5887606734025455 ROC AUC: 0.5866450222267126
Validation loss: 1.6112950595920692 ROC AUC: 0.5802206324510001
Validation loss: 1.6648962153700406 ROC AUC: 0.5791495978985653
9 6 1.6409105062484741
Validation loss: 1.671522260906701 ROC AUC: 0.5997709608001616
Validation loss: 1.5569370808247813 ROC AUC: 0.6350240634471611
Validation loss: 1.55159676648333 ROC AUC: 0.6546446302283291
12 8 1.7077018022537231
Validation loss: 1.5386539819484244 ROC AUC: 0.6564736077995555
Validation loss: 1.5461078927607719 ROC AUC: 0.6601583451202263
Validation loss: 1.4811582300132644 ROC AUC: 0.7012788745201052
15 10 1.628274917602539
Validation loss: 1.4459694554667195 ROC AUC: 0.7120030430389978
Validation loss: 1.4446785416536196 ROC AUC: 0.7114704718124875
Validation loss: 1.389337150032869 ROC AUC: 0.7288395180844616
18 12 1.4564268589019775
Validation loss: 1.3917040793833608 ROC AUC: 0.7307087795514245
Validation loss: 1.4182580587620248 ROC AUC: 0.7260534946453829
Validation loss: 1.4157530473086064 ROC AUC: 0.7344940786017377
21 14 1.4493590593338013
Validation loss: 1.3773144858633588 ROC AUC: 0.7513039048292585
Validation loss: 1.2844759333348705 ROC AUC: 0.7743088815922409
Validation loss: 1.2758058956964222 ROC AUC: 0.773049990907254
Validation loss: 1.2672945812852205 ROC AUC: 0.7808183309759547
25 0 1.440609097480774
Validation loss: 1.2769094153731047 ROC AUC: 0.7800021468983633
Validation loss: 1.2936274795111768 ROC AUC: 0.770109360476864
Validation loss: 1.2550480031298252 ROC AUC: 0.784390054556476
28 2 1.3576632738113403
Validation loss: 1.2389191518087903 ROC AUC: 0.7911302030713276
Validation loss: 1.235676833766257 ROC AUC: 0.7895245150535463
Validation loss: 1.2239459358857485 ROC AUC: 0.7993023125884016
31 4 1.4151934385299683
Validation loss: 1.2151134415475544 ROC AUC: 0.805369450394019
Validation loss: 1.22187590933515 ROC AUC: 0.8007768114770661
Validation loss: 1.1945010555053284 ROC AUC: 0.8096794615073751
34 6 1.1801177263259888
Validation loss: 1.2056828591532125 ROC AUC: 0.8107346312386341
Validation loss: 1.1999161542059185 ROC AUC: 0.8136842897555063
Validation loss: 1.1574673429280817 ROC AUC: 0.8201092281268945
37 8 1.4510478973388672
Validation loss: 1.1688083135532235 ROC AUC: 0.8179649959587797
Validation loss: 1.1726074885270878 ROC AUC: 0.8267148605778946
Validation loss: 1.1751992313083044 ROC AUC: 0.8184264588805819
40 10 1.2191640138626099
Validation loss: 1.123157973279934 ROC AUC: 0.842671216407355
Validation loss: 1.1255994654131796 ROC AUC: 0.838168864417054
Validation loss: 1.1110496693001481 ROC AUC: 0.8403695261669025
43 12 1.3162528276443481
Validation loss: 1.1267767688315473 ROC AUC: 0.8450048040008082
Validation loss: 1.096701902473618 ROC AUC: 0.8501631976156799
Validation loss: 1.0865824146117857 ROC AUC: 0.8449545685997171
46 14 1.1534502506256104
Validation loss: 1.0823296172346524 ROC AUC: 0.8560437371186097
Validation loss: 1.0278548601872934 ROC AUC: 0.8610974510002022
Validation loss: 1.0161423871894637 ROC AUC: 0.865112908668418
Validation loss: 1.0542126444872013 ROC AUC: 0.8559148898767427
50 0 1.1319353580474854
Validation loss: 0.9760806304897239 ROC AUC: 0.8719458345120227
Validation loss: 1.009740782882981 ROC AUC: 0.867773098605779
Validation loss: 0.9953111296665215 ROC AUC: 0.8735166407355022
53 2 1.1308051347732544
Validation loss: 0.9815760996633159 ROC AUC: 0.8811782845019195
Validation loss: 0.9724191303004721 ROC AUC: 0.8814494645382907
Validation loss: 0.9902518079849426 ROC AUC: 0.8753155597090322
56 4 1.133176565170288
Validation loss: 0.9527450028306735 ROC AUC: 0.8783707789452416
Validation loss: 0.9308091576448184 ROC AUC: 0.8923645019195797
Validation loss: 0.9295910710323311 ROC AUC: 0.8909860466760963
59 6 1.0723872184753418
Validation loss: 0.9080290562643077 ROC AUC: 0.8951319357445948
Validation loss: 0.9727560690266336 ROC AUC: 0.883169629218024
Validation loss: 0.9275058399221462 ROC AUC: 0.898111496261871
62 8 1.0187488794326782
Validation loss: 0.9202989349384346 ROC AUC: 0.8999123226914527
Validation loss: 0.8735959477319507 ROC AUC: 0.9095709880783996
Validation loss: 0.8756049668382786 ROC AUC: 0.9074593311780157
65 10 1.3467899560928345
Validation loss: 0.8765281104372594 ROC AUC: 0.9049939432208529
Validation loss: 0.8679222690318534 ROC AUC: 0.9044921024449384
Validation loss: 0.8977844154906416 ROC AUC: 0.9028937886441705
68 12 1.1115126609802246
Validation loss: 0.8594518420930377 ROC AUC: 0.912062945039402
Validation loss: 0.829771778626528 ROC AUC: 0.9142764851485149
Validation loss: 0.8628970118228324 ROC AUC: 0.9130189856536675
71 14 0.9074916839599609
Validation loss: 0.8019897157778004 ROC AUC: 0.9235049747423723
Validation loss: 0.7956664427248892 ROC AUC: 0.9214680571832694
Validation loss: 0.79755038285781 ROC AUC: 0.9237145120226307
Validation loss: 0.8203185898268629 ROC AUC: 0.9207494746413417
75 0 1.2853999137878418
Validation loss: 0.7669458589955179 ROC AUC: 0.9308227520711254
Validation loss: 0.7747189573391167 ROC AUC: 0.9251257223681553
Validation loss: 0.7719441875666081 ROC AUC: 0.9279777793493634
78 2 0.8415408134460449
Validation loss: 0.7880975453552598 ROC AUC: 0.9280066366942817
Validation loss: 0.7604783229932995 ROC AUC: 0.9316691281066882
Validation loss: 0.762276609221059 ROC AUC: 0.9281939401899374
81 4 1.2162528038024902
Validation loss: 0.772758615757516 ROC AUC: 0.9291988159224086
Validation loss: 0.7579305554200748 ROC AUC: 0.9293876722570216
Validation loss: 0.7257426143409255 ROC AUC: 0.9392543220852696
84 6 0.9376347064971924
Validation loss: 0.7450760993546618 ROC AUC: 0.934472575267731
Validation loss: 0.7268676280019757 ROC AUC: 0.937528098605779
Validation loss: 0.7597322247788041 ROC AUC: 0.9334541008284502
87 8 0.9720907807350159
Validation loss: 0.7348624682856466 ROC AUC: 0.9367432238836129
Validation loss: 0.7602274692608025 ROC AUC: 0.9339967367144878
Validation loss: 0.773497002874921 ROC AUC: 0.9267946888260254
90 10 0.8601776361465454
Validation loss: 0.7585604743871517 ROC AUC: 0.9339773176399271
Validation loss: 0.6899682308485608 ROC AUC: 0.948217594463528
Validation loss: 0.7020166222461479 ROC AUC: 0.9426550222267125
93 12 0.7342504262924194
Validation loss: 0.6748981512859016 ROC AUC: 0.9447525085875936
Validation loss: 0.6558992412978996 ROC AUC: 0.9467981935744595
Validation loss: 0.6754081657749856 ROC AUC: 0.9475805324307942
96 14 1.0332019329071045
Validation loss: 0.6789395985956899 ROC AUC: 0.9470426267932914
Validation loss: 0.6526200270843888 ROC AUC: 0.9514344120024246
Validation loss: 0.6717576856364706 ROC AUC: 0.9455021539704991
Validation loss: 0.6115273738910775 ROC AUC: 0.9541181188118812
Loaded trained model with success.
Test loss: 1.722534608721648 Test ROC AUC: 0.7243748958216824
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 20.64387321472168
Validation loss: 14.698782920837402 MAE: 3.174452
Validation loss: 10.985136032104492 MAE: 2.7940397
Validation loss: 8.001791000366211 MAE: 2.4066455
Validation loss: 5.91731071472168 MAE: 2.1012144
Validation loss: 4.8829121589660645 MAE: 1.9466218
Validation loss: 5.044713020324707 MAE: 2.0345955
Validation loss: 6.503290176391602 MAE: 2.1243732
Validation loss: 9.386758804321289 MAE: 2.2839699
Validation loss: 13.860529899597168 MAE: 3.0108926
Validation loss: 18.245765686035156 MAE: 3.6675682
Validation loss: 21.863475799560547 MAE: 4.131483
Validation loss: 25.875173568725586 MAE: 4.5917034
Validation loss: 26.28217315673828 MAE: 4.637673
Validation loss: 25.35589027404785 MAE: 4.5403786
Validation loss: 22.855812072753906 MAE: 4.2662563
Validation loss: 20.549272537231445 MAE: 4.0004606
Validation loss: 18.06474494934082 MAE: 3.6930444
Validation loss: 15.576250076293945 MAE: 3.3526614
Validation loss: 13.356005668640137 MAE: 3.0128927
Validation loss: 11.511337280273438 MAE: 2.6921017
Validation loss: 10.239114761352539 MAE: 2.451004
Validation loss: 9.183775901794434 MAE: 2.3273559
Validation loss: 8.226716041564941 MAE: 2.2193227
Validation loss: 7.604095458984375 MAE: 2.1580803
Validation loss: 6.5726423263549805 MAE: 1.9980055
Validation loss: 5.640583515167236 MAE: 1.8946433
Validation loss: 5.062047958374023 MAE: 1.8179493
Validation loss: 4.379162788391113 MAE: 1.7068887
Validation loss: 3.8433752059936523 MAE: 1.5796427
Validation loss: 3.542109727859497 MAE: 1.4589672
Validation loss: 3.389479398727417 MAE: 1.3916774
Validation loss: 3.331911563873291 MAE: 1.3763235
Validation loss: 3.312741994857788 MAE: 1.3619404
Validation loss: 3.3131868839263916 MAE: 1.3718276
Validation loss: 3.311148166656494 MAE: 1.3448879
Validation loss: 3.311077356338501 MAE: 1.346868
Validation loss: 3.325721263885498 MAE: 1.3612108
Validation loss: 3.3250515460968018 MAE: 1.3654474
Validation loss: 3.3249285221099854 MAE: 1.3751991
Validation loss: 3.3093981742858887 MAE: 1.3893512
Validation loss: 3.2799253463745117 MAE: 1.3698522
Validation loss: 3.2590534687042236 MAE: 1.3594776
Validation loss: 3.249220848083496 MAE: 1.3569446
Validation loss: 3.2417025566101074 MAE: 1.354645
Validation loss: 3.2429800033569336 MAE: 1.3442663
Validation loss: 3.241274833679199 MAE: 1.3228594
Validation loss: 3.2475030422210693 MAE: 1.3195665
Validation loss: 3.256187677383423 MAE: 1.3215437
Validation loss: 3.260802984237671 MAE: 1.322459
Validation loss: 3.2826950550079346 MAE: 1.3398128
50 0 3.073765754699707
Validation loss: 3.3245973587036133 MAE: 1.3654927
Validation loss: 3.371711254119873 MAE: 1.4090269
Validation loss: 3.4034321308135986 MAE: 1.4362962
Validation loss: 3.4151737689971924 MAE: 1.4533684
Validation loss: 3.4300448894500732 MAE: 1.478444
Validation loss: 3.4485273361206055 MAE: 1.5062758
Validation loss: 3.441152334213257 MAE: 1.5145552
Validation loss: 3.4220993518829346 MAE: 1.5148109
Validation loss: 3.417917490005493 MAE: 1.5205474
Validation loss: 3.384746789932251 MAE: 1.5103537
Validation loss: 3.3670365810394287 MAE: 1.5089678
Validation loss: 3.339099884033203 MAE: 1.4984788
Validation loss: 3.310565948486328 MAE: 1.4851979
Validation loss: 3.273432731628418 MAE: 1.4648824
Validation loss: 3.265132188796997 MAE: 1.4628364
Validation loss: 3.2553553581237793 MAE: 1.4555055
Validation loss: 3.263054609298706 MAE: 1.4572408
Validation loss: 3.265986442565918 MAE: 1.4486735
Validation loss: 3.292022466659546 MAE: 1.4538269
Validation loss: 3.3177075386047363 MAE: 1.4523283
Validation loss: 3.354053497314453 MAE: 1.4498062
Validation loss: 3.3893074989318848 MAE: 1.4532905
Validation loss: 3.4219348430633545 MAE: 1.450191
Validation loss: 3.4748425483703613 MAE: 1.4610814
Validation loss: 3.530953884124756 MAE: 1.4776614
Validation loss: 3.5790905952453613 MAE: 1.4914502
Validation loss: 3.639969825744629 MAE: 1.5103579
Validation loss: 3.6756787300109863 MAE: 1.5209882
Validation loss: 3.6655654907226562 MAE: 1.5117028
Validation loss: 3.6932835578918457 MAE: 1.520328
Validation loss: 3.727480888366699 MAE: 1.5342363
Validation loss: 3.760117530822754 MAE: 1.5631175
Validation loss: 3.7130284309387207 MAE: 1.560787
Validation loss: 3.668415069580078 MAE: 1.5569538
Validation loss: 3.643052816390991 MAE: 1.556297
Validation loss: 3.6106491088867188 MAE: 1.5480952
Validation loss: 3.5634982585906982 MAE: 1.5335159
Validation loss: 3.533113718032837 MAE: 1.5219499
Validation loss: 3.4592089653015137 MAE: 1.4937131
Validation loss: 3.3926892280578613 MAE: 1.462793
Validation loss: 3.3441171646118164 MAE: 1.4441819
Validation loss: 3.309055805206299 MAE: 1.4367608
Validation loss: 3.2609119415283203 MAE: 1.4223883
Validation loss: 3.194218158721924 MAE: 1.4046983
Validation loss: 3.1492812633514404 MAE: 1.3999063
Validation loss: 3.131782054901123 MAE: 1.4023331
Validation loss: 3.09456729888916 MAE: 1.3948388
Validation loss: 3.068195104598999 MAE: 1.3804903
Validation loss: 3.0143730640411377 MAE: 1.358101
Validation loss: 2.940502166748047 MAE: 1.3266226
Loaded trained model with success.
Test loss: 6.304449712528902 Test MAE: 2.0346837
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 22.51289939880371
Validation loss: 11.271335523955676 MAE: 2.7573373
Validation loss: 6.37953536364497 MAE: 2.0840626
Validation loss: 5.844744964521759 MAE: 1.9966278
Validation loss: 8.70055798121861 MAE: 2.4319932
Validation loss: 13.073102016838229 MAE: 3.0203998
Validation loss: 15.449973203697983 MAE: 3.3187425
Validation loss: 18.3916638043462 MAE: 3.7348905
Validation loss: 19.22350295709104 MAE: 3.81276
Validation loss: 15.548876665076431 MAE: 3.3592858
Validation loss: 11.904147206520548 MAE: 2.902948
Validation loss: 9.248764816595584 MAE: 2.5359724
Validation loss: 7.670220783778599 MAE: 2.270636
Validation loss: 6.563429608636973 MAE: 2.0992002
Validation loss: 6.089789799281529 MAE: 2.0401814
Validation loss: 5.8876811338930715 MAE: 2.013757
Validation loss: 5.792660207164531 MAE: 1.9985669
Validation loss: 5.703598489566725 MAE: 1.9815067
Validation loss: 5.648700976858334 MAE: 1.9694778
Validation loss: 5.626093348678277 MAE: 1.9607604
Validation loss: 5.49291281797448 MAE: 1.9289597
Validation loss: 5.377144891388562 MAE: 1.9068816
Validation loss: 5.337507053297394 MAE: 1.900863
Validation loss: 5.314064814119923 MAE: 1.897529
Validation loss: 5.489207442925901 MAE: 1.9379045
Validation loss: 5.361632950451909 MAE: 1.9126904
25 0 4.522091388702393
Validation loss: 5.402175066422443 MAE: 1.9231832
Validation loss: 5.360171804622728 MAE: 1.9143319
Validation loss: 5.154957824823808 MAE: 1.8578817
Validation loss: 5.07568748629823 MAE: 1.8372489
Validation loss: 4.99640179653557 MAE: 1.8297141
Validation loss: 5.1665622652793415 MAE: 1.874153
Validation loss: 5.521636563904432 MAE: 1.9446025
Validation loss: 5.903438957370057 MAE: 1.9974326
Validation loss: 5.989179776639355 MAE: 2.0065975
Validation loss: 5.860984091856042 MAE: 1.9896379
Validation loss: 5.542922019958496 MAE: 1.9451965
Validation loss: 5.580407123176419 MAE: 1.9535717
Validation loss: 5.51432110338795 MAE: 1.9491596
Validation loss: 5.326517990657261 MAE: 1.9238565
Validation loss: 5.161139429831992 MAE: 1.89572
Validation loss: 5.043080086610755 MAE: 1.8732967
Validation loss: 5.117178693109629 MAE: 1.8896625
Validation loss: 5.169878171414745 MAE: 1.9009075
Validation loss: 5.2143389351513925 MAE: 1.9096191
Validation loss: 5.074929616889175 MAE: 1.8811578
Validation loss: 5.2886936275326475 MAE: 1.905541
Validation loss: 5.638774920483025 MAE: 1.9374862
Validation loss: 5.747881529282551 MAE: 1.9399211
Validation loss: 5.99658508690036 MAE: 1.965102
Validation loss: 5.898979118892124 MAE: 1.9380575
50 0 4.091413974761963
Validation loss: 5.702898687245894 MAE: 1.8942122
Validation loss: 6.16244802669603 MAE: 1.9533396
Validation loss: 6.478097287976012 MAE: 1.9951931
Validation loss: 5.406259648653926 MAE: 1.8168285
Validation loss: 4.229404060208068 MAE: 1.6378376
Validation loss: 3.9337078697827397 MAE: 1.5758818
Validation loss: 4.159011276400819 MAE: 1.6039046
Validation loss: 4.865357647136766 MAE: 1.7193431
Validation loss: 5.120558991724131 MAE: 1.7627584
Validation loss: 5.519925798688616 MAE: 1.826296
Validation loss: 4.737772085228745 MAE: 1.6858988
Validation loss: 4.1028127086405854 MAE: 1.5672557
Validation loss: 4.24065976240197 MAE: 1.5829244
Validation loss: 4.251474867061693 MAE: 1.5758407
Validation loss: 3.8205210724655463 MAE: 1.5264287
Validation loss: 3.4135869911738803 MAE: 1.4772834
Validation loss: 3.694339246165996 MAE: 1.5281831
Validation loss: 5.299622778989831 MAE: 1.7664481
Validation loss: 5.289215949116921 MAE: 1.8079683
Validation loss: 4.96751881618889 MAE: 1.7461343
Validation loss: 4.625518652857567 MAE: 1.6909947
Validation loss: 4.610142347763996 MAE: 1.6842982
Validation loss: 4.670141589884856 MAE: 1.6943324
Validation loss: 5.032427126047563 MAE: 1.7535298
Validation loss: 3.8557439239657656 MAE: 1.4843435
75 0 3.8226170539855957
Validation loss: 2.220301540530458 MAE: 1.1847949
Validation loss: 2.4499622656374562 MAE: 1.2502478
Validation loss: 2.279070462499346 MAE: 1.2455852
Validation loss: 2.2719344265606938 MAE: 1.2202995
Validation loss: 2.3365517149166184 MAE: 1.2232472
Validation loss: 2.447916045480845 MAE: 1.2465924
Validation loss: 2.4022987326797174 MAE: 1.2277112
Validation loss: 2.231555145614001 MAE: 1.1686261
Validation loss: 2.0521297503490836 MAE: 1.1145407
Validation loss: 2.0072664192744663 MAE: 1.0922598
Validation loss: 1.9119683236491924 MAE: 1.0547051
Validation loss: 1.767983324673711 MAE: 1.020452
Validation loss: 1.975932391322389 MAE: 1.0614226
Validation loss: 2.165646927697318 MAE: 1.1120937
Validation loss: 2.117334472889803 MAE: 1.1054722
Validation loss: 2.184205038206918 MAE: 1.1510829
Validation loss: 2.4398551936052284 MAE: 1.2397177
Validation loss: 2.7863422705202687 MAE: 1.3243496
Validation loss: 3.4418491246748943 MAE: 1.4913245
Validation loss: 4.227175148165956 MAE: 1.6695296
Validation loss: 4.7268979306123695 MAE: 1.7793285
Validation loss: 4.028740824485312 MAE: 1.6207055
Validation loss: 3.6215493922330895 MAE: 1.5374644
Validation loss: 3.5942263262612477 MAE: 1.5372293
Validation loss: 3.559187723665821 MAE: 1.5416867
Loaded trained model with success.
Test loss: 5.89284159390981 Test MAE: 1.9239318
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 12.45603084564209
Validation loss: 6.92893509792559 MAE: 2.1515298
Validation loss: 6.582900619266009 MAE: 2.1406362
Validation loss: 13.857043516756308 MAE: 3.1509643
Validation loss: 15.469424686046562 MAE: 3.3653595
Validation loss: 10.425004121029016 MAE: 2.6833735
Validation loss: 6.400552725551104 MAE: 2.1015644
Validation loss: 5.519079612963127 MAE: 1.9722875
Validation loss: 5.319283717810506 MAE: 1.9414246
Validation loss: 5.120771420122397 MAE: 1.8975208
Validation loss: 5.157041963904795 MAE: 1.8971684
Validation loss: 5.937207264919775 MAE: 2.039716
Validation loss: 6.306871838039822 MAE: 2.097766
12 2 5.5178728103637695
Validation loss: 6.066141017759689 MAE: 2.0638387
Validation loss: 5.802526122391826 MAE: 2.0192642
Validation loss: 5.715832387558137 MAE: 2.0054216
Validation loss: 5.661732837407276 MAE: 2.000638
Validation loss: 6.075482686360677 MAE: 2.0679216
Validation loss: 7.704005039099491 MAE: 2.3137767
Validation loss: 9.672736384651877 MAE: 2.5786479
Validation loss: 8.693684626107265 MAE: 2.453219
Validation loss: 7.239253331916501 MAE: 2.2457159
Validation loss: 6.4698749600034775 MAE: 2.1198027
Validation loss: 5.933361939709596 MAE: 2.033269
Validation loss: 5.5047572839139685 MAE: 1.959341
Validation loss: 5.2540817453403665 MAE: 1.9196833
25 0 4.215494155883789
Validation loss: 5.278692206951103 MAE: 1.9260042
Validation loss: 5.349491292780096 MAE: 1.9374428
Validation loss: 5.121823585394657 MAE: 1.8955867
Validation loss: 5.070832103189796 MAE: 1.8790252
Validation loss: 5.007332809043653 MAE: 1.8631486
Validation loss: 4.881091541714138 MAE: 1.8369011
Validation loss: 5.014041924717451 MAE: 1.8713795
Validation loss: 5.145391464233398 MAE: 1.8933117
Validation loss: 4.921846678762725 MAE: 1.850567
Validation loss: 5.367104432799599 MAE: 1.9341918
Validation loss: 7.078777356581255 MAE: 2.200739
Validation loss: 8.637434227298005 MAE: 2.453184
37 2 4.97248649597168
Validation loss: 7.66666598271842 MAE: 2.300059
Validation loss: 5.418473910803747 MAE: 1.8960955
Validation loss: 4.407653454578284 MAE: 1.7485142
Validation loss: 4.485003240180738 MAE: 1.7726893
Validation loss: 4.418447046568899 MAE: 1.7613094
Validation loss: 4.172471908005801 MAE: 1.7049901
Validation loss: 4.000887555305404 MAE: 1.6542727
Validation loss: 4.14418131414086 MAE: 1.6683488
Validation loss: 4.403608090949781 MAE: 1.7001771
Validation loss: 4.170610746952018 MAE: 1.6579112
Validation loss: 4.196992403329021 MAE: 1.6818805
Validation loss: 6.822571128305762 MAE: 2.1991239
Validation loss: 13.149884002377288 MAE: 3.151948
50 0 5.064156532287598
Validation loss: 9.06652982307203 MAE: 2.542658
Validation loss: 7.983672026431922 MAE: 2.3377614
Validation loss: 8.033309551200482 MAE: 2.3151312
Validation loss: 6.7014708049369585 MAE: 2.1063566
Validation loss: 5.737928280926714 MAE: 1.961864
Validation loss: 5.530020008183489 MAE: 1.9473623
Validation loss: 6.156947150374904 MAE: 2.0631022
Validation loss: 4.519737778287945 MAE: 1.7420665
Validation loss: 3.673862164670771 MAE: 1.5409647
Validation loss: 4.038671117840392 MAE: 1.6247553
Validation loss: 4.414436274104649 MAE: 1.6908333
Validation loss: 4.157168094557945 MAE: 1.6426436
62 2 4.0314459800720215
Validation loss: 3.542617092228899 MAE: 1.5352854
Validation loss: 3.662532738964967 MAE: 1.5778413
Validation loss: 4.2498889499240455 MAE: 1.6906854
Validation loss: 4.530911917638297 MAE: 1.7518686
Validation loss: 4.272503669815834 MAE: 1.6841809
Validation loss: 3.940609435842495 MAE: 1.6124145
Validation loss: 3.9624450002053773 MAE: 1.6186961
Validation loss: 4.652524635045215 MAE: 1.7636867
Validation loss: 5.2752731881960475 MAE: 1.8807125
Validation loss: 4.626786578183222 MAE: 1.7565366
Validation loss: 5.003948124972257 MAE: 1.843044
Validation loss: 13.162015009408046 MAE: 3.117104
Validation loss: 21.034267637464737 MAE: 4.1106315
75 0 4.2121710777282715
Validation loss: 16.89644757665769 MAE: 3.6367376
Validation loss: 10.981801572472158 MAE: 2.812116
Validation loss: 7.342990181662819 MAE: 2.2587893
Validation loss: 6.001097859758319 MAE: 2.0253863
Validation loss: 4.071013108648435 MAE: 1.6286606
Validation loss: 4.0279696951008805 MAE: 1.6222075
Validation loss: 4.0763982546449915 MAE: 1.6309934
Validation loss: 4.946438201750167 MAE: 1.8027484
Validation loss: 5.39913909603851 MAE: 1.8942693
Validation loss: 4.536049734462392 MAE: 1.7381619
Validation loss: 4.359076072471311 MAE: 1.703333
Validation loss: 4.2728500558872415 MAE: 1.6831353
87 2 3.85235333442688
Validation loss: 4.065720805014022 MAE: 1.6407186
Validation loss: 4.319646700464114 MAE: 1.6960555
Validation loss: 5.147074911329481 MAE: 1.8620625
Validation loss: 6.39804401783028 MAE: 2.1075869
Validation loss: 6.457477150541363 MAE: 2.1341562
Validation loss: 6.800293780336476 MAE: 2.205661
Validation loss: 5.516718219024966 MAE: 1.9584088
Validation loss: 6.495986880678119 MAE: 2.1521378
Validation loss: 6.741360640284991 MAE: 2.2006466
Validation loss: 5.508020978985411 MAE: 1.9680504
Validation loss: 4.933675700967962 MAE: 1.8541503
Validation loss: 4.014446720932469 MAE: 1.6440712
Validation loss: 3.5470598779543483 MAE: 1.525229
Loaded trained model with success.
Test loss: 5.8404079572949 Test MAE: 1.9826733
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 24.25002098083496
Validation loss: 5.647814077348565 MAE: 1.9578836
Validation loss: 21.97021823672194 MAE: 4.1520762
Validation loss: 9.76196193215835 MAE: 2.5656962
Validation loss: 5.433374857782718 MAE: 1.9255999
Validation loss: 5.630590431654274 MAE: 1.9547071
Validation loss: 6.186675838489628 MAE: 2.0533094
Validation loss: 7.3013692812703965 MAE: 2.2373865
7 1 5.96552038192749
Validation loss: 6.318839121104485 MAE: 2.0789752
Validation loss: 5.751189394811889 MAE: 1.984527
Validation loss: 5.89945933327603 MAE: 1.9892654
Validation loss: 5.893077732929632 MAE: 1.9877508
Validation loss: 5.675304554215628 MAE: 1.9595973
Validation loss: 5.489417229465504 MAE: 1.931561
Validation loss: 5.3940548681134555 MAE: 1.9120638
14 2 6.464663505554199
Validation loss: 5.616906960405896 MAE: 1.9409026
Validation loss: 6.228789897420299 MAE: 2.0407112
Validation loss: 7.90736571029203 MAE: 2.3069868
Validation loss: 7.081188908773451 MAE: 2.1783888
Validation loss: 6.607997745724779 MAE: 2.103914
Validation loss: 6.046521464783941 MAE: 2.0108864
Validation loss: 5.898792506462366 MAE: 1.9842294
21 3 3.89727520942688
Validation loss: 7.1354309805673575 MAE: 2.1865478
Validation loss: 9.946987851780264 MAE: 2.6105804
Validation loss: 8.465708550496316 MAE: 2.3869357
Validation loss: 8.77745657829783 MAE: 2.439906
Validation loss: 8.485015116744306 MAE: 2.3966575
Validation loss: 7.473768512208258 MAE: 2.2449436
Validation loss: 8.642354040289645 MAE: 2.4227762
28 4 4.012909412384033
Validation loss: 11.970963415788047 MAE: 2.902017
Validation loss: 12.442800176802592 MAE: 2.9693527
Validation loss: 9.767187108945606 MAE: 2.595295
Validation loss: 9.548138606488406 MAE: 2.5619237
Validation loss: 6.531164166915357 MAE: 2.0953412
Validation loss: 3.7278219629172704 MAE: 1.56682
Validation loss: 3.3571467591290496 MAE: 1.4739798
35 5 5.488372325897217
Validation loss: 3.4899062568218864 MAE: 1.506935
Validation loss: 3.323087933075488 MAE: 1.4603915
Validation loss: 4.125458675413276 MAE: 1.6551367
Validation loss: 4.539702720378512 MAE: 1.7345148
Validation loss: 3.825363729467344 MAE: 1.5726401
Validation loss: 3.367951776514101 MAE: 1.4609421
Validation loss: 4.4987609254654926 MAE: 1.729755
42 6 4.810299396514893
Validation loss: 3.7599640260988743 MAE: 1.5737721
Validation loss: 3.217651806285034 MAE: 1.4520702
Validation loss: 3.4209068875816 MAE: 1.4885715
Validation loss: 3.588071422960291 MAE: 1.5326097
Validation loss: 3.354474469045898 MAE: 1.4585559
Validation loss: 3.710066785165413 MAE: 1.5482761
Validation loss: 4.040805289493734 MAE: 1.6340959
Validation loss: 3.214414184416958 MAE: 1.4402456
50 0 3.2598659992218018
Validation loss: 3.1521059634098454 MAE: 1.4291805
Validation loss: 3.6173668422890666 MAE: 1.5268438
Validation loss: 3.193923879508397 MAE: 1.4147986
Validation loss: 3.1694717407226562 MAE: 1.4073942
Validation loss: 3.0572460907787535 MAE: 1.3586802
Validation loss: 3.08943003625726 MAE: 1.3976253
Validation loss: 2.949120046804898 MAE: 1.3688908
57 1 2.351771354675293
Validation loss: 3.227622964274344 MAE: 1.4479012
Validation loss: 3.2877549334387086 MAE: 1.4609534
Validation loss: 3.2808267740748036 MAE: 1.4511703
Validation loss: 3.3216914675343574 MAE: 1.4621431
Validation loss: 3.013099846528403 MAE: 1.3799895
Validation loss: 4.19697153268747 MAE: 1.6669118
Validation loss: 3.7852917726914486 MAE: 1.5694114
64 2 3.104422092437744
Validation loss: 3.356704443543401 MAE: 1.4916949
Validation loss: 3.5683664412953746 MAE: 1.5610137
Validation loss: 2.9774058272491146 MAE: 1.398341
Validation loss: 3.0709962892771965 MAE: 1.3837268
Validation loss: 4.3259402956794855 MAE: 1.687919
Validation loss: 4.52227573778162 MAE: 1.7340109
Validation loss: 3.318387680916331 MAE: 1.4651986
71 3 3.241659641265869
Validation loss: 3.9623186306737774 MAE: 1.6062238
Validation loss: 3.1377012118622285 MAE: 1.3949461
Validation loss: 2.971820143599007 MAE: 1.3490877
Validation loss: 3.7679723728841275 MAE: 1.5536397
Validation loss: 4.278063116361149 MAE: 1.6775035
Validation loss: 3.2641563942684 MAE: 1.4613378
Validation loss: 3.2860497008616 MAE: 1.472947
78 4 2.8304390907287598
Validation loss: 3.4852607298136955 MAE: 1.5154895
Validation loss: 3.220592357405466 MAE: 1.4269334
Validation loss: 3.0122502197572336 MAE: 1.379024
Validation loss: 3.069329603233529 MAE: 1.4167603
Validation loss: 3.0577410836914676 MAE: 1.4140608
Validation loss: 3.0218994126248 MAE: 1.3856974
Validation loss: 2.6769199491146223 MAE: 1.2777656
85 5 2.741295337677002
Validation loss: 2.913557468347214 MAE: 1.350162
Validation loss: 3.642149174033697 MAE: 1.5425613
Validation loss: 2.6046832266764426 MAE: 1.2670075
Validation loss: 2.886400655286396 MAE: 1.3537582
Validation loss: 3.372455504671413 MAE: 1.4690677
Validation loss: 3.0398768480099627 MAE: 1.3687936
Validation loss: 2.658753354345734 MAE: 1.2815119
92 6 8.511201858520508
Validation loss: 2.865709274258446 MAE: 1.3449531
Validation loss: 3.000315564361649 MAE: 1.3710968
Validation loss: 3.784769860943358 MAE: 1.5316367
Validation loss: 4.457167014404757 MAE: 1.6919407
Validation loss: 3.851084371907028 MAE: 1.5675174
Validation loss: 3.287132159549387 MAE: 1.4483192
Validation loss: 3.2031354317113983 MAE: 1.4249338
Validation loss: 3.408642476527535 MAE: 1.4702213
Loaded trained model with success.
Test loss: 4.941335198077433 Test MAE: 1.7886031
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 30.559476852416992
Validation loss: 24.098588507734462 MAE: 4.387036
Validation loss: 5.4111625316864504 MAE: 1.9363331
Validation loss: 5.58110048871241 MAE: 1.9685814
3 2 5.130229949951172
Validation loss: 5.70697608691657 MAE: 1.9927126
Validation loss: 5.7136282357041965 MAE: 1.9930302
Validation loss: 5.722078537415407 MAE: 1.9902171
6 4 6.0524187088012695
Validation loss: 5.743397124066859 MAE: 1.9845078
Validation loss: 5.696264383549203 MAE: 1.9600207
Validation loss: 4.91790210746811 MAE: 1.8268062
9 6 3.984551191329956
Validation loss: 4.75719275694333 MAE: 1.7627014
Validation loss: 4.3682530647767095 MAE: 1.7154312
Validation loss: 4.29722202039195 MAE: 1.7066287
12 8 4.05256462097168
Validation loss: 4.28069565100278 MAE: 1.6965537
Validation loss: 3.89493902699503 MAE: 1.6318767
