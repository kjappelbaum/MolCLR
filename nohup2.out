nohup: ignoring input
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 589
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 549
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 499
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 99
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 20.536457061767578
Validation loss: 16.127077102661133 MAE: 3.4230893
Validation loss: 12.38736629486084 MAE: 2.8581057
Validation loss: 9.192967414855957 MAE: 2.4509163
Validation loss: 6.8973517417907715 MAE: 2.1122217
Validation loss: 5.376668453216553 MAE: 1.9136026
Validation loss: 4.584112167358398 MAE: 1.7777318
Validation loss: 4.443447589874268 MAE: 1.7102408
Validation loss: 5.003071308135986 MAE: 1.7815149
Validation loss: 6.0867533683776855 MAE: 1.963568
Validation loss: 7.384700298309326 MAE: 2.2554054
Validation loss: 8.394287109375 MAE: 2.466464
Validation loss: 9.192950248718262 MAE: 2.6149983
Validation loss: 9.61367416381836 MAE: 2.6883075
Validation loss: 9.850240707397461 MAE: 2.7282465
Validation loss: 10.002121925354004 MAE: 2.7534566
Validation loss: 10.053718566894531 MAE: 2.7620018
Validation loss: 9.760279655456543 MAE: 2.7133746
Validation loss: 9.240883827209473 MAE: 2.623887
Validation loss: 8.533740043640137 MAE: 2.493926
Validation loss: 7.5784430503845215 MAE: 2.2991705
Validation loss: 6.599642753601074 MAE: 2.0661044
Validation loss: 5.80472993850708 MAE: 1.9185511
Validation loss: 5.232597827911377 MAE: 1.8274248
Validation loss: 4.809245586395264 MAE: 1.742105
Validation loss: 4.563870429992676 MAE: 1.7160867
Validation loss: 4.458621978759766 MAE: 1.7087368
Validation loss: 4.421051979064941 MAE: 1.7257907
Validation loss: 4.422372341156006 MAE: 1.7415706
Validation loss: 4.442271709442139 MAE: 1.7521689
Validation loss: 4.463218688964844 MAE: 1.7597079
Validation loss: 4.479946613311768 MAE: 1.764339
Validation loss: 4.4831390380859375 MAE: 1.7654874
Validation loss: 4.482695579528809 MAE: 1.7664331
Validation loss: 4.46661901473999 MAE: 1.7620376
Validation loss: 4.450467586517334 MAE: 1.7580751
Validation loss: 4.433138847351074 MAE: 1.7514207
Validation loss: 4.445690631866455 MAE: 1.7448773
Validation loss: 4.4791412353515625 MAE: 1.7462525
Validation loss: 4.491558074951172 MAE: 1.746053
Validation loss: 4.489683151245117 MAE: 1.7470065
Validation loss: 4.4525933265686035 MAE: 1.7483919
Validation loss: 4.349138259887695 MAE: 1.7430444
Validation loss: 4.261397838592529 MAE: 1.7253987
Validation loss: 4.240047454833984 MAE: 1.7102389
Validation loss: 4.2970685958862305 MAE: 1.7370714
Validation loss: 4.44871711730957 MAE: 1.7658019
Validation loss: 4.643638610839844 MAE: 1.7966491
Validation loss: 4.853532791137695 MAE: 1.8442351
Validation loss: 5.016810894012451 MAE: 1.8764929
Validation loss: 5.162220478057861 MAE: 1.9031827
50 0 4.428103446960449
Validation loss: 5.213086128234863 MAE: 1.9140311
Validation loss: 5.0100274085998535 MAE: 1.8786235
Validation loss: 4.889505386352539 MAE: 1.8561071
Validation loss: 4.840002059936523 MAE: 1.8472377
Validation loss: 4.786823749542236 MAE: 1.8379521
Validation loss: 4.717446327209473 MAE: 1.8246193
Validation loss: 4.671599388122559 MAE: 1.8165847
Validation loss: 4.783326148986816 MAE: 1.8442171
Validation loss: 4.907593250274658 MAE: 1.8713697
Validation loss: 5.166945457458496 MAE: 1.9209323
Validation loss: 5.584665298461914 MAE: 1.9879308
Validation loss: 6.252897262573242 MAE: 2.0765216
Validation loss: 6.699215412139893 MAE: 2.1287088
Validation loss: 6.817725658416748 MAE: 2.142957
Validation loss: 6.9824748039245605 MAE: 2.158406
Validation loss: 6.949865341186523 MAE: 2.1545806
Validation loss: 6.9869818687438965 MAE: 2.1569936
Validation loss: 6.704838752746582 MAE: 2.1264403
Validation loss: 6.729570388793945 MAE: 2.1282406
Validation loss: 6.4396491050720215 MAE: 2.096159
Validation loss: 6.045854568481445 MAE: 2.0506475
Validation loss: 5.752983570098877 MAE: 2.0153508
Validation loss: 5.532528400421143 MAE: 1.9847016
Validation loss: 5.087202548980713 MAE: 1.9186778
Validation loss: 4.566457271575928 MAE: 1.8312467
Validation loss: 4.223835468292236 MAE: 1.7614243
Validation loss: 3.997551441192627 MAE: 1.7099824
Validation loss: 3.796370506286621 MAE: 1.6657491
Validation loss: 3.5711398124694824 MAE: 1.6094184
Validation loss: 3.346752166748047 MAE: 1.5524826
Validation loss: 3.1794114112854004 MAE: 1.5121733
Validation loss: 3.0267908573150635 MAE: 1.4728208
Validation loss: 2.974229574203491 MAE: 1.4806474
Validation loss: 2.8560991287231445 MAE: 1.4595292
Validation loss: 2.88127064704895 MAE: 1.4727588
Validation loss: 3.108579158782959 MAE: 1.5030266
Validation loss: 3.495326519012451 MAE: 1.5706388
Validation loss: 5.106114387512207 MAE: 1.9510945
Validation loss: 8.404151916503906 MAE: 2.5205529
Validation loss: 10.97158432006836 MAE: 2.934677
Validation loss: 12.598365783691406 MAE: 3.1727598
Validation loss: 12.973687171936035 MAE: 3.204069
Validation loss: 14.271209716796875 MAE: 3.3791714
Validation loss: 14.99289608001709 MAE: 3.4618175
Validation loss: 15.931965827941895 MAE: 3.5461872
Validation loss: 16.47382164001465 MAE: 3.5652525
Validation loss: 15.522027015686035 MAE: 3.399103
Validation loss: 12.921483039855957 MAE: 3.0230615
Validation loss: 11.37745475769043 MAE: 2.809386
Validation loss: 9.80085563659668 MAE: 2.5882175
Loaded trained model with success.
Test loss: 5.932398789069232 Test MAE: 2.0237381
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 19.40882682800293
Validation loss: 12.675708050630531 MAE: 2.8968773
Validation loss: 7.586640766688755 MAE: 2.2372303
Validation loss: 5.6922251642966755 MAE: 2.0242064
Validation loss: 6.757811867460912 MAE: 2.1591053
Validation loss: 7.067225592476981 MAE: 2.128411
Validation loss: 7.914002457443549 MAE: 2.1923904
Validation loss: 8.19280022990947 MAE: 2.234908
Validation loss: 7.589863757697904 MAE: 2.1995437
Validation loss: 6.932721498061199 MAE: 2.1564066
Validation loss: 6.406705554650754 MAE: 2.1086793
Validation loss: 6.066454123477547 MAE: 2.0602837
Validation loss: 5.921165339800776 MAE: 2.0498152
Validation loss: 5.845622432475188 MAE: 2.0441773
Validation loss: 5.867041860307966 MAE: 2.0417478
Validation loss: 5.940697922998545 MAE: 2.0456545
Validation loss: 5.97782124305258 MAE: 2.0488694
Validation loss: 5.974862312784 MAE: 2.0512254
Validation loss: 5.997556686401367 MAE: 2.0620103
Validation loss: 6.12108174148871 MAE: 2.0764728
Validation loss: 6.3166861047550125 MAE: 2.1128569
Validation loss: 6.5785541145169 MAE: 2.1647952
Validation loss: 6.759146048098194 MAE: 2.1935072
Validation loss: 6.775465108910385 MAE: 2.1949236
Validation loss: 6.48471907206944 MAE: 2.143553
Validation loss: 6.163890935936752 MAE: 2.083421
25 0 5.368980884552002
Validation loss: 5.9881409236363 MAE: 2.0544128
Validation loss: 5.841077269340048 MAE: 2.0421329
Validation loss: 5.792911763093909 MAE: 2.0369906
Validation loss: 5.7728817511578 MAE: 2.0340161
Validation loss: 5.76591986052844 MAE: 2.033561
Validation loss: 5.771030211935238 MAE: 2.0343192
Validation loss: 5.782005806358493 MAE: 2.0352106
Validation loss: 5.786906232639235 MAE: 2.0357106
Validation loss: 5.799704181904695 MAE: 2.0375867
Validation loss: 5.801782063075474 MAE: 2.0373125
Validation loss: 5.799003474566401 MAE: 2.0360622
Validation loss: 5.791354646488112 MAE: 2.0339954
Validation loss: 5.765821778044408 MAE: 2.0304482
Validation loss: 5.73030898035789 MAE: 2.027233
Validation loss: 5.7011220017258 MAE: 2.0265
Validation loss: 5.692188535417829 MAE: 2.025978
Validation loss: 5.699320462285256 MAE: 2.0250506
Validation loss: 5.737466568849524 MAE: 2.0242944
Validation loss: 5.792879172733852 MAE: 2.0264342
Validation loss: 5.833915661792366 MAE: 2.0325744
Validation loss: 5.882036870839644 MAE: 2.0387683
Validation loss: 5.971549141163728 MAE: 2.0491433
Validation loss: 6.013147422245571 MAE: 2.0520298
Validation loss: 6.031637045801903 MAE: 2.0537732
Validation loss: 5.995652938375668 MAE: 2.0492785
50 0 5.022899627685547
Validation loss: 5.995815481458392 MAE: 2.049515
Validation loss: 6.050566770592514 MAE: 2.0582106
Validation loss: 6.071096264586156 MAE: 2.0624113
Validation loss: 5.977267236125712 MAE: 2.051488
Validation loss: 5.842006284363416 MAE: 2.0352118
Validation loss: 5.752711792381442 MAE: 2.0234282
Validation loss: 5.702941135484345 MAE: 2.0171359
Validation loss: 5.67164151522578 MAE: 2.0190234
Validation loss: 5.645826826290208 MAE: 2.0185895
Validation loss: 5.635662964412144 MAE: 2.0181065
Validation loss: 5.665936907943414 MAE: 2.0195363
Validation loss: 5.677851180641019 MAE: 2.0191295
Validation loss: 5.669255344235167 MAE: 2.0171351
Validation loss: 5.64135557291459 MAE: 2.0130415
Validation loss: 5.588236166506397 MAE: 2.007099
Validation loss: 5.568356621022127 MAE: 2.0059133
Validation loss: 5.560323141059097 MAE: 2.003576
Validation loss: 5.543443125121447 MAE: 1.9996337
Validation loss: 5.4982171058654785 MAE: 1.9949993
Validation loss: 5.448444677858936 MAE: 1.9901845
Validation loss: 5.400452983622649 MAE: 1.9819397
Validation loss: 5.352868050945048 MAE: 1.9712636
Validation loss: 5.304456924905582 MAE: 1.9596187
Validation loss: 5.279463865319077 MAE: 1.9588014
Validation loss: 5.322310068169418 MAE: 1.965916
75 0 5.782167911529541
Validation loss: 5.429842812674386 MAE: 1.9783331
Validation loss: 5.2982010160173685 MAE: 1.9546072
Validation loss: 5.070454334726139 MAE: 1.9132972
Validation loss: 4.98581127244599 MAE: 1.894537
Validation loss: 4.882684230804443 MAE: 1.872677
Validation loss: 4.755090655112753 MAE: 1.841741
Validation loss: 4.65184565952846 MAE: 1.811222
Validation loss: 4.510430822567064 MAE: 1.7756351
Validation loss: 4.384838371860738 MAE: 1.7609892
Validation loss: 4.208311917830486 MAE: 1.732138
Validation loss: 3.9588928125342546 MAE: 1.6751395
Validation loss: 3.771697983449819 MAE: 1.6373606
Validation loss: 3.7930925330337213 MAE: 1.6436787
Validation loss: 3.621463240409384 MAE: 1.5615731
Validation loss: 3.4624611212282765 MAE: 1.5248078
Validation loss: 3.404381888253348 MAE: 1.5103698
Validation loss: 3.459924483785824 MAE: 1.523848
Validation loss: 3.6330644646469428 MAE: 1.5954945
Validation loss: 4.0762925731892485 MAE: 1.7161759
Validation loss: 4.807887777990224 MAE: 1.8369074
Validation loss: 5.693358781386395 MAE: 1.9990321
Validation loss: 6.303458223537523 MAE: 2.1101513
Validation loss: 6.631905127544792 MAE: 2.155716
Validation loss: 6.107403083723419 MAE: 2.062928
Validation loss: 5.167248453412737 MAE: 1.8783538
Loaded trained model with success.
Test loss: 6.20653552863434 Test MAE: 2.0414429
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 20.387516021728516
Validation loss: 6.946139807652945 MAE: 2.1647599
Validation loss: 8.494833031086007 MAE: 2.4000263
Validation loss: 18.05761193747472 MAE: 3.6811368
Validation loss: 11.737959129641755 MAE: 2.80315
Validation loss: 6.237168504734232 MAE: 2.0291266
Validation loss: 5.256975944596108 MAE: 1.9237292
Validation loss: 5.477688295672638 MAE: 1.9627168
Validation loss: 5.69046806566643 MAE: 1.9932016
Validation loss: 5.620257401707197 MAE: 1.9860263
Validation loss: 5.463722537262271 MAE: 1.970206
Validation loss: 5.451239169246018 MAE: 1.9600793
Validation loss: 5.578413833271373 MAE: 1.9727166
12 2 4.686842918395996
Validation loss: 5.732740903141523 MAE: 1.9978195
Validation loss: 5.958451434819385 MAE: 2.0347276
Validation loss: 5.968923400146792 MAE: 2.0315778
Validation loss: 5.84428155783451 MAE: 2.0117698
Validation loss: 5.4610364485268645 MAE: 1.9537706
Validation loss: 5.179920226034492 MAE: 1.9047229
Validation loss: 5.273261643419362 MAE: 1.9192696
Validation loss: 5.258191168910325 MAE: 1.9180429
Validation loss: 5.228158820759166 MAE: 1.9178294
Validation loss: 5.200621710883246 MAE: 1.9093782
Validation loss: 5.362665393135765 MAE: 1.9368907
Validation loss: 5.659316221872966 MAE: 1.9874264
Validation loss: 6.0313769735471165 MAE: 2.0484262
25 0 6.80828332901001
Validation loss: 5.946683324948705 MAE: 2.0359612
Validation loss: 5.601214389608364 MAE: 1.9796779
Validation loss: 5.4546165129151 MAE: 1.9537469
Validation loss: 5.652527048130228 MAE: 1.987187
Validation loss: 5.8419449160797425 MAE: 2.0217276
Validation loss: 6.597619411319193 MAE: 2.1279564
Validation loss: 7.537970099786316 MAE: 2.2521966
Validation loss: 7.782064726858428 MAE: 2.2895606
Validation loss: 7.761837588416205 MAE: 2.2898636
Validation loss: 7.093576767227867 MAE: 2.1899447
Validation loss: 6.09522149538753 MAE: 2.0468411
Validation loss: 5.783459487587515 MAE: 2.0038671
37 2 6.08202600479126
Validation loss: 6.1271534688545 MAE: 2.0514278
Validation loss: 6.453031083550116 MAE: 2.1035259
Validation loss: 6.407082661233767 MAE: 2.0981658
Validation loss: 6.655692037909922 MAE: 2.1317875
Validation loss: 6.341880966918637 MAE: 2.0898325
Validation loss: 5.94033491972721 MAE: 2.0308988
Validation loss: 5.4220899764937585 MAE: 1.9500184
Validation loss: 5.139046466711796 MAE: 1.8998536
Validation loss: 5.0413937616829925 MAE: 1.8781695
Validation loss: 5.119504495100542 MAE: 1.9005826
Validation loss: 5.125561786420418 MAE: 1.9017777
Validation loss: 5.087870438893636 MAE: 1.8907272
Validation loss: 5.090372340847748 MAE: 1.8866262
50 0 4.200075149536133
Validation loss: 5.282144168410638 MAE: 1.9147717
Validation loss: 5.419177179384714 MAE: 1.9340996
Validation loss: 5.358924518931996 MAE: 1.921424
Validation loss: 4.8023939831088285 MAE: 1.8088728
Validation loss: 4.596710583176276 MAE: 1.7805169
Validation loss: 4.873894279653376 MAE: 1.861885
Validation loss: 5.219158134075126 MAE: 1.9354168
Validation loss: 5.994691665726479 MAE: 2.0368772
Validation loss: 6.522451285159949 MAE: 2.101927
Validation loss: 6.281801090848567 MAE: 2.0669265
Validation loss: 5.67489018103089 MAE: 1.9768205
Validation loss: 5.217971445334078 MAE: 1.9114296
62 2 3.5216307640075684
Validation loss: 4.836288984375771 MAE: 1.8515567
Validation loss: 4.968508937142112 MAE: 1.8678256
Validation loss: 5.286000911635582 MAE: 1.9153917
Validation loss: 6.166954594429093 MAE: 2.0439787
Validation loss: 6.589260255447542 MAE: 2.10612
Validation loss: 6.292700093201916 MAE: 2.069644
Validation loss: 6.212863787256106 MAE: 2.0639777
Validation loss: 6.258996086891251 MAE: 2.0704348
Validation loss: 6.27252513230449 MAE: 2.062645
Validation loss: 5.687180591352059 MAE: 1.9580215
Validation loss: 5.4412545844762015 MAE: 1.9119126
Validation loss: 5.194774808305683 MAE: 1.8708547
Validation loss: 5.09407743781504 MAE: 1.8695269
75 0 4.425095081329346
Validation loss: 4.805924434854527 MAE: 1.8271823
Validation loss: 4.675020783838599 MAE: 1.8025497
Validation loss: 4.641464117801551 MAE: 1.7945384
Validation loss: 5.426960428555806 MAE: 1.9218255
Validation loss: 6.510288835775973 MAE: 2.0793426
Validation loss: 6.908890421944435 MAE: 2.143286
Validation loss: 6.496835198065247 MAE: 2.0808208
Validation loss: 5.69101362878626 MAE: 1.9582934
Validation loss: 4.911814077936038 MAE: 1.837418
Validation loss: 4.955070047366498 MAE: 1.8408115
Validation loss: 4.535961536446003 MAE: 1.7676382
Validation loss: 4.350277623744926 MAE: 1.7305887
87 2 3.70021390914917
Validation loss: 4.9341246287028 MAE: 1.8196493
Validation loss: 6.140111452401286 MAE: 2.0179782
Validation loss: 6.451438701514042 MAE: 2.0671294
Validation loss: 5.904844683830184 MAE: 1.982884
Validation loss: 5.353050239158399 MAE: 1.9022205
Validation loss: 4.9437467883331605 MAE: 1.852878
Validation loss: 5.322927354562162 MAE: 1.9074671
Validation loss: 5.454504109392262 MAE: 1.9238828
Validation loss: 5.65112637991857 MAE: 1.9557141
Validation loss: 6.035542781906899 MAE: 2.012018
Validation loss: 6.152419152885977 MAE: 2.0259786
Validation loss: 6.2832955784267845 MAE: 2.0494785
Validation loss: 7.495710960542313 MAE: 2.2417548
Loaded trained model with success.
Test loss: 5.092658854199794 Test MAE: 1.8534769
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 37.55823516845703
Validation loss: 6.0820334568694605 MAE: 2.0096445
Validation loss: 8.78475845279406 MAE: 2.4081578
Validation loss: 7.719923456709589 MAE: 2.2691913
Validation loss: 5.485043679050465 MAE: 1.9373025
Validation loss: 5.657904597383049 MAE: 1.9581909
Validation loss: 5.882905698900846 MAE: 2.0043786
Validation loss: 6.802404276689693 MAE: 2.1463845
7 1 4.040093421936035
Validation loss: 7.072874991738018 MAE: 2.18355
Validation loss: 7.061296855984022 MAE: 2.1839871
Validation loss: 6.015499737993557 MAE: 2.0300117
Validation loss: 6.165902346222844 MAE: 2.0537782
Validation loss: 6.086420016073102 MAE: 2.0414581
Validation loss: 6.459347787214883 MAE: 2.0980394
Validation loss: 5.515201465568351 MAE: 1.9455576
14 2 5.113419532775879
Validation loss: 5.464146599697707 MAE: 1.9343691
Validation loss: 5.261008018225282 MAE: 1.8985403
Validation loss: 5.123097467662102 MAE: 1.8722925
Validation loss: 5.005429913051164 MAE: 1.8475872
Validation loss: 5.226531570281216 MAE: 1.8768976
Validation loss: 6.942271203850981 MAE: 2.1842794
Validation loss: 5.885651725021439 MAE: 2.0203807
21 3 4.818655490875244
Validation loss: 4.958380509860551 MAE: 1.8314478
Validation loss: 4.207711631928257 MAE: 1.648295
Validation loss: 3.9126383838941106 MAE: 1.6103871
Validation loss: 4.209915755382135 MAE: 1.6546376
Validation loss: 5.287352516423518 MAE: 1.873383
Validation loss: 4.5644956581556615 MAE: 1.7295971
Validation loss: 3.920148037186819 MAE: 1.5895671
28 4 3.570250988006592
Validation loss: 3.8661740329397385 MAE: 1.5698662
Validation loss: 3.7267530934894504 MAE: 1.5726228
Validation loss: 4.112995175860036 MAE: 1.6368586
Validation loss: 4.106891479024935 MAE: 1.6389807
Validation loss: 3.7493070286122996 MAE: 1.5676178
Validation loss: 3.675824115024739 MAE: 1.5435935
Validation loss: 3.5732828384667785 MAE: 1.5326023
35 5 5.310029029846191
Validation loss: 3.5414416790008545 MAE: 1.5300169
Validation loss: 3.6346270307224597 MAE: 1.5342386
Validation loss: 3.7688581116834476 MAE: 1.5668693
Validation loss: 3.701993143139173 MAE: 1.5345732
Validation loss: 3.502954297329313 MAE: 1.504094
Validation loss: 3.733732584133819 MAE: 1.5612502
Validation loss: 3.6478433093832967 MAE: 1.5493605
42 6 1.8870446681976318
Validation loss: 3.3437845329543454 MAE: 1.4446657
Validation loss: 3.4002218800573494 MAE: 1.4644988
Validation loss: 3.612846240326388 MAE: 1.5161108
Validation loss: 3.4206226914372277 MAE: 1.453195
Validation loss: 3.6250977899560977 MAE: 1.5266267
Validation loss: 5.509431019500273 MAE: 1.9446313
Validation loss: 5.938190242153915 MAE: 2.0251057
Validation loss: 4.347462754752768 MAE: 1.7045319
50 0 3.9115142822265625
Validation loss: 3.4255189709926968 MAE: 1.4687736
Validation loss: 3.32331730852175 MAE: 1.4386995
Validation loss: 3.6414023955263684 MAE: 1.5428916
Validation loss: 3.619172056715692 MAE: 1.5212542
Validation loss: 4.379189016830981 MAE: 1.6837071
Validation loss: 4.161112624796192 MAE: 1.6487801
Validation loss: 3.5150238221614205 MAE: 1.4901954
57 1 2.79252290725708
Validation loss: 3.248930172704572 MAE: 1.4292986
Validation loss: 5.032089120778606 MAE: 1.804722
Validation loss: 3.6841885115034017 MAE: 1.5520835
Validation loss: 3.8020754950729447 MAE: 1.5509199
Validation loss: 3.7966645854202348 MAE: 1.5544628
Validation loss: 3.301975904397629 MAE: 1.4311781
Validation loss: 3.3847586868995396 MAE: 1.4427135
64 2 3.4316229820251465
Validation loss: 3.401571769810202 MAE: 1.4842576
Validation loss: 3.5200372485060187 MAE: 1.4986001
Validation loss: 4.314163288279395 MAE: 1.6639287
Validation loss: 3.503711043889798 MAE: 1.4854083
Validation loss: 3.209081976857018 MAE: 1.4211271
Validation loss: 3.1989301958275798 MAE: 1.4030105
Validation loss: 4.811251925463653 MAE: 1.7825793
71 3 3.4906768798828125
Validation loss: 3.3288216321312603 MAE: 1.461783
Validation loss: 3.6704100627995015 MAE: 1.5469093
Validation loss: 3.2367475116672226 MAE: 1.4331653
Validation loss: 3.4849049317177814 MAE: 1.4881232
Validation loss: 5.68874338044593 MAE: 1.9455744
Validation loss: 4.7926004088703715 MAE: 1.7732561
Validation loss: 3.539922746581648 MAE: 1.5190822
78 4 3.513587474822998
Validation loss: 3.8556492580241293 MAE: 1.5788478
Validation loss: 3.82682544262565 MAE: 1.556798
Validation loss: 3.08827712188414 MAE: 1.3773043
Validation loss: 3.6269196316824486 MAE: 1.5130514
Validation loss: 3.2197719536834026 MAE: 1.3836424
Validation loss: 2.9709233550270597 MAE: 1.354452
Validation loss: 3.131550423463984 MAE: 1.4050875
85 5 3.5650830268859863
Validation loss: 3.1685030100932674 MAE: 1.4194963
Validation loss: 3.2244491888650098 MAE: 1.4274538
Validation loss: 2.9429534308275387 MAE: 1.3548917
Validation loss: 3.1388466334223146 MAE: 1.4194509
Validation loss: 4.05761409824218 MAE: 1.6148838
Validation loss: 3.118409771116535 MAE: 1.4390618
Validation loss: 3.2485023838790816 MAE: 1.4579288
92 6 1.9426233768463135
Validation loss: 3.525909747310619 MAE: 1.5140551
Validation loss: 4.185320114969608 MAE: 1.6568063
Validation loss: 2.8982025501716078 MAE: 1.342277
Validation loss: 3.4555499799287497 MAE: 1.473657
Validation loss: 2.772359830650253 MAE: 1.3197334
Validation loss: 2.954713715979801 MAE: 1.3573418
Validation loss: 2.6081071343254205 MAE: 1.2675819
Validation loss: 2.7358472898377846 MAE: 1.300591
Loaded trained model with success.
Test loss: 5.287334637546327 Test MAE: 1.8651096
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 20.655447006225586
Validation loss: 11.998198526416848 MAE: 2.891563
Validation loss: 5.65679132675599 MAE: 1.9940244
Validation loss: 6.919960801730414 MAE: 2.1809688
3 2 7.456441402435303
Validation loss: 5.7801842106607015 MAE: 2.0122676
Validation loss: 5.62832525545705 MAE: 1.991416
Validation loss: 6.645726358723306 MAE: 2.1368492
6 4 5.052065372467041
Validation loss: 6.031592554463175 MAE: 2.023582
Validation loss: 5.51057639532911 MAE: 1.9356747
Validation loss: 5.433851932953737 MAE: 1.8712496
9 6 5.618068695068359
Validation loss: 6.815317095162157 MAE: 2.0984323
Validation loss: 6.631010680494901 MAE: 2.0658236
Validation loss: 7.738313963513575 MAE: 2.2261348
12 8 4.313340663909912
Validation loss: 6.211103475643303 MAE: 1.9986866
Validation loss: 4.035765784536908 MAE: 1.6180917
Validation loss: 4.958094073201946 MAE: 1.7785021
15 10 2.315434694290161
Validation loss: 7.28277754544734 MAE: 2.164583
Validation loss: 7.716701910825435 MAE: 2.2266717
Validation loss: 6.925059956873586 MAE: 2.1049552
18 12 5.051314353942871
Validation loss: 4.967845298484237 MAE: 1.7651957
Validation loss: 6.453325794311707 MAE: 2.0264263
Validation loss: 3.986077580996649 MAE: 1.595242
21 14 4.658193588256836
Validation loss: 4.002069158878976 MAE: 1.591833
Validation loss: 5.375831614037554 MAE: 1.847692
Validation loss: 3.426681681482013 MAE: 1.4944652
Validation loss: 4.540328310582346 MAE: 1.7020278
25 0 4.048730850219727
Validation loss: 4.563311756493333 MAE: 1.6885959
Validation loss: 5.175449172576109 MAE: 1.8045905
Validation loss: 3.701427575342641 MAE: 1.5538788
28 2 5.657058238983154
Validation loss: 4.382314019786093 MAE: 1.6601486
Validation loss: 3.5572162897648933 MAE: 1.5216554
Validation loss: 5.267285012529943 MAE: 1.8319224
31 4 2.738473892211914
Validation loss: 3.992108828080202 MAE: 1.5851086
Validation loss: 3.319705022838646 MAE: 1.4852862
Validation loss: 3.3740592975176886 MAE: 1.4920543
34 6 4.155351161956787
Validation loss: 3.622439477630034 MAE: 1.526579
Validation loss: 3.966140107305829 MAE: 1.6041192
Validation loss: 3.4102054745974186 MAE: 1.4832762
37 8 3.875251293182373
Validation loss: 3.173252645140898 MAE: 1.4496515
Validation loss: 3.5502465191728367 MAE: 1.5071175
Validation loss: 3.1909921747410226 MAE: 1.4454426
40 10 3.0527849197387695
Validation loss: 3.202151736658895 MAE: 1.4577456
Validation loss: 3.267405801402304 MAE: 1.4544455
Validation loss: 3.27689303472668 MAE: 1.4540901
43 12 2.586397409439087
Validation loss: 4.2395264256693315 MAE: 1.6315345
Validation loss: 3.627234665329805 MAE: 1.5127459
Validation loss: 3.266443682099153 MAE: 1.4482237
46 14 2.7614800930023193
Validation loss: 3.511719464300152 MAE: 1.4851409
Validation loss: 3.396696488221805 MAE: 1.4704254
Validation loss: 3.148467646333163 MAE: 1.4256594
Validation loss: 3.468780155889018 MAE: 1.4649098
50 0 3.00596022605896
Validation loss: 3.813671080526226 MAE: 1.5528643
Validation loss: 3.8837626563284346 MAE: 1.5475575
Validation loss: 3.4325798078624903 MAE: 1.4618118
53 2 5.094008445739746
Validation loss: 3.099055373835898 MAE: 1.4114772
Validation loss: 3.249695077448904 MAE: 1.4514332
Validation loss: 3.336322138448039 MAE: 1.4558045
56 4 2.5920310020446777
Validation loss: 3.5683674066960216 MAE: 1.4875879
Validation loss: 3.029158471342557 MAE: 1.3940548
Validation loss: 3.3237380398538163 MAE: 1.4442774
59 6 4.129225730895996
Validation loss: 3.1600985804158364 MAE: 1.4047534
Validation loss: 3.189229619765807 MAE: 1.4216264
Validation loss: 3.104538848739349 MAE: 1.4098977
62 8 3.7032761573791504
Validation loss: 3.2212012865261466 MAE: 1.4384676
Validation loss: 3.3348509758890033 MAE: 1.4618316
Validation loss: 3.520276118375973 MAE: 1.4979534
65 10 2.855297088623047
Validation loss: 3.040369425125734 MAE: 1.3908994
Validation loss: 3.183452976968341 MAE: 1.4206653
Validation loss: 2.9796088205310767 MAE: 1.3849823
68 12 3.5338265895843506
Validation loss: 3.0775995302295875 MAE: 1.391455
Validation loss: 2.8916619860815382 MAE: 1.3617738
Validation loss: 3.001906048558757 MAE: 1.381115
71 14 3.7650158405303955
Validation loss: 2.9834093899430636 MAE: 1.3817658
Validation loss: 2.8929829420689828 MAE: 1.3516866
Validation loss: 3.03160592788207 MAE: 1.3853283
Validation loss: 3.2756542633912846 MAE: 1.4258159
75 0 4.135931015014648
Validation loss: 2.751043448706189 MAE: 1.3399675
Validation loss: 2.9374467930000625 MAE: 1.3557445
Validation loss: 2.8484100765121245 MAE: 1.3363384
78 2 2.716190814971924
Validation loss: 2.797113242751372 MAE: 1.3240685
Validation loss: 2.823889128669708 MAE: 1.330518
Validation loss: 2.8348485410571813 MAE: 1.3440174
81 4 4.457810401916504
Validation loss: 2.8504239456925937 MAE: 1.3357164
Validation loss: 3.168367082943658 MAE: 1.3952521
Validation loss: 2.985589566355 MAE: 1.3626986
84 6 3.0309996604919434
Validation loss: 2.965898732145229 MAE: 1.372222
Validation loss: 2.7244779564335735 MAE: 1.3208578
Validation loss: 3.1173813830396693 MAE: 1.3954272
87 8 3.1894595623016357
Validation loss: 2.995065501314366 MAE: 1.3757559
Validation loss: 2.738016680390658 MAE: 1.3033619
Validation loss: 2.6910981654165265 MAE: 1.3070011
90 10 2.5178866386413574
Validation loss: 3.1118125968084547 MAE: 1.3918254
Validation loss: 3.1061238931988426 MAE: 1.3954334
Validation loss: 2.7468762364320622 MAE: 1.317193
93 12 4.731842994689941
Validation loss: 2.7257766083390536 MAE: 1.3105605
Validation loss: 2.855454279568965 MAE: 1.342906
Validation loss: 2.750495195388794 MAE: 1.3248073
96 14 3.815361976623535
Validation loss: 2.557136012461477 MAE: 1.2763535
Validation loss: 2.7635361871165123 MAE: 1.3140092
Validation loss: 2.748803012117833 MAE: 1.3160539
Validation loss: 2.5862452783183247 MAE: 1.2736915
Loaded trained model with success.
Test loss: 4.652924459514809 Test MAE: 1.6929499
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999848297979177, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 659177
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999241489895887, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 659137
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9998482979791774, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 659087
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9996965959583548, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 658987
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9992414898958869, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 658687
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9984829797917738, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 999, Valid size: 999, Test size: 658187
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9751861042183623, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 380
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9503722084367245, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 19, Valid size: 19, Test size: 370
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8759305210918115, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 48, Valid size: 48, Test size: 341
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7518610421836228, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 96, Valid size: 96, Test size: 293
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5037220843672456, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 193, Valid size: 193, Test size: 196
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 589
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 549
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 499
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 99
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 20.329233169555664
Validation loss: 16.53815460205078 MAE: 3.4406102
Validation loss: 12.921871185302734 MAE: 2.8673782
Validation loss: 9.825740814208984 MAE: 2.3669798
Validation loss: 7.533378601074219 MAE: 2.0448892
Validation loss: 5.988586902618408 MAE: 1.9381638
Validation loss: 5.063537120819092 MAE: 1.8854637
Validation loss: 4.699731826782227 MAE: 1.9483833
Validation loss: 4.9758100509643555 MAE: 2.0110521
Validation loss: 5.520208835601807 MAE: 2.0533178
Validation loss: 6.26702356338501 MAE: 2.14775
Validation loss: 6.995848655700684 MAE: 2.2356977
Validation loss: 7.4680914878845215 MAE: 2.2972689
Validation loss: 7.493214130401611 MAE: 2.3014302
Validation loss: 7.166413307189941 MAE: 2.2542186
Validation loss: 6.710346221923828 MAE: 2.2032938
Validation loss: 6.344577312469482 MAE: 2.1556845
Validation loss: 6.008272647857666 MAE: 2.1077971
Validation loss: 5.616678237915039 MAE: 2.04798
Validation loss: 5.2519659996032715 MAE: 2.0215433
Validation loss: 4.988283157348633 MAE: 1.9987893
Validation loss: 4.799644947052002 MAE: 1.9758399
Validation loss: 4.709921836853027 MAE: 1.9535269
Validation loss: 4.703104019165039 MAE: 1.936423
Validation loss: 4.751575946807861 MAE: 1.9190919
Validation loss: 4.85264253616333 MAE: 1.9079268
Validation loss: 5.0562238693237305 MAE: 1.9035759
Validation loss: 5.248802661895752 MAE: 1.9100604
Validation loss: 5.295704364776611 MAE: 1.8960607
Validation loss: 5.111331939697266 MAE: 1.8500257
Validation loss: 4.843533039093018 MAE: 1.7947401
Validation loss: 4.532088279724121 MAE: 1.7322922
Validation loss: 4.249668598175049 MAE: 1.6615975
Validation loss: 4.051010608673096 MAE: 1.5926582
Validation loss: 3.9372401237487793 MAE: 1.5313731
Validation loss: 3.9861576557159424 MAE: 1.5582232
Validation loss: 4.25820779800415 MAE: 1.614387
Validation loss: 4.683654308319092 MAE: 1.6888518
Validation loss: 5.258022785186768 MAE: 1.8734555
Validation loss: 6.000547885894775 MAE: 2.0918007
Validation loss: 7.167409420013428 MAE: 2.3673697
Validation loss: 8.330299377441406 MAE: 2.5972042
Validation loss: 10.043622970581055 MAE: 2.8840694
Validation loss: 12.109504699707031 MAE: 3.1821866
Validation loss: 14.386764526367188 MAE: 3.4657757
Validation loss: 16.044048309326172 MAE: 3.6527426
Validation loss: 18.103361129760742 MAE: 3.865636
Validation loss: 20.180940628051758 MAE: 4.066587
Validation loss: 21.734025955200195 MAE: 4.206721
Validation loss: 23.05980682373047 MAE: 4.324363
Validation loss: 24.062484741210938 MAE: 4.409306
50 0 4.232156753540039
Validation loss: 25.276329040527344 MAE: 4.511944
Validation loss: 26.340503692626953 MAE: 4.595018
Validation loss: 26.186717987060547 MAE: 4.5793
Validation loss: 28.027050018310547 MAE: 4.734867
Validation loss: 28.150659561157227 MAE: 4.7531343
Validation loss: 28.65219497680664 MAE: 4.7977924
Validation loss: 28.6492919921875 MAE: 4.810401
Validation loss: 29.21324920654297 MAE: 4.861987
Validation loss: 29.31976318359375 MAE: 4.879397
Validation loss: 29.349130630493164 MAE: 4.892438
Validation loss: 28.64360809326172 MAE: 4.851621
Validation loss: 27.663928985595703 MAE: 4.782854
Validation loss: 27.31552505493164 MAE: 4.760364
Validation loss: 29.23432159423828 MAE: 4.9131045
Validation loss: 31.094520568847656 MAE: 5.0550904
Validation loss: 31.84986686706543 MAE: 5.117853
Validation loss: 32.58284378051758 MAE: 5.1782284
Validation loss: 34.08866500854492 MAE: 5.2819777
Validation loss: 34.5157356262207 MAE: 5.2968507
Validation loss: 35.525691986083984 MAE: 5.3625135
Validation loss: 37.21855163574219 MAE: 5.4704823
Validation loss: 37.72480392456055 MAE: 5.4997487
Validation loss: 38.68034362792969 MAE: 5.5581417
Validation loss: 40.46595764160156 MAE: 5.690072
Validation loss: 38.20243453979492 MAE: 5.5043545
Validation loss: 35.16428756713867 MAE: 5.2772636
Validation loss: 33.80683898925781 MAE: 5.166565
Validation loss: 32.01336669921875 MAE: 5.032403
Validation loss: 30.416358947753906 MAE: 4.9138126
Validation loss: 27.69556999206543 MAE: 4.7134113
Validation loss: 26.403730392456055 MAE: 4.617161
Validation loss: 24.797283172607422 MAE: 4.4935656
Validation loss: 22.45377540588379 MAE: 4.296042
Validation loss: 19.70388412475586 MAE: 4.044469
Validation loss: 18.369916915893555 MAE: 3.9089537
Validation loss: 17.368303298950195 MAE: 3.8074367
Validation loss: 15.80793285369873 MAE: 3.6409879
Validation loss: 14.566465377807617 MAE: 3.5020952
Validation loss: 13.185725212097168 MAE: 3.3381302
Validation loss: 12.011722564697266 MAE: 3.1896935
Validation loss: 10.651686668395996 MAE: 3.007884
Validation loss: 9.646171569824219 MAE: 2.8650682
Validation loss: 8.78662109375 MAE: 2.7352781
Validation loss: 7.750255107879639 MAE: 2.5659673
Validation loss: 6.7849812507629395 MAE: 2.396213
Validation loss: 5.72658109664917 MAE: 2.1905441
Validation loss: 5.075434684753418 MAE: 2.0495305
Validation loss: 4.536925315856934 MAE: 1.9215516
Validation loss: 3.958658456802368 MAE: 1.7766047
Validation loss: 3.541123628616333 MAE: 1.6668167
Loaded trained model with success.
Test loss: 6.727036321864409 Test MAE: 2.143882
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 24.12531852722168
Validation loss: 15.102325906558912 MAE: 3.2266622
Validation loss: 8.784355942083865 MAE: 2.3645043
Validation loss: 5.321021537391507 MAE: 1.9633018
Validation loss: 5.569516376573212 MAE: 1.9823498
Validation loss: 10.094584095234774 MAE: 2.573545
Validation loss: 17.62141293895488 MAE: 3.676586
Validation loss: 22.52569443838937 MAE: 4.257591
Validation loss: 22.799990595603475 MAE: 4.2888894
Validation loss: 19.301384945305028 MAE: 3.8871179
Validation loss: 15.097967381380043 MAE: 3.3519733
Validation loss: 11.033005169459752 MAE: 2.72719
Validation loss: 8.143603519517548 MAE: 2.297705
Validation loss: 6.413805942146146 MAE: 2.0968044
Validation loss: 5.365171393569635 MAE: 1.9634227
Validation loss: 4.816761264995653 MAE: 1.862764
Validation loss: 4.751986493869704 MAE: 1.8583106
Validation loss: 4.9442190345452754 MAE: 1.8981801
Validation loss: 5.064951594994993 MAE: 1.9283432
Validation loss: 5.119638121857935 MAE: 1.9629581
Validation loss: 5.185304729305968 MAE: 1.9820645
Validation loss: 5.302201387833576 MAE: 2.0021818
Validation loss: 5.347879857433085 MAE: 2.0062249
Validation loss: 5.2338422171923575 MAE: 1.990195
Validation loss: 5.15156686549284 MAE: 1.9739745
Validation loss: 5.11791314884108 MAE: 1.9675263
25 0 4.601589202880859
Validation loss: 5.0823730254659845 MAE: 1.9580697
Validation loss: 5.064969160118881 MAE: 1.949345
Validation loss: 5.0798048097260144 MAE: 1.9386551
Validation loss: 5.141938248459174 MAE: 1.9348568
Validation loss: 5.215739532392853 MAE: 1.9361501
Validation loss: 5.22073237749995 MAE: 1.9341085
Validation loss: 5.276087829044887 MAE: 1.9407557
Validation loss: 5.206770624433245 MAE: 1.9319168
Validation loss: 5.07526700350703 MAE: 1.9211737
Validation loss: 4.983861105782645 MAE: 1.9129918
Validation loss: 4.960885067375338 MAE: 1.9111034
Validation loss: 4.977028447754529 MAE: 1.9079356
Validation loss: 4.951976853974012 MAE: 1.9012676
Validation loss: 4.918399187983299 MAE: 1.8931482
Validation loss: 4.904835525824099 MAE: 1.886846
Validation loss: 4.93999382914329 MAE: 1.887829
Validation loss: 4.983604002972038 MAE: 1.8929149
Validation loss: 5.012214096225038 MAE: 1.8938302
Validation loss: 5.0247255442093826 MAE: 1.8931046
Validation loss: 4.951450659304249 MAE: 1.8827133
Validation loss: 4.835254221546407 MAE: 1.8668543
Validation loss: 4.724629261055771 MAE: 1.8562249
Validation loss: 4.656251440242845 MAE: 1.8494378
Validation loss: 4.584684595769765 MAE: 1.8379235
Validation loss: 4.484179939542498 MAE: 1.8157586
50 0 4.761260032653809
Validation loss: 4.405523373156178 MAE: 1.7989252
Validation loss: 4.2835012601346385 MAE: 1.7681662
Validation loss: 4.149958415907257 MAE: 1.7328477
Validation loss: 3.9881103282072106 MAE: 1.6936067
Validation loss: 3.868756046100539 MAE: 1.6737522
Validation loss: 3.8074803936238193 MAE: 1.6654655
Validation loss: 3.7549516522154516 MAE: 1.6571951
Validation loss: 3.707212798449458 MAE: 1.6478957
Validation loss: 3.6664504177716313 MAE: 1.6383667
Validation loss: 3.5663730757577077 MAE: 1.6150167
Validation loss: 3.421305617507623 MAE: 1.5747372
Validation loss: 3.385841992436623 MAE: 1.561475
Validation loss: 3.2814492595439053 MAE: 1.5327454
Validation loss: 3.242827926363264 MAE: 1.5102723
Validation loss: 3.334339205099612 MAE: 1.517103
Validation loss: 3.3758355257462482 MAE: 1.5442188
Validation loss: 3.3021971644187462 MAE: 1.5392537
Validation loss: 3.2108484774219748 MAE: 1.5246165
Validation loss: 3.1315934560736833 MAE: 1.5061601
Validation loss: 3.076317208153861 MAE: 1.4921294
Validation loss: 3.0276165057201774 MAE: 1.4793404
Validation loss: 2.9556796064182205 MAE: 1.4596262
Validation loss: 2.9262866827906393 MAE: 1.4479929
Validation loss: 2.9315881534498565 MAE: 1.4575555
Validation loss: 2.961837252792047 MAE: 1.4714692
75 0 3.3283607959747314
Validation loss: 2.9963140779612014 MAE: 1.4851602
Validation loss: 3.069506192693905 MAE: 1.5070479
Validation loss: 3.2732532754236336 MAE: 1.5532914
Validation loss: 3.298985096873069 MAE: 1.5623419
Validation loss: 3.0276682522832132 MAE: 1.4971807
Validation loss: 2.8029844712237924 MAE: 1.4317471
Validation loss: 2.738005341315756 MAE: 1.4009625
Validation loss: 2.80498921627901 MAE: 1.3804208
Validation loss: 2.9066343988691057 MAE: 1.3892015
Validation loss: 3.18996922337279 MAE: 1.4470998
Validation loss: 3.2616610040470047 MAE: 1.4582994
Validation loss: 3.1160206356827094 MAE: 1.4251184
Validation loss: 3.0679781339606462 MAE: 1.4077147
Validation loss: 3.057902297195123 MAE: 1.4032869
Validation loss: 3.1005784054191743 MAE: 1.412962
Validation loss: 3.037298499321451 MAE: 1.3995892
Validation loss: 2.8150904324589945 MAE: 1.3619268
Validation loss: 2.6634569362718232 MAE: 1.3650236
Validation loss: 2.629338571003505 MAE: 1.3729349
Validation loss: 2.606804438999721 MAE: 1.3731022
Validation loss: 2.5677537626149705 MAE: 1.3562021
Validation loss: 2.5829227651868547 MAE: 1.3438299
Validation loss: 2.686367309823328 MAE: 1.3274419
Validation loss: 2.7132405456231563 MAE: 1.3074824
Validation loss: 2.6616682544046517 MAE: 1.2886633
Loaded trained model with success.
Test loss: 5.78336434509918 Test MAE: 1.934879
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 21.690746307373047
Validation loss: 8.170411831200726 MAE: 2.301059
Validation loss: 6.553123746255432 MAE: 2.1456633
Validation loss: 11.508084277914028 MAE: 2.8623238
Validation loss: 14.327656533983019 MAE: 3.237285
Validation loss: 12.549455006917318 MAE: 2.9734015
Validation loss: 10.771423927461258 MAE: 2.731868
Validation loss: 8.904600417975223 MAE: 2.4883437
Validation loss: 7.9047743961064505 MAE: 2.3593447
Validation loss: 9.079185071617665 MAE: 2.5116503
Validation loss: 12.163091447618273 MAE: 2.9189541
Validation loss: 8.271493141097253 MAE: 2.4016206
Validation loss: 5.303469966156314 MAE: 1.9032105
12 2 6.827126502990723
Validation loss: 5.220098360620364 MAE: 1.9003428
Validation loss: 5.619762613315775 MAE: 1.9534049
Validation loss: 6.005827894114485 MAE: 2.0253727
Validation loss: 5.967222396773521 MAE: 2.0519211
Validation loss: 5.960834233447759 MAE: 2.065094
Validation loss: 5.870193380298036 MAE: 2.046703
Validation loss: 5.742455752208979 MAE: 2.0130055
Validation loss: 5.742791462426234 MAE: 1.9909467
Validation loss: 5.958364173619434 MAE: 2.0077164
Validation loss: 6.339800064009849 MAE: 2.0611584
Validation loss: 6.466063904039787 MAE: 2.0748389
Validation loss: 6.5037376374909375 MAE: 2.085
Validation loss: 6.35487503475613 MAE: 2.0703
25 0 4.743403434753418
Validation loss: 5.892898130898524 MAE: 2.0058458
Validation loss: 5.610675768418745 MAE: 1.9762372
Validation loss: 5.664110202981968 MAE: 1.9864886
Validation loss: 5.639158692022766 MAE: 1.9931507
Validation loss: 5.671058040676695 MAE: 1.998673
Validation loss: 5.815229830115732 MAE: 2.0110917
Validation loss: 5.8234628282412135 MAE: 2.0091608
Validation loss: 5.573651583507807 MAE: 1.9633037
Validation loss: 5.461831032627761 MAE: 1.9453937
Validation loss: 5.528170913156837 MAE: 1.9589295
Validation loss: 5.503472520847513 MAE: 1.956963
Validation loss: 5.602166683986933 MAE: 1.9752638
37 2 5.761318683624268
Validation loss: 5.65834594013715 MAE: 1.9797711
Validation loss: 5.591900603939789 MAE: 1.96753
Validation loss: 5.401591580323498 MAE: 1.9323
Validation loss: 5.478391417349227 MAE: 1.9447927
Validation loss: 5.387756843759556 MAE: 1.9284724
Validation loss: 5.425065633022424 MAE: 1.9177805
Validation loss: 5.706060274682864 MAE: 1.9601856
Validation loss: 5.8499066275779645 MAE: 1.984978
Validation loss: 5.916528932976 MAE: 1.9909443
Validation loss: 5.920090600697681 MAE: 1.9844623
Validation loss: 5.537081918331108 MAE: 1.901241
Validation loss: 5.289210967343263 MAE: 1.8497053
Validation loss: 5.2117532816800205 MAE: 1.8266282
50 0 5.357303619384766
Validation loss: 5.265127721458975 MAE: 1.8306615
Validation loss: 5.5409254690613405 MAE: 1.8831271
Validation loss: 6.157198491722647 MAE: 2.0043547
Validation loss: 6.494463747197932 MAE: 2.0557818
Validation loss: 6.521586182141545 MAE: 2.0577354
Validation loss: 6.978538089328342 MAE: 2.1192226
Validation loss: 6.357710058038885 MAE: 2.0022151
Validation loss: 5.755656020809906 MAE: 1.8843557
Validation loss: 5.474309343280214 MAE: 1.8348594
Validation loss: 5.038662298761233 MAE: 1.772545
Validation loss: 4.684333921682955 MAE: 1.7153645
Validation loss: 4.912108461062114 MAE: 1.7594649
62 2 4.6175994873046875
Validation loss: 6.010635722767223 MAE: 1.9344044
Validation loss: 6.751832993343623 MAE: 2.0606444
Validation loss: 5.573866574451177 MAE: 1.875988
Validation loss: 5.45344940339676 MAE: 1.8585533
Validation loss: 6.520880891819193 MAE: 2.036329
Validation loss: 9.32070553904832 MAE: 2.5294964
Validation loss: 11.26810223887665 MAE: 2.8438392
Validation loss: 11.290322236340455 MAE: 2.853277
Validation loss: 8.89207086659441 MAE: 2.4563475
Validation loss: 6.974805147960932 MAE: 2.1252124
Validation loss: 6.212539248996311 MAE: 2.0046299
Validation loss: 7.550149580444953 MAE: 2.2200193
Validation loss: 8.456750715621794 MAE: 2.3920836
75 0 4.585659027099609
Validation loss: 8.551565562835847 MAE: 2.4220586
Validation loss: 10.212877601084083 MAE: 2.703649
Validation loss: 12.685906130858141 MAE: 3.0756016
Validation loss: 14.472584791857788 MAE: 3.3151224
Validation loss: 15.385819849341807 MAE: 3.4348154
Validation loss: 14.121947322228943 MAE: 3.2577808
Validation loss: 11.267359102615202 MAE: 2.8430583
Validation loss: 8.858563297926777 MAE: 2.46288
Validation loss: 5.784438778655698 MAE: 1.8912958
Validation loss: 4.714061705753057 MAE: 1.6978902
Validation loss: 7.458395505192304 MAE: 2.2192662
Validation loss: 10.287900850026295 MAE: 2.7040498
87 2 4.375242710113525
Validation loss: 13.993204244459518 MAE: 3.2420247
Validation loss: 15.906505064530807 MAE: 3.492253
Validation loss: 17.55374255324855 MAE: 3.6822562
Validation loss: 13.382246903698853 MAE: 3.148264
Validation loss: 8.166844401696716 MAE: 2.3749545
Validation loss: 8.580530865023835 MAE: 2.4472182
Validation loss: 10.053840203718705 MAE: 2.689528
Validation loss: 10.688976933257749 MAE: 2.7786107
Validation loss: 7.71599981519911 MAE: 2.2786286
Validation loss: 6.161062539225877 MAE: 1.9665469
Validation loss: 6.983645586052326 MAE: 2.153612
Validation loss: 10.044954550386679 MAE: 2.6972718
Validation loss: 11.494540344585072 MAE: 2.915365
Loaded trained model with success.
Test loss: 6.491653767520774 Test MAE: 2.0149188
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 31.151487350463867
Validation loss: 5.348416191848679 MAE: 1.9328179
Validation loss: 8.822926982563345 MAE: 2.4391422
Validation loss: 7.529162459637052 MAE: 2.2724352
Validation loss: 5.243772569014199 MAE: 1.9090925
Validation loss: 5.802713247998875 MAE: 1.9986471
Validation loss: 6.53211689953828 MAE: 2.119723
Validation loss: 6.0416474294422855 MAE: 2.04337
7 1 4.740067481994629
Validation loss: 5.8648276832235515 MAE: 2.0177088
Validation loss: 7.028938013105536 MAE: 2.199213
Validation loss: 7.483411697886098 MAE: 2.2631524
Validation loss: 6.906268608630003 MAE: 2.1824777
Validation loss: 6.293010953682751 MAE: 2.0864396
Validation loss: 5.467029988466196 MAE: 1.9499342
Validation loss: 5.4466617215218855 MAE: 1.9400496
14 2 6.173925399780273
Validation loss: 5.229151383117216 MAE: 1.9085906
Validation loss: 5.189840867890784 MAE: 1.9023715
Validation loss: 5.133978846085132 MAE: 1.8824902
Validation loss: 5.063416730219395 MAE: 1.8678253
Validation loss: 5.105197434449316 MAE: 1.866793
Validation loss: 4.84914043560699 MAE: 1.817906
Validation loss: 5.163022141959799 MAE: 1.8703169
21 3 4.687134265899658
Validation loss: 5.019524181308459 MAE: 1.8480105
Validation loss: 5.212287569764871 MAE: 1.879205
Validation loss: 5.012864680745494 MAE: 1.8244923
Validation loss: 4.896754565550454 MAE: 1.801105
Validation loss: 5.613761516072643 MAE: 1.9177133
Validation loss: 4.938592755015771 MAE: 1.8200254
Validation loss: 4.12641824190341 MAE: 1.6993332
28 4 3.976513624191284
Validation loss: 3.611596567546902 MAE: 1.577369
Validation loss: 3.9074450216101644 MAE: 1.6151103
Validation loss: 3.7671945765988912 MAE: 1.5979455
Validation loss: 3.7093616598215533 MAE: 1.5968653
Validation loss: 3.6651476399982394 MAE: 1.6015503
Validation loss: 3.713888307312625 MAE: 1.6130196
Validation loss: 4.392515832455314 MAE: 1.728
35 5 3.702486276626587
Validation loss: 5.252668534091969 MAE: 1.8795636
Validation loss: 4.534623814587617 MAE: 1.7592031
Validation loss: 3.670656865565621 MAE: 1.5968953
Validation loss: 3.7348672990223872 MAE: 1.5913433
Validation loss: 3.6273844541616773 MAE: 1.5944153
Validation loss: 3.5383739004183057 MAE: 1.5490566
Validation loss: 3.184566838058395 MAE: 1.449553
42 6 2.9054393768310547
Validation loss: 3.7878055069314773 MAE: 1.598956
Validation loss: 3.312987267671518 MAE: 1.4912659
Validation loss: 3.777467141798393 MAE: 1.575541
Validation loss: 4.568379222448148 MAE: 1.7289964
Validation loss: 3.9592766570086457 MAE: 1.6040055
Validation loss: 4.35433797021607 MAE: 1.7135745
Validation loss: 3.7314726599496812 MAE: 1.6067364
Validation loss: 3.4100510735607625 MAE: 1.5236288
50 0 3.4777488708496094
Validation loss: 3.2102008105522426 MAE: 1.4791217
Validation loss: 3.5810200359354067 MAE: 1.5426934
Validation loss: 4.672728267746355 MAE: 1.7268921
Validation loss: 3.631004623731776 MAE: 1.5482193
Validation loss: 3.1259812619817917 MAE: 1.4335649
Validation loss: 3.1066850274052453 MAE: 1.4204718
Validation loss: 3.029445086292286 MAE: 1.3932602
57 1 1.743295431137085
Validation loss: 3.4162382264832156 MAE: 1.4836287
Validation loss: 3.319990852969376 MAE: 1.489778
Validation loss: 4.823206338451136 MAE: 1.7740436
Validation loss: 4.8203527711743686 MAE: 1.7803885
Validation loss: 3.9418445016870547 MAE: 1.6063049
Validation loss: 2.854955674415857 MAE: 1.3671188
Validation loss: 2.867237587070944 MAE: 1.3698354
64 2 2.169795513153076
Validation loss: 3.588264686977444 MAE: 1.5232706
Validation loss: 3.7746989951660885 MAE: 1.5695488
Validation loss: 2.874801376956192 MAE: 1.3695837
Validation loss: 2.9396424628981395 MAE: 1.3825748
Validation loss: 3.8463481586782176 MAE: 1.5524639
Validation loss: 3.550927238847742 MAE: 1.500196
Validation loss: 2.679256657859189 MAE: 1.3341542
71 3 3.6056058406829834
Validation loss: 2.8257965083098293 MAE: 1.3636254
Validation loss: 2.851838957125218 MAE: 1.3608552
Validation loss: 3.396658811137904 MAE: 1.4693213
Validation loss: 2.7945597279610945 MAE: 1.3307682
Validation loss: 2.9569810868507655 MAE: 1.3643992
Validation loss: 2.671152997855565 MAE: 1.3071282
Validation loss: 2.5708033643176207 MAE: 1.2781521
78 4 2.147467613220215
Validation loss: 2.8529361468463685 MAE: 1.3450099
Validation loss: 2.596784180432708 MAE: 1.289045
Validation loss: 2.611185258956411 MAE: 1.3081311
Validation loss: 3.269459607014105 MAE: 1.4548676
Validation loss: 3.047433015689179 MAE: 1.4000342
Validation loss: 2.9415399632861265 MAE: 1.3621768
Validation loss: 2.9611832763082417 MAE: 1.3647139
85 5 3.246424674987793
Validation loss: 2.6348200095957846 MAE: 1.2958031
Validation loss: 2.5626889227622716 MAE: 1.2838424
Validation loss: 3.5031132410519086 MAE: 1.5120409
Validation loss: 4.113574878654289 MAE: 1.6333065
Validation loss: 2.9403691687176576 MAE: 1.3576099
Validation loss: 2.5046201926379945 MAE: 1.267268
Validation loss: 2.4680279050041083 MAE: 1.2615979
92 6 1.6173124313354492
Validation loss: 2.6607710716113373 MAE: 1.2884656
Validation loss: 2.834891391758943 MAE: 1.3362998
Validation loss: 4.027533550358298 MAE: 1.606333
Validation loss: 3.903769890866687 MAE: 1.5899726
Validation loss: 3.144105102548647 MAE: 1.4120885
Validation loss: 3.50212890538738 MAE: 1.4973166
Validation loss: 3.851444628370467 MAE: 1.5983316
Validation loss: 2.8354907356314922 MAE: 1.3245567
Loaded trained model with success.
Test loss: 5.4633017032342925 Test MAE: 1.845608
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 10.131184577941895
Validation loss: 13.545774889852337 MAE: 3.1214967
Validation loss: 5.070057189536238 MAE: 1.8761796
Validation loss: 5.254463181466999 MAE: 1.910736
3 2 5.394050598144531
Validation loss: 5.493538701701499 MAE: 1.9635506
Validation loss: 6.255253205079593 MAE: 2.0386407
Validation loss: 5.1557714752778265 MAE: 1.8655872
6 4 5.896432876586914
Validation loss: 5.502995455671169 MAE: 1.9177836
Validation loss: 6.213218058278422 MAE: 2.0197546
Validation loss: 5.584102084020335 MAE: 1.9071103
9 6 4.133413314819336
Validation loss: 7.097145353863856 MAE: 2.1332316
Validation loss: 4.752457337293452 MAE: 1.7879466
Validation loss: 4.414254842158071 MAE: 1.7025974
12 8 4.312960624694824
Validation loss: 5.009632602722229 MAE: 1.7907836
Validation loss: 4.988594487100421 MAE: 1.7951158
Validation loss: 7.658499151050209 MAE: 2.2089658
15 10 5.825551986694336
Validation loss: 6.694960196653684 MAE: 2.0603354
Validation loss: 6.929376692953473 MAE: 2.094746
Validation loss: 4.334170164708384 MAE: 1.6681571
18 12 5.7099809646606445
Validation loss: 4.806368049017652 MAE: 1.7789088
Validation loss: 3.858165424190208 MAE: 1.6154087
Validation loss: 3.8058275975779683 MAE: 1.628173
21 14 3.858029365539551
Validation loss: 5.091502771587792 MAE: 1.8012232
Validation loss: 5.614444570694276 MAE: 1.9019305
Validation loss: 5.835795659101559 MAE: 1.9433577
Validation loss: 4.024874184556857 MAE: 1.6184801
25 0 3.6574361324310303
Validation loss: 6.757947130528146 MAE: 2.0878882
Validation loss: 6.1721619078534875 MAE: 1.9992448
Validation loss: 5.188521926054257 MAE: 1.8320066
28 2 4.13953971862793
Validation loss: 5.347103118896484 MAE: 1.8255101
Validation loss: 5.709524599965923 MAE: 1.8978938
Validation loss: 5.116361491904708 MAE: 1.8108842
31 4 4.071671962738037
Validation loss: 4.59409292284138 MAE: 1.695542
Validation loss: 4.995868928446798 MAE: 1.7646786
Validation loss: 4.327506607185624 MAE: 1.67297
34 6 3.2866897583007812
Validation loss: 5.095835760265649 MAE: 1.7995744
Validation loss: 5.579644073226409 MAE: 1.8923919
Validation loss: 5.510249949170497 MAE: 1.8625892
37 8 3.5944390296936035
Validation loss: 6.350722432375432 MAE: 2.0191233
Validation loss: 4.205319875705696 MAE: 1.6551858
Validation loss: 4.659864930208317 MAE: 1.7180693
40 10 3.0332627296447754
Validation loss: 4.837268457622948 MAE: 1.7525706
Validation loss: 3.730396384944419 MAE: 1.558684
Validation loss: 4.244124844461261 MAE: 1.6441926
43 12 3.701923131942749
Validation loss: 4.299320967259531 MAE: 1.6574382
Validation loss: 3.9283709965631335 MAE: 1.5901806
Validation loss: 5.481234861041358 MAE: 1.8706601
46 14 3.663480758666992
Validation loss: 4.617471909475231 MAE: 1.7153406
Validation loss: 4.501121734091657 MAE: 1.7094914
Validation loss: 3.92610147338592 MAE: 1.585521
Validation loss: 3.5807003239113726 MAE: 1.5272654
50 0 4.3994140625
Validation loss: 4.866085527416222 MAE: 1.7677205
Validation loss: 3.995740325274114 MAE: 1.609172
Validation loss: 3.586366845037273 MAE: 1.5284479
53 2 4.532105445861816
Validation loss: 3.7227399834172283 MAE: 1.5564384
Validation loss: 3.4609689062726283 MAE: 1.5123291
Validation loss: 4.305005482537952 MAE: 1.6452852
56 4 2.816141366958618
Validation loss: 3.302697437798571 MAE: 1.4678391
Validation loss: 3.6464149650925384 MAE: 1.5485624
Validation loss: 3.1944585257398344 MAE: 1.452317
59 6 3.7276766300201416
Validation loss: 3.978683322130559 MAE: 1.6188512
Validation loss: 3.0298734174701636 MAE: 1.4294548
Validation loss: 3.410944767132073 MAE: 1.5023628
62 8 3.5432345867156982
Validation loss: 2.9793863645297494 MAE: 1.4028449
Validation loss: 3.6546191595838162 MAE: 1.5430492
Validation loss: 3.0903239266905853 MAE: 1.4136273
65 10 2.8390045166015625
Validation loss: 3.024445889230243 MAE: 1.4001075
Validation loss: 3.1976276671958113 MAE: 1.4371252
Validation loss: 3.4366748261308384 MAE: 1.4809722
68 12 3.7467074394226074
Validation loss: 3.519804194838346 MAE: 1.497232
Validation loss: 3.7034523190859563 MAE: 1.5298069
Validation loss: 3.024539682334793 MAE: 1.4010152
71 14 4.6393513679504395
Validation loss: 3.4766494363008853 MAE: 1.506974
Validation loss: 3.6225663760382094 MAE: 1.5035691
Validation loss: 2.922931317575948 MAE: 1.3846858
Validation loss: 2.9625428496955153 MAE: 1.4028697
75 0 2.1425905227661133
Validation loss: 3.131923007582854 MAE: 1.4260771
Validation loss: 3.356325432389437 MAE: 1.454302
Validation loss: 2.8698216358979862 MAE: 1.3822159
78 2 3.57645320892334
Validation loss: 3.3786074097505314 MAE: 1.4782774
Validation loss: 4.297169335141688 MAE: 1.6532298
Validation loss: 2.920750371917694 MAE: 1.3898187
81 4 5.18395471572876
Validation loss: 3.5409366109805975 MAE: 1.5012301
Validation loss: 2.8281081341550443 MAE: 1.342542
Validation loss: 3.026016197128143 MAE: 1.404039
84 6 3.40630841255188
Validation loss: 2.8855122158188142 MAE: 1.367221
Validation loss: 2.7339718098153094 MAE: 1.3475595
Validation loss: 3.0244832301665405 MAE: 1.3953521
87 8 3.137493371963501
Validation loss: 2.781850581656477 MAE: 1.3531545
Validation loss: 2.7257212402825366 MAE: 1.3209691
Validation loss: 2.822062610385413 MAE: 1.360633
90 10 3.36735200881958
Validation loss: 2.7372003174974826 MAE: 1.3284506
Validation loss: 2.989969097301812 MAE: 1.3809083
Validation loss: 2.700038651187339 MAE: 1.3152521
93 12 2.9115378856658936
Validation loss: 2.6684076723928203 MAE: 1.2966024
Validation loss: 3.0644122589088396 MAE: 1.4184468
Validation loss: 2.612116494971908 MAE: 1.3006476
96 14 3.219125747680664
Validation loss: 2.6135089158534046 MAE: 1.2945979
Validation loss: 2.8028889361746563 MAE: 1.3449763
Validation loss: 2.684387063693427 MAE: 1.2986007
Validation loss: 3.2857683488505636 MAE: 1.4477946
Loaded trained model with success.
Test loss: 4.382216603460918 Test MAE: 1.6739367
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999848297979177, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 659177
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999241489895887, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 659137
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9998482979791774, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 659087
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9996965959583548, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 658987
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9992414898958869, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 658687
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9984829797917738, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 999, Valid size: 999, Test size: 658187
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9751861042183623, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 380
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9503722084367245, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 19, Valid size: 19, Test size: 370
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8759305210918115, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 48, Valid size: 48, Test size: 341
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7518610421836228, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 96, Valid size: 96, Test size: 293
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5037220843672456, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 193, Valid size: 193, Test size: 196
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 589
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 549
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 499
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 99
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 18.36817169189453
Validation loss: 13.513571739196777 MAE: 3.1835694
Validation loss: 10.04985523223877 MAE: 2.81753
Validation loss: 7.3161468505859375 MAE: 2.4277508
Validation loss: 5.48809289932251 MAE: 2.0130625
Validation loss: 4.771097183227539 MAE: 1.7519491
Validation loss: 5.263552188873291 MAE: 1.8078916
Validation loss: 7.165919780731201 MAE: 2.0886984
Validation loss: 10.28757095336914 MAE: 2.5529175
Validation loss: 14.806625366210938 MAE: 3.1898499
Validation loss: 20.763702392578125 MAE: 4.001132
Validation loss: 27.281099319458008 MAE: 4.746687
Validation loss: 33.21480178833008 MAE: 5.335709
Validation loss: 37.83822250366211 MAE: 5.7530923
Validation loss: 42.34800720214844 MAE: 6.133074
Validation loss: 43.28253173828125 MAE: 6.2096043
Validation loss: 40.76995849609375 MAE: 6.0044184
Validation loss: 36.683433532714844 MAE: 5.653257
Validation loss: 33.29032897949219 MAE: 5.3436007
Validation loss: 29.773582458496094 MAE: 5.0018163
Validation loss: 25.774538040161133 MAE: 4.5835643
Validation loss: 21.066682815551758 MAE: 4.0694666
Validation loss: 17.356048583984375 MAE: 3.6161084
Validation loss: 13.776725769042969 MAE: 3.1162703
Validation loss: 9.679988861083984 MAE: 2.4778886
Validation loss: 6.974298477172852 MAE: 2.0874083
Validation loss: 5.441802501678467 MAE: 1.9405373
Validation loss: 4.091894626617432 MAE: 1.7643028
Validation loss: 3.5655953884124756 MAE: 1.6542513
Validation loss: 3.529313325881958 MAE: 1.642125
Validation loss: 3.3315374851226807 MAE: 1.6223986
Validation loss: 3.239985227584839 MAE: 1.5959358
Validation loss: 3.392489194869995 MAE: 1.5456187
Validation loss: 3.55112886428833 MAE: 1.5647509
Validation loss: 3.6421940326690674 MAE: 1.598633
Validation loss: 4.0057053565979 MAE: 1.680116
Validation loss: 4.456830978393555 MAE: 1.8334639
Validation loss: 4.860166549682617 MAE: 1.9626865
Validation loss: 5.063986301422119 MAE: 2.0198221
Validation loss: 5.251010417938232 MAE: 2.0665512
Validation loss: 5.29142951965332 MAE: 2.0765774
Validation loss: 5.490419387817383 MAE: 2.1212635
Validation loss: 5.608479022979736 MAE: 2.1471472
Validation loss: 5.839232444763184 MAE: 2.193221
Validation loss: 6.2254204750061035 MAE: 2.267093
Validation loss: 6.295919895172119 MAE: 2.2782445
Validation loss: 6.37208890914917 MAE: 2.2900217
Validation loss: 6.553917407989502 MAE: 2.3216329
Validation loss: 6.671266078948975 MAE: 2.3404577
Validation loss: 6.81988000869751 MAE: 2.36368
Validation loss: 6.903642654418945 MAE: 2.376186
50 0 2.9867470264434814
Validation loss: 6.910030841827393 MAE: 2.373911
Validation loss: 6.918485641479492 MAE: 2.3721418
Validation loss: 6.872280120849609 MAE: 2.359867
Validation loss: 6.890560626983643 MAE: 2.3603106
Validation loss: 6.988516330718994 MAE: 2.374527
Validation loss: 6.97365665435791 MAE: 2.3678753
Validation loss: 6.84284782409668 MAE: 2.3421125
Validation loss: 6.612372398376465 MAE: 2.296387
Validation loss: 6.417235374450684 MAE: 2.2547288
Validation loss: 6.249428749084473 MAE: 2.217349
Validation loss: 6.213595867156982 MAE: 2.203668
Validation loss: 5.904421329498291 MAE: 2.139246
Validation loss: 5.621093273162842 MAE: 2.077653
Validation loss: 5.358238220214844 MAE: 2.017253
Validation loss: 5.064438819885254 MAE: 1.945643
Validation loss: 4.711756706237793 MAE: 1.8579946
Validation loss: 4.490647792816162 MAE: 1.7930436
Validation loss: 4.4383463859558105 MAE: 1.7638556
Validation loss: 4.283339977264404 MAE: 1.7103631
Validation loss: 4.078558921813965 MAE: 1.6386161
Validation loss: 4.08824348449707 MAE: 1.6221921
Validation loss: 4.239504814147949 MAE: 1.6452156
Validation loss: 4.362854957580566 MAE: 1.6556582
Validation loss: 4.409086227416992 MAE: 1.6441896
Validation loss: 4.5168070793151855 MAE: 1.6394137
Validation loss: 4.645288944244385 MAE: 1.6653991
Validation loss: 4.864816665649414 MAE: 1.7272239
Validation loss: 5.09153413772583 MAE: 1.8119545
Validation loss: 5.19037389755249 MAE: 1.8650594
Validation loss: 5.588318824768066 MAE: 1.9731783
Validation loss: 5.614849090576172 MAE: 2.0080926
Validation loss: 5.774445056915283 MAE: 2.0667825
Validation loss: 6.11298131942749 MAE: 2.1504717
Validation loss: 6.445356369018555 MAE: 2.2286856
Validation loss: 6.680727481842041 MAE: 2.2838702
Validation loss: 6.877536296844482 MAE: 2.3313692
Validation loss: 7.384108543395996 MAE: 2.4179444
Validation loss: 7.188446044921875 MAE: 2.3925617
Validation loss: 7.169713497161865 MAE: 2.394353
Validation loss: 6.962529182434082 MAE: 2.370424
Validation loss: 6.392311096191406 MAE: 2.2686462
Validation loss: 5.955809116363525 MAE: 2.194791
Validation loss: 5.597259044647217 MAE: 2.1380482
Validation loss: 5.260408878326416 MAE: 2.083778
Validation loss: 4.760690689086914 MAE: 1.9802661
Validation loss: 4.220478534698486 MAE: 1.8572326
Validation loss: 4.0314154624938965 MAE: 1.8174624
Validation loss: 3.8301734924316406 MAE: 1.7738996
Validation loss: 3.4788944721221924 MAE: 1.683742
Validation loss: 3.3912415504455566 MAE: 1.6691905
Loaded trained model with success.
Test loss: 6.367530205670525 Test MAE: 2.0472488
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 20.03925132751465
Validation loss: 13.932894083918358 MAE: 3.0650494
Validation loss: 7.747653202134735 MAE: 2.2380278
Validation loss: 5.252840470294563 MAE: 1.9034019
Validation loss: 7.314707561415069 MAE: 2.277073
Validation loss: 14.325274486931002 MAE: 3.244456
Validation loss: 22.702526579097825 MAE: 4.210523
Validation loss: 26.719511109955455 MAE: 4.656146
Validation loss: 26.65138073356784 MAE: 4.642575
Validation loss: 19.40583065577916 MAE: 3.8343306
Validation loss: 12.592843717458297 MAE: 3.0270445
Validation loss: 8.165633785481356 MAE: 2.4188838
Validation loss: 6.047352333458102 MAE: 2.0729036
Validation loss: 5.222378146891692 MAE: 1.9128132
Validation loss: 5.0348762590058 MAE: 1.8618664
Validation loss: 5.108694261434127 MAE: 1.869465
Validation loss: 5.198983143786995 MAE: 1.8848612
Validation loss: 5.270524336367237 MAE: 1.8958215
Validation loss: 5.274360841634322 MAE: 1.8969611
Validation loss: 5.251492928485481 MAE: 1.8909918
Validation loss: 5.2340951160508755 MAE: 1.8899064
Validation loss: 5.213908039793676 MAE: 1.8921092
Validation loss: 5.226702665796085 MAE: 1.8966762
Validation loss: 5.216752675114845 MAE: 1.8946079
Validation loss: 5.205333748642279 MAE: 1.8909165
Validation loss: 5.124726733382867 MAE: 1.8716768
25 0 5.155651092529297
Validation loss: 5.048062207747479 MAE: 1.8628254
Validation loss: 5.064524261318907 MAE: 1.8669866
Validation loss: 5.128286799606012 MAE: 1.877194
Validation loss: 5.207175284015889 MAE: 1.8868912
Validation loss: 5.280074995391223 MAE: 1.8951249
Validation loss: 5.330083652418487 MAE: 1.9022182
Validation loss: 5.326015423755257 MAE: 1.9010684
Validation loss: 5.295049317029058 MAE: 1.8964697
Validation loss: 5.258275557537468 MAE: 1.8905668
Validation loss: 5.241823790024738 MAE: 1.8858602
Validation loss: 5.2130754626527125 MAE: 1.8779563
Validation loss: 5.184632680854019 MAE: 1.8721105
Validation loss: 5.130587023131701 MAE: 1.8642149
Validation loss: 5.066942322010896 MAE: 1.8544621
Validation loss: 5.03248727564909 MAE: 1.8483974
Validation loss: 5.007832838564503 MAE: 1.8457692
Validation loss: 4.986490794590542 MAE: 1.8462925
Validation loss: 4.990348699141522 MAE: 1.8474199
Validation loss: 4.9825951809785805 MAE: 1.849476
Validation loss: 4.987603080515959 MAE: 1.8509206
Validation loss: 4.973178766211685 MAE: 1.8490052
Validation loss: 4.852268987772416 MAE: 1.8298712
Validation loss: 4.703310908103476 MAE: 1.8077351
Validation loss: 4.573401159169722 MAE: 1.7908591
Validation loss: 4.484251878699478 MAE: 1.7818456
50 0 3.5860493183135986
Validation loss: 4.398772054789018 MAE: 1.7694142
Validation loss: 4.324303179371114 MAE: 1.7577063
Validation loss: 4.272126402173724 MAE: 1.743877
Validation loss: 4.180324622562954 MAE: 1.7230341
Validation loss: 4.117192039684373 MAE: 1.7046189
Validation loss: 4.0609094658676455 MAE: 1.686799
Validation loss: 3.9574416802853953 MAE: 1.6650593
Validation loss: 3.8815248207170137 MAE: 1.6530584
Validation loss: 3.761501253867636 MAE: 1.6361359
Validation loss: 3.6653678660490074 MAE: 1.6215093
Validation loss: 3.5940282831386643 MAE: 1.6161286
Validation loss: 3.51549844839135 MAE: 1.6038082
Validation loss: 3.3654286618135414 MAE: 1.5778532
Validation loss: 3.232211784440644 MAE: 1.5418453
Validation loss: 3.1365974144059785 MAE: 1.5107749
Validation loss: 3.2266890126831678 MAE: 1.526676
Validation loss: 3.391852378845215 MAE: 1.5452383
Validation loss: 3.6894918169294084 MAE: 1.574917
Validation loss: 3.89990065049152 MAE: 1.6101543
Validation loss: 4.029625264965758 MAE: 1.6311524
Validation loss: 4.0066516107442425 MAE: 1.6316631
Validation loss: 3.8012230834182428 MAE: 1.5944209
Validation loss: 3.5635556493486678 MAE: 1.5529383
Validation loss: 3.252731955781275 MAE: 1.4994553
Validation loss: 3.0977336922470404 MAE: 1.4888818
75 0 2.4936702251434326
Validation loss: 3.1186454879994296 MAE: 1.5048403
Validation loss: 2.9437497878561216 MAE: 1.4639649
Validation loss: 2.94643479950574 MAE: 1.4598342
Validation loss: 3.0428402764456615 MAE: 1.479098
Validation loss: 2.9309230872562955 MAE: 1.4586817
Validation loss: 2.8491301487903207 MAE: 1.4385936
Validation loss: 2.7271547025563767 MAE: 1.4047012
Validation loss: 2.678465877260481 MAE: 1.3835766
Validation loss: 2.5113585773779423 MAE: 1.3506136
Validation loss: 2.525002581732614 MAE: 1.3455517
Validation loss: 2.743469539953738 MAE: 1.3853779
Validation loss: 2.892334908855205 MAE: 1.4071614
Validation loss: 3.071759822417279 MAE: 1.4404345
Validation loss: 3.2028261690723654 MAE: 1.4723954
Validation loss: 3.264179521677445 MAE: 1.4838969
Validation loss: 3.1584905750897465 MAE: 1.4588186
Validation loss: 2.9086006076968447 MAE: 1.3909237
Validation loss: 2.634857644840163 MAE: 1.3402121
Validation loss: 2.531882193623757 MAE: 1.3179667
Validation loss: 2.4440939134481003 MAE: 1.2843059
Validation loss: 2.4506964488905303 MAE: 1.2892157
Validation loss: 2.4220517606151346 MAE: 1.286332
Validation loss: 2.4049336885919375 MAE: 1.2911524
Validation loss: 2.4752096886537513 MAE: 1.3085841
Validation loss: 2.7387870039258684 MAE: 1.3547158
Loaded trained model with success.
Test loss: 6.441828654922602 Test MAE: 1.990732
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 18.39017105102539
Validation loss: 8.770951955005376 MAE: 2.4097278
Validation loss: 6.852390173709754 MAE: 2.1453342
Validation loss: 15.50580712520715 MAE: 3.327847
Validation loss: 19.428197244201044 MAE: 3.8127453
Validation loss: 21.96858716251874 MAE: 4.1279283
Validation loss: 14.06370510717835 MAE: 3.1458864
Validation loss: 8.117027330880214 MAE: 2.3111787
Validation loss: 5.9380245545897825 MAE: 1.9651604
Validation loss: 5.747384596352625 MAE: 1.9644207
Validation loss: 5.837485000340625 MAE: 1.9865342
Validation loss: 5.580572202952221 MAE: 1.9535812
Validation loss: 5.628777585848414 MAE: 1.9906739
12 2 7.795391082763672
Validation loss: 6.160107740248092 MAE: 2.0622118
Validation loss: 6.321815269161957 MAE: 2.0831745
Validation loss: 5.900914278897372 MAE: 2.0246952
Validation loss: 5.677618262743709 MAE: 1.9930525
Validation loss: 5.452055637282554 MAE: 1.9605224
Validation loss: 5.386765316279248 MAE: 1.9480122
Validation loss: 5.49899514034541 MAE: 1.9673226
Validation loss: 5.584031076142282 MAE: 1.9807267
Validation loss: 5.802100807729394 MAE: 2.022333
Validation loss: 5.775869622375026 MAE: 2.0190501
Validation loss: 5.879311453212392 MAE: 2.0324898
Validation loss: 5.597944171741755 MAE: 1.9837747
Validation loss: 5.320289043465046 MAE: 1.929035
25 0 5.905118942260742
Validation loss: 5.383977641962995 MAE: 1.9378763
Validation loss: 5.365586707086274 MAE: 1.9313447
Validation loss: 5.608416769239637 MAE: 1.9707985
Validation loss: 5.786274303089488 MAE: 2.0025275
Validation loss: 5.745926175454651 MAE: 1.9964774
Validation loss: 5.536858871729687 MAE: 1.9618435
Validation loss: 5.227415513510656 MAE: 1.9088913
Validation loss: 4.903904192375414 MAE: 1.8464277
Validation loss: 4.742034394331653 MAE: 1.8021377
Validation loss: 4.691398042621034 MAE: 1.7782072
Validation loss: 4.605730292773006 MAE: 1.7627549
Validation loss: 4.540053761366642 MAE: 1.7531027
37 2 6.039199352264404
Validation loss: 4.470357732339338 MAE: 1.7526546
Validation loss: 4.456800133290917 MAE: 1.7437491
Validation loss: 4.548686085325299 MAE: 1.7519141
Validation loss: 5.287307476756548 MAE: 1.8870232
Validation loss: 5.1140915022956 MAE: 1.8582684
Validation loss: 4.241814639833239 MAE: 1.6791703
Validation loss: 4.098828111032043 MAE: 1.6380457
Validation loss: 3.9749508722864015 MAE: 1.643661
Validation loss: 3.9785241382290617 MAE: 1.6494062
Validation loss: 3.894824748087411 MAE: 1.6075377
Validation loss: 4.131042547900267 MAE: 1.6413875
Validation loss: 3.767304955106793 MAE: 1.5739934
Validation loss: 3.5038185414641796 MAE: 1.5106828
50 0 4.765742778778076
Validation loss: 5.222007356508814 MAE: 1.835486
Validation loss: 5.109321166770627 MAE: 1.8162112
Validation loss: 4.926523584308046 MAE: 1.7862175
Validation loss: 4.186215605398621 MAE: 1.6473819
Validation loss: 3.6991815952339557 MAE: 1.548482
Validation loss: 3.321995056036747 MAE: 1.4842292
Validation loss: 3.4768170443448154 MAE: 1.5488836
Validation loss: 3.978276992085004 MAE: 1.6389732
Validation loss: 4.019595680814801 MAE: 1.6409942
Validation loss: 3.576323234673702 MAE: 1.5561024
Validation loss: 3.338349121989626 MAE: 1.5077089
Validation loss: 3.1207535435455016 MAE: 1.447797
62 2 3.594953775405884
Validation loss: 3.061584457002505 MAE: 1.3998044
Validation loss: 3.1002369480903704 MAE: 1.3967334
Validation loss: 3.1308153446274574 MAE: 1.4104637
Validation loss: 3.0246466410280477 MAE: 1.3928406
Validation loss: 3.0413962614656698 MAE: 1.4129611
Validation loss: 3.6782351346931073 MAE: 1.5619375
Validation loss: 3.9968875375660984 MAE: 1.635359
Validation loss: 3.238089547614859 MAE: 1.4792365
Validation loss: 2.9802084450769906 MAE: 1.4042625
Validation loss: 3.1506450019701564 MAE: 1.460249
Validation loss: 2.956755279290556 MAE: 1.4068902
Validation loss: 3.0004580550723605 MAE: 1.4202743
Validation loss: 3.0162868018102165 MAE: 1.423289
75 0 1.560537576675415
Validation loss: 2.975671078219558 MAE: 1.4140044
Validation loss: 2.9294628278173582 MAE: 1.407043
Validation loss: 2.8574417383983883 MAE: 1.3856869
Validation loss: 2.8537613767566103 MAE: 1.3721839
Validation loss: 2.694897508380389 MAE: 1.323613
Validation loss: 2.6644133353474166 MAE: 1.3178844
Validation loss: 2.573756627362184 MAE: 1.2910562
Validation loss: 3.0436257930717083 MAE: 1.4025022
Validation loss: 3.7889425306007114 MAE: 1.5657579
Validation loss: 3.8589915013072464 MAE: 1.5858892
Validation loss: 3.9902988250809486 MAE: 1.6144739
Validation loss: 5.1953916308855765 MAE: 1.8771837
87 2 3.6510326862335205
Validation loss: 6.321772554908136 MAE: 2.1075275
Validation loss: 6.0665269235167845 MAE: 2.0607967
Validation loss: 5.24909156741518 MAE: 1.8953913
Validation loss: 5.1113777738628965 MAE: 1.8783774
Validation loss: 4.601502281246764 MAE: 1.7727536
Validation loss: 3.612904110340157 MAE: 1.5559182
Validation loss: 2.892035166422526 MAE: 1.3833585
Validation loss: 2.5514460428796633 MAE: 1.2761178
Validation loss: 3.2043239504399925 MAE: 1.4192611
Validation loss: 4.899663862555918 MAE: 1.8276582
Validation loss: 6.975937631395128 MAE: 2.2401028
Validation loss: 8.937877240807119 MAE: 2.5645928
Validation loss: 7.061006912077316 MAE: 2.2297928
Loaded trained model with success.
Test loss: 5.9112391686869525 Test MAE: 1.9277838
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 22.770845413208008
Validation loss: 5.303091384657663 MAE: 1.9319335
Validation loss: 16.342020504438697 MAE: 3.4853892
Validation loss: 7.443450180130388 MAE: 2.2415323
Validation loss: 5.123427849918155 MAE: 1.9140787
Validation loss: 5.097125257079925 MAE: 1.9093361
Validation loss: 5.173672988187128 MAE: 1.923207
Validation loss: 5.224335990359435 MAE: 1.9305638
7 1 3.7391347885131836
Validation loss: 5.169597652090255 MAE: 1.9271599
Validation loss: 5.1888405749546225 MAE: 1.928945
Validation loss: 5.326668198983274 MAE: 1.946741
Validation loss: 5.376316142441639 MAE: 1.9540609
Validation loss: 5.36601208921653 MAE: 1.9529097
Validation loss: 5.266615999403911 MAE: 1.9405751
Validation loss: 5.219384758915734 MAE: 1.9333652
14 2 5.258976936340332
Validation loss: 5.231843847725259 MAE: 1.9343461
Validation loss: 5.2267824800769285 MAE: 1.9298512
Validation loss: 5.1934919501069805 MAE: 1.9180157
Validation loss: 5.33578896881947 MAE: 1.9269468
Validation loss: 4.909207799326834 MAE: 1.8741502
Validation loss: 4.945980285280314 MAE: 1.8670499
Validation loss: 4.822487142217819 MAE: 1.8419585
21 3 3.53590726852417
Validation loss: 4.596469805468267 MAE: 1.8038046
Validation loss: 4.635201040823855 MAE: 1.8004476
Validation loss: 4.798112586515034 MAE: 1.8172617
Validation loss: 4.59569318809701 MAE: 1.7885128
Validation loss: 4.309689060527476 MAE: 1.726723
Validation loss: 4.135650971427036 MAE: 1.6932849
Validation loss: 4.185294212408401 MAE: 1.7158443
28 4 3.7423975467681885
Validation loss: 4.212917160149195 MAE: 1.7088734
Validation loss: 4.530076177875001 MAE: 1.768455
Validation loss: 5.424476520499992 MAE: 1.9115607
Validation loss: 3.894668047152572 MAE: 1.6461802
Validation loss: 3.9966212780631367 MAE: 1.6634338
Validation loss: 5.073990900911878 MAE: 1.8423913
Validation loss: 3.8688972631291527 MAE: 1.6429844
35 5 6.5169501304626465
Validation loss: 3.791703570428206 MAE: 1.6279746
Validation loss: 3.878764048892649 MAE: 1.658329
Validation loss: 3.909998847911106 MAE: 1.6660926
Validation loss: 3.829486232307089 MAE: 1.6436114
Validation loss: 3.872594346952199 MAE: 1.6531596
Validation loss: 3.4944902520682946 MAE: 1.5408868
Validation loss: 3.4725081393467123 MAE: 1.5419034
42 6 4.290004253387451
Validation loss: 3.5434916929983014 MAE: 1.5649688
Validation loss: 3.643771619652983 MAE: 1.5837114
Validation loss: 4.325396770208925 MAE: 1.7149097
Validation loss: 3.6906223824275797 MAE: 1.5680248
Validation loss: 3.452338608066041 MAE: 1.5442992
Validation loss: 3.5218435543865416 MAE: 1.5670422
Validation loss: 3.4511316595365056 MAE: 1.5265144
Validation loss: 3.343042824136552 MAE: 1.504359
50 0 4.627730846405029
Validation loss: 3.3309300664681287 MAE: 1.4952664
Validation loss: 3.3158710817595822 MAE: 1.4960674
Validation loss: 3.375956192687528 MAE: 1.5114231
Validation loss: 3.589295503482148 MAE: 1.580514
Validation loss: 3.678572764947786 MAE: 1.5488256
Validation loss: 3.3894116866528687 MAE: 1.4914207
Validation loss: 3.2727323536896824 MAE: 1.4913377
57 1 3.512218713760376
Validation loss: 3.257302463354178 MAE: 1.4743465
Validation loss: 3.199469085913807 MAE: 1.4639914
Validation loss: 3.613216882974059 MAE: 1.5836471
Validation loss: 3.2766083341148033 MAE: 1.4961836
Validation loss: 3.1331197718280044 MAE: 1.4523643
Validation loss: 3.06165434128076 MAE: 1.4162586
Validation loss: 3.0819280494996653 MAE: 1.4387971
64 2 2.907991647720337
Validation loss: 3.051121255261215 MAE: 1.4360849
Validation loss: 2.997291447529242 MAE: 1.4069198
Validation loss: 3.032877931642772 MAE: 1.4029903
Validation loss: 3.3271081639294646 MAE: 1.4955564
Validation loss: 3.1449446306755795 MAE: 1.4500693
Validation loss: 3.2275894802419383 MAE: 1.4686046
Validation loss: 3.501724275512312 MAE: 1.5371896
71 3 3.64028263092041
Validation loss: 2.9442850477132367 MAE: 1.3806232
Validation loss: 3.018062402255571 MAE: 1.4221609
Validation loss: 3.7202949344213283 MAE: 1.5973308
Validation loss: 3.2082612628313765 MAE: 1.4569834
Validation loss: 3.0306978417401336 MAE: 1.3983964
Validation loss: 3.0830386236085365 MAE: 1.450493
Validation loss: 2.8213217833533357 MAE: 1.3735147
78 4 4.426981449127197
Validation loss: 2.8264994956740184 MAE: 1.3705819
Validation loss: 3.079214837682906 MAE: 1.4310777
Validation loss: 3.109473931729494 MAE: 1.4177271
Validation loss: 2.885058818750046 MAE: 1.3907895
Validation loss: 3.0053064667399805 MAE: 1.4214083
Validation loss: 2.578935431475615 MAE: 1.2984709
Validation loss: 2.669541160664966 MAE: 1.3206741
85 5 2.698331832885742
Validation loss: 2.700624496493507 MAE: 1.3288319
Validation loss: 2.619431845506831 MAE: 1.3246518
Validation loss: 2.690344883568922 MAE: 1.3330233
Validation loss: 2.5901709423592343 MAE: 1.291401
Validation loss: 2.6003599861758437 MAE: 1.3085719
Validation loss: 2.7222227055822783 MAE: 1.3305054
Validation loss: 3.1388459025914943 MAE: 1.4422611
92 6 4.159871578216553
Validation loss: 3.570261738408151 MAE: 1.5437595
Validation loss: 3.303004022818714 MAE: 1.4559342
Validation loss: 3.200983033108352 MAE: 1.4515659
Validation loss: 2.945099328630534 MAE: 1.4063629
Validation loss: 2.6881663811266723 MAE: 1.3223263
Validation loss: 2.6042146634815926 MAE: 1.2985183
Validation loss: 2.5103737014022904 MAE: 1.2673897
Validation loss: 2.643167788059867 MAE: 1.3290106
Loaded trained model with success.
Test loss: 4.662417828771213 Test MAE: 1.7451091
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 30.787372589111328
Validation loss: 21.986708673542154 MAE: 4.1692915
Validation loss: 5.2394089918576165 MAE: 1.913779
Validation loss: 5.348108590724234 MAE: 1.9372363
3 2 4.603123664855957
Validation loss: 5.514444513645822 MAE: 1.9666218
Validation loss: 5.418928000157725 MAE: 1.951417
Validation loss: 5.4047005133542845 MAE: 1.9342837
6 4 6.0038676261901855
Validation loss: 5.342335592052024 MAE: 1.9216683
Validation loss: 5.322877358339115 MAE: 1.9049759
Validation loss: 4.588318777466585 MAE: 1.7909696
9 6 6.046236991882324
Validation loss: 4.233043980741788 MAE: 1.7058182
Validation loss: 4.842240998644628 MAE: 1.7965643
Validation loss: 4.150335999911199 MAE: 1.6819087
12 8 4.544493675231934
Validation loss: 3.9814791354483257 MAE: 1.6478034
Validation loss: 3.9908820899550568 MAE: 1.6533369
Validation loss: 4.011759061373785 MAE: 1.6474526
15 10 4.551551342010498
Validation loss: 4.007375577647605 MAE: 1.649794
Validation loss: 4.0238423357029 MAE: 1.6391144
Validation loss: 4.343017100332256 MAE: 1.7013791
18 12 4.314966201782227
Validation loss: 3.757575364772208 MAE: 1.5801114
Validation loss: 4.008764789673035 MAE: 1.6233319
Validation loss: 3.8714733367453595 MAE: 1.6166097
21 14 2.8018178939819336
Validation loss: 3.7442080740460413 MAE: 1.5846305
Validation loss: 4.82636215166004 MAE: 1.7789986
Validation loss: 3.6393979412759236 MAE: 1.5576016
Validation loss: 3.713605466968789 MAE: 1.5522094
25 0 3.824172019958496
Validation loss: 3.7408358936080472 MAE: 1.5640063
Validation loss: 3.9508905104979246 MAE: 1.6104164
Validation loss: 4.269664385514651 MAE: 1.6696965
28 2 4.113737106323242
Validation loss: 4.4265400231004 MAE: 1.7103945
Validation loss: 6.528973496270801 MAE: 2.0876434
Validation loss: 4.869602444176683 MAE: 1.78854
31 4 3.2928237915039062
Validation loss: 3.8895232921134015 MAE: 1.60504
Validation loss: 6.134129215576845 MAE: 2.03373
Validation loss: 4.188257593907909 MAE: 1.6684997
34 6 4.165408611297607
Validation loss: 5.3608361981913655 MAE: 1.894717
Validation loss: 4.387059730613877 MAE: 1.7056457
Validation loss: 3.571206793278635 MAE: 1.5367955
37 8 2.9848644733428955
Validation loss: 3.463497827908319 MAE: 1.4961952
Validation loss: 5.48241619786662 MAE: 1.9129199
Validation loss: 3.7777178717519573 MAE: 1.5898155
40 10 3.2415969371795654
Validation loss: 3.35005166869842 MAE: 1.4846524
Validation loss: 4.657848684008948 MAE: 1.760065
Validation loss: 4.34009367573954 MAE: 1.6934676
43 12 5.5371880531311035
Validation loss: 4.273180336178185 MAE: 1.6891956
Validation loss: 3.7966204406264312 MAE: 1.5930411
Validation loss: 3.4583991190235697 MAE: 1.4753158
46 14 2.6559243202209473
Validation loss: 3.603911096920709 MAE: 1.5454901
Validation loss: 3.215210442074793 MAE: 1.4472603
Validation loss: 4.036131789067943 MAE: 1.62641
Validation loss: 3.0845011728321143 MAE: 1.4211628
50 0 3.8391196727752686
Validation loss: 3.144191213504585 MAE: 1.4315633
Validation loss: 4.039919543122958 MAE: 1.628756
Validation loss: 3.0224494645017423 MAE: 1.3941938
53 2 3.728731870651245
Validation loss: 4.1235829536804935 MAE: 1.6682227
Validation loss: 3.100975334285973 MAE: 1.4349159
Validation loss: 3.1293493903471616 MAE: 1.4508842
56 4 4.550084590911865
Validation loss: 3.128298260167032 MAE: 1.4070702
Validation loss: 3.036268384757644 MAE: 1.4043646
Validation loss: 3.648545598697089 MAE: 1.5570612
59 6 3.3982744216918945
Validation loss: 2.9230045923489127 MAE: 1.3881482
Validation loss: 6.668636250352573 MAE: 2.1359649
Validation loss: 3.105532173164383 MAE: 1.4265952
62 8 3.3634777069091797
Validation loss: 3.1462879290800534 MAE: 1.4355112
Validation loss: 3.2582707084969194 MAE: 1.4311631
Validation loss: 5.034283332213132 MAE: 1.809435
65 10 3.8376245498657227
Validation loss: 3.3123539464029377 MAE: 1.4838209
Validation loss: 3.0904750685414712 MAE: 1.4326816
Validation loss: 2.932888993758238 MAE: 1.385263
68 12 4.804780006408691
Validation loss: 3.2093574355742733 MAE: 1.4644405
Validation loss: 3.317679678748748 MAE: 1.4735051
Validation loss: 2.9650145255492064 MAE: 1.3830509
71 14 3.9956114292144775
Validation loss: 3.8016187654946276 MAE: 1.5837357
Validation loss: 3.4924698826784124 MAE: 1.522644
Validation loss: 3.3075977977148754 MAE: 1.4822198
Validation loss: 2.906728452097677 MAE: 1.3785803
75 0 2.716801643371582
Validation loss: 2.7520059158424575 MAE: 1.3321873
Validation loss: 3.591988993551067 MAE: 1.5267444
Validation loss: 3.00872829204093 MAE: 1.4158034
78 2 3.362368106842041
Validation loss: 3.077642980223906 MAE: 1.4242822
Validation loss: 3.871143352531479 MAE: 1.6044294
Validation loss: 3.0303548347496077 MAE: 1.4117528
81 4 2.6588027477264404
Validation loss: 3.3259189233990134 MAE: 1.4659057
Validation loss: 3.461587432868973 MAE: 1.5130527
Validation loss: 3.1793643357997428 MAE: 1.456188
84 6 4.52026891708374
Validation loss: 3.456448542331168 MAE: 1.4963939
Validation loss: 2.9148685413754296 MAE: 1.3882493
Validation loss: 3.6552009166839845 MAE: 1.5367938
87 8 5.044888973236084
Validation loss: 3.3705330712045125 MAE: 1.492357
Validation loss: 3.5393750175445495 MAE: 1.5212902
Validation loss: 2.6402979494335654 MAE: 1.3228294
90 10 4.471246719360352
Validation loss: 2.6502381966921513 MAE: 1.3087951
Validation loss: 2.626164641313419 MAE: 1.3022914
Validation loss: 2.762420582150171 MAE: 1.34588
93 12 4.629975318908691
Validation loss: 2.8633359677805927 MAE: 1.3840078
Validation loss: 3.4497016694598304 MAE: 1.4982053
Validation loss: 2.6813245842117586 MAE: 1.3104217
96 14 3.315844774246216
Validation loss: 2.646517918439571 MAE: 1.3034467
Validation loss: 2.575227693947618 MAE: 1.2950718
Validation loss: 3.044499151214569 MAE: 1.4052745
Validation loss: 3.0072193938887906 MAE: 1.3851993
Loaded trained model with success.
Test loss: 4.084771900671382 Test MAE: 1.6229458
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999848297979177, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 659177
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999241489895887, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 659137
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9998482979791774, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 659087
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9996965959583548, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 658987
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9992414898958869, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 658687
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9984829797917738, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 999, Valid size: 999, Test size: 658187
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9751861042183623, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 380
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9503722084367245, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 19, Valid size: 19, Test size: 370
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8759305210918115, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 48, Valid size: 48, Test size: 341
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7518610421836228, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 96, Valid size: 96, Test size: 293
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5037220843672456, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 193, Valid size: 193, Test size: 196
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 589
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 549
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 499
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 99
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 23.015323638916016
Validation loss: 17.75272560119629 MAE: 3.6357388
Validation loss: 13.517705917358398 MAE: 2.9973662
Validation loss: 9.989044189453125 MAE: 2.37258
Validation loss: 7.297741413116455 MAE: 1.9555857
Validation loss: 5.46362829208374 MAE: 1.7215648
Validation loss: 4.5909318923950195 MAE: 1.7733535
Validation loss: 4.8035993576049805 MAE: 1.8572363
Validation loss: 6.213271141052246 MAE: 2.1777039
Validation loss: 7.28350830078125 MAE: 2.3161879
Validation loss: 7.492734909057617 MAE: 2.3318353
Validation loss: 8.916861534118652 MAE: 2.5246572
Validation loss: 9.994067192077637 MAE: 2.605978
Validation loss: 11.24269962310791 MAE: 2.7555552
Validation loss: 11.775298118591309 MAE: 2.8372812
Validation loss: 11.664897918701172 MAE: 2.8303118
Validation loss: 11.247408866882324 MAE: 2.779091
Validation loss: 10.349356651306152 MAE: 2.6564806
Validation loss: 8.398407936096191 MAE: 2.348058
Validation loss: 6.844457626342773 MAE: 2.1008766
Validation loss: 5.522571086883545 MAE: 1.9052203
Validation loss: 4.238649368286133 MAE: 1.664375
Validation loss: 3.3152899742126465 MAE: 1.4801502
Validation loss: 2.853241205215454 MAE: 1.3959317
Validation loss: 2.577932834625244 MAE: 1.3495318
Validation loss: 2.411540985107422 MAE: 1.3481623
Validation loss: 2.281965732574463 MAE: 1.3434616
Validation loss: 2.1721644401550293 MAE: 1.3296596
Validation loss: 2.125680923461914 MAE: 1.3157362
Validation loss: 2.1169586181640625 MAE: 1.3014016
Validation loss: 2.139540672302246 MAE: 1.2946879
Validation loss: 2.171623945236206 MAE: 1.283859
Validation loss: 2.3099453449249268 MAE: 1.2799433
Validation loss: 2.484585762023926 MAE: 1.2956074
Validation loss: 2.699047565460205 MAE: 1.3204145
Validation loss: 2.7345268726348877 MAE: 1.3230225
Validation loss: 2.786139726638794 MAE: 1.327903
Validation loss: 2.8056094646453857 MAE: 1.3289763
Validation loss: 2.834282875061035 MAE: 1.3361715
Validation loss: 2.712733507156372 MAE: 1.3168428
Validation loss: 2.716188669204712 MAE: 1.3209052
Validation loss: 2.8374552726745605 MAE: 1.3557793
Validation loss: 3.0485541820526123 MAE: 1.4113137
Validation loss: 3.108738422393799 MAE: 1.4242623
Validation loss: 3.2000515460968018 MAE: 1.444451
Validation loss: 3.2742269039154053 MAE: 1.461542
Validation loss: 3.3265223503112793 MAE: 1.4714248
Validation loss: 3.440366506576538 MAE: 1.492887
Validation loss: 3.524885892868042 MAE: 1.5085132
Validation loss: 3.640066385269165 MAE: 1.5279294
Validation loss: 3.7832424640655518 MAE: 1.5508246
50 0 3.335596799850464
Validation loss: 3.815561532974243 MAE: 1.5532616
Validation loss: 3.8735475540161133 MAE: 1.5624793
Validation loss: 3.8487226963043213 MAE: 1.5574722
Validation loss: 3.9585139751434326 MAE: 1.5753856
Validation loss: 4.144789218902588 MAE: 1.6057897
Validation loss: 4.4610748291015625 MAE: 1.6597532
Validation loss: 4.679752349853516 MAE: 1.7208561
Validation loss: 4.8336663246154785 MAE: 1.7625154
Validation loss: 5.051514148712158 MAE: 1.8227937
Validation loss: 5.291261196136475 MAE: 1.8864896
Validation loss: 5.426115036010742 MAE: 1.9274362
Validation loss: 5.636168956756592 MAE: 1.9807576
Validation loss: 5.612427234649658 MAE: 1.9897963
Validation loss: 5.675840377807617 MAE: 2.012262
Validation loss: 5.538839340209961 MAE: 1.9966856
Validation loss: 5.56087064743042 MAE: 2.0095854
Validation loss: 5.616718769073486 MAE: 2.0288591
Validation loss: 5.487563133239746 MAE: 2.0098405
Validation loss: 5.362330436706543 MAE: 1.991511
Validation loss: 5.281010150909424 MAE: 1.9832463
Validation loss: 5.018829345703125 MAE: 1.9364706
Validation loss: 4.884516716003418 MAE: 1.9125739
Validation loss: 5.0517897605896 MAE: 1.9537885
Validation loss: 5.166778564453125 MAE: 1.9821235
Validation loss: 5.257511615753174 MAE: 2.0053945
Validation loss: 5.279904842376709 MAE: 2.0140293
Validation loss: 5.320902347564697 MAE: 2.0221908
Validation loss: 5.493444442749023 MAE: 2.0546968
Validation loss: 5.688605308532715 MAE: 2.0862687
Validation loss: 5.673237323760986 MAE: 2.0716286
Validation loss: 5.704612731933594 MAE: 2.0670063
Validation loss: 5.773172378540039 MAE: 2.0640259
Validation loss: 5.708778381347656 MAE: 2.0393682
Validation loss: 5.686767101287842 MAE: 2.040774
Validation loss: 5.664246559143066 MAE: 2.0476484
Validation loss: 5.577218532562256 MAE: 2.0473168
Validation loss: 5.433625221252441 MAE: 2.0375829
Validation loss: 4.877105236053467 MAE: 1.9282507
Validation loss: 4.311922073364258 MAE: 1.7969736
Validation loss: 3.49824595451355 MAE: 1.5617243
Validation loss: 2.916003704071045 MAE: 1.3520429
Validation loss: 2.6787374019622803 MAE: 1.2733274
Validation loss: 2.5380029678344727 MAE: 1.2303725
Validation loss: 2.5173110961914062 MAE: 1.2253652
Validation loss: 2.674001693725586 MAE: 1.2707932
Validation loss: 3.161350727081299 MAE: 1.448008
Validation loss: 3.7519993782043457 MAE: 1.6448793
Validation loss: 4.83646297454834 MAE: 1.9267099
Validation loss: 5.51243782043457 MAE: 2.0687475
Validation loss: 6.003600120544434 MAE: 2.1594265
Loaded trained model with success.
Test loss: 6.740202959846048 Test MAE: 2.1407473
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 19.62135124206543
Validation loss: 10.73200021471296 MAE: 2.6512403
Validation loss: 6.2388253406602505 MAE: 2.00909
Validation loss: 5.291490661854646 MAE: 1.938582
Validation loss: 7.577477513527383 MAE: 2.2830951
Validation loss: 12.86291165254554 MAE: 3.0158694
Validation loss: 17.748274121965682 MAE: 3.6720185
Validation loss: 17.021849846353337 MAE: 3.5765388
Validation loss: 13.414932679156868 MAE: 3.0979352
Validation loss: 10.07420808441785 MAE: 2.6448193
Validation loss: 8.1021691147162 MAE: 2.3589787
Validation loss: 6.4362978254045755 MAE: 2.1175988
Validation loss: 5.642930001628642 MAE: 1.9902258
Validation loss: 5.274515881830332 MAE: 1.9341508
Validation loss: 5.196871991060218 MAE: 1.9220713
Validation loss: 5.156540160276452 MAE: 1.9175035
Validation loss: 5.1183001167920175 MAE: 1.908832
Validation loss: 5.089850124047727 MAE: 1.9019004
Validation loss: 5.093705060530682 MAE: 1.8990647
Validation loss: 5.1389786029348565 MAE: 1.897695
Validation loss: 5.314622849834208 MAE: 1.9240184
Validation loss: 5.454390545280612 MAE: 1.9454129
Validation loss: 5.5607051265483 MAE: 1.9600046
Validation loss: 5.501979068833954 MAE: 1.9474704
Validation loss: 5.387491673839335 MAE: 1.9236157
Validation loss: 5.249393686956289 MAE: 1.9037292
25 0 5.835496425628662
Validation loss: 5.170481526121801 MAE: 1.9005214
Validation loss: 5.131357533591134 MAE: 1.9004136
Validation loss: 5.124426773616245 MAE: 1.904887
Validation loss: 5.137168495022521 MAE: 1.9131383
Validation loss: 5.180132311217639 MAE: 1.9258065
Validation loss: 5.224651453446369 MAE: 1.9361728
Validation loss: 5.2759407880354905 MAE: 1.9477229
Validation loss: 5.286489759172712 MAE: 1.9522659
Validation loss: 5.266908227180948 MAE: 1.9499558
Validation loss: 5.260699194304797 MAE: 1.9458191
Validation loss: 5.27205127599288 MAE: 1.9433526
Validation loss: 5.267727890793158 MAE: 1.9424806
Validation loss: 5.274193724807428 MAE: 1.9440943
Validation loss: 5.231836698493179 MAE: 1.9357889
Validation loss: 5.180005832594269 MAE: 1.9290044
Validation loss: 5.1544551265483 MAE: 1.9265014
Validation loss: 5.167058545715955 MAE: 1.9283724
Validation loss: 5.162032141977427 MAE: 1.9268428
Validation loss: 5.147101236849415 MAE: 1.9224595
Validation loss: 5.124008529040278 MAE: 1.9147805
Validation loss: 5.09059782417453 MAE: 1.9054585
Validation loss: 5.038737394371811 MAE: 1.8909678
Validation loss: 5.00793762596286 MAE: 1.8800191
Validation loss: 4.986573121985611 MAE: 1.8715076
Validation loss: 4.96790091845454 MAE: 1.8601542
50 0 4.825055122375488
Validation loss: 4.965203586889773 MAE: 1.8518411
Validation loss: 4.946700611893012 MAE: 1.8402663
Validation loss: 4.913391161938103 MAE: 1.8316228
Validation loss: 4.824712466220467 MAE: 1.8098739
Validation loss: 4.725542506393121 MAE: 1.7902492
Validation loss: 4.593637500490461 MAE: 1.7613535
Validation loss: 4.415210475727004 MAE: 1.7194027
Validation loss: 4.2410701440305125 MAE: 1.697208
Validation loss: 4.078366780767635 MAE: 1.684722
Validation loss: 3.907091948450828 MAE: 1.6658198
Validation loss: 3.8295169168589065 MAE: 1.6714202
Validation loss: 4.095805460092973 MAE: 1.6893045
Validation loss: 3.9754901808135363 MAE: 1.6579015
Validation loss: 3.586285503543153 MAE: 1.5861827
Validation loss: 3.223307210571912 MAE: 1.5230173
Validation loss: 3.049868938874225 MAE: 1.4764774
Validation loss: 2.840730939592634 MAE: 1.4158121
Validation loss: 2.6549533046021754 MAE: 1.3543091
Validation loss: 2.55085927126359 MAE: 1.3000169
Validation loss: 2.570742504937308 MAE: 1.2832835
Validation loss: 2.5595828708337276 MAE: 1.2624538
Validation loss: 2.5063383117014046 MAE: 1.2470448
Validation loss: 2.398806041600753 MAE: 1.2355112
Validation loss: 2.263013625631527 MAE: 1.2090638
Validation loss: 2.2624528894619065 MAE: 1.1919421
75 0 3.067079782485962
Validation loss: 2.2249552498058396 MAE: 1.1717157
Validation loss: 2.158331705599415 MAE: 1.1536965
Validation loss: 2.03534747143181 MAE: 1.1465422
Validation loss: 1.9185824394226074 MAE: 1.1272607
Validation loss: 1.907167646349693 MAE: 1.1265272
Validation loss: 1.9074166113016557 MAE: 1.1103001
Validation loss: 2.0632427419934953 MAE: 1.1272702
Validation loss: 2.736819637065031 MAE: 1.2781069
Validation loss: 4.009089810507638 MAE: 1.6082327
Validation loss: 5.195455950133654 MAE: 1.8653401
Validation loss: 5.309773727339142 MAE: 1.8964896
Validation loss: 5.035626975857482 MAE: 1.8539038
Validation loss: 4.340340716498239 MAE: 1.7182988
Validation loss: 3.233892922498742 MAE: 1.4468853
Validation loss: 2.318847335114771 MAE: 1.2022468
Validation loss: 1.8725814624708526 MAE: 1.1231003
Validation loss: 1.8183663207657483 MAE: 1.1017733
Validation loss: 1.8721914388695542 MAE: 1.0993947
Validation loss: 1.8355933257511683 MAE: 1.0961456
Validation loss: 1.699725783601099 MAE: 1.0731244
Validation loss: 1.6498341073795242 MAE: 1.0542868
Validation loss: 1.6494611769306415 MAE: 1.0439261
Validation loss: 1.6671153282632634 MAE: 1.0460279
Validation loss: 1.6907959835869926 MAE: 1.0509263
Validation loss: 1.739263155022446 MAE: 1.0707542
Loaded trained model with success.
Test loss: 8.212112750715882 Test MAE: 2.2923582
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 25.221586227416992
Validation loss: 9.330044910462215 MAE: 2.4038262
Validation loss: 6.419564801033097 MAE: 2.1665459
Validation loss: 16.38421618336379 MAE: 3.4484842
Validation loss: 24.249721854624124 MAE: 4.341848
Validation loss: 17.45647766614201 MAE: 3.5710816
Validation loss: 10.461408253872033 MAE: 2.6845348
Validation loss: 8.164856862540196 MAE: 2.3886018
Validation loss: 7.1634003851148815 MAE: 2.2594993
Validation loss: 6.912676136903088 MAE: 2.2218769
Validation loss: 6.693899087231569 MAE: 2.1885955
Validation loss: 7.058498483715636 MAE: 2.232388
Validation loss: 6.509346586285216 MAE: 2.1546254
12 2 4.434704303741455
Validation loss: 5.872358081316707 MAE: 2.0530124
Validation loss: 5.656658293020846 MAE: 2.0393486
Validation loss: 5.672137602411135 MAE: 2.060475
Validation loss: 5.690949677216886 MAE: 2.066979
Validation loss: 5.747423559728295 MAE: 2.0734973
Validation loss: 5.782211738403397 MAE: 2.0694413
Validation loss: 5.772873969993206 MAE: 2.0617855
Validation loss: 5.711542847180607 MAE: 2.05599
Validation loss: 5.823186650420681 MAE: 2.0686524
Validation loss: 5.6795480407849706 MAE: 2.0637991
Validation loss: 5.633869402336352 MAE: 2.0646799
Validation loss: 5.625198060815984 MAE: 2.0619626
Validation loss: 5.614512597671663 MAE: 2.0547814
25 0 4.283175945281982
Validation loss: 5.787208493309792 MAE: 2.063577
Validation loss: 5.711328942366321 MAE: 2.0506465
Validation loss: 5.707840750915835 MAE: 2.0364218
Validation loss: 5.671266322184091 MAE: 2.0109537
Validation loss: 5.453008764922017 MAE: 1.9729031
Validation loss: 5.085251552890045 MAE: 1.9290476
Validation loss: 5.001478753908716 MAE: 1.9058512
Validation loss: 5.431074807138154 MAE: 1.9337623
Validation loss: 5.891678477778579 MAE: 1.9733241
Validation loss: 5.814652984792536 MAE: 1.9427184
Validation loss: 5.386181956589824 MAE: 1.8689427
Validation loss: 5.297382735242747 MAE: 1.8412609
37 2 4.9508056640625
Validation loss: 5.685597689464839 MAE: 1.8812473
Validation loss: 5.812765340612392 MAE: 1.9116399
Validation loss: 5.583284508098256 MAE: 1.9155805
Validation loss: 5.180902086123072 MAE: 1.8889183
Validation loss: 4.448741997131194 MAE: 1.7782824
Validation loss: 3.725610411904677 MAE: 1.5911821
Validation loss: 3.794845361902256 MAE: 1.6149824
Validation loss: 4.196141715001578 MAE: 1.6850611
Validation loss: 4.063505375024044 MAE: 1.6235304
Validation loss: 3.5805413698909256 MAE: 1.4978783
Validation loss: 3.866750885741879 MAE: 1.5347363
Validation loss: 4.709136750962999 MAE: 1.7064468
Validation loss: 4.49819956644617 MAE: 1.6710705
50 0 4.143458366394043
Validation loss: 4.27015773214475 MAE: 1.6335585
Validation loss: 4.489120172731804 MAE: 1.6697024
Validation loss: 4.725082334845957 MAE: 1.7261488
Validation loss: 4.662356957040652 MAE: 1.7368581
Validation loss: 3.7547527322865495 MAE: 1.59358
Validation loss: 3.3007812283255835 MAE: 1.5146942
Validation loss: 3.3753463914900115 MAE: 1.51134
Validation loss: 3.441015800141325 MAE: 1.49652
Validation loss: 3.5495586901000054 MAE: 1.5291516
Validation loss: 3.7414140556797837 MAE: 1.5221277
Validation loss: 3.7522929617852876 MAE: 1.530714
Validation loss: 3.5286870821557863 MAE: 1.5024173
62 2 3.3549513816833496
Validation loss: 3.4952288162377148 MAE: 1.54716
Validation loss: 3.7230340206261836 MAE: 1.6261553
Validation loss: 3.3459659658297145 MAE: 1.5181065
Validation loss: 3.6081655772045407 MAE: 1.5641844
Validation loss: 3.7833569651902326 MAE: 1.6042986
Validation loss: 3.577664683563541 MAE: 1.5591031
Validation loss: 3.2231365020829017 MAE: 1.4495722
Validation loss: 3.143520522900302 MAE: 1.4028622
Validation loss: 3.1716400776246583 MAE: 1.4595264
Validation loss: 3.365647631462174 MAE: 1.5316434
Validation loss: 3.3431158258457376 MAE: 1.5257262
Validation loss: 3.170423075406238 MAE: 1.4458622
Validation loss: 3.6167599944153217 MAE: 1.4856825
75 0 4.364781856536865
Validation loss: 4.123123640965933 MAE: 1.5632024
Validation loss: 5.4544498173877445 MAE: 1.8308501
Validation loss: 5.332532463651715 MAE: 1.7782502
Validation loss: 4.252133470593077 MAE: 1.5293711
Validation loss: 3.4324085977342396 MAE: 1.350841
Validation loss: 2.9782489044497713 MAE: 1.3080728
Validation loss: 2.9137044627257067 MAE: 1.332617
Validation loss: 2.9778219220614193 MAE: 1.3536638
Validation loss: 3.247246645917796 MAE: 1.3768358
Validation loss: 3.74724485416605 MAE: 1.461654
Validation loss: 3.5552567628899006 MAE: 1.3834441
Validation loss: 3.192634853449735 MAE: 1.3262156
87 2 3.605313777923584
Validation loss: 3.056166713887995 MAE: 1.3244996
Validation loss: 2.889481297045043 MAE: 1.3243791
Validation loss: 3.251767548647794 MAE: 1.4190807
Validation loss: 4.050557985450283 MAE: 1.6020235
Validation loss: 4.03677081339287 MAE: 1.5651268
Validation loss: 3.6251306919136432 MAE: 1.411633
Validation loss: 2.98673826034623 MAE: 1.2888753
Validation loss: 2.941068320563345 MAE: 1.3048222
Validation loss: 3.0453788535763517 MAE: 1.313946
Validation loss: 3.1052592739914404 MAE: 1.3223599
Validation loss: 2.971214371498185 MAE: 1.3189799
Validation loss: 3.4876757089537804 MAE: 1.547255
Validation loss: 3.8971601592169867 MAE: 1.6748183
Loaded trained model with success.
Test loss: 5.302284325769764 Test MAE: 1.8323047
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 18.62696647644043
Validation loss: 6.324191095840991 MAE: 2.1083372
Validation loss: 13.258153239686285 MAE: 3.0165386
Validation loss: 6.557984498277981 MAE: 2.0854151
Validation loss: 6.032236356831076 MAE: 2.0556383
Validation loss: 6.117427787589069 MAE: 2.084071
Validation loss: 5.87352913707944 MAE: 2.0479636
Validation loss: 5.851590405756505 MAE: 2.0263937
7 1 7.503390312194824
Validation loss: 6.107612708106113 MAE: 2.0419643
Validation loss: 5.999329931172893 MAE: 2.0174549
Validation loss: 6.040360539402794 MAE: 2.027122
Validation loss: 5.941830893856796 MAE: 2.0242188
Validation loss: 5.70675164131663 MAE: 2.01273
Validation loss: 5.877099255221573 MAE: 2.032416
Validation loss: 5.652251660524302 MAE: 1.9715307
14 2 5.594952583312988
Validation loss: 5.791625541658258 MAE: 1.9673994
Validation loss: 6.040168491440203 MAE: 1.9949074
Validation loss: 5.746561917827357 MAE: 1.9466485
Validation loss: 5.345960236074936 MAE: 1.8899444
Validation loss: 5.09744312775195 MAE: 1.8528866
Validation loss: 4.957414333544784 MAE: 1.8265104
Validation loss: 4.726666494829571 MAE: 1.7792879
21 3 3.7157249450683594
Validation loss: 4.6334676838400375 MAE: 1.7499791
Validation loss: 4.4837254687170285 MAE: 1.7006379
Validation loss: 4.444628955131799 MAE: 1.6864283
Validation loss: 4.747919836835046 MAE: 1.7683152
Validation loss: 4.063747622858939 MAE: 1.6567174
Validation loss: 4.875932292123536 MAE: 1.7617401
Validation loss: 4.661822883328002 MAE: 1.7267087
28 4 3.0759265422821045
Validation loss: 4.545249807175679 MAE: 1.724786
Validation loss: 4.5580544903050715 MAE: 1.7102422
Validation loss: 4.109015344974384 MAE: 1.6190423
Validation loss: 4.023794392245499 MAE: 1.602836
Validation loss: 4.037845765825492 MAE: 1.5732167
Validation loss: 4.038245136414341 MAE: 1.5821501
Validation loss: 3.906038718007917 MAE: 1.5676441
35 5 4.219336986541748
Validation loss: 4.305539068864219 MAE: 1.6457219
Validation loss: 5.353590325494507 MAE: 1.8348999
Validation loss: 5.360872148868427 MAE: 1.8409654
Validation loss: 5.020341324446789 MAE: 1.7631024
Validation loss: 5.411714330989512 MAE: 1.8424363
Validation loss: 4.494900566848679 MAE: 1.6583043
Validation loss: 4.278427939918173 MAE: 1.6183327
42 6 4.252525806427002
Validation loss: 4.724717528376747 MAE: 1.7037857
Validation loss: 5.548467818217062 MAE: 1.8653493
Validation loss: 4.102990949573229 MAE: 1.5642093
Validation loss: 5.117522730899217 MAE: 1.790687
Validation loss: 7.606052022483481 MAE: 2.2621121
Validation loss: 7.3217363357543945 MAE: 2.2221391
Validation loss: 4.236488215288325 MAE: 1.5799987
Validation loss: 3.8765476097413645 MAE: 1.5092111
50 0 4.1871137619018555
Validation loss: 8.338039700110354 MAE: 2.4062
Validation loss: 10.269677243640075 MAE: 2.737231
Validation loss: 5.984871615117519 MAE: 1.9786754
Validation loss: 4.855779060766325 MAE: 1.7142838
Validation loss: 5.066700412999445 MAE: 1.7556809
Validation loss: 4.3302144746684545 MAE: 1.5891794
Validation loss: 3.563764991472714 MAE: 1.4460069
57 1 3.6314339637756348
Validation loss: 4.116460311352907 MAE: 1.5666482
Validation loss: 3.711784405923968 MAE: 1.4904914
Validation loss: 4.395237493754632 MAE: 1.6309639
Validation loss: 5.303534488582132 MAE: 1.8345412
Validation loss: 5.315385040925376 MAE: 1.8420882
Validation loss: 5.194787336953321 MAE: 1.8078804
Validation loss: 5.849428447646711 MAE: 1.9551097
64 2 3.317188262939453
Validation loss: 4.402744760465382 MAE: 1.6351207
Validation loss: 2.9795805593231814 MAE: 1.3481606
Validation loss: 3.083968645364196 MAE: 1.3699337
Validation loss: 3.843802257997906 MAE: 1.5125809
Validation loss: 5.169197177168113 MAE: 1.7981143
Validation loss: 7.613716835951685 MAE: 2.2935762
Validation loss: 5.713706427483103 MAE: 1.913504
71 3 2.699946165084839
Validation loss: 3.994725845566946 MAE: 1.538676
Validation loss: 6.5633420057632215 MAE: 2.09075
Validation loss: 10.898416363414208 MAE: 2.8957777
Validation loss: 6.577188230639127 MAE: 2.1098218
Validation loss: 3.7542527836171824 MAE: 1.4832592
Validation loss: 4.077704715968377 MAE: 1.5542387
Validation loss: 4.2482288818263525 MAE: 1.600292
78 4 3.2242844104766846
Validation loss: 3.4248388196954775 MAE: 1.4264156
Validation loss: 5.990254656154307 MAE: 1.9914827
Validation loss: 8.949794989734439 MAE: 2.5752072
Validation loss: 6.436476688289163 MAE: 2.0843134
Validation loss: 3.489223851630436 MAE: 1.4250286
Validation loss: 3.3188417520954383 MAE: 1.3799033
Validation loss: 6.203315754032614 MAE: 2.0323272
85 5 3.896059513092041
Validation loss: 4.367685459366995 MAE: 1.6599363
Validation loss: 2.675966791172123 MAE: 1.3317975
Validation loss: 4.1657976744762015 MAE: 1.6399649
Validation loss: 5.030610412808519 MAE: 1.8258084
Validation loss: 4.137860809738313 MAE: 1.5989505
Validation loss: 3.693178740578081 MAE: 1.4767615
Validation loss: 3.3745438130057637 MAE: 1.408496
92 6 7.432251930236816
Validation loss: 3.626357104910079 MAE: 1.4863223
Validation loss: 2.8847047479907473 MAE: 1.3197414
Validation loss: 3.196666542609133 MAE: 1.3986462
Validation loss: 3.1446034500946354 MAE: 1.3853701
Validation loss: 3.060430415910692 MAE: 1.3539815
Validation loss: 3.019230933045622 MAE: 1.3384175
Validation loss: 3.094616063276128 MAE: 1.3447405
Validation loss: 3.026357483324693 MAE: 1.3274152
Loaded trained model with success.
Test loss: 5.849466055167014 Test MAE: 1.8822579
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 24.2009334564209
Validation loss: 15.826209081676536 MAE: 3.36081
Validation loss: 5.493075503137164 MAE: 1.9876186
Validation loss: 5.452281998727986 MAE: 1.9818108
3 2 5.304322242736816
Validation loss: 5.500974608327678 MAE: 1.9900553
Validation loss: 5.441515874767112 MAE: 1.9817277
Validation loss: 5.381142425154875 MAE: 1.949323
6 4 5.733123779296875
Validation loss: 5.235509741521311 MAE: 1.9316013
Validation loss: 5.111819155469447 MAE: 1.9089607
Validation loss: 5.010462135972384 MAE: 1.870159
9 6 4.791728973388672
Validation loss: 4.8506220299638585 MAE: 1.8408352
Validation loss: 4.549820695468084 MAE: 1.7542598
Validation loss: 4.497051368017713 MAE: 1.7350613
12 8 4.903933048248291
Validation loss: 4.5152114464906985 MAE: 1.7777581
Validation loss: 4.1640018002542565 MAE: 1.6915848
Validation loss: 4.064767420889142 MAE: 1.6584549
15 10 5.1451191902160645
Validation loss: 4.173887525149481 MAE: 1.6655666
Validation loss: 4.153254907451316 MAE: 1.6531992
Validation loss: 4.075393252477856 MAE: 1.667796
18 12 3.101612091064453
Validation loss: 4.356946626980462 MAE: 1.7142695
Validation loss: 4.8823153566501905 MAE: 1.7900034
Validation loss: 3.7658170077031503 MAE: 1.6043069
21 14 7.348211765289307
Validation loss: 4.825461105736559 MAE: 1.7753065
Validation loss: 3.8510905487503937 MAE: 1.5928317
Validation loss: 4.492655279163368 MAE: 1.7134856
Validation loss: 4.94733371285494 MAE: 1.8175834
25 0 4.312063694000244
Validation loss: 5.522552761620654 MAE: 1.9031466
Validation loss: 4.654677112976869 MAE: 1.7586248
Validation loss: 4.472661436918026 MAE: 1.72393
28 2 3.3020546436309814
Validation loss: 5.144956029727607 MAE: 1.828926
Validation loss: 4.675918788374784 MAE: 1.7452142
Validation loss: 5.315235344345918 MAE: 1.837958
31 4 5.6093034744262695
Validation loss: 4.162941176810103 MAE: 1.6537107
Validation loss: 3.9152442247929695 MAE: 1.6164467
Validation loss: 3.5397123669335744 MAE: 1.5344468
34 6 5.076704025268555
Validation loss: 4.2152910232543945 MAE: 1.6622416
Validation loss: 4.15845787787963 MAE: 1.6293454
Validation loss: 4.786301452315642 MAE: 1.7727665
37 8 2.988100051879883
Validation loss: 3.4939236488036496 MAE: 1.513029
Validation loss: 4.03133253296296 MAE: 1.6306213
Validation loss: 4.1977378294797605 MAE: 1.648606
40 10 3.688598155975342
Validation loss: 4.839241759810514 MAE: 1.7499423
Validation loss: 4.284659551953027 MAE: 1.6465367
Validation loss: 3.343292950628277 MAE: 1.5130831
43 12 3.439951181411743
Validation loss: 4.153529384809888 MAE: 1.6354057
Validation loss: 3.8761294198657326 MAE: 1.6017543
Validation loss: 3.3098588730385883 MAE: 1.500922
46 14 3.8258142471313477
Validation loss: 3.3634489304078126 MAE: 1.4770668
Validation loss: 3.910937765079414 MAE: 1.5909019
Validation loss: 4.154339548103318 MAE: 1.638942
Validation loss: 3.1040876212722077 MAE: 1.4440081
50 0 4.203271865844727
Validation loss: 3.3257453379506816 MAE: 1.4856877
Validation loss: 4.03830173641503 MAE: 1.6284305
Validation loss: 4.956817370856214 MAE: 1.7933942
53 2 5.153842926025391
Validation loss: 3.58415804023972 MAE: 1.5393883
Validation loss: 3.1227381172065507 MAE: 1.4491906
Validation loss: 3.5225978948788077 MAE: 1.5097154
56 4 2.9588210582733154
Validation loss: 3.4490826249361515 MAE: 1.4991119
Validation loss: 3.7732166073365296 MAE: 1.553258
Validation loss: 3.6088400383989416 MAE: 1.5151289
59 6 3.475829601287842
Validation loss: 4.507470007172089 MAE: 1.69628
Validation loss: 3.6073433516737454 MAE: 1.5140116
Validation loss: 3.3431375877173966 MAE: 1.4581394
62 8 2.893399238586426
Validation loss: 3.5650967877947974 MAE: 1.5341657
Validation loss: 3.3790414280786303 MAE: 1.4665211
Validation loss: 3.7516195824246608 MAE: 1.5475247
65 10 4.067538738250732
Validation loss: 3.6489763049658888 MAE: 1.5285947
Validation loss: 3.697338843871214 MAE: 1.511035
Validation loss: 3.2319003054517546 MAE: 1.4424194
68 12 2.3666625022888184
Validation loss: 2.9816281704721086 MAE: 1.3962972
Validation loss: 2.968625141766841 MAE: 1.3997108
Validation loss: 3.4610174399817395 MAE: 1.5009749
71 14 2.9266252517700195
Validation loss: 3.1069239222692824 MAE: 1.4199637
Validation loss: 3.273077517568707 MAE: 1.456861
Validation loss: 3.565231154581349 MAE: 1.4985902
Validation loss: 3.0279561512933704 MAE: 1.3830916
75 0 2.9208664894104004
Validation loss: 2.9088123967508994 MAE: 1.3684033
Validation loss: 2.889671197157346 MAE: 1.3651838
Validation loss: 3.10479304976836 MAE: 1.4380236
78 2 3.301604986190796
Validation loss: 3.6410486693372706 MAE: 1.5038719
Validation loss: 3.0828592428463493 MAE: 1.4148061
Validation loss: 3.2917980975760726 MAE: 1.456646
81 4 5.013705253601074
Validation loss: 3.5448967736804176 MAE: 1.4838488
Validation loss: 3.0367392017272765 MAE: 1.404525
Validation loss: 3.7687285964140194 MAE: 1.5542079
84 6 2.656869649887085
Validation loss: 2.8086550603648703 MAE: 1.3520843
Validation loss: 3.198127133573941 MAE: 1.4369276
Validation loss: 3.0664996470143655 MAE: 1.4300283
87 8 2.604212760925293
Validation loss: 3.413306543965617 MAE: 1.4936417
Validation loss: 3.9481716633798603 MAE: 1.5976044
Validation loss: 3.021306392425048 MAE: 1.4003127
90 10 3.251889228820801
Validation loss: 3.4101924485338473 MAE: 1.4729575
Validation loss: 2.7802942214843505 MAE: 1.3495669
Validation loss: 4.009965504816395 MAE: 1.5895473
93 12 2.812203884124756
Validation loss: 3.0945279851466236 MAE: 1.4092462
Validation loss: 2.791935491657448 MAE: 1.3436984
Validation loss: 2.897330571749884 MAE: 1.3679198
96 14 3.5321455001831055
Validation loss: 2.7181752105514128 MAE: 1.3187288
Validation loss: 3.217036990698927 MAE: 1.4262446
Validation loss: 2.84561492015938 MAE: 1.3572556
Validation loss: 3.2743458833866463 MAE: 1.4450166
Loaded trained model with success.
Test loss: 4.148712226778368 Test MAE: 1.6412929
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999848297979177, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 659177
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999241489895887, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 659137
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9998482979791774, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 659087
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9996965959583548, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 658987
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9992414898958869, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 658687
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9984829797917738, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 999, Valid size: 999, Test size: 658187
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9751861042183623, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 380
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9503722084367245, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 19, Valid size: 19, Test size: 370
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8759305210918115, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 48, Valid size: 48, Test size: 341
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7518610421836228, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 96, Valid size: 96, Test size: 293
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5037220843672456, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 193, Valid size: 193, Test size: 196
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 589
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 549
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 499
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 99
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 18.96905517578125
Validation loss: 13.203174591064453 MAE: 3.0337458
Validation loss: 9.909440040588379 MAE: 2.554558
Validation loss: 7.260580062866211 MAE: 2.0498059
Validation loss: 5.363277912139893 MAE: 1.7289892
Validation loss: 4.443315029144287 MAE: 1.7496488
Validation loss: 4.407385349273682 MAE: 1.8221893
Validation loss: 5.353438377380371 MAE: 1.9239249
Validation loss: 7.315008163452148 MAE: 2.259088
Validation loss: 9.806809425354004 MAE: 2.7347395
Validation loss: 13.087793350219727 MAE: 3.215718
Validation loss: 16.120994567871094 MAE: 3.5844312
Validation loss: 18.730911254882812 MAE: 3.865449
Validation loss: 21.03002166748047 MAE: 4.0979548
Validation loss: 22.990713119506836 MAE: 4.336738
Validation loss: 22.670520782470703 MAE: 4.303345
Validation loss: 20.61192512512207 MAE: 4.059683
Validation loss: 17.908445358276367 MAE: 3.7791824
Validation loss: 14.918933868408203 MAE: 3.4466238
Validation loss: 12.079654693603516 MAE: 3.0848324
Validation loss: 10.09451675415039 MAE: 2.7928667
Validation loss: 8.390716552734375 MAE: 2.5127885
Validation loss: 6.131591320037842 MAE: 2.0828922
Validation loss: 4.702817440032959 MAE: 1.7331111
Validation loss: 4.153741359710693 MAE: 1.6546385
Validation loss: 3.9355201721191406 MAE: 1.6215839
Validation loss: 3.9780867099761963 MAE: 1.6168491
Validation loss: 4.091994285583496 MAE: 1.6219773
Validation loss: 4.253519535064697 MAE: 1.6379986
Validation loss: 4.38987922668457 MAE: 1.6566085
Validation loss: 4.520070552825928 MAE: 1.6927171
Validation loss: 4.611266136169434 MAE: 1.737749
Validation loss: 4.6520466804504395 MAE: 1.7647433
Validation loss: 4.676848411560059 MAE: 1.8070818
Validation loss: 4.667415618896484 MAE: 1.8276639
Validation loss: 4.688366413116455 MAE: 1.8837308
Validation loss: 4.665100574493408 MAE: 1.8979032
Validation loss: 4.714382171630859 MAE: 1.9449136
Validation loss: 4.784231185913086 MAE: 1.9787965
Validation loss: 4.91632080078125 MAE: 2.0157464
Validation loss: 4.950446128845215 MAE: 2.0230203
Validation loss: 5.014986991882324 MAE: 2.032224
Validation loss: 5.060937881469727 MAE: 2.03575
Validation loss: 5.357950687408447 MAE: 2.0690048
Validation loss: 5.643546104431152 MAE: 2.0889096
Validation loss: 5.606130599975586 MAE: 2.0743518
Validation loss: 5.732756614685059 MAE: 2.0747054
Validation loss: 5.841413497924805 MAE: 2.0743368
Validation loss: 5.817239761352539 MAE: 2.0629835
Validation loss: 5.901540279388428 MAE: 2.060994
Validation loss: 5.805988311767578 MAE: 2.0474558
50 0 4.1510515213012695
Validation loss: 5.771244525909424 MAE: 2.0375113
Validation loss: 5.938963413238525 MAE: 2.0593646
Validation loss: 6.184817790985107 MAE: 2.0995796
Validation loss: 6.525812149047852 MAE: 2.149246
Validation loss: 6.661488056182861 MAE: 2.167901
Validation loss: 7.060953617095947 MAE: 2.2295702
Validation loss: 7.382515907287598 MAE: 2.288358
Validation loss: 7.607243061065674 MAE: 2.3266454
Validation loss: 8.159374237060547 MAE: 2.4154825
Validation loss: 8.248005867004395 MAE: 2.4276183
Validation loss: 8.041081428527832 MAE: 2.3920274
Validation loss: 7.666390419006348 MAE: 2.3278131
Validation loss: 7.062995910644531 MAE: 2.2186873
Validation loss: 6.45335054397583 MAE: 2.1266992
Validation loss: 6.2929205894470215 MAE: 2.1039457
Validation loss: 5.8001604080200195 MAE: 2.041851
Validation loss: 5.581826686859131 MAE: 2.0266314
Validation loss: 5.361227035522461 MAE: 2.0078764
Validation loss: 5.25473690032959 MAE: 1.9957805
Validation loss: 5.3320183753967285 MAE: 2.000086
Validation loss: 5.421476364135742 MAE: 2.0040019
Validation loss: 5.629687786102295 MAE: 2.0179949
Validation loss: 5.831140518188477 MAE: 2.0306084
Validation loss: 6.1073503494262695 MAE: 2.072137
Validation loss: 6.509977340698242 MAE: 2.128722
Validation loss: 6.680098056793213 MAE: 2.1507616
Validation loss: 6.784870624542236 MAE: 2.1634085
Validation loss: 6.835983753204346 MAE: 2.1680622
Validation loss: 6.7334184646606445 MAE: 2.153074
Validation loss: 6.573709487915039 MAE: 2.132344
Validation loss: 6.442135334014893 MAE: 2.1144555
Validation loss: 6.299733638763428 MAE: 2.0957499
Validation loss: 6.051303863525391 MAE: 2.060952
Validation loss: 5.848045825958252 MAE: 2.0274858
Validation loss: 5.722593307495117 MAE: 2.0064592
Validation loss: 5.852753162384033 MAE: 2.022591
Validation loss: 5.784587860107422 MAE: 2.0099978
Validation loss: 5.845541000366211 MAE: 2.016075
Validation loss: 5.833054542541504 MAE: 2.0116835
Validation loss: 5.7857842445373535 MAE: 2.0006995
Validation loss: 5.749300956726074 MAE: 1.9901913
Validation loss: 5.908832550048828 MAE: 2.007479
Validation loss: 6.10893440246582 MAE: 2.0359888
Validation loss: 6.108480453491211 MAE: 2.037255
Validation loss: 5.962932586669922 MAE: 2.0072947
Validation loss: 5.991638660430908 MAE: 2.0118036
Validation loss: 5.825910568237305 MAE: 1.975584
Validation loss: 5.827445030212402 MAE: 1.9851384
Validation loss: 5.576066970825195 MAE: 1.9627385
Validation loss: 5.0604448318481445 MAE: 1.9163693
Loaded trained model with success.
Test loss: 5.9709685620139625 Test MAE: 2.0131872
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 23.569435119628906
Validation loss: 15.687659321999064 MAE: 3.3232527
Validation loss: 9.443679692793866 MAE: 2.463617
Validation loss: 5.895600455147879 MAE: 1.9997213
Validation loss: 5.248537452853456 MAE: 1.9256405
Validation loss: 6.763393514010371 MAE: 2.1539865
Validation loss: 8.026314521322446 MAE: 2.3037777
Validation loss: 8.900991887462382 MAE: 2.4084513
Validation loss: 9.276796194971825 MAE: 2.4672277
Validation loss: 8.822074150552554 MAE: 2.4120235
Validation loss: 7.919807258917361 MAE: 2.2956603
Validation loss: 6.744438901239512 MAE: 2.1409495
Validation loss: 5.791876598280304 MAE: 2.0132592
Validation loss: 5.308864885446977 MAE: 1.9455984
Validation loss: 5.259211150967345 MAE: 1.9309684
Validation loss: 5.306594712393625 MAE: 1.9240808
Validation loss: 5.273377408786696 MAE: 1.9118227
Validation loss: 5.1633864422233735 MAE: 1.8870198
Validation loss: 4.995014794018804 MAE: 1.842076
Validation loss: 4.937091068345673 MAE: 1.7980297
Validation loss: 5.102343179741684 MAE: 1.8230438
Validation loss: 5.368425563890106 MAE: 1.9019227
Validation loss: 5.892529857401946 MAE: 2.040194
Validation loss: 6.519735842334981 MAE: 2.18386
Validation loss: 7.171759391317562 MAE: 2.3120842
Validation loss: 7.258420798243309 MAE: 2.3282766
25 0 5.370518684387207
Validation loss: 7.3793346443954775 MAE: 2.3510766
Validation loss: 7.223038361997021 MAE: 2.3218713
Validation loss: 6.959375498246174 MAE: 2.2741864
Validation loss: 6.731147639605464 MAE: 2.2302456
Validation loss: 6.82551232162787 MAE: 2.2488005
Validation loss: 6.748353121232014 MAE: 2.2338367
Validation loss: 6.701367553399534 MAE: 2.225724
Validation loss: 6.895605525191949 MAE: 2.2644207
Validation loss: 6.932627765499816 MAE: 2.2727456
Validation loss: 6.773885113852365 MAE: 2.2434516
Validation loss: 6.65258957415211 MAE: 2.2206464
Validation loss: 6.583171863945163 MAE: 2.2074244
Validation loss: 6.596700921350596 MAE: 2.2112772
Validation loss: 6.321110365342121 MAE: 2.1553326
Validation loss: 5.900267980536636 MAE: 2.056891
Validation loss: 5.531892270457988 MAE: 1.9587514
Validation loss: 5.361560743682238 MAE: 1.9152968
Validation loss: 5.243906721776845 MAE: 1.8876225
Validation loss: 5.1899087672330895 MAE: 1.8776454
Validation loss: 5.247549786859629 MAE: 1.8974166
Validation loss: 5.344164605043372 MAE: 1.9320774
Validation loss: 5.350597556756467 MAE: 1.9431484
Validation loss: 5.327644513577831 MAE: 1.9455984
Validation loss: 5.313160769793452 MAE: 1.9505955
Validation loss: 5.25172115831959 MAE: 1.9442052
50 0 5.314866065979004
Validation loss: 5.032450831666285 MAE: 1.9016937
Validation loss: 4.800640388410919 MAE: 1.8581014
Validation loss: 4.503647590170101 MAE: 1.7927784
Validation loss: 4.293833878575539 MAE: 1.7475617
Validation loss: 4.24046854097016 MAE: 1.736339
Validation loss: 4.217131522237038 MAE: 1.7258825
Validation loss: 4.23396297376983 MAE: 1.7136648
Validation loss: 4.467261518750872 MAE: 1.7440323
Validation loss: 4.9564235161761845 MAE: 1.8367677
Validation loss: 5.834571030675148 MAE: 1.9850923
Validation loss: 6.548722919152707 MAE: 2.0912042
Validation loss: 6.435364791325161 MAE: 2.0566072
Validation loss: 5.905464892484704 MAE: 1.950949
Validation loss: 5.811604820952123 MAE: 1.9287443
Validation loss: 5.501689044796691 MAE: 1.858802
Validation loss: 4.8331195578283195 MAE: 1.6993022
Validation loss: 4.025311489494479 MAE: 1.5527376
Validation loss: 3.427008852666738 MAE: 1.4571868
Validation loss: 3.014762304267105 MAE: 1.355698
Validation loss: 2.8734152608988235 MAE: 1.3105307
Validation loss: 2.9824813482712726 MAE: 1.3632659
Validation loss: 3.401727394181855 MAE: 1.4629582
Validation loss: 3.8499214405916176 MAE: 1.5309544
Validation loss: 3.678341495747469 MAE: 1.4759175
Validation loss: 3.461374127134985 MAE: 1.4309164
75 0 3.151848316192627
Validation loss: 3.3000772729211922 MAE: 1.3843576
Validation loss: 2.97861318199002 MAE: 1.2857987
Validation loss: 2.727755926093277 MAE: 1.2033098
Validation loss: 2.543744928982793 MAE: 1.1729118
Validation loss: 2.4725194755865605 MAE: 1.1488966
Validation loss: 2.501471572992753 MAE: 1.1296479
Validation loss: 2.7001050345751705 MAE: 1.1919811
Validation loss: 2.9760135241917203 MAE: 1.2843475
Validation loss: 3.1372432368142262 MAE: 1.3389103
Validation loss: 3.2127654236190173 MAE: 1.3506713
Validation loss: 3.331333423147396 MAE: 1.3908128
Validation loss: 3.479586815347477 MAE: 1.43691
Validation loss: 3.1904751524633292 MAE: 1.3406554
Validation loss: 2.8940333882156684 MAE: 1.2425816
Validation loss: 2.4749641710398147 MAE: 1.1075095
Validation loss: 2.1465290857821095 MAE: 1.0413504
Validation loss: 2.153980386500456 MAE: 1.0625168
Validation loss: 2.2432941660589103 MAE: 1.1278124
Validation loss: 2.435823241058661 MAE: 1.2128582
Validation loss: 2.4270746270004584 MAE: 1.2231879
Validation loss: 2.428319181714739 MAE: 1.2320372
Validation loss: 2.4027784454579257 MAE: 1.2298346
Validation loss: 2.3492047932683207 MAE: 1.2145472
Validation loss: 2.1872957969198423 MAE: 1.1418673
Validation loss: 2.1602400030408586 MAE: 1.0961392
Loaded trained model with success.
Test loss: 5.983601326250848 Test MAE: 2.0221815
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 27.353763580322266
Validation loss: 8.732764282611885 MAE: 2.387434
Validation loss: 5.983100322761921 MAE: 2.0368812
Validation loss: 10.172939430583607 MAE: 2.6496909
Validation loss: 13.17618820884011 MAE: 3.0617151
Validation loss: 10.536930209458477 MAE: 2.7028368
Validation loss: 7.7103163015962854 MAE: 2.2786353
Validation loss: 5.61087440601503 MAE: 1.9862019
Validation loss: 5.688492507645578 MAE: 1.9885285
Validation loss: 5.902369622028235 MAE: 2.0077255
Validation loss: 6.002315786149767 MAE: 2.0157647
Validation loss: 5.99327515110825 MAE: 2.0200965
Validation loss: 5.870439512561066 MAE: 2.0171928
12 2 4.921060562133789
Validation loss: 5.93501203228729 MAE: 2.0336716
Validation loss: 6.064805844817498 MAE: 2.0601835
Validation loss: 5.816757414076063 MAE: 2.0166175
Validation loss: 5.874562696977095 MAE: 2.0128806
Validation loss: 6.246378716796335 MAE: 2.045449
Validation loss: 6.748333690142391 MAE: 2.1176667
Validation loss: 6.637083210126318 MAE: 2.1025255
Validation loss: 6.240418453409214 MAE: 2.054291
Validation loss: 5.842566846597074 MAE: 2.005829
Validation loss: 5.689583556820648 MAE: 1.991864
Validation loss: 5.734363800347453 MAE: 2.000754
Validation loss: 5.79875571318347 MAE: 2.0042143
Validation loss: 6.033466237964052 MAE: 2.0234013
25 0 7.135089874267578
Validation loss: 6.191914832953251 MAE: 2.0479417
Validation loss: 5.984304572596694 MAE: 2.0265052
Validation loss: 5.608812563347094 MAE: 1.9754333
Validation loss: 5.4831343877195104 MAE: 1.9529624
Validation loss: 5.490433726647888 MAE: 1.9540426
Validation loss: 5.51817926493558 MAE: 1.9586664
Validation loss: 5.5631441106699935 MAE: 1.9652299
Validation loss: 5.693928335652207 MAE: 1.9831518
Validation loss: 5.869677452125934 MAE: 2.0118105
Validation loss: 6.391564032044074 MAE: 2.08469
Validation loss: 6.031088973536636 MAE: 2.040993
Validation loss: 5.608021967338793 MAE: 1.9779603
37 2 4.230385780334473
Validation loss: 5.826418975386956 MAE: 2.0020928
Validation loss: 6.124246050613095 MAE: 2.0388856
Validation loss: 6.780180198977692 MAE: 2.1236258
Validation loss: 6.973441974081174 MAE: 2.1522756
Validation loss: 6.186024651382908 MAE: 2.0515788
Validation loss: 6.43805320335157 MAE: 2.0839303
Validation loss: 6.544034823022708 MAE: 2.0943959
Validation loss: 6.2987640433841285 MAE: 2.0625308
Validation loss: 6.372613502271248 MAE: 2.0716558
Validation loss: 5.797322378014073 MAE: 1.9920177
Validation loss: 5.998042121078029 MAE: 2.024004
Validation loss: 6.414410176903311 MAE: 2.080557
Validation loss: 6.4947931308939 MAE: 2.0872684
50 0 4.597626686096191
Validation loss: 6.468614038794931 MAE: 2.0824983
Validation loss: 5.996766928470496 MAE: 2.0273814
Validation loss: 6.013139570602263 MAE: 2.0217242
Validation loss: 5.734453740746084 MAE: 1.9791601
Validation loss: 5.6587205053579925 MAE: 1.9708216
Validation loss: 6.270845663667929 MAE: 2.0535944
Validation loss: 6.4227136939462985 MAE: 2.0686884
Validation loss: 5.574592790218315 MAE: 1.9539012
Validation loss: 4.342874526977539 MAE: 1.7253461
Validation loss: 4.353349497824004 MAE: 1.7368352
Validation loss: 4.886172954482261 MAE: 1.8384429
Validation loss: 5.255970945261946 MAE: 1.898638
62 2 4.93569278717041
Validation loss: 4.536476581385641 MAE: 1.7882236
Validation loss: 3.9337484258593935 MAE: 1.6548225
Validation loss: 3.8487432316096144 MAE: 1.6186138
Validation loss: 4.150536893594144 MAE: 1.6413078
Validation loss: 4.2977199289533825 MAE: 1.7141596
Validation loss: 5.327237095495667 MAE: 1.9307773
Validation loss: 5.5921841631032 MAE: 1.9786893
Validation loss: 5.989742233295633 MAE: 2.0673559
Validation loss: 7.629429740135116 MAE: 2.3542724
Validation loss: 5.668259668831873 MAE: 2.012232
Validation loss: 4.010356864543876 MAE: 1.6842557
Validation loss: 3.856497063781276 MAE: 1.68065
Validation loss: 3.8182580037550493 MAE: 1.6463876
75 0 3.864133596420288
Validation loss: 4.16210131181611 MAE: 1.6389674
Validation loss: 4.28863197926319 MAE: 1.6496925
Validation loss: 3.847621540830593 MAE: 1.5897694
Validation loss: 3.69969721153529 MAE: 1.5766923
Validation loss: 4.74231359513119 MAE: 1.7853663
Validation loss: 4.884263717766964 MAE: 1.8047214
Validation loss: 4.953092868881996 MAE: 1.8213617
Validation loss: 5.17479409051664 MAE: 1.8612219
Validation loss: 5.5822237296537915 MAE: 1.9020365
Validation loss: 4.919225815570716 MAE: 1.8015667
Validation loss: 4.588884228407735 MAE: 1.7614994
Validation loss: 5.44238527615865 MAE: 1.9322821
87 2 4.9740190505981445
Validation loss: 6.151343321559405 MAE: 2.0695746
Validation loss: 6.223724557895853 MAE: 2.0888622
Validation loss: 4.93672057354089 MAE: 1.8371444
Validation loss: 4.860515002048377 MAE: 1.8097975
Validation loss: 6.030680151298792 MAE: 1.9933363
Validation loss: 6.129200988345676 MAE: 2.0138428
Validation loss: 5.445272101296319 MAE: 1.8987281
Validation loss: 4.9299583338727855 MAE: 1.7797521
Validation loss: 5.362607624795702 MAE: 1.850394
Validation loss: 4.56591882127704 MAE: 1.7126669
Validation loss: 4.444256488722984 MAE: 1.7080935
Validation loss: 5.134216775797834 MAE: 1.8265028
Validation loss: 6.156105450909547 MAE: 2.026207
Loaded trained model with success.
Test loss: 5.213973038660023 Test MAE: 1.8042372
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 19.91950225830078
Validation loss: 6.215797489012905 MAE: 2.0714865
Validation loss: 10.838393196987747 MAE: 2.7244456
Validation loss: 8.071203663121516 MAE: 2.3541532
Validation loss: 6.239183135967159 MAE: 2.075725
Validation loss: 6.73717228252085 MAE: 2.153998
Validation loss: 6.967081375457534 MAE: 2.1623695
Validation loss: 5.579846398914279 MAE: 1.9690208
7 1 7.540300369262695
Validation loss: 5.479624796153313 MAE: 1.9642911
Validation loss: 5.6922123180561925 MAE: 2.0021675
Validation loss: 5.658765344763521 MAE: 2.0000887
Validation loss: 5.40889591188287 MAE: 1.9527658
Validation loss: 5.404414938921905 MAE: 1.9365706
Validation loss: 5.837950095459444 MAE: 1.9774985
Validation loss: 5.478527564499246 MAE: 1.9539561
14 2 6.344165802001953
Validation loss: 5.433634161350116 MAE: 1.9549785
Validation loss: 5.381766165920238 MAE: 1.9466964
Validation loss: 5.414313757239873 MAE: 1.9350874
Validation loss: 5.459655585600503 MAE: 1.9296896
Validation loss: 5.586056886605881 MAE: 1.9421448
Validation loss: 5.285390381837011 MAE: 1.9128749
Validation loss: 5.192558918766041 MAE: 1.9018371
21 3 4.073796272277832
Validation loss: 5.1076725559618 MAE: 1.8841105
Validation loss: 5.1803765440706036 MAE: 1.874305
Validation loss: 4.992249352249069 MAE: 1.8296462
Validation loss: 4.69540525561002 MAE: 1.7801391
Validation loss: 4.513703938105597 MAE: 1.7528026
Validation loss: 4.324275245618581 MAE: 1.710632
Validation loss: 4.488518603483037 MAE: 1.7503526
28 4 5.175137996673584
Validation loss: 4.510067337122395 MAE: 1.770235
Validation loss: 4.923442477556928 MAE: 1.8385249
Validation loss: 4.843717376191412 MAE: 1.8006034
Validation loss: 4.348267480955651 MAE: 1.6834116
Validation loss: 4.8953937549686914 MAE: 1.8097261
Validation loss: 4.252761385548654 MAE: 1.692423
Validation loss: 4.20599324739159 MAE: 1.7000281
35 5 3.7809078693389893
Validation loss: 4.1932556760970074 MAE: 1.6874353
Validation loss: 4.026644881646238 MAE: 1.6401008
Validation loss: 5.228986925815218 MAE: 1.7975084
Validation loss: 4.739192712846114 MAE: 1.7274796
Validation loss: 4.517403382152768 MAE: 1.7573411
Validation loss: 4.1546303303397485 MAE: 1.6763049
Validation loss: 4.0126315600907985 MAE: 1.6279247
42 6 4.737399101257324
Validation loss: 4.116306461880555 MAE: 1.6757362
Validation loss: 3.936013485319051 MAE: 1.635843
Validation loss: 4.030591646031518 MAE: 1.66125
Validation loss: 4.254476393886547 MAE: 1.7158753
Validation loss: 3.989934592989821 MAE: 1.6554023
Validation loss: 4.153885841369629 MAE: 1.6773303
Validation loss: 4.015197535855087 MAE: 1.6360811
Validation loss: 3.942090712600018 MAE: 1.6151112
50 0 4.7678117752075195
Validation loss: 4.091025563340691 MAE: 1.6527556
Validation loss: 4.316465327488118 MAE: 1.7185534
Validation loss: 3.9336614213397154 MAE: 1.6358933
Validation loss: 4.127338962938318 MAE: 1.6889695
Validation loss: 4.260209323173791 MAE: 1.7051963
Validation loss: 3.7701719921437937 MAE: 1.6036137
Validation loss: 4.193994546056393 MAE: 1.7045662
57 1 4.894230365753174
Validation loss: 4.113528685354108 MAE: 1.6722667
Validation loss: 3.748252976479842 MAE: 1.5846177
Validation loss: 3.90243989858196 MAE: 1.6234134
Validation loss: 4.050890236044649 MAE: 1.6627556
Validation loss: 4.544116283780966 MAE: 1.7782366
Validation loss: 3.757480158877732 MAE: 1.5964022
Validation loss: 4.008273257682072 MAE: 1.6325443
64 2 3.0671889781951904
Validation loss: 3.79483043248929 MAE: 1.5787305
Validation loss: 3.795052252822186 MAE: 1.5720768
Validation loss: 3.8746674288457363 MAE: 1.5991304
Validation loss: 4.155867108148546 MAE: 1.6610457
Validation loss: 3.8807806321723977 MAE: 1.6123335
Validation loss: 4.138076815772895 MAE: 1.6614699
Validation loss: 3.553230294929677 MAE: 1.541044
71 3 4.702189922332764
Validation loss: 3.6930404212606613 MAE: 1.567066
Validation loss: 4.0860997959597025 MAE: 1.636088
Validation loss: 3.572333879207247 MAE: 1.5349017
Validation loss: 3.650911412646423 MAE: 1.5628566
Validation loss: 3.825058182280267 MAE: 1.602462
Validation loss: 3.823064859188981 MAE: 1.578715
Validation loss: 3.5127334055589072 MAE: 1.5286243
78 4 4.043955326080322
Validation loss: 4.581393766642815 MAE: 1.7256448
Validation loss: 3.920641987767052 MAE: 1.6032352
Validation loss: 3.33722224786653 MAE: 1.4949871
Validation loss: 3.459516341961808 MAE: 1.5265446
Validation loss: 3.564477571290941 MAE: 1.5485736
Validation loss: 3.7380370566593344 MAE: 1.5687814
Validation loss: 3.5508914928340434 MAE: 1.5314438
85 5 3.9206478595733643
Validation loss: 3.967758310500102 MAE: 1.6348635
Validation loss: 5.569872978344635 MAE: 1.9710855
Validation loss: 4.547784431495858 MAE: 1.7747167
Validation loss: 3.7503947840264096 MAE: 1.5806173
Validation loss: 4.122544059801341 MAE: 1.6734128
Validation loss: 4.916997427916407 MAE: 1.851035
Validation loss: 4.68778414462679 MAE: 1.796466
92 6 4.070927143096924
Validation loss: 4.416115717672223 MAE: 1.7287148
Validation loss: 3.7558181465570653 MAE: 1.5899364
Validation loss: 4.9178083673793465 MAE: 1.8167793
Validation loss: 3.5101377161303957 MAE: 1.5167559
Validation loss: 3.5028568763828756 MAE: 1.5118194
Validation loss: 3.61534649043826 MAE: 1.5342759
Validation loss: 4.352051474940238 MAE: 1.7111025
Validation loss: 4.51814133917267 MAE: 1.7606773
Loaded trained model with success.
Test loss: 4.869491504932565 Test MAE: 1.7860687
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 21.538105010986328
Validation loss: 21.23812786706225 MAE: 4.0770874
Validation loss: 5.627647591975027 MAE: 1.9845635
Validation loss: 5.322557620390622 MAE: 1.9232006
3 2 5.093134880065918
Validation loss: 5.364256002621087 MAE: 1.945507
Validation loss: 5.335596544231346 MAE: 1.9483664
Validation loss: 5.364214722283617 MAE: 1.9176553
6 4 4.6681718826293945
Validation loss: 5.122214248519622 MAE: 1.8770722
Validation loss: 4.990735845240897 MAE: 1.8654741
Validation loss: 4.931413451273121 MAE: 1.8482275
9 6 5.904933929443359
Validation loss: 4.737100568228589 MAE: 1.8016746
Validation loss: 4.789509630872157 MAE: 1.8106692
Validation loss: 4.434684996136682 MAE: 1.7534977
12 8 7.465415954589844
Validation loss: 4.303248114958555 MAE: 1.7372291
Validation loss: 4.195680558084247 MAE: 1.7006748
Validation loss: 4.307571303629445 MAE: 1.7189769
15 10 6.3933868408203125
Validation loss: 4.422622262117619 MAE: 1.7563672
Validation loss: 4.28629871265205 MAE: 1.7056664
Validation loss: 9.369285036901195 MAE: 2.5159533
18 12 5.8868513107299805
Validation loss: 6.465813452351786 MAE: 2.0428276
Validation loss: 5.821475793460089 MAE: 1.9289135
Validation loss: 9.361003168599161 MAE: 2.544616
21 14 2.8915209770202637
Validation loss: 12.54892868508318 MAE: 3.043212
Validation loss: 6.432368354950257 MAE: 2.0269394
Validation loss: 6.523330053012214 MAE: 2.044871
Validation loss: 4.650859806962863 MAE: 1.7617894
25 0 4.131178379058838
Validation loss: 4.57195060668823 MAE: 1.7389939
Validation loss: 6.65737872802184 MAE: 2.0830483
Validation loss: 5.690154334586226 MAE: 1.920521
28 2 4.07307243347168
Validation loss: 5.740483310752976 MAE: 1.9293536
Validation loss: 5.343216710195752 MAE: 1.856004
Validation loss: 8.081762758190026 MAE: 2.348353
31 4 3.2780022621154785
Validation loss: 6.772169587129581 MAE: 2.1248271
Validation loss: 7.269737257030541 MAE: 2.2187212
Validation loss: 4.461344025178041 MAE: 1.6856657
34 6 4.277689456939697
Validation loss: 4.652423081751577 MAE: 1.7013644
Validation loss: 4.5883509080730125 MAE: 1.703492
Validation loss: 4.15057637744055 MAE: 1.6347789
37 8 3.346587657928467
Validation loss: 6.691788480372611 MAE: 2.1154943
Validation loss: 5.099162569982494 MAE: 1.8184035
Validation loss: 5.381124293875837 MAE: 1.8644347
40 10 4.945868492126465
Validation loss: 5.964929004470427 MAE: 1.9746177
Validation loss: 3.973845186596643 MAE: 1.5808573
Validation loss: 5.097371565793941 MAE: 1.8145275
43 12 4.859776973724365
Validation loss: 4.396043844356805 MAE: 1.693737
Validation loss: 4.357333526343764 MAE: 1.6542348
Validation loss: 3.547147767577238 MAE: 1.5178896
46 14 2.913661003112793
Validation loss: 5.112832446375448 MAE: 1.8170036
Validation loss: 3.6974125204678767 MAE: 1.5163478
Validation loss: 5.144786318700634 MAE: 1.8117862
Validation loss: 3.8747854911253783 MAE: 1.5708866
50 0 3.7347686290740967
Validation loss: 4.0897650326898916 MAE: 1.6108
Validation loss: 4.036345414981574 MAE: 1.598954
Validation loss: 4.2627437119493505 MAE: 1.6341885
53 2 4.245956897735596
Validation loss: 4.0044558712380205 MAE: 1.5756345
Validation loss: 4.090871927972308 MAE: 1.601791
Validation loss: 4.078927158114905 MAE: 1.600166
56 4 3.4412598609924316
Validation loss: 3.5645655754333987 MAE: 1.474172
Validation loss: 3.6005481918732483 MAE: 1.4982501
Validation loss: 3.54361277543949 MAE: 1.4946789
59 6 4.451760292053223
Validation loss: 4.127601288602443 MAE: 1.6204954
Validation loss: 3.9133307078558364 MAE: 1.5633438
Validation loss: 3.9822768123450882 MAE: 1.5766941
62 8 4.8078389167785645
Validation loss: 3.679788135813329 MAE: 1.5012941
Validation loss: 4.012291105572351 MAE: 1.5864567
Validation loss: 3.9488034339132674 MAE: 1.5887254
65 10 4.8380208015441895
Validation loss: 3.395131242060231 MAE: 1.4393054
Validation loss: 3.349284866768755 MAE: 1.4375584
Validation loss: 3.3899242395389533 MAE: 1.472374
68 12 5.334393501281738
Validation loss: 3.1756813502263928 MAE: 1.4191964
Validation loss: 3.227408965269406 MAE: 1.4224098
Validation loss: 3.3262356278413763 MAE: 1.4515837
71 14 2.842315435409546
Validation loss: 3.1857951103088133 MAE: 1.4448198
Validation loss: 3.600320726215003 MAE: 1.5127223
Validation loss: 3.167947769165039 MAE: 1.4276873
Validation loss: 3.321537447357942 MAE: 1.4281558
75 0 4.073482513427734
Validation loss: 3.3142504357622715 MAE: 1.4619182
Validation loss: 3.4276383773597305 MAE: 1.4706466
Validation loss: 3.874855028603502 MAE: 1.5693048
78 2 4.286965370178223
Validation loss: 3.3095824348185965 MAE: 1.4468104
Validation loss: 3.4705092768392007 MAE: 1.4482383
Validation loss: 3.840810652486308 MAE: 1.574681
81 4 3.0598597526550293
Validation loss: 3.4597739781549794 MAE: 1.4752009
Validation loss: 3.5588579282970847 MAE: 1.5215346
Validation loss: 3.337374340317292 MAE: 1.4440575
84 6 4.306936264038086
Validation loss: 3.2995497028908893 MAE: 1.4210271
Validation loss: 3.1013870124587553 MAE: 1.4218829
Validation loss: 2.9984995583016314 MAE: 1.360617
87 8 3.834813356399536
Validation loss: 3.545775438836199 MAE: 1.4953592
Validation loss: 3.20410043060899 MAE: 1.4243536
Validation loss: 3.3818074414629735 MAE: 1.4515116
90 10 3.1716678142547607
Validation loss: 3.166744346847993 MAE: 1.4061037
Validation loss: 3.1948251662130107 MAE: 1.4368671
Validation loss: 2.9325861620281883 MAE: 1.3685112
93 12 2.51162052154541
Validation loss: 2.9782853288975413 MAE: 1.3672159
Validation loss: 3.285315747729284 MAE: 1.4249842
Validation loss: 3.0523338781330054 MAE: 1.3739021
96 14 2.3240885734558105
Validation loss: 3.6403131284312398 MAE: 1.5189451
Validation loss: 3.0648610114095685 MAE: 1.3808337
Validation loss: 2.7395000639324913 MAE: 1.3235186
Validation loss: 3.360501754737808 MAE: 1.4523124
Loaded trained model with success.
Test loss: 3.8376091802399293 Test MAE: 1.60356
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999848297979177, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 659177
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999241489895887, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 659137
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9998482979791774, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 659087
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9996965959583548, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 658987
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9992414898958869, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 658687
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9984829797917738, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 999, Valid size: 999, Test size: 658187
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9751861042183623, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 380
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9503722084367245, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 19, Valid size: 19, Test size: 370
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8759305210918115, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 48, Valid size: 48, Test size: 341
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7518610421836228, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 96, Valid size: 96, Test size: 293
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5037220843672456, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 193, Valid size: 193, Test size: 196
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 589
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 549
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 499
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 99
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 17.617664337158203
Validation loss: 14.411128997802734 MAE: 3.328907
Validation loss: 11.244260787963867 MAE: 2.8133597
Validation loss: 8.593582153320312 MAE: 2.3558064
Validation loss: 6.461202144622803 MAE: 2.0643623
Validation loss: 4.946909427642822 MAE: 1.8254852
Validation loss: 3.9938344955444336 MAE: 1.6732804
Validation loss: 3.487961769104004 MAE: 1.5602232
Validation loss: 3.328444004058838 MAE: 1.6062589
Validation loss: 3.4605798721313477 MAE: 1.6449289
Validation loss: 3.71787428855896 MAE: 1.6737813
Validation loss: 3.94258713722229 MAE: 1.6914492
Validation loss: 4.001397132873535 MAE: 1.6954943
Validation loss: 3.920574188232422 MAE: 1.6898717
Validation loss: 3.782475709915161 MAE: 1.6798564
Validation loss: 3.597097635269165 MAE: 1.6634469
Validation loss: 3.438429117202759 MAE: 1.6415697
Validation loss: 3.3578343391418457 MAE: 1.6177564
Validation loss: 3.356837749481201 MAE: 1.5903223
Validation loss: 3.4518959522247314 MAE: 1.5640253
Validation loss: 3.6186931133270264 MAE: 1.5813775
Validation loss: 3.8223812580108643 MAE: 1.6354209
Validation loss: 4.074671745300293 MAE: 1.6886997
Validation loss: 4.36163330078125 MAE: 1.739324
Validation loss: 4.628260135650635 MAE: 1.7804027
Validation loss: 4.847731590270996 MAE: 1.8111348
Validation loss: 5.071872234344482 MAE: 1.8392309
Validation loss: 5.234189987182617 MAE: 1.859757
Validation loss: 5.26576042175293 MAE: 1.8686758
Validation loss: 5.210606575012207 MAE: 1.8594908
Validation loss: 5.1420159339904785 MAE: 1.8479337
Validation loss: 5.031031608581543 MAE: 1.8270452
Validation loss: 4.84187126159668 MAE: 1.7905483
Validation loss: 4.684641361236572 MAE: 1.760134
Validation loss: 4.4351325035095215 MAE: 1.7151141
Validation loss: 4.140766620635986 MAE: 1.6657767
Validation loss: 3.73949933052063 MAE: 1.5909543
Validation loss: 3.331610679626465 MAE: 1.5063539
Validation loss: 2.9092633724212646 MAE: 1.4054415
Validation loss: 2.5973732471466064 MAE: 1.3188394
Validation loss: 2.398928642272949 MAE: 1.2762207
Validation loss: 2.147045612335205 MAE: 1.2214667
Validation loss: 1.9376752376556396 MAE: 1.1541352
Validation loss: 1.8404507637023926 MAE: 1.097624
Validation loss: 1.8199876546859741 MAE: 1.0665016
Validation loss: 1.9541668891906738 MAE: 1.1448431
Validation loss: 2.2575020790100098 MAE: 1.290787
Validation loss: 2.678084373474121 MAE: 1.4608061
Validation loss: 3.6338016986846924 MAE: 1.7615781
Validation loss: 5.227353572845459 MAE: 2.1132889
Validation loss: 7.388631343841553 MAE: 2.4747534
50 0 2.344045400619507
Validation loss: 9.088654518127441 MAE: 2.7092943
Validation loss: 10.24300765991211 MAE: 2.8531444
Validation loss: 9.038257598876953 MAE: 2.69818
Validation loss: 9.751347541809082 MAE: 2.793753
Validation loss: 9.33066463470459 MAE: 2.7374725
Validation loss: 8.827098846435547 MAE: 2.6688087
Validation loss: 8.138943672180176 MAE: 2.573645
Validation loss: 7.410856246948242 MAE: 2.4709578
Validation loss: 6.818136692047119 MAE: 2.381538
Validation loss: 6.007805824279785 MAE: 2.2500677
Validation loss: 5.704732894897461 MAE: 2.2047222
Validation loss: 5.883727073669434 MAE: 2.2446568
Validation loss: 5.913962364196777 MAE: 2.2561607
Validation loss: 6.254912853240967 MAE: 2.3207166
Validation loss: 6.291145324707031 MAE: 2.3295107
Validation loss: 6.544756889343262 MAE: 2.3781781
Validation loss: 7.7236328125 MAE: 2.567871
Validation loss: 8.289209365844727 MAE: 2.6505325
Validation loss: 8.629276275634766 MAE: 2.697079
Validation loss: 9.492765426635742 MAE: 2.810793
Validation loss: 10.132667541503906 MAE: 2.8981023
Validation loss: 11.106170654296875 MAE: 3.0385644
Validation loss: 12.723896026611328 MAE: 3.2700493
Validation loss: 15.119754791259766 MAE: 3.5934796
Validation loss: 15.922003746032715 MAE: 3.6906137
Validation loss: 16.567520141601562 MAE: 3.7725286
Validation loss: 15.95095157623291 MAE: 3.7128847
Validation loss: 16.033016204833984 MAE: 3.7358077
Validation loss: 15.645978927612305 MAE: 3.6986248
Validation loss: 15.73202896118164 MAE: 3.7190793
Validation loss: 15.582356452941895 MAE: 3.7047348
Validation loss: 14.234539031982422 MAE: 3.5359333
Validation loss: 13.869308471679688 MAE: 3.4874263
Validation loss: 12.953632354736328 MAE: 3.3648577
Validation loss: 11.877694129943848 MAE: 3.216902
Validation loss: 10.212615966796875 MAE: 2.9722266
Validation loss: 8.924579620361328 MAE: 2.7619476
Validation loss: 7.565823078155518 MAE: 2.5216696
Validation loss: 6.53419828414917 MAE: 2.3257697
Validation loss: 5.944660663604736 MAE: 2.207732
Validation loss: 5.852788925170898 MAE: 2.1963618
Validation loss: 6.013413906097412 MAE: 2.2347658
Validation loss: 6.839877128601074 MAE: 2.4083278
Validation loss: 7.805100440979004 MAE: 2.597946
Validation loss: 8.408695220947266 MAE: 2.7110014
Validation loss: 8.020259857177734 MAE: 2.647029
Validation loss: 7.9854254722595215 MAE: 2.6466122
Validation loss: 7.711433410644531 MAE: 2.6005664
Validation loss: 6.996284484863281 MAE: 2.4774075
Validation loss: 6.981194496154785 MAE: 2.4804635
Loaded trained model with success.
Test loss: 8.638265441445743 Test MAE: 2.415557
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 24.516433715820312
Validation loss: 16.253551463691554 MAE: 3.3502614
Validation loss: 9.246883723200584 MAE: 2.3906648
Validation loss: 5.850361619676862 MAE: 2.02965
Validation loss: 6.841893546435298 MAE: 2.1980512
Validation loss: 12.207176227958835 MAE: 2.9340982
Validation loss: 19.497491388904805 MAE: 3.8319316
Validation loss: 22.915105235819915 MAE: 4.227611
Validation loss: 21.413956233433314 MAE: 4.063299
Validation loss: 17.378404383756678 MAE: 3.5948243
Validation loss: 13.70099281778141 MAE: 3.1346025
Validation loss: 10.650227916483976 MAE: 2.7479882
Validation loss: 8.676757033990354 MAE: 2.4726224
Validation loss: 7.297291463735152 MAE: 2.2629373
Validation loss: 6.631045925373933 MAE: 2.1557043
Validation loss: 6.395655612556302 MAE: 2.1218839
Validation loss: 6.321117858497464 MAE: 2.1083922
Validation loss: 6.3571345076269035 MAE: 2.1113107
Validation loss: 6.692923652882478 MAE: 2.1688774
Validation loss: 7.211495633027991 MAE: 2.2525504
Validation loss: 7.710254241009148 MAE: 2.3341362
Validation loss: 7.846168595917371 MAE: 2.3498564
Validation loss: 8.13397656654825 MAE: 2.3898976
Validation loss: 8.81952716866318 MAE: 2.4800072
Validation loss: 8.380636760166713 MAE: 2.416269
Validation loss: 7.9544722498679645 MAE: 2.353464
25 0 4.857870578765869
Validation loss: 7.3008142490776216 MAE: 2.2589023
Validation loss: 6.245974618561414 MAE: 2.0930042
Validation loss: 5.7805103574480325 MAE: 2.0204074
Validation loss: 5.425808410255277 MAE: 1.9677219
Validation loss: 5.296451403170216 MAE: 1.9573691
Validation loss: 5.27151007554969 MAE: 1.9620407
Validation loss: 5.294115241692991 MAE: 1.9659564
Validation loss: 5.325672777331605 MAE: 1.9679276
Validation loss: 5.371061412655577 MAE: 1.9732561
Validation loss: 5.386568594952019 MAE: 1.9734027
Validation loss: 5.372369522951087 MAE: 1.9714401
Validation loss: 5.356667703511763 MAE: 1.9716102
Validation loss: 5.3738284938189445 MAE: 1.9738109
Validation loss: 5.397411589719812 MAE: 1.976318
Validation loss: 5.408976983050911 MAE: 1.9776671
Validation loss: 5.378379763389121 MAE: 1.971634
Validation loss: 5.3423845719318 MAE: 1.966767
Validation loss: 5.308431566977988 MAE: 1.9611825
Validation loss: 5.290469782693045 MAE: 1.9590133
Validation loss: 5.248855834104577 MAE: 1.9539217
Validation loss: 5.222802103782187 MAE: 1.9499527
Validation loss: 5.184073311941964 MAE: 1.9422812
Validation loss: 5.1511260830626195 MAE: 1.9346966
Validation loss: 5.126375957411163 MAE: 1.9295485
Validation loss: 5.065941888458875 MAE: 1.9184657
50 0 6.637382984161377
Validation loss: 4.97432161837208 MAE: 1.9004691
Validation loss: 4.918303742700694 MAE: 1.8904504
Validation loss: 4.87032581835377 MAE: 1.8779156
Validation loss: 4.821136980640645 MAE: 1.8623495
Validation loss: 4.773719077207605 MAE: 1.8401561
Validation loss: 4.717618329184396 MAE: 1.8012524
Validation loss: 4.940546814276248 MAE: 1.808464
Validation loss: 5.041485314466516 MAE: 1.8034698
Validation loss: 4.514698797342729 MAE: 1.7065471
Validation loss: 4.189837290316212 MAE: 1.6466416
Validation loss: 3.984040917182455 MAE: 1.6082351
Validation loss: 3.9459122978911108 MAE: 1.6126968
Validation loss: 3.940813025649713 MAE: 1.6304601
Validation loss: 3.9653851304735457 MAE: 1.6455555
Validation loss: 4.846258435930524 MAE: 1.7976605
Validation loss: 4.691737369615204 MAE: 1.779637
Validation loss: 4.671358259356752 MAE: 1.7907547
Validation loss: 4.875054485943853 MAE: 1.8150634
Validation loss: 4.9885748259875236 MAE: 1.8285624
Validation loss: 4.676208934005426 MAE: 1.7666442
Validation loss: 4.510534101602983 MAE: 1.7333939
Validation loss: 4.791446111640152 MAE: 1.7874767
Validation loss: 5.217930346119161 MAE: 1.8707911
Validation loss: 5.545146475032884 MAE: 1.9347385
Validation loss: 5.273073391038544 MAE: 1.8948444
75 0 3.312429189682007
Validation loss: 5.285210560779182 MAE: 1.8899237
Validation loss: 5.22944966627627 MAE: 1.8623476
Validation loss: 5.0268058387600645 MAE: 1.8157783
Validation loss: 5.003987292854154 MAE: 1.8118778
Validation loss: 5.21604382261938 MAE: 1.8347635
Validation loss: 6.130833119762187 MAE: 1.9845033
Validation loss: 7.01948560014063 MAE: 2.1478267
Validation loss: 7.128127896055883 MAE: 2.1739182
Validation loss: 6.802238629788769 MAE: 2.1338747
Validation loss: 6.822365245040582 MAE: 2.1459203
Validation loss: 6.442577381523288 MAE: 2.0897036
Validation loss: 6.090535115222542 MAE: 2.0360248
Validation loss: 5.505013310179418 MAE: 1.9382328
Validation loss: 4.844379921348727 MAE: 1.7938018
Validation loss: 3.9414912145964953 MAE: 1.5997049
Validation loss: 3.666897569383894 MAE: 1.5405663
Validation loss: 3.294201743846037 MAE: 1.4473888
Validation loss: 3.3073408165756537 MAE: 1.4512802
Validation loss: 3.6024428046479517 MAE: 1.5220516
Validation loss: 3.7650020657753456 MAE: 1.5638393
Validation loss: 4.109188907000483 MAE: 1.6316248
Validation loss: 5.0851993268849895 MAE: 1.8227302
Validation loss: 6.183306703762132 MAE: 1.9943701
Validation loss: 5.966962220717449 MAE: 1.9521301
Validation loss: 5.588608070295685 MAE: 1.8711761
Loaded trained model with success.
Test loss: 6.274037772462568 Test MAE: 2.0439754
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 15.963935852050781
Validation loss: 6.646981034616028 MAE: 2.10471
Validation loss: 6.558685331633597 MAE: 2.1147678
Validation loss: 10.864327199531324 MAE: 2.716021
Validation loss: 13.456941166309395 MAE: 3.094413
Validation loss: 10.614925731312145 MAE: 2.6892235
Validation loss: 7.110894771537396 MAE: 2.1983147
Validation loss: 5.518310443319455 MAE: 1.956547
Validation loss: 5.084483531990436 MAE: 1.9159561
Validation loss: 5.11608592909996 MAE: 1.9251114
Validation loss: 5.077025382205694 MAE: 1.9050754
Validation loss: 5.199903199166963 MAE: 1.905777
Validation loss: 5.250990241464942 MAE: 1.9151747
12 2 4.8445892333984375
Validation loss: 5.125131544440683 MAE: 1.9037132
Validation loss: 5.2098749141500456 MAE: 1.9361267
Validation loss: 5.591929806603326 MAE: 1.9895725
Validation loss: 5.821140356738158 MAE: 2.0124578
Validation loss: 5.541128678755327 MAE: 1.9838778
Validation loss: 5.295612036579787 MAE: 1.9529041
Validation loss: 5.111657219703751 MAE: 1.9194571
Validation loss: 5.077689642858023 MAE: 1.9126904
Validation loss: 5.197614234806311 MAE: 1.9382913
Validation loss: 5.54768142796526 MAE: 1.9834524
Validation loss: 6.155170515330151 MAE: 2.0461454
Validation loss: 6.312704380112465 MAE: 2.0668776
Validation loss: 5.893102828902427 MAE: 2.016808
25 0 5.234981536865234
Validation loss: 5.632858420863296 MAE: 1.9921012
Validation loss: 5.607732209292325 MAE: 1.9888357
Validation loss: 5.785518429496071 MAE: 2.0048544
Validation loss: 6.021242122457485 MAE: 2.0312634
Validation loss: 5.764638620193558 MAE: 2.002933
Validation loss: 6.1552417495033955 MAE: 2.0483687
Validation loss: 6.17772321990042 MAE: 2.0505614
Validation loss: 5.622119927647138 MAE: 1.9876148
Validation loss: 5.286566951058128 MAE: 1.9496958
Validation loss: 4.9976706263994926 MAE: 1.8998148
Validation loss: 5.181776137062998 MAE: 1.9360013
Validation loss: 5.5943225495743025 MAE: 1.9841487
37 2 4.516878604888916
Validation loss: 6.164773618332063 MAE: 2.0538266
Validation loss: 6.127339497961179 MAE: 2.0502124
Validation loss: 5.761036641669996 MAE: 2.0043912
Validation loss: 5.529900141436644 MAE: 1.9763424
Validation loss: 5.7738145577787146 MAE: 2.0062132
Validation loss: 6.064011573791504 MAE: 2.0411928
Validation loss: 6.570655013575698 MAE: 2.11265
Validation loss: 7.252296929407602 MAE: 2.21398
Validation loss: 7.528691494103634 MAE: 2.2569497
Validation loss: 6.841536517095084 MAE: 2.152077
Validation loss: 6.153439770443271 MAE: 2.0547671
Validation loss: 6.109104168535483 MAE: 2.0520818
Validation loss: 6.368225617842241 MAE: 2.087628
50 0 5.227987289428711
Validation loss: 6.725887365413435 MAE: 2.1376123
Validation loss: 6.227631612257524 MAE: 2.0734992
Validation loss: 5.495497154467033 MAE: 1.9834579
Validation loss: 4.940390267155387 MAE: 1.9074895
Validation loss: 4.557144988666881 MAE: 1.8384538
Validation loss: 4.617102343626697 MAE: 1.8482714
Validation loss: 4.984967462944262 MAE: 1.9070891
Validation loss: 5.056924323842983 MAE: 1.9106004
Validation loss: 5.009393027334502 MAE: 1.8902358
Validation loss: 5.434841151189322 MAE: 1.9623607
Validation loss: 5.603038667428373 MAE: 1.9866905
Validation loss: 4.53599811804415 MAE: 1.8114775
62 2 4.76784610748291
Validation loss: 4.183694957482694 MAE: 1.7303649
Validation loss: 4.238323476579454 MAE: 1.7354169
Validation loss: 4.405233496367329 MAE: 1.7427156
Validation loss: 4.6390179284293245 MAE: 1.7549143
Validation loss: 3.965210189723005 MAE: 1.6775622
Validation loss: 4.54530306536742 MAE: 1.8112179
Validation loss: 4.964532529464876 MAE: 1.8625215
Validation loss: 5.09932908385691 MAE: 1.8809431
Validation loss: 5.165890987473305 MAE: 1.9023257
Validation loss: 5.706815295749241 MAE: 1.9908652
Validation loss: 5.566987333875714 MAE: 1.9696392
Validation loss: 4.5505850592044865 MAE: 1.7875586
Validation loss: 3.922327039217708 MAE: 1.65433
75 0 4.450870990753174
Validation loss: 3.7759072286914095 MAE: 1.631809
Validation loss: 3.6494114696979523 MAE: 1.6002308
Validation loss: 3.5897734622762663 MAE: 1.582516
Validation loss: 3.5699110560946994 MAE: 1.5785999
Validation loss: 3.586773406375538 MAE: 1.5765433
Validation loss: 3.8864452935228444 MAE: 1.6131796
Validation loss: 4.469335382634943 MAE: 1.7182711
Validation loss: 4.1880789332919655 MAE: 1.704021
Validation loss: 4.0537419030160615 MAE: 1.7071764
Validation loss: 4.165166927106453 MAE: 1.7313787
Validation loss: 4.090136012645683 MAE: 1.7007198
Validation loss: 3.9444432547598174 MAE: 1.6599725
87 2 2.733259677886963
Validation loss: 3.808660858809346 MAE: 1.6261421
Validation loss: 3.8792668448554144 MAE: 1.6210105
Validation loss: 3.972414402046589 MAE: 1.6385235
Validation loss: 4.359234843591247 MAE: 1.7040627
Validation loss: 3.9548782170420944 MAE: 1.6464481
Validation loss: 3.668865811343145 MAE: 1.5919789
Validation loss: 3.76100106913634 MAE: 1.599497
Validation loss: 3.9194792978691333 MAE: 1.6312076
Validation loss: 4.9848338618423 MAE: 1.8637885
Validation loss: 5.031239456600613 MAE: 1.8665473
Validation loss: 3.873759611688479 MAE: 1.5931766
Validation loss: 3.3637534440165817 MAE: 1.5199417
Validation loss: 3.7491519234397193 MAE: 1.5996057
Loaded trained model with success.
Test loss: 4.4597071397280645 Test MAE: 1.7309313
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 30.670024871826172
Validation loss: 5.836335340336938 MAE: 2.0291579
Validation loss: 18.19194861752304 MAE: 3.7122178
Validation loss: 8.014513533319061 MAE: 2.3247583
Validation loss: 5.581398542202897 MAE: 1.9699323
Validation loss: 5.893852876059374 MAE: 2.0172453
Validation loss: 5.659011943855477 MAE: 1.9891615
Validation loss: 5.588643172278476 MAE: 1.9776479
7 1 4.844992160797119
Validation loss: 5.739579768636119 MAE: 2.009939
Validation loss: 6.17870116353634 MAE: 2.0899837
Validation loss: 6.111285576269255 MAE: 2.0741408
Validation loss: 6.661778013909881 MAE: 2.167061
Validation loss: 6.730548651973207 MAE: 2.1793115
Validation loss: 5.596959145224873 MAE: 1.9804534
Validation loss: 5.5608245451845715 MAE: 1.9643052
14 2 5.3016462326049805
Validation loss: 5.426649772941167 MAE: 1.9441152
Validation loss: 5.545238998068038 MAE: 1.9744403
Validation loss: 6.173261740698886 MAE: 2.0939426
Validation loss: 5.407729079375914 MAE: 1.945457
Validation loss: 5.142672454891493 MAE: 1.8872133
Validation loss: 4.996929465226792 MAE: 1.8572679
Validation loss: 4.914918576053639 MAE: 1.8368691
21 3 4.8956451416015625
Validation loss: 4.866056621973239 MAE: 1.8475552
Validation loss: 5.377886878785176 MAE: 1.9711206
Validation loss: 4.999415294608879 MAE: 1.9033326
Validation loss: 5.466552894918164 MAE: 1.9772842
Validation loss: 4.615133340634293 MAE: 1.802632
Validation loss: 4.515840004436934 MAE: 1.7763773
Validation loss: 4.481553509007746 MAE: 1.7033182
28 4 4.7169036865234375
Validation loss: 5.526164605988929 MAE: 1.8823835
Validation loss: 5.686507735420112 MAE: 1.8880872
Validation loss: 4.828873241367052 MAE: 1.7469765
Validation loss: 7.250536499310978 MAE: 2.1787975
Validation loss: 6.477036258084091 MAE: 2.0451539
Validation loss: 4.609699559571156 MAE: 1.7253289
Validation loss: 4.306212338969935 MAE: 1.6642374
35 5 3.4655139446258545
Validation loss: 4.149663709515902 MAE: 1.6288586
Validation loss: 4.596479010941395 MAE: 1.7514541
Validation loss: 5.888021991480535 MAE: 2.0149944
Validation loss: 3.56255765656131 MAE: 1.5728937
Validation loss: 4.355302212825372 MAE: 1.6682559
Validation loss: 5.762685083264682 MAE: 1.9370469
Validation loss: 5.128222851297963 MAE: 1.8118771
42 6 5.4989519119262695
Validation loss: 4.651897825787415 MAE: 1.717518
Validation loss: 3.4834994622810402 MAE: 1.4734664
Validation loss: 3.7374737610169992 MAE: 1.5188854
Validation loss: 4.5925949770002505 MAE: 1.6918101
Validation loss: 4.0464432479149135 MAE: 1.5829784
Validation loss: 3.6684974036624083 MAE: 1.5092549
Validation loss: 3.6895949277446496 MAE: 1.5459764
Validation loss: 3.287621029657335 MAE: 1.4612657
50 0 4.028255462646484
Validation loss: 3.561087096755828 MAE: 1.4963921
Validation loss: 3.247025997794453 MAE: 1.4486259
Validation loss: 4.1002779905520494 MAE: 1.6946515
Validation loss: 4.4966026083308845 MAE: 1.7527851
Validation loss: 3.3214374211565336 MAE: 1.4545969
Validation loss: 3.2402344037539996 MAE: 1.4419571
Validation loss: 3.7913084988618015 MAE: 1.5429559
57 1 4.368466377258301
Validation loss: 5.2379457339569555 MAE: 1.8545371
Validation loss: 3.628351762666175 MAE: 1.4869198
Validation loss: 3.171702375364064 MAE: 1.425626
Validation loss: 3.004914397570356 MAE: 1.4136941
Validation loss: 2.9543661687841367 MAE: 1.4275398
Validation loss: 3.034101967835546 MAE: 1.4480716
Validation loss: 3.0676542358781824 MAE: 1.4213878
64 2 3.6533584594726562
Validation loss: 3.032488175972023 MAE: 1.4371905
Validation loss: 3.065349101421222 MAE: 1.4051664
Validation loss: 3.359748009461254 MAE: 1.4511958
Validation loss: 3.1246487758866506 MAE: 1.4154887
Validation loss: 2.952393722294563 MAE: 1.3841923
Validation loss: 3.0238819829183607 MAE: 1.4146879
Validation loss: 3.205146079087377 MAE: 1.4359459
71 3 3.2139058113098145
Validation loss: 5.399691744665405 MAE: 1.8916076
Validation loss: 4.710638636919721 MAE: 1.7510998
Validation loss: 3.3659532034217414 MAE: 1.4627506
Validation loss: 2.992143041524456 MAE: 1.3871803
Validation loss: 2.857433043532635 MAE: 1.3599896
Validation loss: 2.8103900279232006 MAE: 1.3564522
Validation loss: 2.9506746584446586 MAE: 1.3767829
78 4 2.819620132446289
Validation loss: 2.8208360300591244 MAE: 1.3617098
Validation loss: 3.046081055348842 MAE: 1.3988862
Validation loss: 2.758231330756566 MAE: 1.3517144
Validation loss: 2.9582808245366543 MAE: 1.3759096
Validation loss: 2.8966551509933853 MAE: 1.3828349
Validation loss: 2.676745790932047 MAE: 1.3498574
Validation loss: 2.8269650720471713 MAE: 1.386427
85 5 3.0211760997772217
Validation loss: 3.0922143087914242 MAE: 1.4103333
Validation loss: 2.971162459059576 MAE: 1.3670018
Validation loss: 2.7654362036355176 MAE: 1.3179228
Validation loss: 2.6202494786612354 MAE: 1.3088534
Validation loss: 2.802985177567257 MAE: 1.3431761
Validation loss: 3.545644615762797 MAE: 1.4927418
Validation loss: 3.5201016179281264 MAE: 1.478211
92 6 3.3945956230163574
Validation loss: 3.899574206702074 MAE: 1.5606508
Validation loss: 3.377074766398674 MAE: 1.4284327
Validation loss: 3.1799439269693655 MAE: 1.404626
Validation loss: 3.9615988635537613 MAE: 1.5890958
Validation loss: 3.838067054748535 MAE: 1.5650693
Validation loss: 2.5397075133108014 MAE: 1.2625326
Validation loss: 2.827065624184345 MAE: 1.3156396
Validation loss: 2.710608140907096 MAE: 1.2978879
Loaded trained model with success.
Test loss: 5.381915408943703 Test MAE: 1.8562096
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 18.649513244628906
Validation loss: 7.756934169776931 MAE: 2.2639637
Validation loss: 6.203879193934744 MAE: 2.0675595
Validation loss: 10.517220124453008 MAE: 2.6835134
3 2 3.971675395965576
Validation loss: 5.811118704044747 MAE: 2.0091922
Validation loss: 5.78021175445679 MAE: 2.0104518
Validation loss: 6.004962220698416 MAE: 2.043918
6 4 6.063477039337158
Validation loss: 5.477301492480811 MAE: 1.9575237
Validation loss: 5.077768559446316 MAE: 1.8794508
Validation loss: 4.55843791694106 MAE: 1.7809856
9 6 4.952756404876709
Validation loss: 4.468628855649837 MAE: 1.7652025
Validation loss: 4.797315732271733 MAE: 1.8207245
Validation loss: 4.116253952225129 MAE: 1.6766788
12 8 5.266839981079102
Validation loss: 3.9979170787788347 MAE: 1.6518863
Validation loss: 4.025537564424809 MAE: 1.6590276
Validation loss: 4.060698651120753 MAE: 1.6519331
15 10 3.9883127212524414
Validation loss: 6.085613633922202 MAE: 1.9717883
Validation loss: 3.887728268732289 MAE: 1.6282985
Validation loss: 3.718345727136952 MAE: 1.578117
18 12 4.478166103363037
Validation loss: 4.365560814469515 MAE: 1.725981
Validation loss: 3.7573744137444813 MAE: 1.5688078
Validation loss: 3.6393911365516676 MAE: 1.5564814
21 14 4.205932140350342
Validation loss: 3.6181103466507905 MAE: 1.5549201
Validation loss: 4.154004053983516 MAE: 1.6632136
Validation loss: 3.7716587961078405 MAE: 1.5859761
Validation loss: 3.541128844201923 MAE: 1.509922
25 0 1.5834476947784424
Validation loss: 4.475385405974302 MAE: 1.7331452
Validation loss: 4.131343438295659 MAE: 1.662141
Validation loss: 4.074999944958276 MAE: 1.6474881
28 2 3.661410331726074
Validation loss: 3.7014228002819602 MAE: 1.5120593
Validation loss: 3.6694484722160383 MAE: 1.5311133
Validation loss: 4.2341604471684455 MAE: 1.6596019
31 4 4.112878322601318
Validation loss: 3.356787671545942 MAE: 1.4832989
Validation loss: 3.521002636166039 MAE: 1.5086415
Validation loss: 4.280418356817089 MAE: 1.6867309
34 6 5.003904342651367
Validation loss: 3.544988920311173 MAE: 1.5339174
Validation loss: 3.339166176343012 MAE: 1.4551784
Validation loss: 3.515225934122273 MAE: 1.5214251
37 8 2.9150454998016357
Validation loss: 3.599725133192563 MAE: 1.5523621
Validation loss: 3.7928661865318465 MAE: 1.5664004
Validation loss: 3.504123105314786 MAE: 1.4940763
40 10 4.361145973205566
Validation loss: 3.879435854588816 MAE: 1.590116
Validation loss: 3.577226446721262 MAE: 1.5135965
Validation loss: 3.261015650743473 MAE: 1.4295282
43 12 4.409069538116455
Validation loss: 3.6468593959579008 MAE: 1.550247
Validation loss: 3.2653377672474466 MAE: 1.4257731
Validation loss: 3.669852795725117 MAE: 1.5316852
46 14 3.661524534225464
Validation loss: 3.1785438027315007 MAE: 1.428021
Validation loss: 3.263762042135418 MAE: 1.412077
Validation loss: 3.9913122873745843 MAE: 1.6027272
Validation loss: 4.299813080407335 MAE: 1.658903
50 0 2.6028192043304443
Validation loss: 3.7725468365128387 MAE: 1.574956
Validation loss: 3.288611069948735 MAE: 1.4508991
Validation loss: 3.086679542709687 MAE: 1.3947282
53 2 4.113103866577148
Validation loss: 3.9980696074231594 MAE: 1.5806904
Validation loss: 3.6986248908874266 MAE: 1.5508798
Validation loss: 3.2459346087041023 MAE: 1.436807
56 4 3.6649951934814453
Validation loss: 3.295574180587738 MAE: 1.4353741
Validation loss: 3.4988563734448266 MAE: 1.5091242
Validation loss: 3.1469902887134134 MAE: 1.4191872
59 6 3.839284896850586
Validation loss: 3.318297704379401 MAE: 1.4688613
Validation loss: 3.0495702905024222 MAE: 1.4081507
Validation loss: 2.9789404166724256 MAE: 1.3927504
62 8 3.2326645851135254
Validation loss: 2.966827661097647 MAE: 1.3765416
Validation loss: 3.170351969216295 MAE: 1.4217275
Validation loss: 3.020939010178637 MAE: 1.3918132
65 10 4.376247882843018
Validation loss: 3.085810784108653 MAE: 1.4239005
Validation loss: 2.9910416120517707 MAE: 1.3771391
Validation loss: 2.970636815967445 MAE: 1.3852353
68 12 2.976980209350586
Validation loss: 2.959017526171728 MAE: 1.3922675
Validation loss: 3.1726697389491814 MAE: 1.4154321
Validation loss: 2.9417073521203174 MAE: 1.3804036
71 14 4.123260974884033
Validation loss: 2.8729404977901667 MAE: 1.3528329
Validation loss: 6.932795647867696 MAE: 2.1290913
Validation loss: 3.0680426500125497 MAE: 1.4044591
Validation loss: 3.245541858768654 MAE: 1.4690667
75 0 5.834549427032471
Validation loss: 3.0577026751332865 MAE: 1.4059812
Validation loss: 2.925706205482712 MAE: 1.3830779
Validation loss: 3.133819796518238 MAE: 1.4114318
78 2 2.496523141860962
Validation loss: 3.454552539125951 MAE: 1.5188507
Validation loss: 2.9719358398345763 MAE: 1.3717304
Validation loss: 3.0202993692042592 MAE: 1.3962346
81 4 3.5057220458984375
Validation loss: 2.821482735310862 MAE: 1.3466483
Validation loss: 3.022083798964659 MAE: 1.3883827
Validation loss: 3.3396832761401405 MAE: 1.4765172
84 6 5.174055576324463
Validation loss: 2.8864080318229233 MAE: 1.3615073
Validation loss: 2.9207071235519133 MAE: 1.3679773
Validation loss: 2.906612978191796 MAE: 1.3702406
87 8 2.210174560546875
Validation loss: 2.9840092128646636 MAE: 1.403404
Validation loss: 2.9414636190525276 MAE: 1.3720121
Validation loss: 2.84684104957657 MAE: 1.3610412
90 10 4.004278182983398
Validation loss: 2.8133017218901304 MAE: 1.3379393
Validation loss: 2.93203983421555 MAE: 1.380146
Validation loss: 2.758538980522232 MAE: 1.3237529
93 12 2.3367068767547607
Validation loss: 2.860780385787597 MAE: 1.3593937
Validation loss: 2.862537960729045 MAE: 1.3657334
Validation loss: 2.928950984396772 MAE: 1.3773873
96 14 2.779460906982422
Validation loss: 2.774853145431182 MAE: 1.3314002
Validation loss: 2.803160577116605 MAE: 1.3352687
Validation loss: 3.168725623396451 MAE: 1.4316746
Validation loss: 3.0029643045398657 MAE: 1.3996774
Loaded trained model with success.
Test loss: 4.426279266542416 Test MAE: 1.6327485
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999848297979177, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 659177
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999241489895887, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 659137
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9998482979791774, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 659087
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9996965959583548, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 658987
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9992414898958869, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 658687
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9984829797917738, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 999, Valid size: 999, Test size: 658187
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9751861042183623, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 380
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9503722084367245, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 19, Valid size: 19, Test size: 370
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8759305210918115, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 48, Valid size: 48, Test size: 341
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7518610421836228, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 96, Valid size: 96, Test size: 293
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5037220843672456, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 193, Valid size: 193, Test size: 196
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 589
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 549
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 499
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 99
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 19.679983139038086
Validation loss: 17.10540771484375 MAE: 3.5896733
Validation loss: 13.260422706604004 MAE: 3.0707467
Validation loss: 10.013416290283203 MAE: 2.736581
Validation loss: 7.408708572387695 MAE: 2.3914943
Validation loss: 5.559805393218994 MAE: 2.0425847
Validation loss: 4.519751071929932 MAE: 1.7474284
Validation loss: 4.221950054168701 MAE: 1.6702017
Validation loss: 4.668669700622559 MAE: 1.738387
Validation loss: 5.492227554321289 MAE: 1.8849235
Validation loss: 6.487092971801758 MAE: 2.0107656
Validation loss: 7.4735846519470215 MAE: 2.159621
Validation loss: 8.361513137817383 MAE: 2.310152
Validation loss: 9.237531661987305 MAE: 2.4686651
Validation loss: 9.51660442352295 MAE: 2.516321
Validation loss: 9.395878791809082 MAE: 2.494939
Validation loss: 9.138161659240723 MAE: 2.4497056
Validation loss: 8.332719802856445 MAE: 2.3080132
Validation loss: 7.0061492919921875 MAE: 2.0856705
Validation loss: 5.918954849243164 MAE: 1.8714777
Validation loss: 5.139096736907959 MAE: 1.7478536
Validation loss: 4.6633782386779785 MAE: 1.7077608
Validation loss: 4.400059700012207 MAE: 1.6780238
Validation loss: 4.282242774963379 MAE: 1.658671
Validation loss: 4.240200996398926 MAE: 1.6405574
Validation loss: 4.190638542175293 MAE: 1.6432776
Validation loss: 4.135453701019287 MAE: 1.644847
Validation loss: 3.9997236728668213 MAE: 1.6301134
Validation loss: 3.8491978645324707 MAE: 1.6019064
Validation loss: 3.784848928451538 MAE: 1.5851318
Validation loss: 3.7863519191741943 MAE: 1.6112156
Validation loss: 4.041033744812012 MAE: 1.7431743
Validation loss: 4.595322608947754 MAE: 1.8854727
Validation loss: 5.489297389984131 MAE: 2.0386667
Validation loss: 6.880305290222168 MAE: 2.215352
Validation loss: 8.200655937194824 MAE: 2.4117825
Validation loss: 9.488532066345215 MAE: 2.6797447
Validation loss: 10.753448486328125 MAE: 2.9203856
Validation loss: 10.501019477844238 MAE: 2.9040332
Validation loss: 11.349924087524414 MAE: 3.063768
Validation loss: 13.6423978805542 MAE: 3.4164922
Validation loss: 16.175615310668945 MAE: 3.7528446
Validation loss: 21.120849609375 MAE: 4.3148675
Validation loss: 29.28285789489746 MAE: 5.0877013
Validation loss: 34.649044036865234 MAE: 5.5289516
Validation loss: 38.45775604248047 MAE: 5.8177915
Validation loss: 42.679779052734375 MAE: 6.115681
Validation loss: 42.37384796142578 MAE: 6.092268
Validation loss: 40.37748718261719 MAE: 5.951548
Validation loss: 35.64092254638672 MAE: 5.5938373
Validation loss: 31.14253044128418 MAE: 5.232997
50 0 3.8575830459594727
Validation loss: 28.520164489746094 MAE: 5.0059795
Validation loss: 25.09071159362793 MAE: 4.6902614
Validation loss: 20.868003845214844 MAE: 4.2703605
Validation loss: 18.073198318481445 MAE: 3.966648
Validation loss: 16.411710739135742 MAE: 3.7702708
Validation loss: 15.514840126037598 MAE: 3.6579409
Validation loss: 16.44865608215332 MAE: 3.7648027
Validation loss: 16.538129806518555 MAE: 3.7721224
Validation loss: 17.729907989501953 MAE: 3.9058864
Validation loss: 19.545560836791992 MAE: 4.0977
Validation loss: 20.757686614990234 MAE: 4.2233744
Validation loss: 22.688575744628906 MAE: 4.4124985
Validation loss: 23.041278839111328 MAE: 4.4493656
Validation loss: 24.437034606933594 MAE: 4.5821133
Validation loss: 25.059743881225586 MAE: 4.6396713
Validation loss: 27.220928192138672 MAE: 4.818072
Validation loss: 27.962011337280273 MAE: 4.8712373
Validation loss: 28.75969696044922 MAE: 4.9289117
Validation loss: 30.243263244628906 MAE: 5.045382
Validation loss: 31.96438980102539 MAE: 5.203538
Validation loss: 31.774864196777344 MAE: 5.1928415
Validation loss: 30.52013397216797 MAE: 5.105081
Validation loss: 27.58267593383789 MAE: 4.8408666
Validation loss: 23.00404167175293 MAE: 4.4076023
Validation loss: 18.22899627685547 MAE: 3.900733
Validation loss: 16.571125030517578 MAE: 3.7108896
Validation loss: 16.76687240600586 MAE: 3.7413156
Validation loss: 14.924501419067383 MAE: 3.5089893
Validation loss: 13.116533279418945 MAE: 3.2813175
Validation loss: 12.253847122192383 MAE: 3.1720905
Validation loss: 10.845537185668945 MAE: 2.9801283
Validation loss: 10.421802520751953 MAE: 2.9259489
Validation loss: 9.77615737915039 MAE: 2.825483
Validation loss: 8.975871086120605 MAE: 2.693219
Validation loss: 8.778885841369629 MAE: 2.6563408
Validation loss: 8.939878463745117 MAE: 2.672413
Validation loss: 9.888138771057129 MAE: 2.813563
Validation loss: 10.799846649169922 MAE: 2.9329324
Validation loss: 11.688983917236328 MAE: 3.0456874
Validation loss: 16.425004959106445 MAE: 3.6259673
Validation loss: 19.00238037109375 MAE: 3.8729565
Validation loss: 17.41643714904785 MAE: 3.6506739
Validation loss: 15.61733627319336 MAE: 3.4752102
Validation loss: 13.65427017211914 MAE: 3.2672966
Validation loss: 10.032414436340332 MAE: 2.8152359
Validation loss: 8.07294750213623 MAE: 2.5381093
Validation loss: 6.240437030792236 MAE: 2.2237427
Validation loss: 5.067352771759033 MAE: 1.9792943
Validation loss: 4.677165508270264 MAE: 1.8926531
Validation loss: 4.25820255279541 MAE: 1.7953576
Loaded trained model with success.
Test loss: 6.579691101523006 Test MAE: 2.1249287
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 25.905017852783203
Validation loss: 12.32533363420136 MAE: 2.7938342
Validation loss: 6.952440407811379 MAE: 2.0957217
Validation loss: 5.081548739452751 MAE: 1.8806894
Validation loss: 6.839906595191177 MAE: 2.178766
Validation loss: 10.760997091020856 MAE: 2.7834454
Validation loss: 15.225625816656619 MAE: 3.4051301
Validation loss: 17.113326092155614 MAE: 3.6426826
Validation loss: 15.154802517015106 MAE: 3.395985
Validation loss: 12.696292215464066 MAE: 3.0494263
Validation loss: 9.898203616239586 MAE: 2.6646605
Validation loss: 7.484397975765929 MAE: 2.2939775
Validation loss: 6.169206609531325 MAE: 2.0727472
Validation loss: 5.324025981280268 MAE: 1.946721
Validation loss: 5.0354816183751945 MAE: 1.8688483
Validation loss: 4.984773314729029 MAE: 1.8430251
Validation loss: 5.029935924374327 MAE: 1.8289816
Validation loss: 5.1573837776573335 MAE: 1.8274589
Validation loss: 5.30040015979689 MAE: 1.8608097
Validation loss: 5.35651142743169 MAE: 1.8801894
Validation loss: 5.385363929125727 MAE: 1.8905666
Validation loss: 5.432922227042062 MAE: 1.8980483
Validation loss: 5.548476209445876 MAE: 1.9046645
Validation loss: 5.7077180609411124 MAE: 1.9148139
Validation loss: 5.905296335414964 MAE: 1.9372048
Validation loss: 6.181140160074039 MAE: 1.9814758
25 0 5.817273139953613
Validation loss: 6.35972784003433 MAE: 2.0073738
Validation loss: 6.330413098237952 MAE: 2.0031655
Validation loss: 6.2963910005530535 MAE: 1.9990505
Validation loss: 6.202975779163594 MAE: 1.9861023
Validation loss: 6.038658862211267 MAE: 1.9622365
Validation loss: 5.74293581320315 MAE: 1.922754
Validation loss: 5.640332572314204 MAE: 1.908874
Validation loss: 5.542793984315833 MAE: 1.8938532
Validation loss: 5.615771478536177 MAE: 1.9069625
Validation loss: 5.832503172816063 MAE: 1.942602
Validation loss: 5.989303238537847 MAE: 1.9656056
Validation loss: 6.186202574749382 MAE: 1.9928507
Validation loss: 6.402025573107661 MAE: 2.0196993
Validation loss: 6.629767972595838 MAE: 2.0416284
Validation loss: 6.630774955360257 MAE: 2.034746
Validation loss: 6.816352941551987 MAE: 2.0528574
Validation loss: 6.96791444505964 MAE: 2.0618367
Validation loss: 7.243464396924389 MAE: 2.0919542
Validation loss: 7.434196783571827 MAE: 2.107033
Validation loss: 7.90781612785495 MAE: 2.1701286
Validation loss: 8.157047602595116 MAE: 2.2039545
Validation loss: 8.715399167975601 MAE: 2.2828245
Validation loss: 9.474016812382912 MAE: 2.392625
Validation loss: 10.342669681626923 MAE: 2.5313785
Validation loss: 11.357142662515445 MAE: 2.7032673
50 0 3.341538429260254
Validation loss: 11.970620330499143 MAE: 2.8115227
Validation loss: 12.49664762068768 MAE: 2.9060905
Validation loss: 12.938674907295072 MAE: 2.983028
Validation loss: 12.995237973271584 MAE: 2.995445
Validation loss: 12.611747002115054 MAE: 2.938727
Validation loss: 11.799541317686742 MAE: 2.8152356
Validation loss: 10.633946165746572 MAE: 2.6377845
Validation loss: 10.576208318982806 MAE: 2.6227865
Validation loss: 11.109634632966957 MAE: 2.708784
Validation loss: 11.773882466919568 MAE: 2.8184824
Validation loss: 12.172640255519322 MAE: 2.886294
Validation loss: 12.21010042696583 MAE: 2.897585
Validation loss: 11.89514448204819 MAE: 2.8557577
Validation loss: 10.977154673362264 MAE: 2.724935
Validation loss: 10.680433263584058 MAE: 2.6901479
Validation loss: 9.944996580785634 MAE: 2.5882
Validation loss: 8.322152312921018 MAE: 2.3318155
Validation loss: 7.618819032396589 MAE: 2.2218363
Validation loss: 7.9806597962671395 MAE: 2.2754915
Validation loss: 8.057034677388717 MAE: 2.2851062
Validation loss: 8.336384617552465 MAE: 2.3250222
Validation loss: 8.383687155587333 MAE: 2.326137
Validation loss: 8.072683178648656 MAE: 2.2589655
Validation loss: 8.455651185950455 MAE: 2.3147144
Validation loss: 9.27135792557074 MAE: 2.4687557
75 0 3.384424924850464
Validation loss: 9.525123888132523 MAE: 2.5165617
Validation loss: 9.486344746180944 MAE: 2.512252
Validation loss: 9.591779163905553 MAE: 2.5364218
Validation loss: 9.706510748182025 MAE: 2.5633895
Validation loss: 9.86631457659663 MAE: 2.5957954
Validation loss: 9.9116929599217 MAE: 2.6104708
Validation loss: 9.755406749491788 MAE: 2.5938148
Validation loss: 9.91085838784977 MAE: 2.6338837
Validation loss: 9.495024447538414 MAE: 2.5687919
Validation loss: 8.936572717160594 MAE: 2.474982
Validation loss: 8.78443176892339 MAE: 2.456948
Validation loss: 8.714398033764898 MAE: 2.4488406
Validation loss: 8.703795822299256 MAE: 2.4576473
Validation loss: 8.337232862200056 MAE: 2.3904076
Validation loss: 7.569289012831085 MAE: 2.252873
Validation loss: 6.6818435630019835 MAE: 2.0928323
Validation loss: 5.7304438474226975 MAE: 1.9182054
Validation loss: 5.067147994528011 MAE: 1.7922573
Validation loss: 4.913738912465621 MAE: 1.7468698
Validation loss: 5.323809059298768 MAE: 1.8200932
Validation loss: 5.557352980788873 MAE: 1.8678613
Validation loss: 5.247145234322061 MAE: 1.7954757
Validation loss: 5.333874488363461 MAE: 1.8141494
Validation loss: 4.861889080125458 MAE: 1.7171106
Validation loss: 4.736829358704236 MAE: 1.6995289
Loaded trained model with success.
Test loss: 7.8811524551333365 Test MAE: 2.2846503
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 19.567020416259766
Validation loss: 7.651180806786123 MAE: 2.268949
Validation loss: 6.243709063289141 MAE: 2.0263557
Validation loss: 11.617304115584403 MAE: 2.8195503
Validation loss: 12.507587057171445 MAE: 2.939918
Validation loss: 9.985056154655688 MAE: 2.6036375
Validation loss: 6.838952644906863 MAE: 2.1224668
Validation loss: 5.676183647579617 MAE: 2.0101721
Validation loss: 5.852100838314403 MAE: 2.0480764
Validation loss: 6.125330074869021 MAE: 2.0922792
Validation loss: 6.151619776330813 MAE: 2.104212
Validation loss: 6.167680391157516 MAE: 2.10761
Validation loss: 6.639990074465973 MAE: 2.1785114
12 2 5.5526885986328125
Validation loss: 6.643114330792668 MAE: 2.173886
Validation loss: 6.258397892268017 MAE: 2.1195154
Validation loss: 6.074761101693818 MAE: 2.089232
Validation loss: 6.155130911355067 MAE: 2.0901
Validation loss: 6.213646622619244 MAE: 2.0919797
Validation loss: 6.284509837025344 MAE: 2.099494
Validation loss: 6.156318079341542 MAE: 2.0829992
Validation loss: 5.904096362566707 MAE: 2.0564134
Validation loss: 5.897748976042776 MAE: 2.0629065
Validation loss: 6.1096503325182985 MAE: 2.0951772
Validation loss: 6.305319159921973 MAE: 2.1199656
Validation loss: 5.842968410915798 MAE: 2.05644
Validation loss: 5.823011624692667 MAE: 2.0439782
25 0 5.888734817504883
Validation loss: 6.066140603537511 MAE: 2.0697615
Validation loss: 6.219473713576192 MAE: 2.0868032
Validation loss: 6.249111002141779 MAE: 2.085732
Validation loss: 6.82717706699564 MAE: 2.1634798
Validation loss: 7.359305579252918 MAE: 2.2462113
Validation loss: 6.940376170957931 MAE: 2.1862378
Validation loss: 6.326040145122644 MAE: 2.08902
Validation loss: 5.717488955969762 MAE: 1.9976338
Validation loss: 5.605025539494524 MAE: 1.9838909
Validation loss: 6.307676711467781 MAE: 2.087812
Validation loss: 6.022774465156324 MAE: 2.0370264
Validation loss: 6.7392661077807645 MAE: 2.1584136
37 2 7.636227130889893
Validation loss: 6.663886349610608 MAE: 2.1462996
Validation loss: 6.6054313014252015 MAE: 2.1343908
Validation loss: 6.019082194626933 MAE: 2.0370617
Validation loss: 5.6070608803720186 MAE: 1.9778699
Validation loss: 5.46377135406841 MAE: 1.9514695
Validation loss: 5.638177611611106 MAE: 1.9768455
Validation loss: 6.207155025366581 MAE: 2.0788598
Validation loss: 6.930399730952099 MAE: 2.1876414
Validation loss: 6.72537736218385 MAE: 2.1553001
Validation loss: 6.455146232036629 MAE: 2.1159117
Validation loss: 6.163819221535114 MAE: 2.0685153
Validation loss: 5.2403669977428935 MAE: 1.9033207
Validation loss: 5.905085416755291 MAE: 1.9969394
50 0 5.989083766937256
Validation loss: 6.815298966687135 MAE: 2.1707866
Validation loss: 7.70457378421167 MAE: 2.3039367
Validation loss: 7.634123975580389 MAE: 2.291684
Validation loss: 7.499546089557686 MAE: 2.2758515
Validation loss: 6.807609871180371 MAE: 2.1790273
Validation loss: 6.699339681201511 MAE: 2.1717565
Validation loss: 7.379300471508142 MAE: 2.2704217
Validation loss: 6.459996784576262 MAE: 2.1164522
Validation loss: 8.840907925307148 MAE: 2.4810014
Validation loss: 9.771124001705285 MAE: 2.617473
Validation loss: 9.717222806179162 MAE: 2.60425
Validation loss: 10.774806995584507 MAE: 2.7661893
62 2 5.752064228057861
Validation loss: 9.556704583794179 MAE: 2.6003335
Validation loss: 8.352864727829441 MAE: 2.4241962
Validation loss: 8.378613220922874 MAE: 2.428948
Validation loss: 7.298365804884169 MAE: 2.2586722
Validation loss: 3.76333271373402 MAE: 1.6163447
Validation loss: 3.3452393057370426 MAE: 1.4726666
Validation loss: 3.623682460399589 MAE: 1.5513175
Validation loss: 3.5383224884668985 MAE: 1.5482024
Validation loss: 3.10562333675346 MAE: 1.4602937
Validation loss: 3.295021155867914 MAE: 1.4797553
Validation loss: 3.438614014423255 MAE: 1.5046791
Validation loss: 3.184066160760745 MAE: 1.4447842
Validation loss: 2.919941136331269 MAE: 1.398011
75 0 3.9196836948394775
Validation loss: 2.859801174414278 MAE: 1.3889092
Validation loss: 2.9241639559317116 MAE: 1.398719
Validation loss: 3.0903744408578584 MAE: 1.440927
Validation loss: 3.668573943051425 MAE: 1.5669638
Validation loss: 4.037756686258798 MAE: 1.6326346
Validation loss: 4.347868566561227 MAE: 1.6907742
Validation loss: 4.880314075585567 MAE: 1.8209964
Validation loss: 5.1773943178581465 MAE: 1.878432
Validation loss: 4.80316956837972 MAE: 1.7849426
Validation loss: 5.157989343007405 MAE: 1.8543103
Validation loss: 4.874760507333158 MAE: 1.7883474
Validation loss: 4.581465906567043 MAE: 1.7503752
87 2 3.629127264022827
Validation loss: 3.6292003718289463 MAE: 1.5385326
Validation loss: 3.4703708212785047 MAE: 1.5116715
Validation loss: 2.8199306040099175 MAE: 1.3536786
Validation loss: 2.6916184521684743 MAE: 1.3334315
Validation loss: 3.345646718836794 MAE: 1.4631557
Validation loss: 4.935582962903109 MAE: 1.8089082
Validation loss: 5.120773156483968 MAE: 1.8358827
Validation loss: 4.0363538626468545 MAE: 1.6104884
Validation loss: 3.3402445207942617 MAE: 1.4535074
Validation loss: 3.1895175485899956 MAE: 1.4391205
Validation loss: 3.2227922220422762 MAE: 1.4514022
Validation loss: 3.316926339660028 MAE: 1.4602051
Validation loss: 3.514333898370916 MAE: 1.5096924
Loaded trained model with success.
Test loss: 6.556688148177458 Test MAE: 2.0639296
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 16.790910720825195
Validation loss: 5.434154982542871 MAE: 1.955755
Validation loss: 15.730383197266852 MAE: 3.4211051
Validation loss: 13.609471134204961 MAE: 3.132055
Validation loss: 6.627273776423392 MAE: 2.146154
Validation loss: 5.831837570247938 MAE: 2.0040338
Validation loss: 5.711388868303155 MAE: 2.0003574
Validation loss: 5.297540858762348 MAE: 1.9290612
7 1 4.610184192657471
Validation loss: 5.383958322618475 MAE: 1.9524916
Validation loss: 5.360871208373027 MAE: 1.9351233
Validation loss: 5.400757589531903 MAE: 1.92757
Validation loss: 5.330912309675361 MAE: 1.9259889
Validation loss: 5.303985904808619 MAE: 1.9339057
Validation loss: 5.311171790463241 MAE: 1.9363
Validation loss: 5.288773392912131 MAE: 1.9221796
14 2 6.587582588195801
Validation loss: 5.312376772339021 MAE: 1.9283987
Validation loss: 5.186963662430269 MAE: 1.9044205
Validation loss: 5.417330866482989 MAE: 1.9127903
Validation loss: 5.243415027407545 MAE: 1.8863986
Validation loss: 5.160727948998686 MAE: 1.8697672
Validation loss: 4.9637890509025535 MAE: 1.8430469
Validation loss: 4.7228414521145465 MAE: 1.8130097
21 3 4.790848255157471
Validation loss: 4.485074931652702 MAE: 1.7735869
Validation loss: 4.4861342823086074 MAE: 1.7706704
Validation loss: 4.1936797927971465 MAE: 1.7146564
Validation loss: 4.013430015525627 MAE: 1.6716434
Validation loss: 3.9495009082046586 MAE: 1.6523412
Validation loss: 3.992256325093945 MAE: 1.6633455
Validation loss: 4.449006150715316 MAE: 1.7370961
28 4 4.980764389038086
Validation loss: 4.032254667138335 MAE: 1.672439
Validation loss: 3.826641757284577 MAE: 1.64002
Validation loss: 3.6959769462221232 MAE: 1.6115899
Validation loss: 3.735238071662098 MAE: 1.6105145
Validation loss: 3.715441266495978 MAE: 1.614974
Validation loss: 3.7245176641186277 MAE: 1.6125445
Validation loss: 3.7079402214318664 MAE: 1.6011364
35 5 4.273340225219727
Validation loss: 3.612366364828905 MAE: 1.580022
Validation loss: 3.683250005520768 MAE: 1.5934091
Validation loss: 3.4963384908647392 MAE: 1.5649959
Validation loss: 3.566264818661177 MAE: 1.5814497
Validation loss: 3.532446358072099 MAE: 1.5660982
Validation loss: 3.4471546477408865 MAE: 1.5408765
Validation loss: 3.786588771858407 MAE: 1.612037
42 6 3.6797516345977783
Validation loss: 3.4913392737882223 MAE: 1.5445492
Validation loss: 3.4485786751886107 MAE: 1.5261863
Validation loss: 3.337199692750097 MAE: 1.5068083
Validation loss: 3.343950223683113 MAE: 1.5347867
Validation loss: 3.508051464905092 MAE: 1.5626858
Validation loss: 3.6152118102989004 MAE: 1.5849079
Validation loss: 3.4336752663904697 MAE: 1.5543969
Validation loss: 3.81774697231887 MAE: 1.6399819
50 0 3.469590187072754
Validation loss: 3.5459742462215713 MAE: 1.5623891
Validation loss: 3.6388640775153385 MAE: 1.5782342
Validation loss: 3.4288586779455446 MAE: 1.5423194
Validation loss: 3.503695471202908 MAE: 1.56207
Validation loss: 3.69298639968412 MAE: 1.615192
Validation loss: 3.9245695564615066 MAE: 1.662723
Validation loss: 3.29976299420074 MAE: 1.527158
57 1 3.661686658859253
Validation loss: 3.5526323629983105 MAE: 1.5735507
Validation loss: 3.738372402574549 MAE: 1.6071339
Validation loss: 3.403801514275709 MAE: 1.5466619
Validation loss: 3.496465281625489 MAE: 1.5582554
Validation loss: 3.4881029805945394 MAE: 1.5502789
Validation loss: 3.442662090512376 MAE: 1.5447452
Validation loss: 3.555371059245201 MAE: 1.563227
64 2 2.8736703395843506
Validation loss: 4.788044882779145 MAE: 1.7715994
Validation loss: 3.6175537660493324 MAE: 1.5660118
Validation loss: 3.134677136962737 MAE: 1.4895366
Validation loss: 3.1015523390554303 MAE: 1.4794545
Validation loss: 3.581465543814041 MAE: 1.5638943
Validation loss: 3.3096574634762863 MAE: 1.5131621
Validation loss: 3.552806796740048 MAE: 1.5606211
71 3 4.42308235168457
Validation loss: 3.5476422058277994 MAE: 1.5670261
Validation loss: 3.266565555304139 MAE: 1.5100548
Validation loss: 3.8004155716105323 MAE: 1.6039002
Validation loss: 4.215481599970679 MAE: 1.6732886
Validation loss: 3.632471036671394 MAE: 1.5543461
Validation loss: 3.3637812586885003 MAE: 1.5240902
Validation loss: 3.5403793181606273 MAE: 1.5483079
78 4 3.5428736209869385
Validation loss: 5.136144786623854 MAE: 1.8106993
Validation loss: 4.425004963898779 MAE: 1.7002201
Validation loss: 3.119418297880259 MAE: 1.4536268
Validation loss: 3.1483929965963315 MAE: 1.465013
Validation loss: 4.247529734618699 MAE: 1.664424
Validation loss: 4.566069375330479 MAE: 1.7272676
Validation loss: 3.619424642629959 MAE: 1.5578251
85 5 3.898918390274048
Validation loss: 3.2696478858065965 MAE: 1.5086713
Validation loss: 3.282606164414679 MAE: 1.4986186
Validation loss: 2.8458563610536967 MAE: 1.3945489
Validation loss: 3.310238701614303 MAE: 1.5243545
Validation loss: 3.3702654419232854 MAE: 1.5170771
Validation loss: 3.5655638105306195 MAE: 1.5445889
Validation loss: 3.2601235272297306 MAE: 1.5040251
92 6 3.0967843532562256
Validation loss: 3.8278528457909973 MAE: 1.5909579
Validation loss: 3.635231678210311 MAE: 1.5482353
Validation loss: 3.01941424757991 MAE: 1.4330782
Validation loss: 3.2579508091337117 MAE: 1.493095
Validation loss: 3.1652491895397703 MAE: 1.4880333
Validation loss: 3.3286310524197678 MAE: 1.5187384
Validation loss: 3.0551993140024156 MAE: 1.4574687
Validation loss: 2.8658277449296348 MAE: 1.4037316
Loaded trained model with success.
Test loss: 5.553330904656901 Test MAE: 1.8868421
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 27.333337783813477
Validation loss: 17.76563604083472 MAE: 3.6406543
Validation loss: 5.202675407539628 MAE: 1.9214432
Validation loss: 5.328829957392507 MAE: 1.9390655
3 2 5.952463626861572
Validation loss: 5.5327923871233375 MAE: 1.9598484
Validation loss: 5.168464956876032 MAE: 1.9051149
Validation loss: 5.272240194385659 MAE: 1.9096103
6 4 5.015714645385742
Validation loss: 5.049042158948635 MAE: 1.8790869
Validation loss: 5.427970276566928 MAE: 1.9093952
Validation loss: 4.2455454484255375 MAE: 1.724773
9 6 5.822021007537842
Validation loss: 5.397167213455231 MAE: 1.8544885
Validation loss: 4.033716808579011 MAE: 1.6798285
Validation loss: 4.722391986178014 MAE: 1.7787552
12 8 2.79579496383667
Validation loss: 5.051558242293303 MAE: 1.8131852
Validation loss: 5.25600812908165 MAE: 1.820459
Validation loss: 5.714664155352331 MAE: 1.9157362
15 10 4.657689094543457
Validation loss: 4.39819786782733 MAE: 1.6805109
Validation loss: 4.102021117487508 MAE: 1.6435596
Validation loss: 5.084309714112827 MAE: 1.8046726
18 12 4.480319023132324
Validation loss: 4.922424249515266 MAE: 1.7949268
Validation loss: 3.8723829342033675 MAE: 1.599618
Validation loss: 4.761096184621593 MAE: 1.7932969
21 14 3.972334384918213
Validation loss: 3.724323297550301 MAE: 1.591809
Validation loss: 4.304063858632334 MAE: 1.6876967
Validation loss: 5.464940478185374 MAE: 1.8930676
Validation loss: 4.227406786534495 MAE: 1.6491722
25 0 2.5390477180480957
Validation loss: 3.9362477998217504 MAE: 1.6000957
Validation loss: 4.438257213584885 MAE: 1.7127848
Validation loss: 3.913422175543103 MAE: 1.6068759
28 2 4.326912879943848
Validation loss: 3.8904332182928174 MAE: 1.5950874
Validation loss: 3.675498154454814 MAE: 1.5661961
Validation loss: 4.0921625498540415 MAE: 1.6349124
31 4 3.3343892097473145
Validation loss: 3.92332968253172 MAE: 1.6020635
Validation loss: 3.8472820771242193 MAE: 1.5979823
Validation loss: 4.1028498055222995 MAE: 1.6469885
34 6 3.5447897911071777
Validation loss: 4.389901667654156 MAE: 1.7018975
Validation loss: 5.011982698956568 MAE: 1.8206038
Validation loss: 3.669806105340411 MAE: 1.5790315
37 8 3.97611141204834
Validation loss: 3.9587724490729506 MAE: 1.6121608
Validation loss: 4.514543880202727 MAE: 1.7134501
Validation loss: 3.7993746119176217 MAE: 1.5861673
40 10 4.356107711791992
Validation loss: 4.12180124160522 MAE: 1.6382462
Validation loss: 3.426482552278018 MAE: 1.5049043
Validation loss: 3.640788465320228 MAE: 1.5382575
43 12 3.4245057106018066
Validation loss: 3.4783124589251133 MAE: 1.5164846
Validation loss: 4.1003870878047595 MAE: 1.6480262
Validation loss: 3.4204501073680564 MAE: 1.508111
46 14 3.119384765625
Validation loss: 3.4856128186166644 MAE: 1.5223956
Validation loss: 3.8276291930364943 MAE: 1.5925555
Validation loss: 3.2097653640296033 MAE: 1.4540639
Validation loss: 3.3587522535381433 MAE: 1.4915935
50 0 2.7714662551879883
Validation loss: 3.3250883447383353 MAE: 1.467612
Validation loss: 3.3822073578117844 MAE: 1.4826144
Validation loss: 3.5708716866487493 MAE: 1.5299855
53 2 3.2608489990234375
Validation loss: 3.038147895274038 MAE: 1.437649
Validation loss: 3.197204318935264 MAE: 1.4568774
Validation loss: 3.0935922920823336 MAE: 1.4233721
56 4 4.137615203857422
Validation loss: 3.4862945285254345 MAE: 1.5022131
Validation loss: 3.2598686920617053 MAE: 1.4798727
Validation loss: 3.060160272345992 MAE: 1.4220563
59 6 3.0556530952453613
Validation loss: 3.0819874459612584 MAE: 1.4364476
Validation loss: 2.981988472068955 MAE: 1.4192169
Validation loss: 2.934942197704124 MAE: 1.3903497
62 8 2.2513439655303955
Validation loss: 2.7679145856945215 MAE: 1.3677646
Validation loss: 3.0117544210506586 MAE: 1.4131331
Validation loss: 3.4113599881380496 MAE: 1.4794701
65 10 3.6378378868103027
Validation loss: 2.7748666784328546 MAE: 1.3680965
Validation loss: 3.030427777456616 MAE: 1.4211951
Validation loss: 2.984275039546714 MAE: 1.4169341
68 12 4.447751998901367
Validation loss: 2.809800259813756 MAE: 1.3681923
Validation loss: 2.76468346974176 MAE: 1.3584273
Validation loss: 3.2460022603342673 MAE: 1.4528996
71 14 2.6907942295074463
Validation loss: 2.702104275116701 MAE: 1.3344821
Validation loss: 2.6702376639914656 MAE: 1.3336308
Validation loss: 2.7762756830226922 MAE: 1.3675946
Validation loss: 2.684133328034548 MAE: 1.3360624
75 0 2.8477301597595215
Validation loss: 2.860422553901443 MAE: 1.3827986
Validation loss: 2.740453896398296 MAE: 1.3525711
Validation loss: 2.6898590333476093 MAE: 1.3313793
78 2 2.2173690795898438
Validation loss: 2.6377860118965346 MAE: 1.3167485
Validation loss: 2.7109788037493137 MAE: 1.3573345
Validation loss: 2.762292404690821 MAE: 1.3614867
81 4 1.9778504371643066
Validation loss: 2.857307905663469 MAE: 1.378705
Validation loss: 2.5179504841745257 MAE: 1.3070977
Validation loss: 2.775266064670616 MAE: 1.375572
84 6 2.5154998302459717
Validation loss: 2.769379465278977 MAE: 1.3514901
Validation loss: 2.621748858797765 MAE: 1.3234215
Validation loss: 2.6251902718821127 MAE: 1.3213369
87 8 3.3081727027893066
Validation loss: 2.493261577132231 MAE: 1.2999656
Validation loss: 2.583569699155544 MAE: 1.3074995
Validation loss: 2.6684424748162705 MAE: 1.3406416
90 10 3.0587005615234375
Validation loss: 2.4740229185693012 MAE: 1.2935121
Validation loss: 2.6188417412713916 MAE: 1.3163388
Validation loss: 2.535438749259842 MAE: 1.2901095
93 12 5.337231636047363
Validation loss: 2.548825780471007 MAE: 1.3076485
Validation loss: 2.52779851934475 MAE: 1.306897
Validation loss: 2.6156994259668016 MAE: 1.3175846
96 14 3.2684826850891113
Validation loss: 2.6890643612894123 MAE: 1.3290088
Validation loss: 2.495720819385353 MAE: 1.2935209
Validation loss: 2.443760055817201 MAE: 1.2828974
Validation loss: 2.436273561450905 MAE: 1.278584
Loaded trained model with success.
Test loss: 4.61566712306096 Test MAE: 1.7015307
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999848297979177, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 659177
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999241489895887, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 659137
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9998482979791774, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 659087
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9996965959583548, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 658987
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9992414898958869, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 658687
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9984829797917738, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 999, Valid size: 999, Test size: 658187
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9751861042183623, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 380
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9503722084367245, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 19, Valid size: 19, Test size: 370
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8759305210918115, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 48, Valid size: 48, Test size: 341
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7518610421836228, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 96, Valid size: 96, Test size: 293
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5037220843672456, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 193, Valid size: 193, Test size: 196
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 589
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 549
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 499
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 99
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 21.033687591552734
Validation loss: 16.17208480834961 MAE: 3.5505936
Validation loss: 12.594334602355957 MAE: 3.0047688
Validation loss: 9.59461784362793 MAE: 2.4917321
Validation loss: 7.216628074645996 MAE: 2.0900674
Validation loss: 5.4209442138671875 MAE: 1.79139
Validation loss: 4.217748165130615 MAE: 1.7179738
Validation loss: 3.6189749240875244 MAE: 1.7819905
Validation loss: 3.6774325370788574 MAE: 1.8447814
Validation loss: 4.226065158843994 MAE: 1.897935
Validation loss: 5.047152996063232 MAE: 1.9429574
Validation loss: 5.931164264678955 MAE: 1.9768584
Validation loss: 6.725788593292236 MAE: 2.0455232
Validation loss: 7.533660888671875 MAE: 2.135975
Validation loss: 8.563075065612793 MAE: 2.3075697
Validation loss: 9.080060005187988 MAE: 2.3955483
Validation loss: 8.86946964263916 MAE: 2.3594255
Validation loss: 8.288193702697754 MAE: 2.257728
Validation loss: 7.391731262207031 MAE: 2.1271853
Validation loss: 6.615898132324219 MAE: 2.039803
Validation loss: 5.830581188201904 MAE: 1.9658843
Validation loss: 5.018960952758789 MAE: 1.9208156
Validation loss: 4.433837890625 MAE: 1.8932177
Validation loss: 4.001845359802246 MAE: 1.8653581
Validation loss: 3.7660624980926514 MAE: 1.8432516
Validation loss: 3.652021646499634 MAE: 1.8261806
Validation loss: 3.6803829669952393 MAE: 1.8103929
Validation loss: 3.76474666595459 MAE: 1.7884424
Validation loss: 3.871892213821411 MAE: 1.7664115
Validation loss: 3.9807417392730713 MAE: 1.7395713
Validation loss: 4.0491790771484375 MAE: 1.7059407
Validation loss: 3.8502426147460938 MAE: 1.6350318
Validation loss: 3.429758071899414 MAE: 1.5375777
Validation loss: 2.945490837097168 MAE: 1.427069
Validation loss: 2.6765780448913574 MAE: 1.3536265
Validation loss: 2.430901527404785 MAE: 1.2749519
Validation loss: 2.3528904914855957 MAE: 1.2039754
Validation loss: 2.5109333992004395 MAE: 1.1902764
Validation loss: 3.3460934162139893 MAE: 1.487123
Validation loss: 4.708705425262451 MAE: 1.8046112
Validation loss: 6.327437877655029 MAE: 2.1356947
Validation loss: 8.119329452514648 MAE: 2.492207
Validation loss: 9.647493362426758 MAE: 2.756917
Validation loss: 12.006237030029297 MAE: 3.115048
Validation loss: 13.613944053649902 MAE: 3.3398108
Validation loss: 15.838481903076172 MAE: 3.62626
Validation loss: 16.566364288330078 MAE: 3.7164776
Validation loss: 16.964736938476562 MAE: 3.7664876
Validation loss: 17.57318115234375 MAE: 3.8434181
Validation loss: 17.491641998291016 MAE: 3.8409314
Validation loss: 14.135590553283691 MAE: 3.4485273
50 0 4.256341934204102
Validation loss: 12.83096694946289 MAE: 3.2833433
Validation loss: 12.316765785217285 MAE: 3.2171543
Validation loss: 14.083819389343262 MAE: 3.452023
Validation loss: 14.30003833770752 MAE: 3.4791565
Validation loss: 11.7574462890625 MAE: 3.1431346
Validation loss: 9.576871871948242 MAE: 2.818839
Validation loss: 9.392864227294922 MAE: 2.785263
Validation loss: 9.164010047912598 MAE: 2.75249
Validation loss: 8.76447582244873 MAE: 2.6879196
Validation loss: 7.123691082000732 MAE: 2.4042003
Validation loss: 6.979044437408447 MAE: 2.378963
Validation loss: 7.519064903259277 MAE: 2.4803936
Validation loss: 7.840981483459473 MAE: 2.546947
Validation loss: 8.039515495300293 MAE: 2.5908175
Validation loss: 7.898261070251465 MAE: 2.571834
Validation loss: 8.51107406616211 MAE: 2.6796331
Validation loss: 9.304295539855957 MAE: 2.8119173
Validation loss: 9.446958541870117 MAE: 2.8317235
Validation loss: 9.906075477600098 MAE: 2.897088
Validation loss: 10.342082977294922 MAE: 2.954166
Validation loss: 13.161843299865723 MAE: 3.3383055
Validation loss: 16.091564178466797 MAE: 3.6926405
Validation loss: 18.425901412963867 MAE: 3.9402177
Validation loss: 22.082040786743164 MAE: 4.305768
Validation loss: 24.654953002929688 MAE: 4.5383396
Validation loss: 30.14462661743164 MAE: 5.011324
Validation loss: 35.139522552490234 MAE: 5.4063807
Validation loss: 41.02851104736328 MAE: 5.862166
Validation loss: 52.852725982666016 MAE: 6.704536
Validation loss: 60.93678283691406 MAE: 7.2417393
Validation loss: 63.25493621826172 MAE: 7.4007087
Validation loss: 64.20858764648438 MAE: 7.471056
Validation loss: 64.84107208251953 MAE: 7.5209756
Validation loss: 63.54397964477539 MAE: 7.445368
Validation loss: 60.83192443847656 MAE: 7.2818093
Validation loss: 53.72892761230469 MAE: 6.8452125
Validation loss: 47.56646728515625 MAE: 6.4373198
Validation loss: 40.83204650878906 MAE: 5.954709
Validation loss: 36.38288497924805 MAE: 5.61628
Validation loss: 33.67981719970703 MAE: 5.394228
Validation loss: 33.51805114746094 MAE: 5.3669486
Validation loss: 30.98046875 MAE: 5.16213
Validation loss: 29.31546401977539 MAE: 5.030642
Validation loss: 27.45330047607422 MAE: 4.8753834
Validation loss: 26.431982040405273 MAE: 4.792483
Validation loss: 28.06083106994629 MAE: 4.9198017
Validation loss: 29.22345733642578 MAE: 5.0177035
Validation loss: 33.021236419677734 MAE: 5.316203
Validation loss: 37.18995666503906 MAE: 5.6176224
Validation loss: 42.527347564697266 MAE: 5.951146
Loaded trained model with success.
Test loss: 8.329494897057028 Test MAE: 2.3824794
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 19.873397827148438
Validation loss: 12.110035857375788 MAE: 2.8844123
Validation loss: 7.216520990644183 MAE: 2.2214413
Validation loss: 5.352659244926608 MAE: 1.9596238
Validation loss: 7.368306792512232 MAE: 2.2089179
Validation loss: 13.978101944436832 MAE: 3.138201
Validation loss: 23.834427463765046 MAE: 4.3205366
Validation loss: 30.91302474664182 MAE: 5.060544
Validation loss: 29.6654675152837 MAE: 4.9601946
Validation loss: 22.346824490294164 MAE: 4.2095394
Validation loss: 17.719117456552933 MAE: 3.6668043
Validation loss: 14.638949102284958 MAE: 3.261008
Validation loss: 11.429355835428042 MAE: 2.8198469
Validation loss: 8.558887987720723 MAE: 2.3885553
Validation loss: 7.0013551517408725 MAE: 2.141638
Validation loss: 6.266208337277782 MAE: 2.0294454
Validation loss: 6.161510448066556 MAE: 2.0072422
Validation loss: 5.738168434220917 MAE: 1.9220966
Validation loss: 4.858728622903629 MAE: 1.7497365
Validation loss: 4.217118165930923 MAE: 1.616063
Validation loss: 3.9128115420438805 MAE: 1.5521923
Validation loss: 4.038421192947699 MAE: 1.6039114
Validation loss: 4.2452481425538355 MAE: 1.6541388
Validation loss: 4.424508513236533 MAE: 1.6948351
Validation loss: 4.471741622808028 MAE: 1.7118552
Validation loss: 4.372974697424441 MAE: 1.695369
25 0 4.054867267608643
Validation loss: 4.478209398230728 MAE: 1.7160735
Validation loss: 4.20142955196147 MAE: 1.6645361
Validation loss: 3.882276846438038 MAE: 1.5971256
Validation loss: 3.5947489543836944 MAE: 1.5362267
Validation loss: 3.3843814888779 MAE: 1.4980541
Validation loss: 3.1164637244477564 MAE: 1.4316391
Validation loss: 4.393467504151014 MAE: 1.6751785
Validation loss: 7.149606150023791 MAE: 2.2003202
Validation loss: 8.176610460086744 MAE: 2.3695483
Validation loss: 6.381263197684775 MAE: 2.063012
Validation loss: 5.33506963690933 MAE: 1.8639045
Validation loss: 5.501088385679284 MAE: 1.8747779
Validation loss: 5.619247553299885 MAE: 1.8804084
Validation loss: 5.3714403522257905 MAE: 1.8348225
Validation loss: 5.163039460474131 MAE: 1.8016104
Validation loss: 5.040814068852638 MAE: 1.7896733
Validation loss: 4.143845460852798 MAE: 1.6489443
Validation loss: 2.8398182002865537 MAE: 1.3520696
Validation loss: 3.696319633600663 MAE: 1.4893742
Validation loss: 5.0602351986632055 MAE: 1.7275399
Validation loss: 4.921603358521754 MAE: 1.7379185
Validation loss: 4.364606039864676 MAE: 1.6422787
Validation loss: 4.2621718499125265 MAE: 1.6258348
Validation loss: 4.3367933643107515 MAE: 1.64815
Validation loss: 4.392403378778575 MAE: 1.6684947
50 0 2.709327220916748
Validation loss: 4.570767714052784 MAE: 1.709985
Validation loss: 4.9454247854193865 MAE: 1.7843796
Validation loss: 4.994378829488949 MAE: 1.7968247
Validation loss: 5.031166699467873 MAE: 1.8032905
Validation loss: 4.760463685405497 MAE: 1.756838
Validation loss: 4.500458045881622 MAE: 1.7070848
Validation loss: 4.553120350351139 MAE: 1.7194116
Validation loss: 4.516774265133605 MAE: 1.7166513
Validation loss: 4.432903961259491 MAE: 1.6987752
Validation loss: 4.6154588485250665 MAE: 1.7325633
Validation loss: 4.764392385677415 MAE: 1.7602555
Validation loss: 4.9576115413587925 MAE: 1.7994268
Validation loss: 4.821839069833561 MAE: 1.7847784
Validation loss: 4.785737120375341 MAE: 1.7871802
Validation loss: 4.732666828194443 MAE: 1.7760987
Validation loss: 4.535228301067741 MAE: 1.7296067
Validation loss: 4.326307486514656 MAE: 1.6786199
Validation loss: 3.8632906407726053 MAE: 1.5754024
Validation loss: 3.9435115541730608 MAE: 1.5880095
Validation loss: 4.274762610999906 MAE: 1.640002
Validation loss: 4.242900697552428 MAE: 1.5996629
Validation loss: 3.199423916485845 MAE: 1.3903459
Validation loss: 2.591796198669745 MAE: 1.2551824
Validation loss: 2.438243194502227 MAE: 1.2126286
Validation loss: 2.46178193481601 MAE: 1.2215537
75 0 2.4468631744384766
Validation loss: 2.4936726117620664 MAE: 1.2301778
Validation loss: 2.568065137279277 MAE: 1.2449739
Validation loss: 2.830552339553833 MAE: 1.2989426
Validation loss: 2.889320436789065 MAE: 1.3089201
Validation loss: 2.708812562786803 MAE: 1.267946
Validation loss: 2.501983258188987 MAE: 1.2233377
Validation loss: 2.2989223319656995 MAE: 1.1731108
Validation loss: 2.1603493057951635 MAE: 1.144788
Validation loss: 1.9854545009379485 MAE: 1.0980347
Validation loss: 1.8380840311245041 MAE: 1.0556886
Validation loss: 1.6455093597879216 MAE: 1.0096303
Validation loss: 1.5488644619377292 MAE: 0.95241666
Validation loss: 1.618754403931754 MAE: 0.9574038
Validation loss: 1.745630295909181 MAE: 0.9925016
Validation loss: 1.9981933321271623 MAE: 1.0799203
Validation loss: 2.3257691714228415 MAE: 1.2025535
Validation loss: 2.464540364790936 MAE: 1.2443436
Validation loss: 2.1483718083829295 MAE: 1.1236857
Validation loss: 2.005398614065988 MAE: 1.0674013
Validation loss: 1.8563009208562422 MAE: 1.0259892
Validation loss: 1.8233388589352977 MAE: 1.0232568
Validation loss: 1.730054573136933 MAE: 0.9954661
Validation loss: 1.7269550586233333 MAE: 0.9883923
Validation loss: 1.7220452926596816 MAE: 0.98891634
Validation loss: 1.6685816463159056 MAE: 0.9717102
Loaded trained model with success.
Test loss: 5.234875518857068 Test MAE: 1.8493452
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 16.2213191986084
Validation loss: 6.501909381211406 MAE: 2.0645075
Validation loss: 6.682068978897249 MAE: 2.165219
Validation loss: 13.230281319281067 MAE: 3.0690982
Validation loss: 19.562845933316932 MAE: 3.85928
Validation loss: 18.36547475872618 MAE: 3.7144415
Validation loss: 13.613985601097646 MAE: 3.1313694
Validation loss: 9.717964124197911 MAE: 2.5966806
Validation loss: 8.761941141552395 MAE: 2.4543965
Validation loss: 5.355392470504299 MAE: 1.86735
Validation loss: 4.839626480834653 MAE: 1.8075796
Validation loss: 4.820790449778239 MAE: 1.8090379
Validation loss: 5.352788366452612 MAE: 1.8917695
12 2 4.999423027038574
Validation loss: 5.8272067272301875 MAE: 1.9666839
Validation loss: 5.630956933955954 MAE: 1.935248
Validation loss: 5.041003439161512 MAE: 1.8438158
Validation loss: 4.926608986324734 MAE: 1.8283669
Validation loss: 4.913573433654477 MAE: 1.8246875
Validation loss: 5.086186744950035 MAE: 1.8585485
Validation loss: 5.435615891157979 MAE: 1.9139795
Validation loss: 5.639922657398262 MAE: 1.9487536
Validation loss: 5.370228382072064 MAE: 1.9112216
Validation loss: 5.234564665592078 MAE: 1.8914281
Validation loss: 5.248321523570051 MAE: 1.8973911
Validation loss: 5.252714371440386 MAE: 1.8955593
Validation loss: 5.089020314842764 MAE: 1.861578
25 0 4.562691688537598
Validation loss: 4.879140384269483 MAE: 1.8186986
Validation loss: 4.843667598685833 MAE: 1.8134769
Validation loss: 4.921489445850103 MAE: 1.8212447
Validation loss: 5.4693536469430635 MAE: 1.9060463
Validation loss: 6.077592396976972 MAE: 2.0014107
Validation loss: 5.813931137624413 MAE: 1.9587609
Validation loss: 5.683640855731386 MAE: 1.9356017
Validation loss: 5.24736905820442 MAE: 1.86585
Validation loss: 4.9858268872656 MAE: 1.8234696
Validation loss: 4.8116521257342715 MAE: 1.8102484
Validation loss: 4.743911979174373 MAE: 1.8098903
Validation loss: 4.77933402013297 MAE: 1.8267217
37 2 4.293586730957031
Validation loss: 4.57408189051079 MAE: 1.7802575
Validation loss: 4.553255826535851 MAE: 1.7605356
Validation loss: 4.9741734398735895 MAE: 1.8178526
Validation loss: 5.624496048147028 MAE: 1.9253945
Validation loss: 5.777166800065474 MAE: 1.9369624
Validation loss: 5.550387382507324 MAE: 1.8995073
Validation loss: 5.044547846823027 MAE: 1.8179152
Validation loss: 4.388756877244121 MAE: 1.7224689
Validation loss: 4.1859831761832185 MAE: 1.701688
Validation loss: 4.321091928867379 MAE: 1.7190995
Validation loss: 4.4596685183168665 MAE: 1.7429333
Validation loss: 4.404611922273732 MAE: 1.731018
Validation loss: 4.173258361190256 MAE: 1.6970894
50 0 4.02264404296875
Validation loss: 4.090523245358708 MAE: 1.6789398
Validation loss: 4.064085719561336 MAE: 1.6375383
Validation loss: 4.029724361920597 MAE: 1.6145662
Validation loss: 3.9753950436909995 MAE: 1.6048949
Validation loss: 3.879500879181756 MAE: 1.5804584
Validation loss: 3.661518092107291 MAE: 1.5549994
Validation loss: 3.5374127156806714 MAE: 1.5372999
Validation loss: 3.5119978394171203 MAE: 1.5387522
Validation loss: 3.5500884537745003 MAE: 1.547008
Validation loss: 3.4523163085634057 MAE: 1.5257624
Validation loss: 3.375732766257392 MAE: 1.4924263
Validation loss: 3.350726052968189 MAE: 1.4650351
62 2 3.2447705268859863
Validation loss: 3.488969102050319 MAE: 1.4866432
Validation loss: 3.6854417950215965 MAE: 1.5143734
Validation loss: 3.7822926158856864 MAE: 1.5494732
Validation loss: 3.2046242603147874 MAE: 1.4326345
Validation loss: 3.374872424385764 MAE: 1.4725422
Validation loss: 3.570655769772 MAE: 1.5018286
Validation loss: 3.6022803518507214 MAE: 1.5197192
Validation loss: 3.268158698322797 MAE: 1.4560385
Validation loss: 3.1865049757138646 MAE: 1.4251889
Validation loss: 3.29326341850589 MAE: 1.4426931
Validation loss: 3.18109271502254 MAE: 1.4519095
Validation loss: 3.4440480771690907 MAE: 1.496302
Validation loss: 4.338602894484395 MAE: 1.6891648
75 0 4.091973781585693
Validation loss: 4.595421391304093 MAE: 1.735744
Validation loss: 3.076660374198297 MAE: 1.4385012
Validation loss: 3.500855477169307 MAE: 1.4402648
Validation loss: 3.8076482445302635 MAE: 1.5122691
Validation loss: 3.9367322994000986 MAE: 1.5979052
Validation loss: 3.473121411872633 MAE: 1.5114883
Validation loss: 3.1758648337739888 MAE: 1.4249663
Validation loss: 3.6898450779192373 MAE: 1.5398426
Validation loss: 3.162265517494895 MAE: 1.4332964
Validation loss: 3.1172747618020185 MAE: 1.3840292
Validation loss: 3.5713632853344235 MAE: 1.4852344
Validation loss: 3.2042827341291638 MAE: 1.4255527
87 2 4.764521598815918
Validation loss: 3.14840099426231 MAE: 1.4326047
Validation loss: 3.120279271193225 MAE: 1.4215333
Validation loss: 3.064850643427685 MAE: 1.4109411
Validation loss: 3.184551243830209 MAE: 1.4652545
Validation loss: 3.332377920548121 MAE: 1.4975809
Validation loss: 3.810002422694004 MAE: 1.5857079
Validation loss: 3.964681047381777 MAE: 1.6134498
Validation loss: 3.2998536524146496 MAE: 1.4772524
Validation loss: 3.228867571763318 MAE: 1.4395858
Validation loss: 3.0287562717090952 MAE: 1.387659
Validation loss: 2.917907637779159 MAE: 1.3641137
Validation loss: 2.839859225533225 MAE: 1.3482025
Validation loss: 3.115439545024525 MAE: 1.4398037
Loaded trained model with success.
Test loss: 6.553399985204479 Test MAE: 2.0469236
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 24.08277702331543
Validation loss: 5.634831488431997 MAE: 1.9969835
Validation loss: 16.47758011841894 MAE: 3.508484
Validation loss: 8.296727674091281 MAE: 2.3679147
Validation loss: 5.13183425539103 MAE: 1.8992187
Validation loss: 5.266495078053307 MAE: 1.8901876
Validation loss: 4.995563073373919 MAE: 1.8588156
Validation loss: 5.083399228714219 MAE: 1.8627994
7 1 5.370230674743652
Validation loss: 5.1793513633498 MAE: 1.8736743
Validation loss: 5.250616591180389 MAE: 1.8784652
Validation loss: 5.445025420069095 MAE: 1.9045174
Validation loss: 5.739392578302317 MAE: 1.9603444
Validation loss: 5.921537281879828 MAE: 2.005787
Validation loss: 5.766798539377337 MAE: 1.9842149
Validation loss: 5.5239772868515855 MAE: 1.9515408
14 2 5.125277042388916
Validation loss: 5.196351625212473 MAE: 1.888548
Validation loss: 5.6252270080336375 MAE: 1.9327093
Validation loss: 5.805548694265548 MAE: 1.946794
Validation loss: 6.313816918799626 MAE: 2.003237
Validation loss: 5.450147300509352 MAE: 1.8664978
Validation loss: 4.663909075847223 MAE: 1.7721688
Validation loss: 4.576950974200838 MAE: 1.7575529
21 3 3.7582125663757324
Validation loss: 4.516616054515743 MAE: 1.7566416
Validation loss: 4.391147257694647 MAE: 1.7255853
Validation loss: 4.370586790631165 MAE: 1.7166436
Validation loss: 4.692050272495902 MAE: 1.7230723
Validation loss: 4.499804755551132 MAE: 1.6957078
Validation loss: 4.2674517044469935 MAE: 1.6818569
Validation loss: 4.274967966367252 MAE: 1.6641034
28 4 5.464287757873535
Validation loss: 4.232436218453412 MAE: 1.6363589
Validation loss: 4.466474482162514 MAE: 1.6661702
Validation loss: 5.3771133231158235 MAE: 1.8304496
Validation loss: 4.434067093547265 MAE: 1.6712064
Validation loss: 4.771734193641337 MAE: 1.7249465
Validation loss: 4.563639401191443 MAE: 1.678646
Validation loss: 4.442173901514791 MAE: 1.670365
35 5 4.8942437171936035
Validation loss: 3.9571718534632545 MAE: 1.5835292
Validation loss: 4.796778626178377 MAE: 1.7699302
Validation loss: 4.04933049570975 MAE: 1.6256274
Validation loss: 3.5636568572653 MAE: 1.5111824
Validation loss: 3.667037369617865 MAE: 1.5233908
Validation loss: 4.068775579557946 MAE: 1.6006488
Validation loss: 3.9578734995731755 MAE: 1.5956832
42 6 3.167998790740967
Validation loss: 3.4621151799532637 MAE: 1.531856
Validation loss: 4.070673257262263 MAE: 1.6465477
Validation loss: 4.484340320280449 MAE: 1.7000471
Validation loss: 4.68475379416691 MAE: 1.7406248
Validation loss: 4.888316963186216 MAE: 1.7806783
Validation loss: 3.919381785033336 MAE: 1.5682597
Validation loss: 3.7451722514090227 MAE: 1.5486863
Validation loss: 3.886177633275938 MAE: 1.5981832
50 0 3.468717336654663
Validation loss: 4.038476220327406 MAE: 1.6214962
Validation loss: 4.43109786330755 MAE: 1.7163061
Validation loss: 4.489405327705882 MAE: 1.7227415
Validation loss: 4.173062919971332 MAE: 1.6401892
Validation loss: 4.640427184464344 MAE: 1.7329614
Validation loss: 4.3484254985598465 MAE: 1.6566724
Validation loss: 3.5846672453472963 MAE: 1.4884772
57 1 2.6118900775909424
Validation loss: 3.3743828121741215 MAE: 1.4929414
Validation loss: 3.8367770191413073 MAE: 1.6062331
Validation loss: 4.2265579568680804 MAE: 1.6668743
Validation loss: 3.937639476066858 MAE: 1.5860571
Validation loss: 3.777270054697391 MAE: 1.5822715
Validation loss: 3.5283976391931273 MAE: 1.5177078
Validation loss: 3.1795960287352902 MAE: 1.4493467
64 2 2.375580310821533
Validation loss: 4.10757972786774 MAE: 1.6379132
Validation loss: 3.783944219800096 MAE: 1.5705299
Validation loss: 3.587536199008999 MAE: 1.5119641
Validation loss: 4.802827614635678 MAE: 1.7801839
Validation loss: 4.555527173095013 MAE: 1.7078104
Validation loss: 3.915780855782667 MAE: 1.5780184
Validation loss: 3.301907043361185 MAE: 1.4487783
71 3 2.6405391693115234
Validation loss: 3.860479759211516 MAE: 1.5760983
Validation loss: 4.323766360929863 MAE: 1.6571411
Validation loss: 3.5212206025818484 MAE: 1.4642287
Validation loss: 2.97915019821282 MAE: 1.3835367
Validation loss: 3.100457256163784 MAE: 1.4088595
Validation loss: 3.1880822313490826 MAE: 1.3783073
Validation loss: 3.402140901915392 MAE: 1.4541197
78 4 4.546030521392822
Validation loss: 3.148525726855101 MAE: 1.4008814
Validation loss: 3.2795412588359123 MAE: 1.4094551
Validation loss: 3.353767149412452 MAE: 1.4952279
Validation loss: 3.0263837965289553 MAE: 1.4233892
Validation loss: 3.1862799785844045 MAE: 1.4370558
Validation loss: 3.2615823266494215 MAE: 1.4644469
Validation loss: 3.5989552981889426 MAE: 1.5015024
85 5 2.1453800201416016
Validation loss: 3.8171258308180613 MAE: 1.5265825
Validation loss: 3.2920024059525685 MAE: 1.4175389
Validation loss: 3.1677379128920973 MAE: 1.4063432
Validation loss: 3.1694353100043444 MAE: 1.444434
Validation loss: 3.989812939011272 MAE: 1.5771707
Validation loss: 2.9100373989373596 MAE: 1.3691128
Validation loss: 2.753586340190178 MAE: 1.3440727
92 6 4.327219486236572
Validation loss: 2.944252885166724 MAE: 1.3508755
Validation loss: 2.7365230351836236 MAE: 1.3053261
Validation loss: 2.836604709002241 MAE: 1.3233861
Validation loss: 3.382955101866219 MAE: 1.450613
Validation loss: 3.380302404638511 MAE: 1.4305689
Validation loss: 2.8218875182932943 MAE: 1.3467348
Validation loss: 2.855467001996448 MAE: 1.3531466
Validation loss: 2.8673197396436527 MAE: 1.3626955
Loaded trained model with success.
Test loss: 5.336253764103675 Test MAE: 1.8312284
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 27.27927017211914
Validation loss: 17.79326257342566 MAE: 3.6553109
Validation loss: 5.307760768041821 MAE: 1.9466922
Validation loss: 5.55179546734613 MAE: 1.998494
3 2 4.030295372009277
Validation loss: 6.168941821746214 MAE: 2.091429
Validation loss: 5.725142740773294 MAE: 2.0217752
Validation loss: 5.6662145683426175 MAE: 1.9973377
6 4 7.5077033042907715
Validation loss: 5.612313673825923 MAE: 1.9778318
Validation loss: 5.364835041558337 MAE: 1.9382659
Validation loss: 5.623371921225875 MAE: 1.9521912
9 6 5.293563365936279
Validation loss: 4.723351555979085 MAE: 1.7737073
Validation loss: 4.67876801270999 MAE: 1.8173434
Validation loss: 4.478928005050323 MAE: 1.7388083
12 8 4.128124237060547
Validation loss: 5.680352705036232 MAE: 1.9198291
Validation loss: 5.0298212410691745 MAE: 1.8056163
Validation loss: 4.21172869324923 MAE: 1.6911168
15 10 4.7828474044799805
Validation loss: 4.958140992927169 MAE: 1.7889088
Validation loss: 4.7155293615643155 MAE: 1.742465
Validation loss: 4.91099397739571 MAE: 1.785493
18 12 5.639374732971191
Validation loss: 3.9320839258855234 MAE: 1.6209528
Validation loss: 4.328238470998699 MAE: 1.6640732
Validation loss: 3.8587162499437353 MAE: 1.6060231
21 14 5.231188774108887
Validation loss: 4.2402179360628605 MAE: 1.6581852
Validation loss: 4.802347113469798 MAE: 1.7709107
Validation loss: 4.289272522400759 MAE: 1.676204
Validation loss: 3.7085903355019365 MAE: 1.5728294
25 0 2.962630033493042
Validation loss: 4.392910121199124 MAE: 1.6852721
Validation loss: 3.824337098307027 MAE: 1.5825776
Validation loss: 3.6613435300892005 MAE: 1.5616764
28 2 6.105701446533203
Validation loss: 4.323743475224068 MAE: 1.6743873
Validation loss: 3.6614642554151273 MAE: 1.5436796
Validation loss: 3.6212732108657013 MAE: 1.5493993
31 4 4.705562114715576
Validation loss: 4.010818967360533 MAE: 1.6170728
Validation loss: 3.4973719292031022 MAE: 1.5231119
Validation loss: 3.4517362007875003 MAE: 1.5220326
34 6 2.664123773574829
Validation loss: 3.6862376792158535 MAE: 1.5540957
Validation loss: 3.822752890462627 MAE: 1.5971807
Validation loss: 3.583511672182408 MAE: 1.55191
37 8 2.7222814559936523
Validation loss: 5.676443864443976 MAE: 1.917598
Validation loss: 3.9478049082364253 MAE: 1.6397066
Validation loss: 3.8125312619792195 MAE: 1.5906551
40 10 3.9857232570648193
Validation loss: 4.27644357318152 MAE: 1.660791
Validation loss: 3.709641770036044 MAE: 1.5413102
Validation loss: 3.7422737501905057 MAE: 1.5663484
43 12 2.7804043292999268
Validation loss: 3.2409752996746666 MAE: 1.4657782
Validation loss: 3.418366828280126 MAE: 1.4995136
Validation loss: 3.5537189223723327 MAE: 1.52071
46 14 3.7804970741271973
Validation loss: 3.330471380440171 MAE: 1.4938525
Validation loss: 3.2798158185993262 MAE: 1.4720356
Validation loss: 4.344665180944011 MAE: 1.6511939
Validation loss: 3.7502116588409056 MAE: 1.570896
50 0 3.4327545166015625
Validation loss: 3.148748157975191 MAE: 1.4595231
Validation loss: 3.0849304844238956 MAE: 1.444301
Validation loss: 3.081741833256815 MAE: 1.428447
53 2 3.8084378242492676
Validation loss: 3.0414110720754866 MAE: 1.4360335
Validation loss: 3.121288904923953 MAE: 1.4478557
Validation loss: 3.2591916865002895 MAE: 1.4558477
56 4 5.646458625793457
Validation loss: 3.1395983844099637 MAE: 1.4419526
Validation loss: 3.071038647022897 MAE: 1.4216918
Validation loss: 2.9640829978820555 MAE: 1.4036214
59 6 4.002549648284912
Validation loss: 3.0170857696112745 MAE: 1.4222167
Validation loss: 3.0611654560647175 MAE: 1.4248083
Validation loss: 2.9342406259509985 MAE: 1.3767912
62 8 4.181825637817383
Validation loss: 2.92810592861596 MAE: 1.4064316
Validation loss: 2.8424255948267385 MAE: 1.3722847
Validation loss: 2.9050444328713274 MAE: 1.3798136
65 10 1.9718328714370728
Validation loss: 3.102936033734339 MAE: 1.4365528
Validation loss: 2.968551875594145 MAE: 1.3971552
Validation loss: 2.9257914771536786 MAE: 1.3989224
68 12 5.354030609130859
Validation loss: 2.7489361452435204 MAE: 1.3677534
Validation loss: 3.02458209074093 MAE: 1.4009136
Validation loss: 2.8121493574612604 MAE: 1.3880792
71 14 3.0048601627349854
Validation loss: 2.887500059150742 MAE: 1.3749101
Validation loss: 2.776530667631803 MAE: 1.3708264
Validation loss: 2.7297399335490438 MAE: 1.3464833
Validation loss: 2.8217287283383294 MAE: 1.3570062
75 0 3.052966594696045
Validation loss: 2.7489938153054765 MAE: 1.3606981
Validation loss: 2.822760932670089 MAE: 1.3496954
Validation loss: 2.885170415312589 MAE: 1.3695877
78 2 2.2528722286224365
Validation loss: 2.723517790108262 MAE: 1.3226088
Validation loss: 2.7509828230183206 MAE: 1.3426793
Validation loss: 2.753526773624764 MAE: 1.34074
81 4 2.652038097381592
Validation loss: 2.769495975039526 MAE: 1.3588737
Validation loss: 2.730015339497813 MAE: 1.3545609
Validation loss: 2.71487742387699 MAE: 1.3300581
84 6 3.683119773864746
Validation loss: 2.7081189241581307 MAE: 1.3185706
Validation loss: 2.7689666485260864 MAE: 1.3688803
Validation loss: 2.693180641334855 MAE: 1.3360344
87 8 2.9342966079711914
Validation loss: 2.8809672417287118 MAE: 1.3708181
Validation loss: 2.96915240469342 MAE: 1.4204355
Validation loss: 2.5637685598017934 MAE: 1.2978653
90 10 2.0069878101348877
Validation loss: 2.720749588910946 MAE: 1.3331559
Validation loss: 2.723804994193251 MAE: 1.3543999
Validation loss: 2.565192822225108 MAE: 1.301048
93 12 3.1607298851013184
Validation loss: 2.6788257663856765 MAE: 1.332715
Validation loss: 2.6771875985399753 MAE: 1.3407717
Validation loss: 2.717365705417488 MAE: 1.340466
96 14 3.339265823364258
Validation loss: 2.791547591796141 MAE: 1.3298663
Validation loss: 2.7543401183011778 MAE: 1.3384624
Validation loss: 2.6037292456579113 MAE: 1.3207868
Validation loss: 2.5999775721219356 MAE: 1.3158647
Loaded trained model with success.
Test loss: 4.418045447422908 Test MAE: 1.6595049
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999848297979177, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 659177
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999241489895887, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 659137
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9998482979791774, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 659087
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9996965959583548, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 658987
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9992414898958869, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 658687
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9984829797917738, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 999, Valid size: 999, Test size: 658187
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9751861042183623, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 380
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9503722084367245, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 19, Valid size: 19, Test size: 370
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8759305210918115, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 48, Valid size: 48, Test size: 341
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7518610421836228, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 96, Valid size: 96, Test size: 293
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5037220843672456, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 193, Valid size: 193, Test size: 196
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 589
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 549
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 499
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 99
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 21.820831298828125
Validation loss: 17.93024444580078 MAE: 3.6870558
Validation loss: 13.879979133605957 MAE: 3.0893545
Validation loss: 10.504976272583008 MAE: 2.5919063
Validation loss: 7.954683780670166 MAE: 2.2438526
Validation loss: 6.018060684204102 MAE: 1.921684
Validation loss: 4.769458293914795 MAE: 1.8006701
Validation loss: 4.332718372344971 MAE: 1.8357893
Validation loss: 4.810740947723389 MAE: 1.9327943
Validation loss: 6.320341110229492 MAE: 2.1720674
Validation loss: 8.984590530395508 MAE: 2.507783
Validation loss: 12.559207916259766 MAE: 2.9934664
Validation loss: 16.240507125854492 MAE: 3.4610095
Validation loss: 18.91193962097168 MAE: 3.8442357
Validation loss: 20.654865264892578 MAE: 4.0786996
Validation loss: 21.509267807006836 MAE: 4.1903453
Validation loss: 20.821863174438477 MAE: 4.1102924
Validation loss: 18.997394561767578 MAE: 3.8783069
Validation loss: 17.534849166870117 MAE: 3.6754909
Validation loss: 16.068180084228516 MAE: 3.4570606
Validation loss: 14.748984336853027 MAE: 3.2450693
Validation loss: 13.335734367370605 MAE: 3.0904455
Validation loss: 11.173681259155273 MAE: 2.8664198
Validation loss: 8.198246955871582 MAE: 2.4825077
Validation loss: 6.154575824737549 MAE: 2.15225
Validation loss: 4.852081775665283 MAE: 1.8860601
Validation loss: 4.15452766418457 MAE: 1.6980239
Validation loss: 3.841923236846924 MAE: 1.6177307
Validation loss: 3.790471315383911 MAE: 1.600872
Validation loss: 3.8297200202941895 MAE: 1.6109079
Validation loss: 3.687055826187134 MAE: 1.5880636
Validation loss: 3.6158838272094727 MAE: 1.5738355
Validation loss: 3.5741467475891113 MAE: 1.5658631
Validation loss: 3.5527238845825195 MAE: 1.5635754
Validation loss: 3.4686594009399414 MAE: 1.5341427
Validation loss: 3.4006800651550293 MAE: 1.5059946
Validation loss: 3.3445022106170654 MAE: 1.4964575
Validation loss: 3.3152964115142822 MAE: 1.5058808
Validation loss: 3.297366142272949 MAE: 1.5250407
Validation loss: 3.2933526039123535 MAE: 1.5452737
Validation loss: 3.223477602005005 MAE: 1.5438458
Validation loss: 3.1900858879089355 MAE: 1.550796
Validation loss: 3.1560921669006348 MAE: 1.5531287
Validation loss: 3.0225443840026855 MAE: 1.5325091
Validation loss: 2.91312837600708 MAE: 1.5146346
Validation loss: 2.8055193424224854 MAE: 1.4940085
Validation loss: 2.679518461227417 MAE: 1.4650232
Validation loss: 2.5627596378326416 MAE: 1.4334474
Validation loss: 2.475338935852051 MAE: 1.4045243
Validation loss: 2.3680872917175293 MAE: 1.3668818
Validation loss: 2.245931625366211 MAE: 1.32089
50 0 3.050940990447998
Validation loss: 2.128408670425415 MAE: 1.2728791
Validation loss: 2.049851417541504 MAE: 1.2322108
Validation loss: 2.009509325027466 MAE: 1.1968668
Validation loss: 1.9936074018478394 MAE: 1.1724573
Validation loss: 1.9004766941070557 MAE: 1.1564857
Validation loss: 1.831358551979065 MAE: 1.1765074
Validation loss: 1.8105934858322144 MAE: 1.1742069
Validation loss: 1.7937407493591309 MAE: 1.1537127
Validation loss: 1.7700800895690918 MAE: 1.1390567
Validation loss: 1.7307575941085815 MAE: 1.1362637
Validation loss: 1.6998244524002075 MAE: 1.1292092
Validation loss: 1.6327452659606934 MAE: 1.1131824
Validation loss: 1.5849910974502563 MAE: 1.0898372
Validation loss: 1.5848362445831299 MAE: 1.11283
Validation loss: 1.6686985492706299 MAE: 1.1922213
Validation loss: 1.8141059875488281 MAE: 1.2566621
Validation loss: 2.0375092029571533 MAE: 1.3168153
Validation loss: 2.293341636657715 MAE: 1.368989
Validation loss: 2.3151915073394775 MAE: 1.3645263
Validation loss: 2.2612357139587402 MAE: 1.3477814
Validation loss: 2.08347225189209 MAE: 1.3053879
Validation loss: 1.901236653327942 MAE: 1.2587829
Validation loss: 1.7748034000396729 MAE: 1.2165648
Validation loss: 1.7701947689056396 MAE: 1.2044926
Validation loss: 1.508769154548645 MAE: 1.1176572
Validation loss: 1.4126520156860352 MAE: 1.0698026
Validation loss: 1.3009047508239746 MAE: 1.0089586
Validation loss: 1.3133981227874756 MAE: 1.0213634
Validation loss: 1.318846583366394 MAE: 1.0356307
Validation loss: 1.3436073064804077 MAE: 1.0669026
Validation loss: 1.399742603302002 MAE: 1.0992484
Validation loss: 1.4683326482772827 MAE: 1.125269
Validation loss: 1.5817877054214478 MAE: 1.1706243
Validation loss: 1.6762895584106445 MAE: 1.1770117
Validation loss: 1.737421989440918 MAE: 1.1701791
Validation loss: 1.7665972709655762 MAE: 1.1469897
Validation loss: 2.008064031600952 MAE: 1.2167101
Validation loss: 2.0999598503112793 MAE: 1.2574399
Validation loss: 2.0856635570526123 MAE: 1.241907
Validation loss: 2.0719032287597656 MAE: 1.2224472
Validation loss: 2.0187323093414307 MAE: 1.2306588
Validation loss: 1.9490983486175537 MAE: 1.2067217
Validation loss: 1.946053385734558 MAE: 1.2005048
Validation loss: 1.9285608530044556 MAE: 1.1926198
Validation loss: 1.902404546737671 MAE: 1.1803097
Validation loss: 1.8165724277496338 MAE: 1.1444751
Validation loss: 1.9267038106918335 MAE: 1.1403232
Validation loss: 2.0832290649414062 MAE: 1.1365738
Validation loss: 1.7725064754486084 MAE: 1.0495847
Validation loss: 1.752413272857666 MAE: 1.0478898
Loaded trained model with success.
Test loss: 6.955039781682632 Test MAE: 2.1187458
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 20.167072296142578
Validation loss: 11.474366479990433 MAE: 2.7402194
Validation loss: 6.6891293914950625 MAE: 2.1026843
Validation loss: 5.205074689826187 MAE: 1.9551803
Validation loss: 7.384332588740757 MAE: 2.2327962
Validation loss: 10.930621088767538 MAE: 2.769028
Validation loss: 12.351802008492607 MAE: 2.9787967
Validation loss: 12.617020840547523 MAE: 3.0007873
Validation loss: 11.653109063907545 MAE: 2.8634136
Validation loss: 9.383279119219099 MAE: 2.5326862
Validation loss: 7.639855073422802 MAE: 2.2711272
Validation loss: 6.536274754271215 MAE: 2.0941021
Validation loss: 5.826114946482133 MAE: 1.9957411
Validation loss: 5.461838196734993 MAE: 1.9559554
Validation loss: 5.314739081324364 MAE: 1.9448206
Validation loss: 5.227733300656689 MAE: 1.9358064
Validation loss: 5.23772380789932 MAE: 1.934522
Validation loss: 5.260738329011566 MAE: 1.9340489
Validation loss: 5.286187658504564 MAE: 1.9343499
Validation loss: 5.343196469910291 MAE: 1.9417372
Validation loss: 5.382000806380291 MAE: 1.948409
Validation loss: 5.241564857716463 MAE: 1.9270377
Validation loss: 5.221761119608977 MAE: 1.971461
Validation loss: 5.491916724613735 MAE: 2.0121818
Validation loss: 5.572169741805719 MAE: 2.0185173
Validation loss: 5.552331613034618 MAE: 2.018524
25 0 4.920383930206299
Validation loss: 5.54578481401716 MAE: 2.0227358
Validation loss: 5.521491936274937 MAE: 2.0271692
Validation loss: 5.491272449493408 MAE: 2.026721
Validation loss: 5.489278987962372 MAE: 2.0280821
Validation loss: 5.453028683759729 MAE: 2.0242665
Validation loss: 5.425596159331652 MAE: 2.0210578
Validation loss: 5.398404160324408 MAE: 2.0176961
Validation loss: 5.36786041454393 MAE: 2.0127747
Validation loss: 5.34422274025119 MAE: 2.0079546
Validation loss: 5.308691482154691 MAE: 2.0011945
Validation loss: 5.270762555453242 MAE: 1.9944338
Validation loss: 5.240287011983443 MAE: 1.9881575
Validation loss: 5.214890100518051 MAE: 1.9824259
Validation loss: 5.178993663009332 MAE: 1.973418
Validation loss: 5.180199433346184 MAE: 1.9716349
Validation loss: 5.190395150865827 MAE: 1.9701338
Validation loss: 5.192289566507145 MAE: 1.9661301
Validation loss: 5.183810272995307 MAE: 1.962147
Validation loss: 5.181470656881527 MAE: 1.9600046
Validation loss: 5.158207377608941 MAE: 1.9529763
Validation loss: 5.14523306671454 MAE: 1.942166
Validation loss: 5.130163659854811 MAE: 1.9277185
Validation loss: 5.154278492440983 MAE: 1.9243686
Validation loss: 5.2591449192592075 MAE: 1.9318073
Validation loss: 5.350196916229871 MAE: 1.9410967
50 0 4.797518730163574
Validation loss: 5.499624816738829 MAE: 1.9556881
Validation loss: 5.709265329399887 MAE: 1.981005
Validation loss: 5.818835599081857 MAE: 2.0000832
Validation loss: 5.919635383450255 MAE: 2.0145152
Validation loss: 5.912222667616241 MAE: 2.0123725
Validation loss: 5.961246607254963 MAE: 2.0183642
Validation loss: 6.094267514287209 MAE: 2.035866
Validation loss: 6.11598775824722 MAE: 2.0384705
Validation loss: 6.094585788493254 MAE: 2.0356498
Validation loss: 6.008996982963717 MAE: 2.0247068
Validation loss: 5.745906469773273 MAE: 1.989376
Validation loss: 5.476695381865209 MAE: 1.9506837
Validation loss: 5.292599084425945 MAE: 1.9228034
Validation loss: 5.067183261014978 MAE: 1.8881735
Validation loss: 5.2334465542618105 MAE: 1.9093828
Validation loss: 5.593136047830387 MAE: 1.9637926
Validation loss: 6.3354860422562576 MAE: 2.072392
Validation loss: 6.489490664735133 MAE: 2.0970864
Validation loss: 5.127035384275476 MAE: 1.8971622
Validation loss: 4.312371886506373 MAE: 1.768127
Validation loss: 3.737637369000182 MAE: 1.6693206
Validation loss: 3.739772387913295 MAE: 1.6268024
Validation loss: 3.7111653503106563 MAE: 1.6406336
Validation loss: 3.707997283157037 MAE: 1.6545659
Validation loss: 3.6831054298245176 MAE: 1.6552016
75 0 4.491262912750244
Validation loss: 3.746853444041038 MAE: 1.6956776
Validation loss: 3.8335527011326382 MAE: 1.7229623
Validation loss: 3.8856869619719836 MAE: 1.7322539
Validation loss: 3.802889313016619 MAE: 1.7119246
Validation loss: 3.717019183295114 MAE: 1.6896262
Validation loss: 3.601959515591057 MAE: 1.6540254
Validation loss: 3.6618266446249828 MAE: 1.6646554
Validation loss: 3.8146997811842938 MAE: 1.6970252
Validation loss: 3.9808999956870568 MAE: 1.728326
Validation loss: 4.370453328502421 MAE: 1.7932504
Validation loss: 4.662516535544882 MAE: 1.8298906
Validation loss: 4.665589332580566 MAE: 1.8259887
Validation loss: 4.722464717164332 MAE: 1.8312459
Validation loss: 4.959246586780159 MAE: 1.8660269
Validation loss: 5.204172873983578 MAE: 1.9073083
Validation loss: 5.7149010288472075 MAE: 1.9841629
Validation loss: 5.737243593955527 MAE: 1.98681
Validation loss: 5.60610462694752 MAE: 1.9611692
Validation loss: 5.733163366512376 MAE: 1.9840056
Validation loss: 5.731058325086321 MAE: 1.9847234
Validation loss: 5.72558611266467 MAE: 1.9813131
Validation loss: 5.679325726567482 MAE: 1.9707617
Validation loss: 5.623128005436489 MAE: 1.9595091
Validation loss: 5.62563402798711 MAE: 1.9594815
Validation loss: 5.602431258376764 MAE: 1.9547946
Loaded trained model with success.
Test loss: 5.598363137427177 Test MAE: 1.916243
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 26.298173904418945
Validation loss: 8.583077710084241 MAE: 2.352394
Validation loss: 7.207220318341496 MAE: 2.2333896
Validation loss: 19.631116587706288 MAE: 3.847899
Validation loss: 18.252807578655204 MAE: 3.7216094
Validation loss: 12.064508746368716 MAE: 2.9047441
Validation loss: 7.281406094329526 MAE: 2.2029614
Validation loss: 5.719248783708823 MAE: 1.9485921
Validation loss: 5.777448668624416 MAE: 1.9806526
Validation loss: 6.049434342769661 MAE: 2.0342414
Validation loss: 6.464968999226888 MAE: 2.0976942
Validation loss: 6.501440645468356 MAE: 2.1066172
Validation loss: 6.138129394463818 MAE: 2.046491
12 2 5.856339931488037
Validation loss: 6.12254642717766 MAE: 2.0427148
Validation loss: 6.237899732108068 MAE: 2.0619535
Validation loss: 6.0446484522386035 MAE: 2.0359714
Validation loss: 5.867033823572024 MAE: 2.0086558
Validation loss: 5.832554971328889 MAE: 2.001847
Validation loss: 5.79318375539298 MAE: 1.9941611
Validation loss: 5.886917314144096 MAE: 2.0037107
Validation loss: 5.8944715249418005 MAE: 2.0053883
Validation loss: 6.04519679329612 MAE: 2.0289254
Validation loss: 6.175613750110973 MAE: 2.0474806
Validation loss: 5.972360037794017 MAE: 2.0151522
Validation loss: 5.768807437684801 MAE: 1.9788889
Validation loss: 5.718784363582881 MAE: 1.9688569
25 0 6.83571720123291
Validation loss: 5.729477867935643 MAE: 1.9707993
Validation loss: 5.7100656779125485 MAE: 1.9622651
Validation loss: 5.980100039279822 MAE: 2.0098088
Validation loss: 6.102379626697964 MAE: 2.0305073
Validation loss: 5.968369984867597 MAE: 2.011897
Validation loss: 5.993262004370641 MAE: 2.0188391
Validation loss: 5.985742617135096 MAE: 2.0206902
Validation loss: 5.993085827490296 MAE: 2.0187938
Validation loss: 6.1025530160075485 MAE: 2.0363293
Validation loss: 5.926526951067375 MAE: 2.0031881
Validation loss: 5.8280523521731595 MAE: 1.982263
Validation loss: 5.7127461433410645 MAE: 1.9597167
37 2 4.706582069396973
Validation loss: 5.603300720754296 MAE: 1.9476386
Validation loss: 5.582338583589804 MAE: 1.939998
Validation loss: 5.587596601910061 MAE: 1.938392
Validation loss: 5.594756107137661 MAE: 1.949744
Validation loss: 5.595584773054027 MAE: 1.9541669
Validation loss: 5.620260096559621 MAE: 1.9625682
Validation loss: 5.956643603064797 MAE: 2.0057597
Validation loss: 6.403322056086377 MAE: 2.0828986
Validation loss: 6.806112234038536 MAE: 2.1542447
Validation loss: 6.981758310337259 MAE: 2.1806045
Validation loss: 6.892429592633488 MAE: 2.164044
Validation loss: 5.2110429195442585 MAE: 1.8641404
Validation loss: 4.484764062997066 MAE: 1.7422149
50 0 5.340029239654541
Validation loss: 4.8553747865888806 MAE: 1.8055284
Validation loss: 5.16479197535852 MAE: 1.8404684
Validation loss: 5.035179446441958 MAE: 1.7986603
Validation loss: 4.616566063177706 MAE: 1.7292808
Validation loss: 4.273436855186116 MAE: 1.6936513
Validation loss: 4.307104433425749 MAE: 1.7101291
Validation loss: 4.317346594550393 MAE: 1.7344396
Validation loss: 4.321691798441337 MAE: 1.7397381
Validation loss: 4.776507142216269 MAE: 1.8280313
Validation loss: 5.713105548511852 MAE: 2.0023706
Validation loss: 6.137938841424807 MAE: 2.0530448
Validation loss: 4.568022790581289 MAE: 1.7863742
62 2 2.895781993865967
Validation loss: 3.9252057171831227 MAE: 1.6605219
Validation loss: 3.878427028656006 MAE: 1.6418984
Validation loss: 3.9299228119127676 MAE: 1.645739
Validation loss: 3.785924717633411 MAE: 1.6039298
Validation loss: 3.6243348458800653 MAE: 1.600857
Validation loss: 3.418311282841846 MAE: 1.5555466
Validation loss: 3.5092668436994456 MAE: 1.5375136
Validation loss: 3.4316230928054963 MAE: 1.5440769
Validation loss: 3.378915695228962 MAE: 1.5509871
Validation loss: 3.3285710865801033 MAE: 1.5333256
Validation loss: 3.5364803689898867 MAE: 1.5384889
Validation loss: 3.6705583490506566 MAE: 1.5391468
Validation loss: 3.591819470578974 MAE: 1.5125029
75 0 3.3496484756469727
Validation loss: 3.6243260099430277 MAE: 1.5214998
Validation loss: 3.3043839805053943 MAE: 1.4824275
Validation loss: 3.2650324696242206 MAE: 1.5069505
Validation loss: 3.3027649214773467 MAE: 1.540814
Validation loss: 3.736814347180453 MAE: 1.6254402
Validation loss: 3.6642118150537666 MAE: 1.6048025
Validation loss: 3.990919231164335 MAE: 1.6623651
Validation loss: 3.4957020788481743 MAE: 1.5745898
Validation loss: 3.12911574888711 MAE: 1.4920795
Validation loss: 3.255996964194558 MAE: 1.5298368
Validation loss: 4.320600239917486 MAE: 1.7242867
Validation loss: 4.367043750454681 MAE: 1.7109089
87 2 3.6128833293914795
Validation loss: 3.49842414801771 MAE: 1.577183
Validation loss: 3.47407271404459 MAE: 1.5746572
Validation loss: 3.452819971123127 MAE: 1.5571449
Validation loss: 3.354892509152191 MAE: 1.5238093
Validation loss: 3.1381764821331912 MAE: 1.4753314
Validation loss: 3.1662720285280788 MAE: 1.465994
Validation loss: 3.308867204068887 MAE: 1.5029433
Validation loss: 3.6015375888708867 MAE: 1.5603995
Validation loss: 3.1959053091328555 MAE: 1.4463955
Validation loss: 2.8967207513674342 MAE: 1.4394144
Validation loss: 3.1694810149645565 MAE: 1.5063138
Validation loss: 3.236443201700846 MAE: 1.5183185
Validation loss: 3.2268075196429935 MAE: 1.5225929
Loaded trained model with success.
Test loss: 5.218825437143475 Test MAE: 1.8497963
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 21.715299606323242
Validation loss: 6.098347613559896 MAE: 2.0793257
Validation loss: 21.298510287874308 MAE: 4.048144
Validation loss: 9.627472048428789 MAE: 2.5519192
Validation loss: 5.985558960305985 MAE: 2.0561624
Validation loss: 5.58960880825867 MAE: 1.9886518
Validation loss: 5.530334522975749 MAE: 1.9772329
Validation loss: 5.680496412305976 MAE: 1.9957681
7 1 6.76182746887207
Validation loss: 5.597350142109933 MAE: 1.9805034
Validation loss: 5.641356923472342 MAE: 1.9881915
Validation loss: 5.630051306144676 MAE: 1.9868603
Validation loss: 5.687311734386425 MAE: 1.9976767
Validation loss: 5.598522977014283 MAE: 1.9835589
Validation loss: 5.566362761971939 MAE: 1.9715213
Validation loss: 5.515108133081216 MAE: 1.955025
14 2 5.487353324890137
Validation loss: 5.662797295268456 MAE: 1.9641917
Validation loss: 5.908884833206484 MAE: 2.0008802
Validation loss: 5.607440982032661 MAE: 1.9759744
Validation loss: 5.325273192707618 MAE: 1.9381568
Validation loss: 5.123141104252494 MAE: 1.8954339
Validation loss: 5.012555587231813 MAE: 1.8707527
Validation loss: 4.8902862012086805 MAE: 1.8365681
21 3 5.741774082183838
Validation loss: 4.932888886437344 MAE: 1.8091801
Validation loss: 5.114410961093615 MAE: 1.8600808
Validation loss: 4.437174092585118 MAE: 1.7488741
Validation loss: 4.31712874934901 MAE: 1.7432076
Validation loss: 4.220134789021171 MAE: 1.7366912
Validation loss: 4.187843647434484 MAE: 1.7063482
Validation loss: 4.567895492716651 MAE: 1.7533379
28 4 2.8068461418151855
Validation loss: 3.9107194725592533 MAE: 1.65309
Validation loss: 3.729118632311797 MAE: 1.6034801
Validation loss: 3.7808613980834807 MAE: 1.5975565
Validation loss: 3.8016551199869895 MAE: 1.6049258
Validation loss: 3.7712846581061283 MAE: 1.6141822
Validation loss: 4.2536314456307105 MAE: 1.67016
Validation loss: 4.3005376437201575 MAE: 1.6757576
35 5 3.577012300491333
Validation loss: 3.636163771452017 MAE: 1.6028126
Validation loss: 3.756087928860631 MAE: 1.6045378
Validation loss: 3.5002077632213955 MAE: 1.5586989
Validation loss: 3.416594034463317 MAE: 1.5300823
Validation loss: 3.4298578854182256 MAE: 1.5406215
Validation loss: 3.5844875580102356 MAE: 1.5834965
Validation loss: 3.331319072138724 MAE: 1.5046315
42 6 3.5587921142578125
Validation loss: 3.3482739937365356 MAE: 1.5134094
Validation loss: 3.532980010737127 MAE: 1.5435725
Validation loss: 3.4865026593807356 MAE: 1.5246453
Validation loss: 3.7519585235634043 MAE: 1.5754771
Validation loss: 3.8462140943536807 MAE: 1.5873091
Validation loss: 4.381614737774259 MAE: 1.6815015
Validation loss: 3.1508785348441735 MAE: 1.462059
Validation loss: 3.454340128443349 MAE: 1.5493995
50 0 4.138162612915039
Validation loss: 3.135076896629142 MAE: 1.4483964
Validation loss: 3.144274249148728 MAE: 1.4203593
Validation loss: 3.554587052695116 MAE: 1.5275564
Validation loss: 4.257490342286364 MAE: 1.6467813
Validation loss: 3.823638835744043 MAE: 1.5570308
Validation loss: 3.3695008976375638 MAE: 1.4824471
Validation loss: 3.2410794766105 MAE: 1.4354644
57 1 3.1431539058685303
Validation loss: 3.2703881101991663 MAE: 1.430996
Validation loss: 3.10409386553357 MAE: 1.4331815
Validation loss: 3.477253456211569 MAE: 1.4780205
Validation loss: 3.772080739838394 MAE: 1.5337172
Validation loss: 3.8481915320583324 MAE: 1.5590725
Validation loss: 3.856278707034624 MAE: 1.5636597
Validation loss: 2.979579515792617 MAE: 1.3605511
64 2 3.598264694213867
Validation loss: 3.0895949727925824 MAE: 1.4080986
Validation loss: 3.0362578288993642 MAE: 1.4079423
Validation loss: 2.742726599151765 MAE: 1.3355609
Validation loss: 2.7864818884499707 MAE: 1.3475244
Validation loss: 4.054017337722395 MAE: 1.6541185
Validation loss: 4.384633773535341 MAE: 1.7080449
Validation loss: 3.3765790076112028 MAE: 1.4817107
71 3 3.944885015487671
Validation loss: 3.165067180317251 MAE: 1.4330263
Validation loss: 2.7472375217993656 MAE: 1.3072565
Validation loss: 2.6419360062584807 MAE: 1.3090323
Validation loss: 2.8334896246991566 MAE: 1.3686594
Validation loss: 3.7093363443211693 MAE: 1.547109
Validation loss: 3.3622524342944273 MAE: 1.473569
Validation loss: 4.708429978720507 MAE: 1.7481809
78 4 4.478226661682129
Validation loss: 4.222744420545185 MAE: 1.6297673
Validation loss: 3.2833866246381596 MAE: 1.4293433
Validation loss: 2.7561677580502764 MAE: 1.3383447
Validation loss: 2.6996010452059647 MAE: 1.3272549
Validation loss: 2.5645147376324062 MAE: 1.2809011
Validation loss: 2.803545404319188 MAE: 1.3105791
Validation loss: 3.714781247191693 MAE: 1.5371121
85 5 2.5128703117370605
Validation loss: 2.8199558881059965 MAE: 1.3172284
Validation loss: 2.6212376721540287 MAE: 1.2679565
Validation loss: 2.736888839970881 MAE: 1.2981917
Validation loss: 2.827928130950161 MAE: 1.3327744
Validation loss: 3.1103091886894187 MAE: 1.4181252
Validation loss: 2.5087255293400443 MAE: 1.2886932
Validation loss: 3.236763467740773 MAE: 1.4556592
92 6 2.720764636993408
Validation loss: 3.4821556830526 MAE: 1.5022908
Validation loss: 3.384340258099925 MAE: 1.4737828
Validation loss: 2.819392784156991 MAE: 1.33512
Validation loss: 3.1910615153049107 MAE: 1.4176313
Validation loss: 3.536187605642194 MAE: 1.514643
Validation loss: 2.4653364174330057 MAE: 1.2798003
Validation loss: 2.3611891401473004 MAE: 1.2525768
Validation loss: 2.56618478639641 MAE: 1.3108255
Loaded trained model with success.
Test loss: 5.108687618792986 Test MAE: 1.7932353
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 19.080352783203125
Validation loss: 21.386551163239567 MAE: 4.0722847
Validation loss: 5.588193976568554 MAE: 1.9690565
Validation loss: 5.157036266250458 MAE: 1.89388
3 2 4.834181785583496
Validation loss: 5.42349941028144 MAE: 1.9403365
Validation loss: 5.66514900547708 MAE: 1.9587353
Validation loss: 5.232241117404793 MAE: 1.8797611
6 4 5.3951311111450195
Validation loss: 5.3047631919264555 MAE: 1.9161017
Validation loss: 4.877113649983683 MAE: 1.8284308
Validation loss: 5.3242565090049485 MAE: 1.884615
9 6 4.290589332580566
Validation loss: 4.7985436147105 MAE: 1.7694706
Validation loss: 4.63985148221553 MAE: 1.749848
Validation loss: 4.348378194835717 MAE: 1.7058889
12 8 3.7671661376953125
Validation loss: 4.791850711157422 MAE: 1.7787988
Validation loss: 5.256047580428496 MAE: 1.837802
Validation loss: 5.114473272182182 MAE: 1.8388214
15 10 3.7008094787597656
Validation loss: 5.57003086315606 MAE: 1.910787
Validation loss: 3.9508817888691814 MAE: 1.6326449
Validation loss: 5.009725840153818 MAE: 1.7915031
18 12 3.7300240993499756
Validation loss: 5.548576654078726 MAE: 1.9075739
Validation loss: 4.5164333450531435 MAE: 1.7528497
Validation loss: 5.336104916666218 MAE: 1.8760359
21 14 4.100589275360107
Validation loss: 4.681200152647519 MAE: 1.7420304
Validation loss: 4.25008574946371 MAE: 1.673846
Validation loss: 4.528615697352346 MAE: 1.7413007
Validation loss: 4.540342372022793 MAE: 1.7262009
25 0 4.274871349334717
Validation loss: 3.9319455086109873 MAE: 1.6107749
Validation loss: 5.8061815149081735 MAE: 1.95228
Validation loss: 4.905022181585461 MAE: 1.799617
28 2 3.7819325923919678
Validation loss: 4.504335651416817 MAE: 1.7033933
Validation loss: 4.227932044164929 MAE: 1.6715866
Validation loss: 4.328052902986148 MAE: 1.6909498
31 4 3.113138437271118
Validation loss: 6.090500956785703 MAE: 2.002806
Validation loss: 5.853554698890579 MAE: 1.9859298
Validation loss: 4.288926217742339 MAE: 1.7006233
34 6 3.4999852180480957
Validation loss: 4.255174138980782 MAE: 1.6452723
Validation loss: 5.346247770504387 MAE: 1.8670447
Validation loss: 4.144736155718267 MAE: 1.6594456
37 8 4.768820762634277
Validation loss: 4.65245173211566 MAE: 1.7547697
Validation loss: 5.233628637088325 MAE: 1.8504366
Validation loss: 3.769206650032548 MAE: 1.573021
40 10 4.931687355041504
Validation loss: 4.639427366619836 MAE: 1.7397586
Validation loss: 5.457129235735876 MAE: 1.8783902
Validation loss: 4.091170500180048 MAE: 1.6212579
43 12 2.8096730709075928
Validation loss: 4.425126743698884 MAE: 1.7163631
Validation loss: 3.9100958044399956 MAE: 1.5893227
Validation loss: 4.649986526053511 MAE: 1.7487527
46 14 5.0871076583862305
Validation loss: 3.3306469210164105 MAE: 1.4853721
Validation loss: 3.5235950846471384 MAE: 1.5327432
Validation loss: 5.90172694823546 MAE: 1.9732485
Validation loss: 3.409056045727166 MAE: 1.5015092
50 0 4.315643310546875
Validation loss: 4.016032538576451 MAE: 1.6048515
Validation loss: 3.908357523725124 MAE: 1.6013427
Validation loss: 4.6807788364395115 MAE: 1.7437027
53 2 4.3727922439575195
Validation loss: 3.5449188768505335 MAE: 1.518016
Validation loss: 4.468740633351053 MAE: 1.688856
Validation loss: 4.112539036240511 MAE: 1.6401725
56 4 4.438080787658691
Validation loss: 3.84824816162935 MAE: 1.5806535
Validation loss: 3.682360429802017 MAE: 1.5618541
Validation loss: 3.545468100564991 MAE: 1.5212995
59 6 3.2053170204162598
Validation loss: 3.3681426354066164 MAE: 1.4977877
Validation loss: 4.9373207866309405 MAE: 1.7848475
Validation loss: 3.097901847892868 MAE: 1.4502939
62 8 3.049795150756836
Validation loss: 3.872344625736764 MAE: 1.6003127
Validation loss: 3.1581663077245494 MAE: 1.4487609
Validation loss: 3.3976637519194273 MAE: 1.5035914
65 10 3.254901647567749
Validation loss: 3.4608515393518973 MAE: 1.5103209
Validation loss: 3.653251164422962 MAE: 1.5436244
Validation loss: 5.026265932706171 MAE: 1.8138859
68 12 3.2379164695739746
Validation loss: 3.161808022994078 MAE: 1.4461535
Validation loss: 2.9390837482077803 MAE: 1.4054664
Validation loss: 3.38354007371203 MAE: 1.4805413
71 14 3.1391913890838623
Validation loss: 3.4865200510005914 MAE: 1.5088718
Validation loss: 3.0086837010775396 MAE: 1.4160594
Validation loss: 3.2212845916021804 MAE: 1.4544872
Validation loss: 3.456431985618117 MAE: 1.498747
75 0 3.2538700103759766
Validation loss: 3.62095416093876 MAE: 1.5271297
Validation loss: 3.7603270692194632 MAE: 1.5628464
Validation loss: 3.270792581753167 MAE: 1.4641509
78 2 3.323643684387207
Validation loss: 4.142677902458665 MAE: 1.6283478
Validation loss: 3.096533715605497 MAE: 1.4367635
Validation loss: 3.500787429675788 MAE: 1.4968954
81 4 2.2342567443847656
Validation loss: 3.501193427848434 MAE: 1.5069889
Validation loss: 3.4076053016410324 MAE: 1.4886717
Validation loss: 3.0340030685455384 MAE: 1.4293039
84 6 5.245816230773926
Validation loss: 3.0717024091250433 MAE: 1.4228386
Validation loss: 3.5972673835639726 MAE: 1.5242363
Validation loss: 3.2615938492432863 MAE: 1.4644431
87 8 3.81887149810791
Validation loss: 2.7780727972248513 MAE: 1.354275
Validation loss: 3.06811543982588 MAE: 1.4106805
Validation loss: 3.404675500187463 MAE: 1.483701
90 10 3.8854618072509766
Validation loss: 2.836742582206497 MAE: 1.3706853
Validation loss: 2.6478745110765964 MAE: 1.3326167
Validation loss: 4.167663429925342 MAE: 1.6273519
93 12 4.372707366943359
Validation loss: 2.6353007980243475 MAE: 1.3084953
Validation loss: 3.033323662553378 MAE: 1.3984582
Validation loss: 3.120799169511738 MAE: 1.4178535
96 14 3.983531951904297
Validation loss: 4.2136052032271945 MAE: 1.6286653
Validation loss: 2.7993872829811846 MAE: 1.3553753
Validation loss: 3.523882917507378 MAE: 1.495759
Validation loss: 3.4728054441287664 MAE: 1.4893783
Loaded trained model with success.
Test loss: 4.38241782874168 Test MAE: 1.6486096
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999848297979177, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 659177
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999241489895887, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 659137
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9998482979791774, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 659087
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9996965959583548, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 658987
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9992414898958869, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 658687
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9984829797917738, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 999, Valid size: 999, Test size: 658187
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9751861042183623, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 380
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9503722084367245, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 19, Valid size: 19, Test size: 370
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8759305210918115, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 48, Valid size: 48, Test size: 341
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7518610421836228, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 96, Valid size: 96, Test size: 293
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5037220843672456, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 193, Valid size: 193, Test size: 196
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9833055091819699, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 589
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9165275459098498, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 549
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8330550918196995, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 499
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.666110183639399, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'FreeSolv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.1652754590984975, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/freesolv/freesolv.csv', 'regression_bin_classes': 2}}
Running on: cpu
598
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 99
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9947340705634544, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1889
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9736703528172722, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1849
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9473407056345445, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 1799
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.894681411269089, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 1699
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'Lipo_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7367035281727224, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'regression_bin_classes': 5}}
Running on: cpu
1898
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 1399
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 20.639097213745117
Validation loss: 14.42788314819336 MAE: 3.2200036
Validation loss: 10.653868675231934 MAE: 2.5949335
Validation loss: 7.643218994140625 MAE: 2.1292548
Validation loss: 5.445520877838135 MAE: 1.922736
Validation loss: 4.279080867767334 MAE: 1.8439685
Validation loss: 4.121236801147461 MAE: 1.8571057
Validation loss: 4.920400619506836 MAE: 1.9325237
Validation loss: 6.651262283325195 MAE: 2.1194017
Validation loss: 9.244233131408691 MAE: 2.4914222
Validation loss: 12.447183609008789 MAE: 2.9729424
Validation loss: 15.57872486114502 MAE: 3.3941946
Validation loss: 17.54518699645996 MAE: 3.672534
Validation loss: 17.98073387145996 MAE: 3.7314377
Validation loss: 17.371339797973633 MAE: 3.6489508
Validation loss: 15.502039909362793 MAE: 3.3831706
Validation loss: 13.937317848205566 MAE: 3.1647122
Validation loss: 12.538694381713867 MAE: 2.9848597
Validation loss: 11.130382537841797 MAE: 2.7872686
Validation loss: 9.812546730041504 MAE: 2.5831254
Validation loss: 8.678692817687988 MAE: 2.413794
Validation loss: 7.6078948974609375 MAE: 2.2646527
Validation loss: 6.778576850891113 MAE: 2.132002
Validation loss: 6.220491409301758 MAE: 2.0620668
Validation loss: 5.604500770568848 MAE: 1.9849943
Validation loss: 5.119847774505615 MAE: 1.9359175
Validation loss: 4.750070095062256 MAE: 1.9088631
Validation loss: 4.499101638793945 MAE: 1.8872969
Validation loss: 4.3272318840026855 MAE: 1.8707937
Validation loss: 4.209835052490234 MAE: 1.8582611
Validation loss: 4.127205848693848 MAE: 1.847645
Validation loss: 4.074666500091553 MAE: 1.8394958
Validation loss: 4.055122375488281 MAE: 1.8353013
Validation loss: 4.059096813201904 MAE: 1.8361855
Validation loss: 4.072549343109131 MAE: 1.839419
Validation loss: 4.087103366851807 MAE: 1.8424085
Validation loss: 4.102360725402832 MAE: 1.8460009
Validation loss: 4.117908000946045 MAE: 1.8500977
Validation loss: 4.1288862228393555 MAE: 1.8547823
Validation loss: 4.15313196182251 MAE: 1.8614068
Validation loss: 4.153183460235596 MAE: 1.8648546
Validation loss: 4.142512798309326 MAE: 1.8671517
Validation loss: 4.124814987182617 MAE: 1.866755
Validation loss: 4.095443248748779 MAE: 1.8643365
Validation loss: 4.069972991943359 MAE: 1.8584162
Validation loss: 4.060022354125977 MAE: 1.8534493
Validation loss: 4.0553131103515625 MAE: 1.8473394
Validation loss: 4.057209491729736 MAE: 1.8409284
Validation loss: 4.057162284851074 MAE: 1.8376615
Validation loss: 4.061608791351318 MAE: 1.8341732
Validation loss: 4.060400009155273 MAE: 1.8318267
50 0 3.7869977951049805
Validation loss: 4.061225891113281 MAE: 1.828267
Validation loss: 4.061277866363525 MAE: 1.8228332
Validation loss: 4.061454772949219 MAE: 1.8180618
Validation loss: 4.06803035736084 MAE: 1.8131
Validation loss: 4.0779571533203125 MAE: 1.8089776
Validation loss: 4.083832263946533 MAE: 1.8051292
Validation loss: 4.087128162384033 MAE: 1.8096335
Validation loss: 4.0941572189331055 MAE: 1.812016
Validation loss: 4.119345188140869 MAE: 1.8105619
Validation loss: 4.206710338592529 MAE: 1.8052813
Validation loss: 4.303677082061768 MAE: 1.797344
Validation loss: 4.427641868591309 MAE: 1.7955205
Validation loss: 4.516046524047852 MAE: 1.7954049
Validation loss: 4.673689365386963 MAE: 1.8069166
Validation loss: 4.702727317810059 MAE: 1.8147025
Validation loss: 4.83720064163208 MAE: 1.8404223
Validation loss: 5.025101661682129 MAE: 1.8705275
Validation loss: 5.1970391273498535 MAE: 1.8939512
Validation loss: 5.144964218139648 MAE: 1.8848869
Validation loss: 5.057695388793945 MAE: 1.8706101
Validation loss: 4.974605083465576 MAE: 1.8581023
Validation loss: 4.753422260284424 MAE: 1.8239013
Validation loss: 4.713610649108887 MAE: 1.8176923
Validation loss: 4.603030681610107 MAE: 1.8000884
Validation loss: 4.405551910400391 MAE: 1.7667975
Validation loss: 4.2075700759887695 MAE: 1.729454
Validation loss: 4.081559181213379 MAE: 1.7106507
Validation loss: 3.9432361125946045 MAE: 1.7009591
Validation loss: 3.876988649368286 MAE: 1.6919318
Validation loss: 3.731074333190918 MAE: 1.6799976
Validation loss: 3.628201484680176 MAE: 1.6672585
Validation loss: 3.5382814407348633 MAE: 1.6537236
Validation loss: 3.487328290939331 MAE: 1.6390982
Validation loss: 3.4280354976654053 MAE: 1.6219236
Validation loss: 3.3642280101776123 MAE: 1.603696
Validation loss: 3.3043317794799805 MAE: 1.5830398
Validation loss: 3.244053363800049 MAE: 1.5604734
Validation loss: 3.187732696533203 MAE: 1.5342089
Validation loss: 3.120850086212158 MAE: 1.5049765
Validation loss: 3.027761459350586 MAE: 1.4718965
Validation loss: 2.9460654258728027 MAE: 1.4348121
Validation loss: 2.839280366897583 MAE: 1.3907866
Validation loss: 2.786228656768799 MAE: 1.3802078
Validation loss: 2.702895164489746 MAE: 1.3538394
Validation loss: 2.640397787094116 MAE: 1.3303198
Validation loss: 2.5627644062042236 MAE: 1.32025
Validation loss: 2.618302345275879 MAE: 1.3191295
Validation loss: 2.7080399990081787 MAE: 1.3103242
Validation loss: 2.6936612129211426 MAE: 1.2809377
Validation loss: 2.632405996322632 MAE: 1.279086
Loaded trained model with success.
Test loss: 6.541095291866975 Test MAE: 2.1166723
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 27.451597213745117
Validation loss: 14.61226716333506 MAE: 3.10013
Validation loss: 9.034239399189852 MAE: 2.3209221
Validation loss: 5.9889421171071575 MAE: 2.0315034
Validation loss: 5.874775672445492 MAE: 2.0261137
Validation loss: 8.717548302241735 MAE: 2.4712756
Validation loss: 12.142110863510442 MAE: 2.9501512
Validation loss: 14.24073059704839 MAE: 3.2269504
Validation loss: 13.941561173419563 MAE: 3.184142
Validation loss: 12.019656337037379 MAE: 2.9344
Validation loss: 10.117147640306122 MAE: 2.6720638
Validation loss: 8.128471170152936 MAE: 2.3829594
Validation loss: 6.599745633650799 MAE: 2.1327362
Validation loss: 5.721692766462054 MAE: 1.9878496
Validation loss: 5.461235474567024 MAE: 1.9765756
Validation loss: 5.406053221955592 MAE: 1.9788558
Validation loss: 5.434377281033263 MAE: 1.9853125
Validation loss: 5.456792763301304 MAE: 1.9892777
Validation loss: 5.460870071333282 MAE: 1.9903904
Validation loss: 5.477071207396838 MAE: 1.9939286
Validation loss: 5.478072906027035 MAE: 1.9980133
Validation loss: 5.486455956283881 MAE: 2.0012968
Validation loss: 5.518734348063567 MAE: 2.007836
Validation loss: 5.576159428577034 MAE: 2.0193374
Validation loss: 5.642050383042316 MAE: 2.0277112
Validation loss: 5.709193823288898 MAE: 2.0319984
25 0 5.286343574523926
Validation loss: 5.733542072529695 MAE: 2.0328274
Validation loss: 5.7305784420091275 MAE: 2.0320594
Validation loss: 5.674362824887646 MAE: 2.0271544
Validation loss: 5.605831457644093 MAE: 2.018655
Validation loss: 5.552010643238924 MAE: 2.0057642
Validation loss: 5.533047189517897 MAE: 1.997974
Validation loss: 5.496181351797921 MAE: 1.992811
Validation loss: 5.47386807324935 MAE: 1.9888947
Validation loss: 5.466796320311877 MAE: 1.9866873
Validation loss: 5.44917310014063 MAE: 1.9805913
Validation loss: 5.430258760646898 MAE: 1.974939
Validation loss: 5.421090301202268 MAE: 1.9694896
Validation loss: 5.399413468886395 MAE: 1.9615011
Validation loss: 5.397363448629574 MAE: 1.9524688
Validation loss: 5.448994120773004 MAE: 1.9419895
Validation loss: 5.543157013095155 MAE: 1.9367386
Validation loss: 5.578270873244928 MAE: 1.9330603
Validation loss: 5.5635345614686305 MAE: 1.9290109
Validation loss: 5.594758218648482 MAE: 1.9263315
Validation loss: 5.432193892342704 MAE: 1.9018217
Validation loss: 5.308661441413724 MAE: 1.8839464
Validation loss: 5.266421532144352 MAE: 1.8717036
Validation loss: 5.21413653237479 MAE: 1.8568283
Validation loss: 5.227349826267788 MAE: 1.8513991
Validation loss: 5.287914918393505 MAE: 1.8482803
50 0 5.05219841003418
Validation loss: 5.27882989572019 MAE: 1.8400685
Validation loss: 5.25376541760503 MAE: 1.8344779
Validation loss: 5.172302129317303 MAE: 1.8316116
Validation loss: 5.081817442057084 MAE: 1.8314444
Validation loss: 5.0009215024052835 MAE: 1.8352407
Validation loss: 4.99486966035804 MAE: 1.840979
Validation loss: 5.252783366612026 MAE: 1.9002894
Validation loss: 5.65962756409937 MAE: 1.987181
Validation loss: 5.5803506617643395 MAE: 1.9777755
Validation loss: 5.052221376068738 MAE: 1.8750473
Validation loss: 4.5392763565997685 MAE: 1.7822471
Validation loss: 4.148011679552039 MAE: 1.6912607
Validation loss: 3.847688168895488 MAE: 1.599949
Validation loss: 3.940082005092076 MAE: 1.6210964
Validation loss: 4.0316755139097875 MAE: 1.6440749
Validation loss: 3.8488995153076795 MAE: 1.5791746
Validation loss: 3.7015213869055925 MAE: 1.4973687
Validation loss: 3.6205187038499482 MAE: 1.473297
Validation loss: 3.5674044502024747 MAE: 1.5116028
Validation loss: 3.630079970067861 MAE: 1.553797
Validation loss: 3.6032036275279764 MAE: 1.5502311
Validation loss: 3.5008267383186187 MAE: 1.5048903
Validation loss: 3.4013680925174636 MAE: 1.4318562
Validation loss: 3.358826608073955 MAE: 1.4118227
Validation loss: 3.4076098860526574 MAE: 1.4006183
75 0 4.0809831619262695
Validation loss: 3.387708089789566 MAE: 1.411116
Validation loss: 3.2806448255266463 MAE: 1.4272854
Validation loss: 3.231278881734731 MAE: 1.4364661
Validation loss: 3.2040658581013584 MAE: 1.4222711
Validation loss: 3.081993433893943 MAE: 1.3888966
Validation loss: 3.184592986593441 MAE: 1.4017994
Validation loss: 3.41651819676769 MAE: 1.4570342
Validation loss: 3.7907378673553467 MAE: 1.5401305
Validation loss: 3.507157247893664 MAE: 1.4695547
Validation loss: 3.4458845294251734 MAE: 1.4433024
Validation loss: 3.5791544427677078 MAE: 1.4686497
Validation loss: 3.751875420005954 MAE: 1.496558
Validation loss: 3.5387221355827485 MAE: 1.4351842
Validation loss: 3.4956459317888533 MAE: 1.4518418
Validation loss: 3.2898112511148256 MAE: 1.4349451
Validation loss: 2.995584147317069 MAE: 1.3751276
Validation loss: 2.7495605021106955 MAE: 1.3102425
Validation loss: 2.680989075680168 MAE: 1.2495722
Validation loss: 2.6590685503823415 MAE: 1.2282904
Validation loss: 2.5919198211358516 MAE: 1.198649
Validation loss: 2.4359613340728137 MAE: 1.179634
Validation loss: 2.39100794889489 MAE: 1.1816145
Validation loss: 2.419170549937657 MAE: 1.1947339
Validation loss: 2.464210266969642 MAE: 1.2306434
Validation loss: 2.780730456722026 MAE: 1.3558446
Loaded trained model with success.
Test loss: 5.880362414221727 Test MAE: 1.9417562
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 23.869829177856445
Validation loss: 8.55303030784684 MAE: 2.3761888
Validation loss: 6.609867794345123 MAE: 2.131325
Validation loss: 22.911317767518938 MAE: 4.2596927
Validation loss: 26.164689131457397 MAE: 4.6317053
Validation loss: 9.456149392055742 MAE: 2.578921
Validation loss: 5.423575709564517 MAE: 1.9157476
Validation loss: 4.746188886237867 MAE: 1.7688752
Validation loss: 4.971252032000609 MAE: 1.8011787
Validation loss: 4.826561566555139 MAE: 1.774296
Validation loss: 4.704227794300426 MAE: 1.7584609
Validation loss: 4.6994975456083665 MAE: 1.7555505
Validation loss: 4.784694045481055 MAE: 1.7652284
12 2 3.6555404663085938
Validation loss: 4.937979500703137 MAE: 1.7900985
Validation loss: 4.834575489313916 MAE: 1.7690102
Validation loss: 5.148032537614457 MAE: 1.8204966
Validation loss: 5.74453704525726 MAE: 1.9376377
Validation loss: 5.9483162273060195 MAE: 1.9750613
Validation loss: 5.925872301814532 MAE: 1.9735191
Validation loss: 5.450979096720917 MAE: 1.9047463
Validation loss: 5.130563996054909 MAE: 1.8489265
Validation loss: 5.114958091215654 MAE: 1.8479495
Validation loss: 5.243077109558413 MAE: 1.874169
Validation loss: 5.155581763296416 MAE: 1.8589306
Validation loss: 5.044135599425345 MAE: 1.8316023
Validation loss: 5.234854664465393 MAE: 1.8509705
25 0 5.258727073669434
Validation loss: 5.303247649260242 MAE: 1.8477141
Validation loss: 5.755310299420597 MAE: 1.92268
Validation loss: 5.373811336478802 MAE: 1.8547502
Validation loss: 5.481398934065694 MAE: 1.8721381
Validation loss: 5.543085630493935 MAE: 1.8926028
Validation loss: 5.098123210849184 MAE: 1.8295162
Validation loss: 4.860622324124731 MAE: 1.7978262
Validation loss: 4.90883319546478 MAE: 1.809309
Validation loss: 4.938966409124509 MAE: 1.8151486
Validation loss: 4.876938424929224 MAE: 1.8011823
Validation loss: 4.952046622531583 MAE: 1.806234
Validation loss: 4.8449623271672415 MAE: 1.7787528
37 2 4.686600685119629
Validation loss: 4.82279433866944 MAE: 1.7657751
Validation loss: 4.922364672627112 MAE: 1.7770364
Validation loss: 4.747261278557055 MAE: 1.7543283
Validation loss: 4.699822001987034 MAE: 1.7712839
Validation loss: 4.619099819298946 MAE: 1.7617952
Validation loss: 4.564009813347248 MAE: 1.7309796
Validation loss: 4.849402550495032 MAE: 1.7664118
Validation loss: 5.325159910953406 MAE: 1.8528851
Validation loss: 5.760484653289872 MAE: 1.9309356
Validation loss: 5.202213884604098 MAE: 1.821399
Validation loss: 5.051314589953182 MAE: 1.788318
Validation loss: 5.03310461236973 MAE: 1.7795432
Validation loss: 4.8157156019499805 MAE: 1.743467
50 0 3.0755956172943115
Validation loss: 4.638861724824617 MAE: 1.7217513
Validation loss: 4.698584310936205 MAE: 1.7477728
Validation loss: 4.665894224186136 MAE: 1.749745
Validation loss: 4.84409518193717 MAE: 1.7938948
Validation loss: 4.2166637471227935 MAE: 1.6825745
Validation loss: 3.792538636561596 MAE: 1.6013731
Validation loss: 3.6157127865637193 MAE: 1.5782356
Validation loss: 3.4564689891506926 MAE: 1.5613607
Validation loss: 3.7621319510719995 MAE: 1.6041301
Validation loss: 4.302177313602332 MAE: 1.7055887
Validation loss: 4.375173289366443 MAE: 1.7191557
Validation loss: 4.034192942609691 MAE: 1.6486443
62 2 3.7688961029052734
Validation loss: 3.6286247390689272 MAE: 1.5808102
Validation loss: 3.496271504296197 MAE: 1.5539329
Validation loss: 3.4692747990290322 MAE: 1.546924
Validation loss: 3.5206943328934486 MAE: 1.5573385
Validation loss: 3.5848149025078975 MAE: 1.5417793
Validation loss: 4.026601599924492 MAE: 1.5835555
Validation loss: 4.09225598971049 MAE: 1.5903171
Validation loss: 3.4336581729879283 MAE: 1.4917644
Validation loss: 3.229033169120249 MAE: 1.5016928
Validation loss: 3.2752205603050464 MAE: 1.5086824
Validation loss: 3.1894040878372962 MAE: 1.4696909
Validation loss: 3.445584678890729 MAE: 1.5079747
Validation loss: 4.100483465676356 MAE: 1.6011773
75 0 4.240667819976807
Validation loss: 3.7569759903532085 MAE: 1.5426794
Validation loss: 3.3995160346079354 MAE: 1.4971001
Validation loss: 3.2441638756279993 MAE: 1.4699643
Validation loss: 3.4657242057299373 MAE: 1.4999338
Validation loss: 3.6069348063131774 MAE: 1.5246962
Validation loss: 3.392770092896741 MAE: 1.4815484
Validation loss: 3.0497545497586027 MAE: 1.4316868
Validation loss: 3.148579585431802 MAE: 1.4572933
Validation loss: 3.241884803531146 MAE: 1.4841139
Validation loss: 3.1229918099413014 MAE: 1.4603628
Validation loss: 3.275201399518986 MAE: 1.4996713
Validation loss: 3.550216667579882 MAE: 1.5496356
87 2 4.4996113777160645
Validation loss: 3.709038090224218 MAE: 1.5816256
Validation loss: 3.460948423905806 MAE: 1.5209628
Validation loss: 3.3963464703222717 MAE: 1.4791992
Validation loss: 3.1540933413939043 MAE: 1.4419113
Validation loss: 2.9356964019813923 MAE: 1.4307587
Validation loss: 3.009828158099242 MAE: 1.4399403
Validation loss: 3.3776947271944295 MAE: 1.5070218
Validation loss: 3.8483975993262396 MAE: 1.6002331
Validation loss: 4.9239314794540405 MAE: 1.7792999
Validation loss: 5.04262834125095 MAE: 1.7919999
Validation loss: 4.539802705398714 MAE: 1.7009575
Validation loss: 4.07224966781308 MAE: 1.6132667
Validation loss: 3.130780542137647 MAE: 1.4516929
Loaded trained model with success.
Test loss: 5.3346806814770895 Test MAE: 1.889698
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 28.046045303344727
Validation loss: 5.5507786094243805 MAE: 1.9738209
Validation loss: 13.050919053542554 MAE: 3.0510764
Validation loss: 12.58740569359094 MAE: 2.9900742
Validation loss: 6.170481267286904 MAE: 2.066064
Validation loss: 5.56236988096381 MAE: 1.9550649
Validation loss: 5.878018204291262 MAE: 1.9958545
Validation loss: 6.441251445655248 MAE: 2.0881162
7 1 6.107775688171387
Validation loss: 5.767262650494599 MAE: 1.980186
Validation loss: 5.372865875761713 MAE: 1.917935
Validation loss: 5.355782475303765 MAE: 1.9212856
Validation loss: 5.366400869647462 MAE: 1.9243532
Validation loss: 5.402827812798658 MAE: 1.9297093
Validation loss: 5.4302666606615535 MAE: 1.9172597
Validation loss: 5.405861186022735 MAE: 1.9052811
14 2 5.505560874938965
Validation loss: 5.251257032605272 MAE: 1.8993386
Validation loss: 5.247986153741578 MAE: 1.8856379
Validation loss: 5.208165736653697 MAE: 1.8968178
Validation loss: 5.056676035550372 MAE: 1.8602729
Validation loss: 5.462856879785432 MAE: 1.9135268
Validation loss: 5.632817829074572 MAE: 1.9545908
Validation loss: 4.969485534495445 MAE: 1.8448625
21 3 5.363609790802002
Validation loss: 4.718989916183242 MAE: 1.790394
Validation loss: 4.849086742305277 MAE: 1.8224435
Validation loss: 4.4742228775168185 MAE: 1.7331239
Validation loss: 4.250533602345529 MAE: 1.7045352
Validation loss: 4.095857589089092 MAE: 1.6726481
Validation loss: 4.039840830031352 MAE: 1.6649925
Validation loss: 6.696077064054096 MAE: 2.1606057
28 4 3.8601555824279785
Validation loss: 5.429200299421147 MAE: 1.930794
Validation loss: 4.24486420981249 MAE: 1.6876482
Validation loss: 5.10179199405651 MAE: 1.8166561
Validation loss: 6.07182356580418 MAE: 1.9655731
Validation loss: 4.521906930597583 MAE: 1.7241997
Validation loss: 4.149731930775858 MAE: 1.657218
Validation loss: 4.327866124148345 MAE: 1.6785781
35 5 3.0009233951568604
Validation loss: 3.5662124384587734 MAE: 1.5453056
Validation loss: 3.4446542835115785 MAE: 1.5003444
Validation loss: 3.570640861089505 MAE: 1.5026193
Validation loss: 3.497018349230589 MAE: 1.504025
Validation loss: 3.3158516656214267 MAE: 1.4949387
Validation loss: 3.2693968987345094 MAE: 1.4683318
Validation loss: 4.038657313016192 MAE: 1.6709349
42 6 5.440792560577393
Validation loss: 4.163984673706131 MAE: 1.6916771
Validation loss: 3.3510359711383457 MAE: 1.5182602
Validation loss: 3.733430594056096 MAE: 1.5566629
Validation loss: 3.0914654863539655 MAE: 1.4402322
Validation loss: 3.1374245145213067 MAE: 1.4714618
Validation loss: 3.438142074412437 MAE: 1.5515404
Validation loss: 3.296398788241286 MAE: 1.4996433
Validation loss: 3.5071376011000206 MAE: 1.5538213
50 0 4.554453372955322
Validation loss: 3.775417995962066 MAE: 1.6223884
Validation loss: 3.038599104138475 MAE: 1.4223329
Validation loss: 2.9713971926339307 MAE: 1.3978434
Validation loss: 3.7171418463165438 MAE: 1.6103052
Validation loss: 3.059286708208784 MAE: 1.4349209
Validation loss: 3.127168959708669 MAE: 1.454957
Validation loss: 3.3013374302255447 MAE: 1.5084144
57 1 3.5729198455810547
Validation loss: 3.523553490039691 MAE: 1.5780127
Validation loss: 3.338446365528969 MAE: 1.4544191
Validation loss: 3.17948073717817 MAE: 1.4212637
Validation loss: 3.2968062521824284 MAE: 1.4347284
Validation loss: 3.427785723652672 MAE: 1.4542958
Validation loss: 3.0452532528632847 MAE: 1.4145713
Validation loss: 2.9762143831157206 MAE: 1.4248308
64 2 3.7265594005584717
Validation loss: 3.0027976886710928 MAE: 1.4188573
Validation loss: 2.8726729094682626 MAE: 1.3616086
Validation loss: 2.8781372063124 MAE: 1.3795894
Validation loss: 2.936476040126091 MAE: 1.4033154
Validation loss: 3.256370706174841 MAE: 1.4986112
Validation loss: 2.9248238682147845 MAE: 1.4086709
Validation loss: 2.8827689616524395 MAE: 1.3868504
71 3 3.993483543395996
Validation loss: 3.016952602707561 MAE: 1.4109834
Validation loss: 3.464417007101241 MAE: 1.450306
Validation loss: 2.947778422628815 MAE: 1.4142692
Validation loss: 3.8790223059342734 MAE: 1.5198023
Validation loss: 5.4597912936953445 MAE: 1.8507428
Validation loss: 3.70630973787164 MAE: 1.4841272
Validation loss: 2.945634042797376 MAE: 1.3380669
78 4 4.372361183166504
Validation loss: 2.9268431052490693 MAE: 1.3362573
Validation loss: 2.907183869999258 MAE: 1.3499558
Validation loss: 2.6857609041971178 MAE: 1.3057475
Validation loss: 2.9817506104857476 MAE: 1.3617159
Validation loss: 5.67369834621947 MAE: 1.9062943
Validation loss: 3.6036576422015627 MAE: 1.458862
Validation loss: 3.1042564966570794 MAE: 1.3869876
85 5 3.294189453125
Validation loss: 2.9256530215392758 MAE: 1.3621341
Validation loss: 2.6981853105914055 MAE: 1.2846847
Validation loss: 2.657991372161175 MAE: 1.3029842
Validation loss: 3.250704827395516 MAE: 1.4731781
Validation loss: 2.7084622179443514 MAE: 1.3299496
Validation loss: 2.808533867399896 MAE: 1.3249264
Validation loss: 3.0725558091647662 MAE: 1.3445337
92 6 1.6449602842330933
Validation loss: 2.8733517105255895 MAE: 1.3436369
Validation loss: 2.5572004270313973 MAE: 1.2657517
Validation loss: 2.7379585935841853 MAE: 1.2969377
Validation loss: 2.6493726908861093 MAE: 1.2760979
Validation loss: 2.5289527830766074 MAE: 1.2774591
Validation loss: 2.6399479679126836 MAE: 1.3174772
Validation loss: 2.6351625854945064 MAE: 1.3041253
Validation loss: 2.725187357945658 MAE: 1.2931378
Loaded trained model with success.
Test loss: 5.127511744509826 Test MAE: 1.8239585
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'regression', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
0 0 29.612258911132812
Validation loss: 20.792293552406328 MAE: 4.005328
Validation loss: 5.547769094516854 MAE: 1.9782479
Validation loss: 5.5729702345593894 MAE: 1.9873595
3 2 4.468319416046143
Validation loss: 5.480604817728719 MAE: 1.9608655
Validation loss: 5.489904967959753 MAE: 1.9478197
Validation loss: 5.452621963554489 MAE: 1.9595591
6 4 6.355268955230713
Validation loss: 5.525656108626861 MAE: 1.9494206
Validation loss: 5.473462698215951 MAE: 1.9222302
Validation loss: 5.008318687966448 MAE: 1.8561062
9 6 4.348306179046631
Validation loss: 5.067224683169134 MAE: 1.8354943
Validation loss: 6.8491850109520795 MAE: 2.0859554
Validation loss: 7.685900338427098 MAE: 2.2215054
12 8 4.88441801071167
Validation loss: 5.247482046574533 MAE: 1.8504013
Validation loss: 5.522175980952078 MAE: 1.8778548
Validation loss: 4.279233774823512 MAE: 1.6776584
15 10 3.552372694015503
Validation loss: 6.2067512328734615 MAE: 1.9922312
Validation loss: 5.485621761941241 MAE: 1.8814912
Validation loss: 4.602171300647254 MAE: 1.7112249
18 12 4.774137020111084
Validation loss: 4.356608917335709 MAE: 1.6838944
Validation loss: 5.042208195688252 MAE: 1.803831
Validation loss: 5.583166972907607 MAE: 1.887099
21 14 3.803697109222412
Validation loss: 4.56033863381059 MAE: 1.7077786
Validation loss: 4.689770348803075 MAE: 1.7328191
Validation loss: 5.36742685696405 MAE: 1.8326054
Validation loss: 6.1064857337661165 MAE: 1.9908445
25 0 3.906012773513794
Validation loss: 6.016094512595442 MAE: 1.9662516
Validation loss: 9.14637285435128 MAE: 2.5496626
Validation loss: 7.269264725740544 MAE: 2.1958184
28 2 3.4783883094787598
Validation loss: 6.257928522411951 MAE: 2.0229933
Validation loss: 3.662442315317586 MAE: 1.5323877
Validation loss: 4.705236737857123 MAE: 1.727587
31 4 4.258876800537109
Validation loss: 3.90535756390176 MAE: 1.5739425
Validation loss: 3.4466213754757136 MAE: 1.4796679
Validation loss: 3.736272320718708 MAE: 1.5250871
34 6 3.1310954093933105
Validation loss: 4.228649215851136 MAE: 1.6078938
Validation loss: 5.165375147649425 MAE: 1.8236475
Validation loss: 5.845475019099478 MAE: 1.920623
37 8 4.139499187469482
Validation loss: 4.532022876108815 MAE: 1.6810288
Validation loss: 3.8022004330086565 MAE: 1.5393991
Validation loss: 5.91341333733293 MAE: 1.9709233
40 10 3.1428442001342773
Validation loss: 3.9175057389693175 MAE: 1.5742127
Validation loss: 3.9279237863773813 MAE: 1.543421
Validation loss: 3.5956909431962067 MAE: 1.4834921
43 12 3.428093194961548
Validation loss: 4.650507269975895 MAE: 1.687076
Validation loss: 4.9590779296859715 MAE: 1.7580993
Validation loss: 4.873020540019553 MAE: 1.7503802
46 14 5.209270000457764
Validation loss: 3.5942409310885566 MAE: 1.490575
Validation loss: 3.7893684220935158 MAE: 1.5263121
Validation loss: 3.8863206807979362 MAE: 1.5596575
Validation loss: 3.9715289878462983 MAE: 1.5734093
50 0 2.7869694232940674
Validation loss: 3.1668263246157844 MAE: 1.4271826
Validation loss: 3.976065568790168 MAE: 1.563331
Validation loss: 3.1962786671632757 MAE: 1.4186184
53 2 3.19305157661438
Validation loss: 3.2929761404981592 MAE: 1.4210349
Validation loss: 3.3066236495016095 MAE: 1.4312048
Validation loss: 3.002294265674446 MAE: 1.3846031
56 4 2.005601644515991
Validation loss: 3.241711331751638 MAE: 1.413098
Validation loss: 4.2835591694635 MAE: 1.6428488
Validation loss: 2.983729619540289 MAE: 1.3874438
59 6 2.948706865310669
Validation loss: 3.330343938303854 MAE: 1.4292117
Validation loss: 2.9999497400257056 MAE: 1.3753666
Validation loss: 3.0551658383830036 MAE: 1.387321
62 8 2.320997476577759
Validation loss: 3.157210506513745 MAE: 1.3972056
Validation loss: 4.163356792950678 MAE: 1.6358368
Validation loss: 3.058541339002774 MAE: 1.3703772
65 10 3.361074447631836
Validation loss: 3.343700435214148 MAE: 1.4360768
Validation loss: 3.1302232727975787 MAE: 1.4008086
Validation loss: 3.0027340466608266 MAE: 1.4057987
68 12 3.1685261726379395
Validation loss: 2.977051954231186 MAE: 1.3748974
Validation loss: 3.058699290594739 MAE: 1.3789523
Validation loss: 2.9503158801543212 MAE: 1.4030766
71 14 3.4363551139831543
Validation loss: 3.244749675532859 MAE: 1.4358517
Validation loss: 3.0046769712635415 MAE: 1.3920337
Validation loss: 3.108648047418537 MAE: 1.4031525
Validation loss: 3.033610155204972 MAE: 1.3861234
75 0 5.046360492706299
Validation loss: 2.905768755681529 MAE: 1.3605461
Validation loss: 3.2599382715855905 MAE: 1.4196055
Validation loss: 2.9580108727625234 MAE: 1.3602316
78 2 3.7126333713531494
Validation loss: 3.095808221247488 MAE: 1.392869
Validation loss: 3.5919861291835686 MAE: 1.4835477
Validation loss: 2.9904764009143165 MAE: 1.3532172
81 4 3.3736231327056885
Validation loss: 2.953463568238314 MAE: 1.3645552
Validation loss: 2.8736582934736967 MAE: 1.3444717
Validation loss: 2.8496844142615676 MAE: 1.3355252
84 6 2.1090471744537354
Validation loss: 2.8927701905160723 MAE: 1.3454465
Validation loss: 3.0491480578879315 MAE: 1.3694896
Validation loss: 2.8661157019391568 MAE: 1.3517259
87 8 2.434736728668213
Validation loss: 2.778926576067785 MAE: 1.3247824
Validation loss: 2.8555309452370317 MAE: 1.3402178
Validation loss: 2.8729558810442386 MAE: 1.337778
90 10 3.001321315765381
Validation loss: 3.0333217179369116 MAE: 1.3825698
Validation loss: 2.9220844839283364 MAE: 1.3560219
Validation loss: 2.905338644742488 MAE: 1.3333142
93 12 4.074770927429199
Validation loss: 2.8588791309234374 MAE: 1.3391974
Validation loss: 2.8040362579789093 MAE: 1.3094877
Validation loss: 2.727518477277431 MAE: 1.2975663
96 14 2.810758590698242
Validation loss: 2.8640328810544675 MAE: 1.3417186
Validation loss: 2.828654502818962 MAE: 1.3255725
Validation loss: 3.027323029084292 MAE: 1.3692471
Validation loss: 2.851617280371442 MAE: 1.330453
Loaded trained model with success.
Test loss: 4.643008313450127 Test MAE: 1.7248449
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9908925318761385, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 1088
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9544626593806922, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 1048
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9089253187613844, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 998
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8178506375227687, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 898
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'opv_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5446265938069217, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/opv/opv.csv', 'regression_bin_classes': 5}}
Running on: cpu
1097
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 598
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999848297979177, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 659177
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9999241489895887, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 49, Valid size: 49, Test size: 659137
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9998482979791774, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 99, Valid size: 99, Test size: 659087
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9996965959583548, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 199, Valid size: 199, Test size: 658987
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9992414898958869, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 499, Valid size: 499, Test size: 658687
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qmug_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9984829797917738, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/qmug/qmug.csv', 'regression_bin_classes': 5}}
Running on: cpu
659186
No validation set, using training set for validation
Train size: 999, Valid size: 999, Test size: 658187
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9751861042183623, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 9, Valid size: 9, Test size: 380
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.9503722084367245, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 19, Valid size: 19, Test size: 370
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.8759305210918115, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 48, Valid size: 48, Test size: 341
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.7518610421836228, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 96, Valid size: 96, Test size: 293
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
{'batch_size': 32, 'epochs': 100, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'photoswitch_2', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0.3, 'pool': 'mean', 'output_dim': 1}, 'dataset': {'num_workers': 4, 'valid_size': 0, 'test_size': 0.5037220843672456, 'splitting': 'stratified', 'task': 'classification', 'data_path': 'data/photoswitch/photoswitch.csv', 'regression_bin_classes': 5}}
Running on: cpu
389
No validation set, using training set for validation
Train size: 193, Valid size: 193, Test size: 196
Model has 2207589 parameters
Loaded pre-trained model with success.
pred_head.0.weight True
pred_head.0.bias True
pred_head.2.weight True
pred_head.2.bias True
pred_head.4.weight True
pred_head.4.bias True
Target 1 is out of bounds.
